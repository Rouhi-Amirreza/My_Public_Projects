{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/researchfiles/ECE IMAPLE/cluster_data/user_data/jw3897/research/git/zero-shot-object-detection/frontend_owlvit/owlv2_coco_base\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/researchfiles/ECE IMAPLE/cluster_data/user_data/jw3897/research/git/zero-shot-object-detection/frontend_owlvit/owlv2_coco_base'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ~/user_data/research/git/zero-shot-object-detection/frontend_owlvit/owlv2_coco_base\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DREXEL/jw3897/miniconda3/envs/owlvit/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x708aa409b9f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import CocoDetection\n",
    "from PIL import ImageDraw\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.39s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "val_image_dir = r'/mnt/active_storage/Joe/coco_set/val2017/images'\n",
    "novel_annotation_path = r'/mnt/active_storage/Joe/coco_set/val2017/annotations/ovd_ins_val2017_t.json'\n",
    "\n",
    "novel_coco_val_dataset = CocoDetection(\n",
    "    root=val_image_dir, \n",
    "    annFile=novel_annotation_path,\n",
    ")\n",
    "\n",
    "base_annotation_path = r'/mnt/active_storage/Joe/coco_set/val2017/annotations/ovd_ins_val2017_b.json'\n",
    "\n",
    "base_coco_val_dataset = CocoDetection(\n",
    "    root=val_image_dir, \n",
    "    annFile=base_annotation_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Images in COCO Base: 4533\n",
      "Num Images in COCO Novel: 2064\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num Images in COCO Base: {len(base_coco_val_dataset)}\")\n",
    "print(f\"Num Images in COCO Novel: {len(novel_coco_val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Shared Images: 1761\n"
     ]
    }
   ],
   "source": [
    "base_image_ids = []\n",
    "for item in base_coco_val_dataset:\n",
    "    base_image_ids.append(item[1][0]['image_id'])\n",
    "\n",
    "novel_image_ids = []\n",
    "for item in novel_coco_val_dataset:\n",
    "    novel_image_ids.append(item[1][0]['image_id'])\n",
    "\n",
    "shared_image_ids = list(set(base_image_ids).intersection(set(novel_image_ids)))\n",
    "shared_image_ids.sort()\n",
    "\n",
    "print(f\"Num Shared Images: {len(shared_image_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761\n"
     ]
    }
   ],
   "source": [
    "shared_coco_val_dataset = []\n",
    "for item in novel_coco_val_dataset:\n",
    "    metadata_idx = 1\n",
    "    image_id = item[metadata_idx][0]['image_id']\n",
    "    if image_id in shared_image_ids:\n",
    "        shared_coco_val_dataset.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['airplane', 'bus', 'cat', 'dog', 'cow', 'elephant', 'umbrella', \\\n",
    "    'tie', 'snowboard', 'skateboard', 'cup', 'knife', 'cake', 'couch', 'keyboard', \\\n",
    "    'sink', 'scissors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ids = novel_coco_val_dataset.coco.loadCats(novel_coco_val_dataset.coco.getCatIds())\n",
    "\n",
    "targets = []\n",
    "target_boxes = []\n",
    "target_labels = []\n",
    "\n",
    "for idx, image_tuple in enumerate(shared_coco_val_dataset):\n",
    "    image = image_tuple[0]\n",
    "    annotations = image_tuple[1]\n",
    "    \n",
    "    for annotation in annotations:\n",
    "        label_name = [category['name'] for category in category_ids if category['id'] == annotation['category_id']][0]\n",
    "\n",
    "        try:\n",
    "            label = category_names.index(label_name)\n",
    "        except ValueError as e:\n",
    "            # If the annotation is not part of the novel categories, skip it\n",
    "            continue\n",
    "\n",
    "        # xmin, ymin, width, height -> xmin, ymin, xmax, ymax\n",
    "        box = annotation['bbox']\n",
    "        bbox = []\n",
    "        bbox.append(int(round(box[0])))\n",
    "        bbox.append(int(round(box[1])))\n",
    "        bbox.append(int(round(box[0] + box[2])))\n",
    "        bbox.append(int(round(box[1] + box[3])))\n",
    "\n",
    "        target_boxes.append(bbox)\n",
    "        target_labels.append(label)\n",
    "\n",
    "    target_boxes = torch.tensor(target_boxes, dtype=torch.int)\n",
    "    target_labels = torch.tensor(target_labels, dtype=torch.int)\n",
    "\n",
    "    target_image_dict = {\n",
    "        'image_id': shared_image_ids[idx],\n",
    "        'boxes': target_boxes,\n",
    "        'labels': target_labels\n",
    "    }\n",
    "\n",
    "    targets.append(target_image_dict)\n",
    "\n",
    "    # Clear boxes and labels\n",
    "    target_boxes = []\n",
    "    target_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/researchfiles/ECE IMAPLE/cluster_data/user_data/jw3897/research/git/zero-shot-object-detection/frontend_owlvit/owlv2_coco_base'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_total = pd.read_parquet(r'/mnt/active_storage/Joe/owlvit_results/unknown_objects_updated_with_novel_labels_obj2_cls1_clipvitbase32.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>objectness_score</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55279</th>\n",
       "      <td>1503</td>\n",
       "      <td>knife</td>\n",
       "      <td>0.276153</td>\n",
       "      <td>0.369445</td>\n",
       "      <td>96.540100</td>\n",
       "      <td>103.998489</td>\n",
       "      <td>120.847557</td>\n",
       "      <td>161.302979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55594</th>\n",
       "      <td>1503</td>\n",
       "      <td>sink</td>\n",
       "      <td>0.471443</td>\n",
       "      <td>0.245349</td>\n",
       "      <td>134.416107</td>\n",
       "      <td>111.131279</td>\n",
       "      <td>205.046005</td>\n",
       "      <td>159.928574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55938</th>\n",
       "      <td>1503</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>0.994812</td>\n",
       "      <td>0.269581</td>\n",
       "      <td>0.308208</td>\n",
       "      <td>130.165726</td>\n",
       "      <td>317.193298</td>\n",
       "      <td>240.838318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55196</th>\n",
       "      <td>1503</td>\n",
       "      <td>tie</td>\n",
       "      <td>0.375620</td>\n",
       "      <td>0.404980</td>\n",
       "      <td>279.463531</td>\n",
       "      <td>93.532410</td>\n",
       "      <td>320.128601</td>\n",
       "      <td>152.998123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54411</th>\n",
       "      <td>1503</td>\n",
       "      <td>knife</td>\n",
       "      <td>0.464695</td>\n",
       "      <td>0.263020</td>\n",
       "      <td>268.243256</td>\n",
       "      <td>6.110020</td>\n",
       "      <td>295.819580</td>\n",
       "      <td>101.931030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167589</th>\n",
       "      <td>581357</td>\n",
       "      <td>tie</td>\n",
       "      <td>0.367143</td>\n",
       "      <td>0.234230</td>\n",
       "      <td>25.962440</td>\n",
       "      <td>337.826660</td>\n",
       "      <td>107.538383</td>\n",
       "      <td>359.686493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168248</th>\n",
       "      <td>581357</td>\n",
       "      <td>tie</td>\n",
       "      <td>0.203935</td>\n",
       "      <td>0.646139</td>\n",
       "      <td>49.977936</td>\n",
       "      <td>327.986267</td>\n",
       "      <td>123.944717</td>\n",
       "      <td>518.138794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166413</th>\n",
       "      <td>581357</td>\n",
       "      <td>cake</td>\n",
       "      <td>0.324012</td>\n",
       "      <td>0.302958</td>\n",
       "      <td>316.926239</td>\n",
       "      <td>114.625443</td>\n",
       "      <td>362.680420</td>\n",
       "      <td>152.093796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167888</th>\n",
       "      <td>581357</td>\n",
       "      <td>umbrella</td>\n",
       "      <td>0.263183</td>\n",
       "      <td>0.206565</td>\n",
       "      <td>61.052029</td>\n",
       "      <td>328.466461</td>\n",
       "      <td>102.281570</td>\n",
       "      <td>410.364929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167550</th>\n",
       "      <td>581357</td>\n",
       "      <td>skateboard</td>\n",
       "      <td>0.897883</td>\n",
       "      <td>0.605037</td>\n",
       "      <td>226.836349</td>\n",
       "      <td>304.741791</td>\n",
       "      <td>375.815613</td>\n",
       "      <td>373.918335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13878 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_id       label     score  objectness_score        xmin  \\\n",
       "55279       1503       knife  0.276153          0.369445   96.540100   \n",
       "55594       1503        sink  0.471443          0.245349  134.416107   \n",
       "55938       1503    keyboard  0.994812          0.269581    0.308208   \n",
       "55196       1503         tie  0.375620          0.404980  279.463531   \n",
       "54411       1503       knife  0.464695          0.263020  268.243256   \n",
       "...          ...         ...       ...               ...         ...   \n",
       "167589    581357         tie  0.367143          0.234230   25.962440   \n",
       "168248    581357         tie  0.203935          0.646139   49.977936   \n",
       "166413    581357        cake  0.324012          0.302958  316.926239   \n",
       "167888    581357    umbrella  0.263183          0.206565   61.052029   \n",
       "167550    581357  skateboard  0.897883          0.605037  226.836349   \n",
       "\n",
       "              ymin        xmax        ymax  \n",
       "55279   103.998489  120.847557  161.302979  \n",
       "55594   111.131279  205.046005  159.928574  \n",
       "55938   130.165726  317.193298  240.838318  \n",
       "55196    93.532410  320.128601  152.998123  \n",
       "54411     6.110020  295.819580  101.931030  \n",
       "...            ...         ...         ...  \n",
       "167589  337.826660  107.538383  359.686493  \n",
       "168248  327.986267  123.944717  518.138794  \n",
       "166413  114.625443  362.680420  152.093796  \n",
       "167888  328.466461  102.281570  410.364929  \n",
       "167550  304.741791  375.815613  373.918335  \n",
       "\n",
       "[13878 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>objectness_score</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [image_id, label, score, objectness_score, xmin, ymin, xmax, ymax]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Confident Annotations: 13878\n",
      " Number of Confident Annotations Sizelimited: 13878\n",
      " Number of Unconfident Annotations: 0\n"
     ]
    }
   ],
   "source": [
    "objectness_threshold = 0.2\n",
    "score_threshold = 0.1\n",
    "min_dim = 0\n",
    "\n",
    "relevant_image_objects = predictions_df_total.loc[predictions_df_total['image_id'].isin(shared_image_ids)]\n",
    "\n",
    "confident_objects = relevant_image_objects[relevant_image_objects['score'] >= score_threshold]\n",
    "unconfident_objects = relevant_image_objects[relevant_image_objects['score'] < score_threshold]\n",
    "\n",
    "confident_objects_sizelimited = confident_objects[((confident_objects['xmax'] - confident_objects['xmin']) > min_dim) & ((confident_objects['ymax'] - confident_objects['ymin']) > min_dim)]\n",
    "\n",
    "print(f\"Number of Confident Annotations: {len(confident_objects)}\\n \\\n",
    "Number of Confident Annotations Sizelimited: {len(confident_objects_sizelimited)}\\n \\\n",
    "Number of Unconfident Annotations: {len(unconfident_objects)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = confident_objects_sizelimited.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "pred_boxes = []\n",
    "pred_scores = []\n",
    "pred_objectness_scores = []\n",
    "pred_labels = []\n",
    "\n",
    "current_img_id = predictions_dict[0]['image_id']\n",
    "for prediction in predictions_dict:\n",
    "    # If on a new image...\n",
    "    if prediction['image_id'] != current_img_id:\n",
    "        # Convert boxes, scores, and labels to tensors\n",
    "        pred_boxes = torch.tensor(pred_boxes, dtype=torch.int)\n",
    "        pred_scores = torch.tensor(pred_scores, dtype=torch.float)\n",
    "        pred_objectness_scores = torch.tensor(pred_objectness_scores, dtype=torch.float)\n",
    "        pred_labels = torch.tensor(pred_labels, dtype=torch.int)\n",
    "\n",
    "        # Create the dict for preds\n",
    "        pred_image_dict = {\n",
    "            'image_id': current_img_id,\n",
    "            'boxes': pred_boxes,\n",
    "            'scores': pred_scores,\n",
    "            'objectness_scores': pred_objectness_scores,\n",
    "            'labels': pred_labels\n",
    "        }\n",
    "\n",
    "        preds.append(pred_image_dict)\n",
    "\n",
    "        # Clear boxes, scores, and labels for the new image\n",
    "        pred_boxes = []\n",
    "        pred_scores = []\n",
    "        pred_objectness_scores = []\n",
    "        pred_labels = []\n",
    "\n",
    "        # Set new current image id\n",
    "        current_img_id = prediction['image_id']\n",
    "\n",
    "    bbox = []\n",
    "    bbox.append(prediction['xmin'])\n",
    "    bbox.append(prediction['ymin'])\n",
    "    bbox.append(prediction['xmax'])\n",
    "    bbox.append(prediction['ymax'])\n",
    "\n",
    "    pred_boxes.append(bbox)\n",
    "    pred_scores.append(prediction['score'])\n",
    "    pred_objectness_scores.append(prediction['objectness_score'])\n",
    "    pred_labels.append(category_names.index(prediction['label']))\n",
    "\n",
    "# Capture the predictions for the last image\n",
    "pred_boxes = torch.tensor(pred_boxes, dtype=torch.int)\n",
    "pred_scores = torch.tensor(pred_scores, dtype=torch.float)\n",
    "pred_objectness_scores = torch.tensor(pred_objectness_scores, dtype=torch.float)\n",
    "pred_labels = torch.tensor(pred_labels, dtype=torch.int)\n",
    "\n",
    "# Create the dict for preds\n",
    "pred_image_dict = {\n",
    "    'image_id': current_img_id,\n",
    "    'boxes': pred_boxes,\n",
    "    'scores': pred_scores,\n",
    "    'objectness_scores': pred_objectness_scores,\n",
    "    'labels': pred_labels\n",
    "}\n",
    "\n",
    "preds.append(pred_image_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_image_ids = np.unique([pred['image_id'] for pred in preds])\n",
    "missing_ids = list(set(shared_image_ids) - set(pred_image_ids))\n",
    "missing_ids.sort()\n",
    "\n",
    "for missing_id in missing_ids:\n",
    "    missing_id_dict = {\n",
    "        'image_id': missing_id,\n",
    "        'boxes': torch.tensor([], dtype=torch.int),\n",
    "        'scores': torch.tensor([], dtype=torch.float),\n",
    "        'objectness_scores': torch.tensor([], dtype=torch.float),\n",
    "        'labels': torch.tensor([], dtype=torch.int),\n",
    "    }\n",
    "    preds.insert(shared_image_ids.index(missing_id), missing_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 1503, 'boxes': tensor([[ 96, 103, 120, 161],\n",
      "        [134, 111, 205, 159],\n",
      "        [  0, 130, 317, 240],\n",
      "        [279,  93, 320, 152],\n",
      "        [268,   6, 295, 101],\n",
      "        [234, 131, 262, 157],\n",
      "        [126, 141, 158, 174],\n",
      "        [163, 152, 315, 198],\n",
      "        [  0, 170, 102, 215]], dtype=torch.int32), 'scores': tensor([0.2762, 0.4714, 0.9948, 0.3756, 0.4647, 0.2947, 0.3313, 0.4394, 0.9836]), 'objectness_scores': tensor([0.3694, 0.2453, 0.2696, 0.4050, 0.2630, 0.4282, 0.4866, 0.8350, 0.2088]), 'labels': tensor([11, 15, 14,  7, 11, 11, 15, 14, 14], dtype=torch.int32)}\n",
      "1503\n",
      "{'image_id': 1584, 'boxes': tensor([[504, 315, 568, 383],\n",
      "        [526, 316, 569, 384],\n",
      "        [126,  89, 521, 533],\n",
      "        [501, 317, 526, 383]], dtype=torch.int32), 'scores': tensor([0.9906, 0.9479, 0.9999, 0.2624]), 'objectness_scores': tensor([0.6540, 0.2014, 0.5937, 0.2578]), 'labels': tensor([ 1,  1,  1, 11], dtype=torch.int32)}\n",
      "1584\n",
      "{'image_id': 1761, 'boxes': tensor([[ 30, 432, 411, 618],\n",
      "        [280, 138, 334, 185],\n",
      "        [150,   8, 222,  85]], dtype=torch.int32), 'scores': tensor([0.2912, 0.3325, 0.9947]), 'objectness_scores': tensor([0.3636, 0.5626, 0.5712]), 'labels': tensor([16,  7,  0], dtype=torch.int32)}\n",
      "1761\n",
      "{'image_id': 2006, 'boxes': tensor([[ 56,   1,  69,  32],\n",
      "        [ 51,  79, 592, 422]], dtype=torch.int32), 'scores': tensor([0.1943, 0.9991]), 'objectness_scores': tensor([0.2605, 0.5249]), 'labels': tensor([14,  1], dtype=torch.int32)}\n",
      "2006\n",
      "{'image_id': 2299, 'boxes': tensor([[101, 226, 109, 242],\n",
      "        [228, 221, 238, 238],\n",
      "        [281,  54, 289,  61],\n",
      "        [174, 228, 182, 242],\n",
      "        [330,  58, 336,  72],\n",
      "        [230,  56, 237,  68],\n",
      "        [ 64, 116,  74, 122],\n",
      "        [161, 115, 172, 120],\n",
      "        [296, 117, 304, 126],\n",
      "        [186,  60, 192,  70],\n",
      "        [247,  99, 260, 109],\n",
      "        [459, 120, 467, 125],\n",
      "        [300, 155, 313, 196],\n",
      "        [  0,  14, 488, 298],\n",
      "        [409,  62, 415,  75],\n",
      "        [ 27, 125,  32, 133]], dtype=torch.int32), 'scores': tensor([0.2744, 0.1827, 0.1573, 0.1405, 0.2190, 0.1952, 0.4420, 0.1864, 0.1693,\n",
      "        0.1551, 0.1383, 0.1603, 0.2453, 0.8574, 0.2652, 0.6932]), 'objectness_scores': tensor([0.3847, 0.2167, 0.3095, 0.3428, 0.4630, 0.3258, 0.3090, 0.2769, 0.2286,\n",
      "        0.4010, 0.3117, 0.2581, 0.2303, 0.2510, 0.4273, 0.2194]), 'labels': tensor([10, 11, 14, 11, 11, 14, 11, 14, 11,  3, 11, 11, 11,  7,  7, 11],\n",
      "       dtype=torch.int32)}\n",
      "2299\n",
      "{'image_id': 2431, 'boxes': tensor([[  1, 268, 452, 637],\n",
      "        [254, 217, 382, 428],\n",
      "        [190, 216, 388, 638],\n",
      "        [  1, 111, 455, 636],\n",
      "        [188, 551, 371, 640],\n",
      "        [302,   1, 426, 208],\n",
      "        [302,  78, 457, 159],\n",
      "        [186, 397, 385, 639],\n",
      "        [357, 413, 454, 636]], dtype=torch.int32), 'scores': tensor([0.5143, 0.1471, 0.5865, 0.6461, 0.6722, 0.7015, 0.6723, 0.3432, 0.2896]), 'objectness_scores': tensor([0.3196, 0.2992, 0.2589, 0.3345, 0.2004, 0.5033, 0.3493, 0.2986, 0.3837]), 'labels': tensor([10, 11, 10, 10, 16, 10, 10,  7, 10], dtype=torch.int32)}\n",
      "2431\n",
      "{'image_id': 2685, 'boxes': tensor([[549, 174, 637, 365],\n",
      "        [556, 143, 585, 173],\n",
      "        [590, 133, 640, 192],\n",
      "        [414, 508, 445, 554],\n",
      "        [ 97, 186, 125, 223],\n",
      "        [160, 134, 217, 187],\n",
      "        [563, 158, 606, 200],\n",
      "        [368, 200, 386, 220],\n",
      "        [476, 461, 515, 497],\n",
      "        [ 89, 531, 111, 555]], dtype=torch.int32), 'scores': tensor([0.2949, 0.3115, 0.5871, 0.2965, 0.7493, 0.1332, 0.3044, 0.5910, 0.3777,\n",
      "        0.1577]), 'objectness_scores': tensor([0.3604, 0.2228, 0.3299, 0.2691, 0.2067, 0.2111, 0.2128, 0.2206, 0.2278,\n",
      "        0.2833]), 'labels': tensor([10, 12, 10, 11,  7,  3, 12, 11,  7, 11], dtype=torch.int32)}\n",
      "2685\n",
      "{'image_id': 3156, 'boxes': tensor([[318, 355, 369, 375],\n",
      "        [  1, 376, 305, 615],\n",
      "        [ 12, 487,  80, 620],\n",
      "        [  0, 157,  60, 235],\n",
      "        [280, 398, 360, 489]], dtype=torch.int32), 'scores': tensor([0.4311, 0.3625, 0.2310, 0.3823, 0.3313]), 'objectness_scores': tensor([0.2348, 0.2329, 0.2016, 0.4301, 0.3330]), 'labels': tensor([11,  8,  7, 11, 11], dtype=torch.int32)}\n",
      "3156\n",
      "{'image_id': 3553, 'boxes': tensor([[181, 271, 367, 367],\n",
      "        [340, 224, 420, 291],\n",
      "        [158, 177, 403, 290]], dtype=torch.int32), 'scores': tensor([0.2660, 0.5792, 0.8183]), 'objectness_scores': tensor([0.5751, 0.3256, 0.3376]), 'labels': tensor([14,  9,  9], dtype=torch.int32)}\n",
      "3553\n",
      "{'image_id': 3661, 'boxes': tensor([[  3, 249, 635, 384],\n",
      "        [564,  17, 641, 243],\n",
      "        [588, 178, 639, 244]], dtype=torch.int32), 'scores': tensor([0.2958, 0.4250, 0.4407]), 'objectness_scores': tensor([0.4511, 0.3723, 0.2101]), 'labels': tensor([11, 11, 11], dtype=torch.int32)}\n",
      "3661\n",
      "{'image_id': 3845, 'boxes': tensor([[ 45,  65, 407, 328],\n",
      "        [173, 244, 222, 292],\n",
      "        [ 77, 260, 139, 291],\n",
      "        [284, 183, 404, 242],\n",
      "        [272, 229, 345, 324],\n",
      "        [ 72, 125, 116, 176],\n",
      "        [218,  63, 403, 208],\n",
      "        [136, 270, 179, 304],\n",
      "        [108,   0, 185,  54],\n",
      "        [199,  79, 234, 145],\n",
      "        [  5,  42, 489, 358],\n",
      "        [ 53, 229,  80, 258],\n",
      "        [101, 113, 189, 179],\n",
      "        [ 58, 178, 123, 264],\n",
      "        [197,  62, 236, 144],\n",
      "        [ 42, 115,  90, 175],\n",
      "        [239, 269, 291, 311],\n",
      "        [  2,   1, 495, 377],\n",
      "        [ 78,  97, 115, 127]], dtype=torch.int32), 'scores': tensor([0.3930, 0.3341, 0.4578, 0.3040, 0.5484, 0.1876, 0.3699, 0.1819, 0.9651,\n",
      "        0.2563, 0.4084, 0.3643, 0.4983, 0.2870, 0.4914, 0.3819, 0.2791, 0.4589,\n",
      "        0.4430]), 'objectness_scores': tensor([0.2612, 0.2069, 0.2193, 0.2749, 0.2614, 0.2341, 0.6112, 0.2199, 0.5307,\n",
      "        0.2355, 0.3886, 0.2072, 0.2262, 0.3053, 0.2560, 0.2558, 0.2423, 0.3757,\n",
      "        0.2252]), 'labels': tensor([11, 11, 12, 11, 12, 12, 11, 11, 10, 12, 11, 11, 12, 11, 11, 12, 12, 11,\n",
      "        11], dtype=torch.int32)}\n",
      "3845\n",
      "{'image_id': 3934, 'boxes': tensor([[136, 298, 248, 402],\n",
      "        [ 73, 130, 101, 189],\n",
      "        [241, 258, 343, 291],\n",
      "        [148, 247, 265, 296],\n",
      "        [ 31,  73,  91, 282],\n",
      "        [ 57, 396, 373, 500],\n",
      "        [135, 222, 374, 364],\n",
      "        [110, 115, 132, 146],\n",
      "        [246, 216, 309, 263],\n",
      "        [306, 224, 373, 282]], dtype=torch.int32), 'scores': tensor([0.3492, 0.6330, 0.3243, 0.2120, 0.1583, 0.8433, 0.9451, 0.9073, 0.1334,\n",
      "        0.9378]), 'objectness_scores': tensor([0.2836, 0.2068, 0.2598, 0.2382, 0.2457, 0.2383, 0.4481, 0.2106, 0.2978,\n",
      "        0.2902]), 'labels': tensor([ 9,  7, 13, 11, 10, 13, 13,  7,  7, 13], dtype=torch.int32)}\n",
      "3934\n",
      "{'image_id': 4134, 'boxes': tensor([[321, 145, 331, 168],\n",
      "        [  0, 281,  26, 301],\n",
      "        [  0, 263,  52, 377],\n",
      "        [396, 190, 432, 361],\n",
      "        [  2, 260, 312, 414],\n",
      "        [233, 266, 278, 277],\n",
      "        [366, 103, 447, 119],\n",
      "        [227, 205, 286, 256],\n",
      "        [  6, 297,  48, 312],\n",
      "        [522, 150, 526, 170],\n",
      "        [263, 151, 571, 425],\n",
      "        [240, 196, 250, 216],\n",
      "        [222, 245, 240, 286],\n",
      "        [267, 277, 294, 292],\n",
      "        [ 25, 147,  36, 213],\n",
      "        [ 15, 263,  51, 274],\n",
      "        [ 21, 246,  36, 279],\n",
      "        [ 32, 255,  54, 268]], dtype=torch.int32), 'scores': tensor([0.3083, 0.2252, 0.2980, 0.7776, 0.8325, 0.2572, 0.8257, 0.3497, 0.2872,\n",
      "        0.1461, 0.9873, 0.1993, 0.2589, 0.3760, 0.3518, 0.2838, 0.5039, 0.3408]), 'objectness_scores': tensor([0.2526, 0.2441, 0.2147, 0.3826, 0.2252, 0.2056, 0.3366, 0.2345, 0.2918,\n",
      "        0.4095, 0.2174, 0.2485, 0.2591, 0.2362, 0.3402, 0.2373, 0.2964, 0.2355]), 'labels': tensor([11, 11, 12,  7,  7, 11, 11,  7, 11, 14,  7, 11, 11, 11, 11, 11,  3, 11],\n",
      "       dtype=torch.int32)}\n",
      "4134\n",
      "{'image_id': 4395, 'boxes': tensor([[  0, 197, 414, 641],\n",
      "        [175, 273, 275, 640]], dtype=torch.int32), 'scores': tensor([0.3681, 0.9998]), 'objectness_scores': tensor([0.2895, 0.5734]), 'labels': tensor([8, 7], dtype=torch.int32)}\n",
      "4395\n",
      "{'image_id': 4495, 'boxes': tensor([[164, 201, 184, 240],\n",
      "        [144,  24, 207, 107],\n",
      "        [178, 168, 278, 242],\n",
      "        [263, 205, 292, 229],\n",
      "        [  0,  20, 102, 168],\n",
      "        [199, 198, 497, 375]], dtype=torch.int32), 'scores': tensor([0.2415, 0.4501, 0.2644, 0.3246, 0.1330, 0.9989]), 'objectness_scores': tensor([0.3274, 0.2911, 0.3781, 0.3882, 0.5461, 0.5807]), 'labels': tensor([11,  7,  7, 11,  9, 13], dtype=torch.int32)}\n",
      "4495\n",
      "{'image_id': 4795, 'boxes': tensor([[  0, 369, 179, 478],\n",
      "        [156, 115, 550, 472]], dtype=torch.int32), 'scores': tensor([0.9814, 0.9431]), 'objectness_scores': tensor([0.3082, 0.4778]), 'labels': tensor([14,  2], dtype=torch.int32)}\n",
      "4795\n",
      "{'image_id': 5001, 'boxes': tensor([[464,  60, 489,  74],\n",
      "        [571, 152, 593, 181],\n",
      "        [ 90, 225, 157, 260],\n",
      "        [ 48,  52,  84,  83],\n",
      "        [479, 298, 504, 314],\n",
      "        [172,  32, 219,  65],\n",
      "        [308, 132, 380, 232],\n",
      "        [285, 256, 336, 320]], dtype=torch.int32), 'scores': tensor([0.2542, 0.3550, 0.3071, 0.1340, 0.3171, 0.3313, 0.5611, 0.2899]), 'objectness_scores': tensor([0.2007, 0.4028, 0.2836, 0.2334, 0.4452, 0.2099, 0.5206, 0.2255]), 'labels': tensor([11, 11,  8, 11,  1, 10, 10,  9], dtype=torch.int32)}\n",
      "5001\n",
      "{'image_id': 5037, 'boxes': tensor([[101,  21, 544, 372],\n",
      "        [192,  49, 281,  79],\n",
      "        [200,  82, 341, 110]], dtype=torch.int32), 'scores': tensor([0.3813, 0.4535, 0.4789]), 'objectness_scores': tensor([0.5711, 0.2096, 0.2083]), 'labels': tensor([11, 14, 11], dtype=torch.int32)}\n",
      "5037\n",
      "{'image_id': 6723, 'boxes': tensor([[ 70, 206,  80, 225],\n",
      "        [100,  91, 130, 222]], dtype=torch.int32), 'scores': tensor([0.1761, 0.1620]), 'objectness_scores': tensor([0.2542, 0.2037]), 'labels': tensor([14,  7], dtype=torch.int32)}\n",
      "6723\n",
      "{'image_id': 6763, 'boxes': tensor([[334, 196, 363, 242],\n",
      "        [  0, 118,  25, 160],\n",
      "        [ 36, 165,  65, 205],\n",
      "        [ 80, 127, 128, 201],\n",
      "        [134, 234, 180, 420],\n",
      "        [ 47, 228,  56, 237],\n",
      "        [  0, 165,  25, 204],\n",
      "        [198, 258, 304, 473],\n",
      "        [290,   0, 374,  39],\n",
      "        [ 37, 121,  66, 161],\n",
      "        [122, 148, 201, 173],\n",
      "        [106, 443, 112, 451]], dtype=torch.int32), 'scores': tensor([0.2641, 0.2950, 0.3784, 0.3494, 0.3642, 0.2450, 0.1650, 0.6863, 0.1795,\n",
      "        0.3170, 0.3641, 0.1709]), 'objectness_scores': tensor([0.2963, 0.2820, 0.3088, 0.2956, 0.4223, 0.2812, 0.2839, 0.3544, 0.2743,\n",
      "        0.3027, 0.2922, 0.3912]), 'labels': tensor([ 7, 11, 11,  8,  7, 11, 14,  7, 11,  8, 11, 11], dtype=torch.int32)}\n",
      "6763\n",
      "{'image_id': 6894, 'boxes': tensor([[209, 129, 638, 293],\n",
      "        [202, 129, 428, 233],\n",
      "        [427, 206, 549, 279],\n",
      "        [  3,  88, 636, 478],\n",
      "        [205, 128, 640, 474]], dtype=torch.int32), 'scores': tensor([0.6604, 0.7834, 0.5893, 0.9983, 0.9922]), 'objectness_scores': tensor([0.2603, 0.2187, 0.2224, 0.4604, 0.3422]), 'labels': tensor([5, 5, 7, 5, 5], dtype=torch.int32)}\n",
      "6894\n",
      "{'image_id': 7088, 'boxes': tensor([[228, 441, 252, 461],\n",
      "        [201, 432, 230, 450],\n",
      "        [179, 235, 273, 367],\n",
      "        [ 83, 175, 306, 342]], dtype=torch.int32), 'scores': tensor([0.1955, 0.3645, 0.3124, 0.9848]), 'objectness_scores': tensor([0.2484, 0.2120, 0.2891, 0.5961]), 'labels': tensor([8, 8, 6, 6], dtype=torch.int32)}\n",
      "7088\n",
      "{'image_id': 7386, 'boxes': tensor([[179, 280, 218, 323],\n",
      "        [361, 215, 442, 321],\n",
      "        [368,  14, 415,  67]], dtype=torch.int32), 'scores': tensor([0.9763, 0.1887, 0.2020]), 'objectness_scores': tensor([0.4891, 0.2095, 0.3037]), 'labels': tensor([3, 7, 8], dtype=torch.int32)}\n",
      "7386\n",
      "{'image_id': 7574, 'boxes': tensor([[ 42, 357, 301, 432],\n",
      "        [215, 239, 227, 259],\n",
      "        [ 42, 367, 171, 431],\n",
      "        [360, 286, 386, 365],\n",
      "        [452, 306, 472, 374],\n",
      "        [101,  88, 203, 216],\n",
      "        [325, 385, 427, 428],\n",
      "        [201,  92, 285, 214],\n",
      "        [142, 414, 210, 451],\n",
      "        [440, 303, 466, 345],\n",
      "        [  0,  84, 102, 152],\n",
      "        [297, 298, 344, 386],\n",
      "        [183, 356, 295, 410],\n",
      "        [362,   5, 546, 258],\n",
      "        [408, 388, 451, 396],\n",
      "        [103, 294, 259, 366],\n",
      "        [ 24,  86, 102, 152],\n",
      "        [297,  56, 365, 222],\n",
      "        [302,  64, 364, 146],\n",
      "        [112, 332, 211, 415],\n",
      "        [464, 312, 485, 381],\n",
      "        [206, 272, 237, 289]], dtype=torch.int32), 'scores': tensor([0.2491, 0.2866, 0.7388, 0.4054, 0.5963, 0.2521, 0.9276, 0.1626, 0.4762,\n",
      "        0.1231, 0.5452, 0.3285, 0.4364, 0.1848, 0.5148, 0.2065, 0.2503, 0.5558,\n",
      "        0.1940, 0.4589, 0.5181, 0.2661]), 'objectness_scores': tensor([0.4465, 0.4634, 0.3495, 0.3325, 0.2432, 0.2798, 0.2152, 0.2306, 0.2028,\n",
      "        0.2089, 0.2244, 0.3725, 0.3298, 0.2826, 0.2790, 0.2083, 0.2160, 0.2224,\n",
      "        0.2718, 0.4872, 0.2931, 0.2110]), 'labels': tensor([15, 14, 15, 11,  7,  8, 12,  9, 14,  2, 14,  8, 15, 16, 11,  1,  8, 16,\n",
      "         6, 15,  7,  9], dtype=torch.int32)}\n",
      "7574\n",
      "{'image_id': 7818, 'boxes': tensor([[259,  83, 368, 302],\n",
      "        [464, 271, 587, 300],\n",
      "        [  0, 300, 133, 327],\n",
      "        [  4, 273, 639, 425],\n",
      "        [230, 267, 292, 283],\n",
      "        [399, 187, 444, 283],\n",
      "        [101, 347, 221, 371],\n",
      "        [211, 257, 286, 289],\n",
      "        [  0, 307, 146, 359],\n",
      "        [215, 257, 281, 273],\n",
      "        [  5, 272, 637, 395],\n",
      "        [ 15, 323, 142, 361]], dtype=torch.int32), 'scores': tensor([0.4477, 0.2974, 0.5991, 0.4443, 0.2868, 0.2613, 0.3428, 0.2416, 0.2755,\n",
      "        0.3117, 0.6224, 0.2977]), 'objectness_scores': tensor([0.4697, 0.4811, 0.2798, 0.4271, 0.2916, 0.5252, 0.2009, 0.2803, 0.2539,\n",
      "        0.3949, 0.2338, 0.2159]), 'labels': tensor([10, 11, 11, 10,  0, 11,  0, 14, 11, 11, 10, 11], dtype=torch.int32)}\n",
      "7818\n",
      "{'image_id': 7977, 'boxes': tensor([[228, 355, 260, 375],\n",
      "        [109, 164, 147, 193],\n",
      "        [190, 404, 230, 423],\n",
      "        [191, 345, 269, 424]], dtype=torch.int32), 'scores': tensor([0.6983, 0.1535, 0.2076, 0.9824]), 'objectness_scores': tensor([0.2038, 0.2996, 0.2065, 0.6975]), 'labels': tensor([ 9,  8, 11,  9], dtype=torch.int32)}\n",
      "7977\n",
      "{'image_id': 7991, 'boxes': tensor([[445, 272, 471, 293],\n",
      "        [469, 261, 491, 283],\n",
      "        [467, 251, 487, 265],\n",
      "        [456, 222, 487, 246],\n",
      "        [518, 244, 554, 287],\n",
      "        [431, 226, 457, 251],\n",
      "        [415, 221, 491, 307],\n",
      "        [428, 251, 454, 282],\n",
      "        [510, 136, 560, 186],\n",
      "        [413, 268, 427, 290],\n",
      "        [  2,  -2, 636, 361],\n",
      "        [420, 282, 448, 306],\n",
      "        [465, 233, 488, 251],\n",
      "        [525, 190, 581, 241],\n",
      "        [447, 244, 468, 273]], dtype=torch.int32), 'scores': tensor([0.2497, 0.2121, 0.3888, 0.2335, 0.1581, 0.3779, 0.2838, 0.1460, 0.1813,\n",
      "        0.9644, 0.4529, 0.2037, 0.3686, 0.2064, 0.1723]), 'objectness_scores': tensor([0.2818, 0.2968, 0.2264, 0.2220, 0.3568, 0.2369, 0.3110, 0.2801, 0.4401,\n",
      "        0.2632, 0.3224, 0.3012, 0.2885, 0.4444, 0.2614]), 'labels': tensor([11, 11, 11, 11, 11, 11, 12, 14, 12,  9, 12, 14, 11,  3,  7],\n",
      "       dtype=torch.int32)}\n",
      "7991\n",
      "{'image_id': 8021, 'boxes': tensor([[317, 198, 340, 305],\n",
      "        [300, 399, 328, 436]], dtype=torch.int32), 'scores': tensor([0.2182, 0.2262]), 'objectness_scores': tensor([0.2918, 0.2255]), 'labels': tensor([11,  8], dtype=torch.int32)}\n",
      "8021\n",
      "{'image_id': 8532, 'boxes': tensor([[335, 134, 525, 190],\n",
      "        [303,   9, 546, 180],\n",
      "        [420, 369, 493, 426]], dtype=torch.int32), 'scores': tensor([0.3434, 0.5639, 0.9663]), 'objectness_scores': tensor([0.4216, 0.3740, 0.4975]), 'labels': tensor([7, 7, 7], dtype=torch.int32)}\n",
      "8532\n",
      "{'image_id': 9400, 'boxes': tensor([[250, 379, 323, 479]], dtype=torch.int32), 'scores': tensor([0.2533]), 'objectness_scores': tensor([0.2404]), 'labels': tensor([10], dtype=torch.int32)}\n",
      "9400\n",
      "{'image_id': 9448, 'boxes': tensor([[  0,  -3, 546, 616],\n",
      "        [140, 202, 380, 554],\n",
      "        [  4,   2, 549, 629],\n",
      "        [  0,   3, 549, 384],\n",
      "        [192, 248, 306, 423]], dtype=torch.int32), 'scores': tensor([0.9988, 0.4437, 0.9984, 0.9966, 0.6756]), 'objectness_scores': tensor([0.2685, 0.3692, 0.3503, 0.2861, 0.2719]), 'labels': tensor([ 6,  7,  6,  6, 12], dtype=torch.int32)}\n",
      "9448\n",
      "{'image_id': 9483, 'boxes': tensor([[159, 297, 641, 479],\n",
      "        [  5, 269, 192, 413],\n",
      "        [205,  35, 572, 309],\n",
      "        [556, 423, 570, 439],\n",
      "        [  5, 272, 635, 481],\n",
      "        [304, 317, 420, 361],\n",
      "        [530, 420, 544, 441],\n",
      "        [109, 142, 131, 218],\n",
      "        [420, 323, 589, 412]], dtype=torch.int32), 'scores': tensor([0.8325, 0.6031, 0.3062, 0.1883, 0.2511, 0.9023, 0.6072, 0.3134, 0.4620]), 'objectness_scores': tensor([0.2072, 0.2419, 0.2800, 0.2106, 0.2843, 0.7635, 0.3798, 0.4907, 0.3582]), 'labels': tensor([14,  7,  8, 14,  7, 14, 11, 11, 14], dtype=torch.int32)}\n",
      "9483\n",
      "{'image_id': 9590, 'boxes': tensor([[252, 249, 275, 271],\n",
      "        [348, 269, 387, 310],\n",
      "        [175, 255, 637, 425],\n",
      "        [541, 215, 570, 238],\n",
      "        [465, 262, 495, 300],\n",
      "        [179, 280, 207, 309],\n",
      "        [579, 239, 614, 287]], dtype=torch.int32), 'scores': tensor([0.2527, 0.9880, 0.4873, 0.2305, 0.3320, 0.7320, 0.1422]), 'objectness_scores': tensor([0.2233, 0.2200, 0.2451, 0.2500, 0.2225, 0.2653, 0.2003]), 'labels': tensor([15, 10, 10, 10, 14, 10,  8], dtype=torch.int32)}\n",
      "9590\n",
      "{'image_id': 9772, 'boxes': tensor([[103, 368, 152, 383],\n",
      "        [447, 497, 491, 566],\n",
      "        [205, 563, 425, 636],\n",
      "        [402, 444, 451, 525],\n",
      "        [139, 407, 167, 444],\n",
      "        [  0, 486,  63, 542],\n",
      "        [ 97, 112, 430, 355],\n",
      "        [274, 368, 296, 381],\n",
      "        [337, 382, 408, 396],\n",
      "        [172, 379, 254, 394],\n",
      "        [212, 344, 227, 379],\n",
      "        [294, 239, 304, 249],\n",
      "        [412, 409, 438, 446],\n",
      "        [ 72, 193, 139, 295],\n",
      "        [351, 342, 366, 379],\n",
      "        [168, 302, 193, 337],\n",
      "        [131, 434, 170, 485]], dtype=torch.int32), 'scores': tensor([0.1557, 0.2593, 0.6251, 0.1970, 0.2423, 0.3585, 0.4326, 0.4502, 0.9612,\n",
      "        0.6376, 0.3013, 0.2273, 0.3291, 0.7161, 0.3821, 0.4722, 0.5734]), 'objectness_scores': tensor([0.2004, 0.4030, 0.2514, 0.3526, 0.2155, 0.3965, 0.2700, 0.2053, 0.4214,\n",
      "        0.4249, 0.4239, 0.3349, 0.2507, 0.2630, 0.3626, 0.2858, 0.3464]), 'labels': tensor([14,  8,  7,  7, 10,  8, 15, 11,  8,  7, 11, 11, 11,  9, 11,  7,  7],\n",
      "       dtype=torch.int32)}\n",
      "9772\n",
      "{'image_id': 9891, 'boxes': tensor([[501, 159, 563, 215],\n",
      "        [379,  81, 456, 100],\n",
      "        [ 31, 182, 207, 458]], dtype=torch.int32), 'scores': tensor([0.1335, 0.2402, 0.5211]), 'objectness_scores': tensor([0.3196, 0.2053, 0.4867]), 'labels': tensor([10,  6,  9], dtype=torch.int32)}\n",
      "9891\n",
      "{'image_id': 9914, 'boxes': tensor([[  3,  41, 153, 155],\n",
      "        [  6, 190, 174, 334],\n",
      "        [  2,   3, 634, 479],\n",
      "        [178,   2, 561, 335],\n",
      "        [135,   0, 227,  25]], dtype=torch.int32), 'scores': tensor([0.4115, 0.5112, 0.2828, 0.2888, 0.2078]), 'objectness_scores': tensor([0.4417, 0.2644, 0.3632, 0.3909, 0.2375]), 'labels': tensor([12, 12,  4,  4, 11], dtype=torch.int32)}\n",
      "9914\n",
      "{'image_id': 10363, 'boxes': tensor([[ 64,   3, 147,  67],\n",
      "        [251, 106, 464, 244],\n",
      "        [235,  15, 382,  30],\n",
      "        [  1,   0,  82, 228],\n",
      "        [236,  22, 318,  72],\n",
      "        [  9, 118,  49, 260]], dtype=torch.int32), 'scores': tensor([0.6143, 0.3848, 0.2866, 0.3633, 0.5745, 0.4397]), 'objectness_scores': tensor([0.2133, 0.4834, 0.2340, 0.2282, 0.2469, 0.2453]), 'labels': tensor([ 6, 11, 11,  9, 14, 11], dtype=torch.int32)}\n",
      "10363\n",
      "{'image_id': 10583, 'boxes': tensor([[  3, 157, 609, 611],\n",
      "        [ 10,   0,  78,  31],\n",
      "        [228, 116, 279, 171],\n",
      "        [270, 119, 437, 214],\n",
      "        [269, 398, 415, 468],\n",
      "        [  2,   5, 606, 610],\n",
      "        [104, 386, 295, 508],\n",
      "        [258, 338, 392, 408],\n",
      "        [  0,   0, 235,  68],\n",
      "        [172, 109, 430, 211]], dtype=torch.int32), 'scores': tensor([0.5684, 0.2497, 0.3509, 0.9284, 0.9686, 0.3695, 0.4777, 0.9481, 0.4473,\n",
      "        0.4826]), 'objectness_scores': tensor([0.4155, 0.2154, 0.2338, 0.2132, 0.2215, 0.2322, 0.2357, 0.2061, 0.3816,\n",
      "        0.2651]), 'labels': tensor([12, 11, 11, 12, 12, 12, 12, 12, 11, 11], dtype=torch.int32)}\n",
      "10583\n",
      "{'image_id': 10707, 'boxes': tensor([[181, 378, 206, 431],\n",
      "        [103, 359, 308, 479],\n",
      "        [121, 359, 149, 422],\n",
      "        [145, 380, 169, 432],\n",
      "        [316, 211, 639, 479],\n",
      "        [232, 335, 251, 370],\n",
      "        [  1, 199, 228, 430],\n",
      "        [151, 368, 175, 417]], dtype=torch.int32), 'scores': tensor([0.4068, 0.2579, 0.2387, 0.6883, 0.3507, 0.4369, 0.9885, 0.6700]), 'objectness_scores': tensor([0.3690, 0.2028, 0.2879, 0.3430, 0.2583, 0.3885, 0.3652, 0.3980]), 'labels': tensor([10, 13, 10, 10,  7, 11, 13,  7], dtype=torch.int32)}\n",
      "10707\n",
      "{'image_id': 10977, 'boxes': tensor([[295, 236, 414, 345],\n",
      "        [387,  32, 425, 183],\n",
      "        [ 73, 207, 113, 225],\n",
      "        [341, 218, 419, 253],\n",
      "        [228, 125, 234, 140],\n",
      "        [221, 125, 227, 140],\n",
      "        [ 11, 234, 108, 345],\n",
      "        [109, 322, 211, 345],\n",
      "        [261,  30, 320, 257],\n",
      "        [396, 191, 405, 212],\n",
      "        [104, 223, 268, 329]], dtype=torch.int32), 'scores': tensor([0.6304, 0.3267, 0.4542, 0.8141, 0.2175, 0.2013, 0.2855, 0.2607, 0.2833,\n",
      "        0.1830, 0.7854]), 'objectness_scores': tensor([0.2889, 0.4511, 0.4349, 0.5168, 0.2287, 0.2783, 0.3771, 0.2708, 0.3914,\n",
      "        0.2462, 0.6132]), 'labels': tensor([15, 11, 11, 15,  0, 11, 11,  4,  7, 11, 15], dtype=torch.int32)}\n",
      "10977\n",
      "{'image_id': 11051, 'boxes': tensor([[195, 198, 253, 417],\n",
      "        [344, 220, 353, 229],\n",
      "        [277, 241, 286, 250],\n",
      "        [  5, 169, 397, 535],\n",
      "        [428, 263, 634, 534],\n",
      "        [495, 236, 575, 308],\n",
      "        [331, 284, 361, 307],\n",
      "        [487, 191, 491, 197],\n",
      "        [255, 206, 299, 248]], dtype=torch.int32), 'scores': tensor([0.2448, 0.2310, 0.1833, 0.9618, 0.2764, 0.4730, 0.2905, 0.2479, 0.2934]), 'objectness_scores': tensor([0.4571, 0.2888, 0.2829, 0.3156, 0.3270, 0.5052, 0.3071, 0.2460, 0.3869]), 'labels': tensor([ 7, 11, 11,  7,  0,  7, 11, 11, 10], dtype=torch.int32)}\n",
      "11051\n",
      "{'image_id': 12576, 'boxes': tensor([[381, 111, 424, 173],\n",
      "        [299, 281, 480, 337],\n",
      "        [344, 103, 379, 170],\n",
      "        [418, 368, 465, 419],\n",
      "        [271, 117, 312, 199],\n",
      "        [380, 405, 477, 582],\n",
      "        [365, 211, 456, 375],\n",
      "        [141, 202, 218, 345],\n",
      "        [  4, 149, 479, 633]], dtype=torch.int32), 'scores': tensor([0.6012, 0.7196, 0.3248, 0.4168, 0.5195, 0.5523, 0.8088, 0.5307, 0.6323]), 'objectness_scores': tensor([0.2931, 0.2566, 0.2831, 0.2073, 0.3771, 0.3158, 0.3885, 0.3935, 0.2013]), 'labels': tensor([10, 10,  7,  7, 10,  7, 10, 10, 11], dtype=torch.int32)}\n",
      "12576\n",
      "{'image_id': 13201, 'boxes': tensor([[109, 423, 177, 522],\n",
      "        [  2, 431, 421, 637],\n",
      "        [223, 306, 237, 322],\n",
      "        [129, 410, 180, 470],\n",
      "        [352, 573, 380, 594],\n",
      "        [107, 105, 122, 123],\n",
      "        [221, 194, 269, 240]], dtype=torch.int32), 'scores': tensor([0.9409, 0.9285, 0.2334, 0.8507, 0.5309, 0.4290, 0.2426]), 'objectness_scores': tensor([0.6394, 0.2087, 0.3814, 0.2040, 0.2917, 0.4467, 0.2933]), 'labels': tensor([ 9,  9, 16,  9, 14,  7,  7], dtype=torch.int32)}\n",
      "13201\n",
      "{'image_id': 13348, 'boxes': tensor([[ 72, 140, 135, 213],\n",
      "        [ -2, 137, 554, 290],\n",
      "        [268, 238, 343, 284],\n",
      "        [268, 194, 285, 203],\n",
      "        [ 75, 293,  80, 303],\n",
      "        [338, 281, 343, 292],\n",
      "        [  0, 222,  51, 243]], dtype=torch.int32), 'scores': tensor([0.7973, 0.9591, 0.3753, 0.1822, 0.2726, 0.2455, 0.9653]), 'objectness_scores': tensor([0.3529, 0.5135, 0.4246, 0.2570, 0.6464, 0.5348, 0.4635]), 'labels': tensor([ 0,  0,  0,  7, 11, 14,  0], dtype=torch.int32)}\n",
      "13348\n",
      "{'image_id': 13546, 'boxes': tensor([[447,   3, 455,  21]], dtype=torch.int32), 'scores': tensor([0.1867]), 'objectness_scores': tensor([0.2231]), 'labels': tensor([14], dtype=torch.int32)}\n",
      "13546\n",
      "{'image_id': 13659, 'boxes': tensor([[ 83, 158, 228, 268],\n",
      "        [137,  95, 186, 135],\n",
      "        [ 82,  90, 129, 131],\n",
      "        [254, 180, 281, 199],\n",
      "        [ 83, 127, 130, 173]], dtype=torch.int32), 'scores': tensor([0.4654, 0.4974, 0.2864, 0.4445, 0.2622]), 'objectness_scores': tensor([0.2677, 0.2992, 0.2247, 0.2320, 0.2168]), 'labels': tensor([11, 14,  8, 11, 12], dtype=torch.int32)}\n",
      "13659\n",
      "{'image_id': 13729, 'boxes': tensor([[297, 221, 310, 228],\n",
      "        [555, 234, 573, 285],\n",
      "        [403, 227, 419, 240],\n",
      "        [537, 330, 595, 401],\n",
      "        [222, 194, 431, 360]], dtype=torch.int32), 'scores': tensor([0.2009, 0.7375, 0.3197, 0.2513, 0.1917]), 'objectness_scores': tensor([0.2471, 0.2482, 0.2066, 0.2066, 0.2775]), 'labels': tensor([11, 14,  3, 12, 11], dtype=torch.int32)}\n",
      "13729\n",
      "{'image_id': 13923, 'boxes': tensor([[ 37, 234,  82, 252],\n",
      "        [274, 142, 336, 206],\n",
      "        [169, 241, 258, 301],\n",
      "        [449, 260, 489, 322],\n",
      "        [119, 216, 162, 242],\n",
      "        [ 87, 199, 121, 247],\n",
      "        [ 10, 207, 179, 326],\n",
      "        [362, 280, 419, 356],\n",
      "        [  0, 273,  58, 342],\n",
      "        [436, 177, 468, 206],\n",
      "        [428, 201, 458, 241]], dtype=torch.int32), 'scores': tensor([0.3780, 0.2748, 0.3732, 0.9218, 0.9390, 0.2670, 0.9899, 0.3787, 0.5886,\n",
      "        0.2980, 0.2721]), 'objectness_scores': tensor([0.2367, 0.2121, 0.2661, 0.2547, 0.2239, 0.2351, 0.4233, 0.2412, 0.3205,\n",
      "        0.2064, 0.2070]), 'labels': tensor([11, 10, 14,  7,  7,  7, 13, 10,  7,  7, 11], dtype=torch.int32)}\n",
      "13923\n",
      "{'image_id': 14007, 'boxes': tensor([[392,   0, 527,  90],\n",
      "        [520, 324, 581, 425],\n",
      "        [360, 217, 396, 237],\n",
      "        [339, 156, 414, 298]], dtype=torch.int32), 'scores': tensor([0.2688, 0.3278, 0.3576, 0.9381]), 'objectness_scores': tensor([0.2005, 0.2406, 0.2365, 0.5128]), 'labels': tensor([11,  9, 11,  2], dtype=torch.int32)}\n",
      "14007\n",
      "{'image_id': 14038, 'boxes': tensor([[532, 302, 616, 388],\n",
      "        [334,   0, 487,  33],\n",
      "        [283, 286, 318, 328],\n",
      "        [471, 198, 485, 214],\n",
      "        [145, 197, 172, 259],\n",
      "        [ 56, 126, 118, 183],\n",
      "        [390, 199, 406, 216],\n",
      "        [408, 189, 425, 205]], dtype=torch.int32), 'scores': tensor([0.9427, 0.1626, 0.2428, 0.3903, 0.1990, 0.9670, 0.3952, 0.1645]), 'objectness_scores': tensor([0.3239, 0.2306, 0.4625, 0.2487, 0.2480, 0.5391, 0.3170, 0.2959]), 'labels': tensor([13,  7,  6, 11, 11,  0, 11, 12], dtype=torch.int32)}\n",
      "14038\n",
      "{'image_id': 14831, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "14831\n",
      "{'image_id': 15079, 'boxes': tensor([[  4, 106, 637, 424],\n",
      "        [ 17,  80, 627, 404]], dtype=torch.int32), 'scores': tensor([0.8357, 0.9492]), 'objectness_scores': tensor([0.4986, 0.5282]), 'labels': tensor([12, 12], dtype=torch.int32)}\n",
      "15079\n",
      "{'image_id': 15335, 'boxes': tensor([[105, 184, 137, 265],\n",
      "        [367, 443, 421, 480],\n",
      "        [ 49, 336,  55, 342]], dtype=torch.int32), 'scores': tensor([0.8589, 0.3422, 0.2765]), 'objectness_scores': tensor([0.4617, 0.3436, 0.3013]), 'labels': tensor([ 0,  7, 11], dtype=torch.int32)}\n",
      "15335\n",
      "{'image_id': 15338, 'boxes': tensor([[440, 169, 533, 280],\n",
      "        [136, 368, 159, 424],\n",
      "        [228, 106, 269, 251],\n",
      "        [ 27,  33,  95, 272]], dtype=torch.int32), 'scores': tensor([0.9959, 0.3026, 0.2631, 0.3842]), 'objectness_scores': tensor([0.5246, 0.2034, 0.2144, 0.2194]), 'labels': tensor([ 1, 11,  8,  0], dtype=torch.int32)}\n",
      "15338\n",
      "{'image_id': 15497, 'boxes': tensor([[149, 334, 435, 479],\n",
      "        [ 43,  30, 476, 445]], dtype=torch.int32), 'scores': tensor([0.7322, 0.9475]), 'objectness_scores': tensor([0.2182, 0.6013]), 'labels': tensor([2, 2], dtype=torch.int32)}\n",
      "15497\n",
      "{'image_id': 15597, 'boxes': tensor([[249, 403, 275, 426],\n",
      "        [ 78, 241, 139, 274],\n",
      "        [107, 316, 203, 384],\n",
      "        [149, 307, 188, 340],\n",
      "        [ 96, 342, 122, 378],\n",
      "        [ 91, 177, 143, 218]], dtype=torch.int32), 'scores': tensor([0.2091, 0.3215, 0.6204, 0.1939, 0.3170, 0.2674]), 'objectness_scores': tensor([0.2346, 0.2051, 0.5908, 0.2225, 0.2488, 0.3487]), 'labels': tensor([11,  7,  9,  7,  7,  2], dtype=torch.int32)}\n",
      "15597\n",
      "{'image_id': 16010, 'boxes': tensor([[ 25, 218,  47, 228]], dtype=torch.int32), 'scores': tensor([0.2851]), 'objectness_scores': tensor([0.2213]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "16010\n",
      "{'image_id': 16228, 'boxes': tensor([[346, 130, 479, 170],\n",
      "        [348, 131, 477, 193]], dtype=torch.int32), 'scores': tensor([0.7656, 0.3159]), 'objectness_scores': tensor([0.2212, 0.2479]), 'labels': tensor([12,  6], dtype=torch.int32)}\n",
      "16228\n",
      "{'image_id': 16451, 'boxes': tensor([[150, 120, 286, 199],\n",
      "        [  2, 230,  13, 239],\n",
      "        [473, 354, 501, 366],\n",
      "        [482, 363, 510, 375]], dtype=torch.int32), 'scores': tensor([0.4687, 0.2384, 0.2395, 0.4553]), 'objectness_scores': tensor([0.5159, 0.2074, 0.4344, 0.4019]), 'labels': tensor([ 8, 13, 11, 11], dtype=torch.int32)}\n",
      "16451\n",
      "{'image_id': 16598, 'boxes': tensor([[225, 299, 308, 450],\n",
      "        [341, 150, 412, 268],\n",
      "        [400, 281, 417, 310],\n",
      "        [ 31, 242,  65, 279],\n",
      "        [  3, 238, 436, 639]], dtype=torch.int32), 'scores': tensor([0.8559, 0.4049, 0.1759, 0.2437, 0.9744]), 'objectness_scores': tensor([0.2112, 0.5362, 0.5666, 0.2042, 0.2069]), 'labels': tensor([ 7,  7, 11,  7,  7], dtype=torch.int32)}\n",
      "16598\n",
      "{'image_id': 17029, 'boxes': tensor([[521,  70, 553, 102],\n",
      "        [157, 119, 411, 534],\n",
      "        [291, 174, 316, 200]], dtype=torch.int32), 'scores': tensor([0.2356, 0.9605, 0.5153]), 'objectness_scores': tensor([0.2912, 0.4981, 0.3129]), 'labels': tensor([11, 13, 11], dtype=torch.int32)}\n",
      "17029\n",
      "{'image_id': 17207, 'boxes': tensor([[ 25, 164,  51, 175],\n",
      "        [569, 168, 598, 212],\n",
      "        [109, 222, 171, 249],\n",
      "        [  3, 165,  24, 176]], dtype=torch.int32), 'scores': tensor([0.4797, 0.4742, 0.2989, 0.3998]), 'objectness_scores': tensor([0.2355, 0.3186, 0.2217, 0.2204]), 'labels': tensor([14,  8, 11,  0], dtype=torch.int32)}\n",
      "17207\n",
      "{'image_id': 17379, 'boxes': tensor([[282, 387, 325, 436],\n",
      "        [307, 374, 354, 431],\n",
      "        [  0,   3, 474, 495],\n",
      "        [322, 308, 355, 353],\n",
      "        [  0,  98, 472, 483],\n",
      "        [ 27, 365,  57, 382],\n",
      "        [ 48, 550, 106, 597],\n",
      "        [375, 520, 478, 574],\n",
      "        [385, 482, 429, 518]], dtype=torch.int32), 'scores': tensor([0.1989, 0.4760, 0.7566, 0.2479, 0.1612, 0.4244, 0.1584, 0.5777, 0.1841]), 'objectness_scores': tensor([0.4298, 0.3632, 0.2149, 0.2019, 0.6111, 0.2983, 0.4396, 0.6245, 0.5405]), 'labels': tensor([ 9, 16, 15, 10, 11, 11, 11,  8,  7], dtype=torch.int32)}\n",
      "17379\n",
      "{'image_id': 17627, 'boxes': tensor([[175, 198, 230, 212],\n",
      "        [595, 196, 607, 224],\n",
      "        [175, 256, 185, 267],\n",
      "        [141, 163, 160, 208],\n",
      "        [371, 201, 385, 228]], dtype=torch.int32), 'scores': tensor([0.5034, 0.1695, 0.3173, 0.2609, 0.2820]), 'objectness_scores': tensor([0.2304, 0.2015, 0.2101, 0.2372, 0.2292]), 'labels': tensor([14,  8, 14, 11,  7], dtype=torch.int32)}\n",
      "17627\n",
      "{'image_id': 17714, 'boxes': tensor([[100, 217, 360, 479],\n",
      "        [423, 327, 565, 418],\n",
      "        [200, 117, 305, 202],\n",
      "        [123,  89, 564, 472],\n",
      "        [374, 230, 567, 424],\n",
      "        [319, 178, 415, 257],\n",
      "        [464, 367, 566, 418]], dtype=torch.int32), 'scores': tensor([0.7455, 0.4343, 0.9744, 0.3368, 0.3514, 0.8814, 0.1949]), 'objectness_scores': tensor([0.2515, 0.2453, 0.3446, 0.2986, 0.2477, 0.3074, 0.2306]), 'labels': tensor([12, 11,  3, 12, 12, 10,  6], dtype=torch.int32)}\n",
      "17714\n",
      "{'image_id': 17899, 'boxes': tensor([[376, 229, 433, 264],\n",
      "        [306, 321, 335, 352],\n",
      "        [282, 489, 340, 542],\n",
      "        [177, 528, 227, 558],\n",
      "        [332, 469, 356, 492],\n",
      "        [333, 231, 482, 311],\n",
      "        [ 72, 394, 179, 455],\n",
      "        [215, 542, 266, 573],\n",
      "        [356, 465, 379, 486],\n",
      "        [356, 422, 379, 442],\n",
      "        [301, 391, 320, 410],\n",
      "        [210, 439, 277, 489],\n",
      "        [411,  93, 477, 151],\n",
      "        [321, 396, 345, 418],\n",
      "        [165, 339, 277, 393],\n",
      "        [109, 491, 220, 538],\n",
      "        [107, 500, 163, 536],\n",
      "        [227, 488, 280, 513],\n",
      "        [143, 452, 211, 497],\n",
      "        [275, 435, 297, 458],\n",
      "        [353, 161, 394, 224],\n",
      "        [281, 464, 306, 490],\n",
      "        [194, 172, 212, 190],\n",
      "        [363, 450, 383, 471],\n",
      "        [354,  91, 481, 231],\n",
      "        [309, 394, 376, 500],\n",
      "        [417, 428, 482, 498],\n",
      "        [ 97, 118, 165, 150],\n",
      "        [355, 435, 378, 453],\n",
      "        [237, 512, 277, 538],\n",
      "        [427, 194, 479, 274],\n",
      "        [313, 409, 337, 433],\n",
      "        [226, 354, 232, 359],\n",
      "        [311, 461, 335, 485],\n",
      "        [252, 380, 305, 442],\n",
      "        [412, 490, 482, 608],\n",
      "        [ 17, 374, 215, 504],\n",
      "        [336, 418, 357, 439],\n",
      "        [  1, 306, 446, 644],\n",
      "        [356, 120, 413, 160],\n",
      "        [349, 410, 480, 591],\n",
      "        [284, 420, 304, 440],\n",
      "        [180, 315, 204, 333],\n",
      "        [262, 543, 313, 578],\n",
      "        [ 26, 460, 141, 522],\n",
      "        [345, 442, 370, 470],\n",
      "        [354, 481, 378, 502],\n",
      "        [ 66, 524, 359, 641],\n",
      "        [324, 428, 346, 450],\n",
      "        [ 96, 352, 384, 636],\n",
      "        [140, 369, 209, 400],\n",
      "        [326, 451, 348, 472],\n",
      "        [311, 437, 334, 462],\n",
      "        [292, 404, 313, 423],\n",
      "        [147, 492, 220, 537],\n",
      "        [292, 452, 314, 472],\n",
      "        [300, 421, 320, 442],\n",
      "        [366, 402, 388, 425]], dtype=torch.int32), 'scores': tensor([0.2692, 0.5301, 0.2647, 0.2095, 0.3428, 0.4272, 0.6269, 0.3409, 0.1947,\n",
      "        0.2698, 0.2332, 0.6114, 0.9838, 0.1623, 0.7279, 0.3597, 0.1881, 0.5232,\n",
      "        0.3907, 0.3320, 0.1933, 0.5521, 0.9957, 0.2909, 0.9543, 0.3927, 0.9435,\n",
      "        0.4624, 0.3323, 0.1753, 0.3657, 0.5533, 0.1373, 0.2818, 0.7871, 0.8897,\n",
      "        0.5303, 0.2204, 0.8433, 0.1760, 0.5413, 0.2939, 0.2317, 0.2651, 0.8263,\n",
      "        0.6803, 0.1390, 0.3819, 0.2240, 0.6339, 0.8326, 0.2951, 0.3436, 0.2632,\n",
      "        0.6813, 0.2199, 0.3884, 0.2847]), 'objectness_scores': tensor([0.2202, 0.2174, 0.3595, 0.3851, 0.3183, 0.2745, 0.3033, 0.3666, 0.3139,\n",
      "        0.2552, 0.2463, 0.3756, 0.4967, 0.2329, 0.2822, 0.3594, 0.2902, 0.3693,\n",
      "        0.3795, 0.2656, 0.2263, 0.2854, 0.2153, 0.2255, 0.5322, 0.2461, 0.5025,\n",
      "        0.2653, 0.2599, 0.3493, 0.2266, 0.2516, 0.3411, 0.2869, 0.4056, 0.5117,\n",
      "        0.2036, 0.2319, 0.2719, 0.4219, 0.3378, 0.2363, 0.2900, 0.3790, 0.2867,\n",
      "        0.2522, 0.3284, 0.3172, 0.2669, 0.2371, 0.2063, 0.2846, 0.2755, 0.2536,\n",
      "        0.2821, 0.2993, 0.2590, 0.2623]), 'labels': tensor([ 2, 10,  4,  7, 11, 14, 12,  8, 11, 11, 11, 12, 13,  7, 11, 12,  7, 11,\n",
      "        12, 11,  7, 10,  6, 11, 13, 12, 10, 11, 11,  9,  7, 11, 10, 11,  3, 10,\n",
      "        12, 11, 12, 11, 10, 11,  7,  9,  7, 10,  4,  5, 11, 12,  7, 11, 11, 11,\n",
      "        12, 11, 11, 12], dtype=torch.int32)}\n",
      "17899\n",
      "{'image_id': 18150, 'boxes': tensor([[ 99, 156, 151, 216],\n",
      "        [369, 280, 481, 438],\n",
      "        [401, 272, 634, 471],\n",
      "        [  0, 394, 334, 481],\n",
      "        [358, 312, 445, 378]], dtype=torch.int32), 'scores': tensor([0.6484, 0.4848, 0.2034, 0.1997, 0.2704]), 'objectness_scores': tensor([0.5189, 0.2503, 0.2173, 0.3244, 0.2856]), 'labels': tensor([ 7, 13,  7,  9,  7], dtype=torch.int32)}\n",
      "18150\n",
      "{'image_id': 18380, 'boxes': tensor([[340, 145, 351, 158],\n",
      "        [  0,   1,  63, 110],\n",
      "        [405, 134, 435, 157],\n",
      "        [348, 174, 365, 196],\n",
      "        [560,  88, 586, 120],\n",
      "        [281, 213, 302, 239],\n",
      "        [407, 306, 441, 358],\n",
      "        [506, 241, 639, 429],\n",
      "        [119, 227, 145, 248],\n",
      "        [364, 228, 387, 247],\n",
      "        [391, 259, 420, 327],\n",
      "        [272, 321, 305, 388],\n",
      "        [239, 135, 536, 410],\n",
      "        [ 56,   0, 105,  88],\n",
      "        [368, 206, 410, 222],\n",
      "        [236, 293, 270, 319],\n",
      "        [479, 165, 504, 183],\n",
      "        [372, 191, 389, 226],\n",
      "        [497, 344, 514, 371],\n",
      "        [240, 316, 274, 368],\n",
      "        [413, 361, 528, 427],\n",
      "        [206, 252, 266, 283],\n",
      "        [356, 242, 382, 282],\n",
      "        [507,   0, 631,  66],\n",
      "        [346, 121, 356, 142],\n",
      "        [241, 373, 286, 425],\n",
      "        [290, 166, 305, 182],\n",
      "        [343, 162, 358, 183],\n",
      "        [ 19, 263,  63, 311],\n",
      "        [567, 216, 609, 249],\n",
      "        [280, 326, 316, 419],\n",
      "        [252, 241, 279, 312],\n",
      "        [292, 184, 309, 206],\n",
      "        [330, 148, 344, 180],\n",
      "        [305, 133, 316, 154],\n",
      "        [199, 234, 209, 250]], dtype=torch.int32), 'scores': tensor([0.2830, 0.5245, 0.2385, 0.2346, 0.2030, 0.9995, 0.9697, 0.3590, 0.3694,\n",
      "        0.1680, 0.7058, 0.4114, 0.4772, 0.6102, 0.2342, 0.2092, 0.4055, 0.2015,\n",
      "        0.3051, 0.9189, 0.3305, 0.4337, 0.7694, 0.4708, 0.7626, 0.9715, 0.2380,\n",
      "        0.3321, 0.9467, 0.3984, 0.2047, 0.4258, 0.2108, 0.2038, 0.3297, 0.1763]), 'objectness_scores': tensor([0.2227, 0.2264, 0.2561, 0.2558, 0.2133, 0.2126, 0.2734, 0.2113, 0.2795,\n",
      "        0.2015, 0.2534, 0.2296, 0.2655, 0.2472, 0.2147, 0.2177, 0.3001, 0.2036,\n",
      "        0.2596, 0.2878, 0.2097, 0.2083, 0.2798, 0.2521, 0.2395, 0.3153, 0.2374,\n",
      "        0.2641, 0.3174, 0.3370, 0.3633, 0.2664, 0.2553, 0.2341, 0.2519, 0.2592]), 'labels': tensor([14,  8,  7, 14,  7, 14, 10, 12, 11,  9, 10, 10,  7,  8, 14,  9,  7, 11,\n",
      "        11, 10, 11,  9, 10,  0,  3, 10, 14, 14, 14,  7, 10, 11,  7, 11, 14, 11],\n",
      "       dtype=torch.int32)}\n",
      "18380\n",
      "{'image_id': 18575, 'boxes': tensor([[  0,  94, 343, 462],\n",
      "        [444, 347, 524, 430],\n",
      "        [247,  36, 376, 138],\n",
      "        [408,  16, 621, 198],\n",
      "        [349, 196, 625, 473],\n",
      "        [ 57,  94, 323, 309],\n",
      "        [422, 200, 554, 322],\n",
      "        [408,  13, 618, 201],\n",
      "        [386, 164, 624, 365],\n",
      "        [505, 192, 577, 238],\n",
      "        [  0, 134,  18, 209],\n",
      "        [  5,  12, 638, 476],\n",
      "        [228,   0, 364, 119],\n",
      "        [416, 163, 577, 243],\n",
      "        [424, 201, 539, 314]], dtype=torch.int32), 'scores': tensor([0.6566, 0.3718, 0.8658, 0.6947, 0.6052, 0.3198, 0.1667, 0.7467, 0.4841,\n",
      "        0.3350, 0.3333, 0.4959, 0.9454, 0.3236, 0.2953]), 'objectness_scores': tensor([0.3263, 0.2172, 0.2369, 0.5204, 0.3102, 0.5447, 0.5895, 0.3566, 0.3570,\n",
      "        0.2100, 0.3316, 0.3984, 0.5103, 0.3814, 0.2170]), 'labels': tensor([12,  8, 10, 12, 12,  4,  3, 12, 12,  7, 11, 12, 10,  7,  7],\n",
      "       dtype=torch.int32)}\n",
      "18575\n",
      "{'image_id': 18770, 'boxes': tensor([[207,  20, 635, 427],\n",
      "        [169, 172, 225, 234],\n",
      "        [284, 171, 360, 345]], dtype=torch.int32), 'scores': tensor([0.2655, 0.1804, 0.9160]), 'objectness_scores': tensor([0.2220, 0.2469, 0.5670]), 'labels': tensor([ 7, 10,  7], dtype=torch.int32)}\n",
      "18770\n",
      "{'image_id': 19786, 'boxes': tensor([[ 10,  63, 113, 196],\n",
      "        [237,  58, 290, 164],\n",
      "        [ 10,  60, 343, 321],\n",
      "        [102,   2, 219, 374],\n",
      "        [449,   0, 495,  44]], dtype=torch.int32), 'scores': tensor([0.2769, 0.3484, 0.7429, 0.6553, 0.3088]), 'objectness_scores': tensor([0.2452, 0.2392, 0.6251, 0.4995, 0.2155]), 'labels': tensor([13, 11, 12,  7,  7], dtype=torch.int32)}\n",
      "19786\n",
      "{'image_id': 19924, 'boxes': tensor([[ 40,  26, 426, 317],\n",
      "        [316, 442, 400, 484],\n",
      "        [143, 296, 282, 499],\n",
      "        [339, 262, 349, 278],\n",
      "        [ 73, 292, 323, 495]], dtype=torch.int32), 'scores': tensor([0.2201, 0.6106, 0.9404, 0.2143, 0.9837]), 'objectness_scores': tensor([0.4563, 0.6757, 0.3930, 0.5797, 0.3101]), 'labels': tensor([ 6, 11,  7, 14,  7], dtype=torch.int32)}\n",
      "19924\n",
      "{'image_id': 20333, 'boxes': tensor([[174, 286, 239, 506],\n",
      "        [  0, 476,  71, 513]], dtype=torch.int32), 'scores': tensor([0.8246, 0.3229]), 'objectness_scores': tensor([0.6219, 0.3078]), 'labels': tensor([ 0, 11], dtype=torch.int32)}\n",
      "20333\n",
      "{'image_id': 20553, 'boxes': tensor([[320, 164, 426, 313],\n",
      "        [194,  75, 291, 146],\n",
      "        [270, 173, 320, 192],\n",
      "        [391, 111, 431, 150],\n",
      "        [194, 127, 221, 153],\n",
      "        [335, 157, 352, 188],\n",
      "        [170, 154, 214, 203]], dtype=torch.int32), 'scores': tensor([0.6304, 0.5127, 0.7822, 0.2858, 0.2315, 0.2687, 0.1819]), 'objectness_scores': tensor([0.2763, 0.2135, 0.2479, 0.3558, 0.2449, 0.2627, 0.4447]), 'labels': tensor([ 9,  5, 11,  8, 11, 11,  3], dtype=torch.int32)}\n",
      "20553\n",
      "{'image_id': 21167, 'boxes': tensor([[362, 428, 386, 457],\n",
      "        [194,  43, 236, 226],\n",
      "        [178, 149, 426, 641],\n",
      "        [ 42, 225, 207, 637],\n",
      "        [235, 147, 361, 367],\n",
      "        [261, 173, 318, 285],\n",
      "        [258, 296, 314, 375]], dtype=torch.int32), 'scores': tensor([0.6279, 0.3354, 0.9433, 0.6700, 0.9809, 0.9917, 0.4442]), 'objectness_scores': tensor([0.3053, 0.2045, 0.2131, 0.3688, 0.2342, 0.4260, 0.5305]), 'labels': tensor([11, 11,  7,  7,  7,  7, 10], dtype=torch.int32)}\n",
      "21167\n",
      "{'image_id': 21503, 'boxes': tensor([[269,  45, 637, 142],\n",
      "        [316, 102, 559, 188]], dtype=torch.int32), 'scores': tensor([0.5885, 0.4633]), 'objectness_scores': tensor([0.2395, 0.2041]), 'labels': tensor([12, 11], dtype=torch.int32)}\n",
      "21503\n",
      "{'image_id': 21604, 'boxes': tensor([[204, 602, 307, 639],\n",
      "        [175, 107, 301, 152],\n",
      "        [239, 345, 248, 357],\n",
      "        [223, 476, 235, 490],\n",
      "        [250, 244, 302, 564],\n",
      "        [ 48, 202, 478, 638]], dtype=torch.int32), 'scores': tensor([0.1780, 0.2799, 0.1941, 0.2172, 0.3524, 0.9731]), 'objectness_scores': tensor([0.2175, 0.3464, 0.4872, 0.2110, 0.5869, 0.3537]), 'labels': tensor([11,  7, 14, 11,  8,  7], dtype=torch.int32)}\n",
      "21604\n",
      "{'image_id': 21903, 'boxes': tensor([[478, 350, 525, 376],\n",
      "        [450, 342, 462, 357],\n",
      "        [620, 242, 638, 257],\n",
      "        [454, 358, 473, 481],\n",
      "        [  2, 109, 325, 393]], dtype=torch.int32), 'scores': tensor([0.6008, 0.1545, 0.2639, 0.4446, 0.9995]), 'objectness_scores': tensor([0.4219, 0.5611, 0.2043, 0.2914, 0.7540]), 'labels': tensor([11, 14, 11, 11,  5], dtype=torch.int32)}\n",
      "21903\n",
      "{'image_id': 22192, 'boxes': tensor([[  0, 350, 102, 424],\n",
      "        [ 72, 120, 219, 373],\n",
      "        [475, 279, 639, 426],\n",
      "        [  0, 259,  98, 396]], dtype=torch.int32), 'scores': tensor([0.3812, 0.9732, 0.4587, 0.5618]), 'objectness_scores': tensor([0.2161, 0.4156, 0.2162, 0.2092]), 'labels': tensor([ 7,  3, 13,  7], dtype=torch.int32)}\n",
      "22192\n",
      "{'image_id': 22371, 'boxes': tensor([[277, 228, 283, 248],\n",
      "        [340, 232, 358, 253],\n",
      "        [  2, 244, 421, 282],\n",
      "        [251, 267, 277, 279],\n",
      "        [308, 213, 345, 271],\n",
      "        [165, 134, 200, 247],\n",
      "        [181,  87, 251, 151]], dtype=torch.int32), 'scores': tensor([0.2803, 0.2458, 0.3402, 0.2038, 0.7313, 0.9895, 0.5288]), 'objectness_scores': tensor([0.2073, 0.2443, 0.2483, 0.3456, 0.5385, 0.6415, 0.5259]), 'labels': tensor([11,  7,  9,  8, 11,  7,  7], dtype=torch.int32)}\n",
      "22371\n",
      "{'image_id': 22479, 'boxes': tensor([[ 18,  90,  48, 253],\n",
      "        [248,  62, 255,  77],\n",
      "        [565, 335, 639, 362],\n",
      "        [260, 281, 484, 476],\n",
      "        [256, 279, 362, 394],\n",
      "        [361, 382, 486, 468]], dtype=torch.int32), 'scores': tensor([0.2404, 0.3355, 0.2624, 0.9614, 0.6658, 0.3518]), 'objectness_scores': tensor([0.2626, 0.5266, 0.2228, 0.6065, 0.2860, 0.2243]), 'labels': tensor([ 7, 11, 11,  9,  9,  8], dtype=torch.int32)}\n",
      "22479\n",
      "{'image_id': 22755, 'boxes': tensor([[404, 212, 409, 219],\n",
      "        [361, 192, 374, 207],\n",
      "        [188, 104, 483, 377],\n",
      "        [179,   0, 358, 143],\n",
      "        [360, 214, 371, 222]], dtype=torch.int32), 'scores': tensor([0.1619, 0.2451, 0.2042, 0.6595, 0.2940]), 'objectness_scores': tensor([0.2450, 0.2039, 0.4083, 0.2318, 0.2094]), 'labels': tensor([ 0, 11,  3,  1, 11], dtype=torch.int32)}\n",
      "22755\n",
      "{'image_id': 22892, 'boxes': tensor([[370, 268, 456, 333],\n",
      "        [ 38,  74, 291, 292],\n",
      "        [205, 216, 438, 333],\n",
      "        [237,  21, 500, 256],\n",
      "        [ 94, 175, 116, 229]], dtype=torch.int32), 'scores': tensor([0.5354, 0.9955, 0.5999, 0.9661, 0.5121]), 'objectness_scores': tensor([0.2858, 0.5062, 0.2876, 0.5574, 0.3102]), 'labels': tensor([10,  4,  7,  2, 11], dtype=torch.int32)}\n",
      "22892\n",
      "{'image_id': 23272, 'boxes': tensor([[215, 143, 321, 202],\n",
      "        [155, 241, 182, 279],\n",
      "        [ 48, 294, 306, 375],\n",
      "        [187,  74, 313, 149]], dtype=torch.int32), 'scores': tensor([0.2165, 0.7928, 0.3780, 0.9620]), 'objectness_scores': tensor([0.4978, 0.2046, 0.2037, 0.5431]), 'labels': tensor([12, 10,  7,  2], dtype=torch.int32)}\n",
      "23272\n",
      "{'image_id': 23359, 'boxes': tensor([[267, 198, 281, 216],\n",
      "        [307, 102, 330, 115],\n",
      "        [308,  95, 329, 113],\n",
      "        [251, 110, 273, 125],\n",
      "        [299, 160, 326, 178],\n",
      "        [267, 240, 298, 263]], dtype=torch.int32), 'scores': tensor([0.1845, 0.2076, 0.2161, 0.6010, 0.3512, 0.1928]), 'objectness_scores': tensor([0.2269, 0.4160, 0.2677, 0.4687, 0.4682, 0.3243]), 'labels': tensor([ 2, 14,  8, 11, 11, 11], dtype=torch.int32)}\n",
      "23359\n",
      "{'image_id': 23899, 'boxes': tensor([[333, 146, 520, 340],\n",
      "        [ 72,  83, 174, 130],\n",
      "        [568, 262, 584, 286]], dtype=torch.int32), 'scores': tensor([0.3425, 0.1831, 0.4507]), 'objectness_scores': tensor([0.2664, 0.2248, 0.4752]), 'labels': tensor([13, 14, 11], dtype=torch.int32)}\n",
      "23899\n",
      "{'image_id': 23937, 'boxes': tensor([[458,   0, 639, 252]], dtype=torch.int32), 'scores': tensor([0.3977]), 'objectness_scores': tensor([0.2666]), 'labels': tensor([4], dtype=torch.int32)}\n",
      "23937\n",
      "{'image_id': 24021, 'boxes': tensor([[ 66,  76,  73,  85],\n",
      "        [316, 270, 325, 286],\n",
      "        [515, 154, 519, 163],\n",
      "        [550, 104, 556, 115],\n",
      "        [438, 138, 443, 148],\n",
      "        [111, 107, 117, 118],\n",
      "        [470, 162, 476, 173],\n",
      "        [413, 199, 419, 214],\n",
      "        [292, 138, 297, 149],\n",
      "        [584, 110, 588, 115],\n",
      "        [196, 161, 201, 173],\n",
      "        [577, 162, 583, 171],\n",
      "        [405,  75, 410,  83],\n",
      "        [139, 151, 145, 160],\n",
      "        [ 40, 264,  47, 284],\n",
      "        [ 80, 172,  85, 180],\n",
      "        [469,  77, 473,  88],\n",
      "        [320, 199, 327, 214],\n",
      "        [185, 101, 189, 107],\n",
      "        [374,  70, 378,  77],\n",
      "        [627, 166, 632, 178],\n",
      "        [245, 101, 250, 110],\n",
      "        [244, 163, 249, 174],\n",
      "        [605, 313, 631, 329],\n",
      "        [133, 253, 139, 270],\n",
      "        [484, 273, 501, 296],\n",
      "        [ 32, 202,  39, 215],\n",
      "        [149, 237, 155, 245],\n",
      "        [436,  72, 441,  79],\n",
      "        [258, 295, 285, 321],\n",
      "        [602, 196, 610, 211],\n",
      "        [552, 103, 557, 110],\n",
      "        [119, 169, 124, 178],\n",
      "        [531, 166, 537, 174],\n",
      "        [ 84, 137,  90, 146],\n",
      "        [  8, 181,  13, 188],\n",
      "        [352, 201, 357, 211],\n",
      "        [218, 156, 227, 165],\n",
      "        [566,  83, 570,  90],\n",
      "        [484, 195, 490, 205],\n",
      "        [485, 195, 496, 202],\n",
      "        [520, 197, 528, 209],\n",
      "        [ 16, 120,  20, 128],\n",
      "        [598, 140, 603, 149],\n",
      "        [178, 253, 185, 272],\n",
      "        [  5, 206,  11, 233],\n",
      "        [ 68, 204,  74, 216],\n",
      "        [501, 159, 508, 174],\n",
      "        [337, 101, 341, 109],\n",
      "        [101, 288, 129, 315],\n",
      "        [417, 105, 421, 114],\n",
      "        [377, 155, 383, 162],\n",
      "        [221, 102, 226, 113],\n",
      "        [230, 250, 238, 267],\n",
      "        [599, 250, 604, 262],\n",
      "        [551, 150, 557, 160],\n",
      "        [265,  84, 269,  95],\n",
      "        [ 80, 245,  87, 255],\n",
      "        [141, 111, 147, 125],\n",
      "        [468, 223, 475, 239],\n",
      "        [230, 137, 237, 145],\n",
      "        [413, 163, 418, 171],\n",
      "        [234, 199, 242, 215],\n",
      "        [534,  74, 538,  80],\n",
      "        [133, 199, 140, 217],\n",
      "        [111, 208, 118, 218],\n",
      "        [318, 197, 328, 204],\n",
      "        [303,  81, 308,  86],\n",
      "        [ 78, 110,  83, 116],\n",
      "        [332, 243, 338, 255],\n",
      "        [564, 195, 571, 205],\n",
      "        [573, 164, 581, 182],\n",
      "        [502,  74, 507,  80],\n",
      "        [  2, 132,   7, 142],\n",
      "        [485, 103, 492, 110],\n",
      "        [307, 106, 312, 114],\n",
      "        [102,  81, 107,  88],\n",
      "        [130,  82, 135,  93],\n",
      "        [395, 137, 401, 152],\n",
      "        [ 42, 172,  47, 180],\n",
      "        [165, 217, 171, 225],\n",
      "        [397, 102, 401, 108],\n",
      "        [274, 193, 279, 203],\n",
      "        [617, 111, 622, 120],\n",
      "        [229, 248, 237, 255],\n",
      "        [487, 139, 491, 147],\n",
      "        [ 21,  84,  25,  89],\n",
      "        [277, 102, 281, 112],\n",
      "        [300, 160, 307, 176],\n",
      "        [178, 252, 185, 272],\n",
      "        [161,  86, 168,  91],\n",
      "        [527, 265, 535, 286],\n",
      "        [356, 163, 362, 171],\n",
      "        [150, 166, 155, 177],\n",
      "        [ 20, 163,  28, 170]], dtype=torch.int32), 'scores': tensor([0.1681, 0.1917, 0.3053, 0.2872, 0.1985, 0.1620, 0.1925, 0.2255, 0.1774,\n",
      "        0.2414, 0.1977, 0.2669, 0.2295, 0.2229, 0.2170, 0.2086, 0.5189, 0.2477,\n",
      "        0.1683, 0.2114, 0.2224, 0.1840, 0.1968, 0.2267, 0.1520, 0.3318, 0.1735,\n",
      "        0.3757, 0.1738, 0.2557, 0.2418, 0.2168, 0.2225, 0.2138, 0.2010, 0.1835,\n",
      "        0.1671, 0.1303, 0.2407, 0.1463, 0.1497, 0.3417, 0.3516, 0.2208, 0.2342,\n",
      "        0.1818, 0.1961, 0.1374, 0.1324, 0.3501, 0.1944, 0.1487, 0.3365, 0.2130,\n",
      "        0.1810, 0.1869, 0.1667, 0.1670, 0.2380, 0.2521, 0.3078, 0.1997, 0.2295,\n",
      "        0.2403, 0.2073, 0.2216, 0.1933, 0.2267, 0.1953, 0.1978, 0.1717, 0.1296,\n",
      "        0.2128, 0.1968, 0.2117, 0.2151, 0.3059, 0.1868, 0.1652, 0.1911, 0.1695,\n",
      "        0.2312, 0.2131, 0.1644, 0.1513, 0.1922, 0.2385, 0.1829, 0.2042, 0.3423,\n",
      "        0.1623, 0.2471, 0.1505, 0.1476, 0.1385]), 'objectness_scores': tensor([0.2300, 0.3168, 0.2439, 0.3559, 0.3987, 0.5523, 0.4691, 0.4865, 0.2470,\n",
      "        0.3348, 0.5315, 0.2016, 0.4836, 0.2166, 0.3605, 0.3179, 0.3581, 0.4542,\n",
      "        0.4250, 0.3922, 0.5483, 0.2739, 0.4516, 0.2115, 0.2185, 0.4256, 0.4833,\n",
      "        0.2871, 0.3797, 0.2074, 0.4920, 0.2461, 0.3240, 0.3487, 0.2050, 0.2445,\n",
      "        0.4089, 0.2175, 0.4002, 0.3757, 0.2037, 0.3676, 0.3428, 0.3093, 0.3124,\n",
      "        0.3925, 0.5544, 0.3049, 0.3852, 0.2043, 0.4298, 0.3155, 0.4972, 0.3656,\n",
      "        0.4452, 0.3352, 0.3742, 0.2980, 0.2992, 0.2909, 0.2018, 0.4940, 0.4308,\n",
      "        0.4825, 0.4123, 0.3707, 0.2194, 0.3042, 0.3925, 0.4024, 0.5080, 0.3415,\n",
      "        0.3875, 0.4185, 0.2391, 0.3564, 0.3713, 0.2062, 0.2592, 0.3639, 0.3420,\n",
      "        0.3496, 0.4917, 0.3732, 0.2343, 0.2557, 0.2888, 0.4627, 0.5638, 0.2308,\n",
      "        0.3673, 0.4063, 0.4425, 0.5680, 0.3079]), 'labels': tensor([11, 11, 14, 10, 11, 11, 11, 11, 11, 11, 11, 14, 14, 11, 14, 14, 11, 11,\n",
      "        14, 11, 14, 11,  7, 11, 11,  7, 11,  2, 11,  7, 14, 14,  5, 11, 11, 14,\n",
      "        14, 11,  8, 11, 11,  7,  7, 14, 14, 14,  7, 11, 14, 11, 14, 14, 11,  2,\n",
      "        14, 14, 14, 11, 14, 14, 14, 11, 14, 14,  0, 11, 11, 11,  7, 14, 14, 11,\n",
      "        14, 11, 14, 14, 14,  0, 11, 14, 11, 11, 11, 14, 11, 11, 11, 11, 11, 14,\n",
      "         2,  9, 11, 11, 14], dtype=torch.int32)}\n",
      "24021\n",
      "{'image_id': 24243, 'boxes': tensor([[290, 168, 306, 193],\n",
      "        [  0, 307,  28, 321],\n",
      "        [  0, 306,  29, 342],\n",
      "        [615,  75, 628,  93],\n",
      "        [347, 270, 363, 286],\n",
      "        [266, 413, 304, 441],\n",
      "        [536,  74, 564, 117],\n",
      "        [ 39, 114, 211, 341],\n",
      "        [ 30, 277,  61, 326],\n",
      "        [  0, 317,  25, 358]], dtype=torch.int32), 'scores': tensor([0.7397, 0.2750, 0.3961, 0.1789, 0.1630, 0.3859, 0.4757, 0.2912, 0.8237,\n",
      "        0.2618]), 'objectness_scores': tensor([0.3449, 0.2041, 0.3083, 0.2344, 0.2168, 0.2208, 0.3260, 0.2614, 0.3998,\n",
      "        0.3277]), 'labels': tensor([10, 11, 10,  7,  4,  9,  7,  7, 10, 11], dtype=torch.int32)}\n",
      "24243\n",
      "{'image_id': 24610, 'boxes': tensor([[580, 139, 620, 191],\n",
      "        [223, 310, 430, 432],\n",
      "        [168, 192, 198, 223]], dtype=torch.int32), 'scores': tensor([0.1564, 0.7599, 0.2381]), 'objectness_scores': tensor([0.2301, 0.2263, 0.3362]), 'labels': tensor([ 7, 10,  3], dtype=torch.int32)}\n",
      "24610\n",
      "{'image_id': 25096, 'boxes': tensor([[211, 276, 301, 325],\n",
      "        [ 96, 282, 329, 411],\n",
      "        [ 34, 307, 145, 393],\n",
      "        [126, 276, 314, 376],\n",
      "        [  2, 254, 376, 497],\n",
      "        [  0, 223, 143, 390],\n",
      "        [126, 314, 223, 374]], dtype=torch.int32), 'scores': tensor([0.4034, 0.9941, 0.8079, 0.9716, 0.9909, 0.4889, 0.5371]), 'objectness_scores': tensor([0.2754, 0.3206, 0.3978, 0.2452, 0.3457, 0.3210, 0.2882]), 'labels': tensor([13, 12, 11, 12, 12, 11, 12], dtype=torch.int32)}\n",
      "25096\n",
      "{'image_id': 25393, 'boxes': tensor([[427, 198, 455, 302],\n",
      "        [ 67, 137,  88, 159],\n",
      "        [433, 421, 447, 446],\n",
      "        [201, 139, 231, 259],\n",
      "        [190, 449, 225, 479],\n",
      "        [148, 121, 286, 280]], dtype=torch.int32), 'scores': tensor([0.9999, 0.4545, 0.2422, 0.7369, 0.2466, 0.9904]), 'objectness_scores': tensor([0.4229, 0.2706, 0.2002, 0.4279, 0.2037, 0.2002]), 'labels': tensor([ 7,  8, 11, 11, 11,  7], dtype=torch.int32)}\n",
      "25393\n",
      "{'image_id': 25394, 'boxes': tensor([[152, 321, 270, 446],\n",
      "        [247, 435, 365, 640],\n",
      "        [354, 408, 415, 577]], dtype=torch.int32), 'scores': tensor([0.3914, 0.9581, 0.8982]), 'objectness_scores': tensor([0.2595, 0.2859, 0.3472]), 'labels': tensor([10, 10, 10], dtype=torch.int32)}\n",
      "25394\n",
      "{'image_id': 25560, 'boxes': tensor([[135, 186, 510, 342],\n",
      "        [305,  72, 342,  87],\n",
      "        [158, 319, 558, 479]], dtype=torch.int32), 'scores': tensor([0.8990, 0.4105, 0.2888]), 'objectness_scores': tensor([0.5469, 0.2738, 0.2950]), 'labels': tensor([2, 7, 3], dtype=torch.int32)}\n",
      "25560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 25603, 'boxes': tensor([[ 66,  47,  94,  76],\n",
      "        [317,   0, 338,  21],\n",
      "        [202, 316, 481, 418],\n",
      "        [429, 355, 525, 425],\n",
      "        [  9, 355, 292, 480],\n",
      "        [150, 177, 379, 286],\n",
      "        [266,  51, 315,  98],\n",
      "        [524, 327, 576, 373],\n",
      "        [  4, 275, 630, 479],\n",
      "        [359, 294, 372, 315],\n",
      "        [313, 318, 397, 479],\n",
      "        [ 35, 406, 153, 480]], dtype=torch.int32), 'scores': tensor([0.2929, 0.2097, 0.4012, 0.3370, 0.3561, 0.1542, 0.1308, 0.2994, 0.4184,\n",
      "        0.2606, 0.6071, 0.2365]), 'objectness_scores': tensor([0.2169, 0.2444, 0.3765, 0.2147, 0.2951, 0.2051, 0.2138, 0.4239, 0.2567,\n",
      "        0.3305, 0.4687, 0.4071]), 'labels': tensor([11, 16, 10,  3, 12, 10,  8,  7,  7, 11, 10, 12], dtype=torch.int32)}\n",
      "25603\n",
      "{'image_id': 25986, 'boxes': tensor([[  0, 251, 154, 431],\n",
      "        [512, 117, 562, 154],\n",
      "        [373, 201, 448, 301],\n",
      "        [108, 310, 402, 481],\n",
      "        [351,  34, 499,  80],\n",
      "        [279,  35, 497,  88],\n",
      "        [384, 112, 584, 180],\n",
      "        [601, 110, 630, 136],\n",
      "        [536, 101, 569, 134],\n",
      "        [452, 195, 595, 297],\n",
      "        [435, 188, 628, 307],\n",
      "        [  4,  39, 636, 478],\n",
      "        [407,  88, 568, 155]], dtype=torch.int32), 'scores': tensor([0.4440, 0.2470, 0.9494, 0.5565, 0.4494, 0.3202, 0.6557, 0.3626, 0.3564,\n",
      "        0.3337, 0.4597, 0.6510, 0.4225]), 'objectness_scores': tensor([0.3258, 0.3178, 0.5390, 0.3326, 0.2241, 0.2148, 0.3704, 0.2648, 0.3483,\n",
      "        0.2796, 0.3518, 0.3363, 0.2108]), 'labels': tensor([15, 12, 10, 12,  7, 11, 12, 12, 11, 12, 12,  3, 12], dtype=torch.int32)}\n",
      "25986\n",
      "{'image_id': 26204, 'boxes': tensor([[130,  88, 149,  96],\n",
      "        [105,  76, 173,  89],\n",
      "        [109, 157, 126, 189],\n",
      "        [212, 223, 216, 233]], dtype=torch.int32), 'scores': tensor([0.2761, 0.3418, 0.6159, 0.3365]), 'objectness_scores': tensor([0.2101, 0.2983, 0.2585, 0.2186]), 'labels': tensor([14, 14,  4, 11], dtype=torch.int32)}\n",
      "26204\n",
      "{'image_id': 26465, 'boxes': tensor([[  1, 128, 496, 375],\n",
      "        [ 71, 168, 114, 251],\n",
      "        [145, 169, 363, 235]], dtype=torch.int32), 'scores': tensor([0.9839, 0.6507, 0.9990]), 'objectness_scores': tensor([0.5272, 0.4579, 0.4581]), 'labels': tensor([14, 11, 14], dtype=torch.int32)}\n",
      "26465\n",
      "{'image_id': 26564, 'boxes': tensor([[400, 194, 433, 260],\n",
      "        [  8, 252, 629, 425],\n",
      "        [217, 267, 413, 329],\n",
      "        [  0, 219,  58, 342],\n",
      "        [474, 297, 638, 425],\n",
      "        [202, 284, 236, 298]], dtype=torch.int32), 'scores': tensor([0.2545, 0.9985, 0.9988, 0.2656, 0.1965, 0.6405]), 'objectness_scores': tensor([0.3648, 0.2968, 0.2565, 0.2056, 0.2033, 0.2119]), 'labels': tensor([ 7, 14, 14, 14,  7, 11], dtype=torch.int32)}\n",
      "26564\n",
      "{'image_id': 26690, 'boxes': tensor([[315, 175, 325, 185],\n",
      "        [ 74, 296, 105, 316],\n",
      "        [187, 450, 209, 464],\n",
      "        [256, 513, 280, 532],\n",
      "        [348, 548, 370, 563],\n",
      "        [ 20, 346,  48, 365],\n",
      "        [392, 569, 410, 585],\n",
      "        [112, 433, 134, 451],\n",
      "        [270, 538, 311, 588],\n",
      "        [ 88, 399, 111, 415],\n",
      "        [108, 431, 118, 441],\n",
      "        [180, 449, 209, 474],\n",
      "        [340, 182, 380, 217],\n",
      "        [304, 515, 323, 527],\n",
      "        [294, 253, 327, 278],\n",
      "        [  0, 382, 347, 639],\n",
      "        [ 64, 308,  75, 316],\n",
      "        [127, 472, 144, 483],\n",
      "        [219, 244, 266, 296],\n",
      "        [274, 498, 296, 513],\n",
      "        [393, 566, 411, 580],\n",
      "        [256, 524, 276, 539],\n",
      "        [ 34, 404,  47, 420]], dtype=torch.int32), 'scores': tensor([0.1904, 0.5177, 0.2710, 0.4449, 0.1870, 0.1727, 0.1906, 0.1573, 0.8392,\n",
      "        0.5486, 0.2543, 0.2692, 0.4734, 0.3385, 0.4187, 0.5486, 0.1262, 0.4276,\n",
      "        0.5313, 0.4382, 0.3940, 0.2798, 0.2045]), 'objectness_scores': tensor([0.3169, 0.3912, 0.2371, 0.3348, 0.3895, 0.3828, 0.3385, 0.3568, 0.3425,\n",
      "        0.4265, 0.3489, 0.3829, 0.4602, 0.3124, 0.2141, 0.2039, 0.2390, 0.2560,\n",
      "        0.4805, 0.4185, 0.2441, 0.4203, 0.2680]), 'labels': tensor([11, 11, 11, 11, 11, 11, 11, 11, 10, 11, 11, 14,  8, 11, 11,  9, 13, 11,\n",
      "         9, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "26690\n",
      "{'image_id': 27186, 'boxes': tensor([[349, 158, 591, 400],\n",
      "        [162, 166, 393, 429],\n",
      "        [  0, 169, 201, 429],\n",
      "        [332, 153, 402, 210],\n",
      "        [379, 382, 639, 427],\n",
      "        [  0, 160, 633, 428]], dtype=torch.int32), 'scores': tensor([0.3324, 0.4364, 0.4609, 0.7611, 0.1874, 0.7476]), 'objectness_scores': tensor([0.3099, 0.4154, 0.3345, 0.2393, 0.2166, 0.4384]), 'labels': tensor([ 7,  7, 13, 16,  9, 12], dtype=torch.int32)}\n",
      "27186\n",
      "{'image_id': 27620, 'boxes': tensor([[522,   3, 640, 103],\n",
      "        [157, 326, 237, 431],\n",
      "        [383,  93, 436, 129],\n",
      "        [129, 125, 170, 147],\n",
      "        [ 77, 111, 555, 456],\n",
      "        [472,  89, 521, 107],\n",
      "        [  0, 320, 157, 479],\n",
      "        [523, 138, 638, 220],\n",
      "        [478, 421, 637, 481],\n",
      "        [ 14, 389, 145, 448],\n",
      "        [248, 294, 284, 322],\n",
      "        [236, 174, 393, 207]], dtype=torch.int32), 'scores': tensor([0.5343, 0.8417, 0.9617, 0.3633, 0.2792, 0.6580, 0.9660, 0.4471, 0.2383,\n",
      "        0.9100, 0.1951, 0.6592]), 'objectness_scores': tensor([0.4819, 0.2736, 0.4232, 0.2152, 0.3163, 0.2073, 0.3531, 0.3470, 0.2219,\n",
      "        0.3014, 0.2148, 0.4527]), 'labels': tensor([14, 10,  4,  7, 14, 11, 14, 14,  7, 14, 16, 14], dtype=torch.int32)}\n",
      "27620\n",
      "{'image_id': 27696, 'boxes': tensor([[ 88,  40, 528, 300],\n",
      "        [328,  69, 361, 103],\n",
      "        [301,  30, 465,  77],\n",
      "        [ 91, 208, 145, 250],\n",
      "        [197,  51, 393, 128],\n",
      "        [449, 114, 485, 137],\n",
      "        [428,  74, 518, 165],\n",
      "        [287,  52, 320,  74],\n",
      "        [231, 296, 298, 329],\n",
      "        [259, 126, 420, 290],\n",
      "        [399, 229, 460, 266],\n",
      "        [513, 128, 550, 164],\n",
      "        [102,  98, 223, 171],\n",
      "        [128, 151, 280, 300],\n",
      "        [482, 132, 517, 165],\n",
      "        [359, 110, 406, 132],\n",
      "        [246, 152, 305, 186],\n",
      "        [  0,   0, 143,  72],\n",
      "        [  2,  37, 635, 410],\n",
      "        [190,  73, 298, 116],\n",
      "        [411, 107, 456, 129],\n",
      "        [ 89, 152, 134, 186],\n",
      "        [422,  68, 495,  99],\n",
      "        [269,  61, 396, 131],\n",
      "        [225,  48, 252,  73],\n",
      "        [193, 231, 281, 267],\n",
      "        [221, 310, 267, 335]], dtype=torch.int32), 'scores': tensor([0.8265, 0.2108, 0.3743, 0.3971, 0.2332, 0.3753, 0.5064, 0.1608, 0.2855,\n",
      "        0.7448, 0.4960, 0.5058, 0.2280, 0.4461, 0.3048, 0.3381, 0.3570, 0.3072,\n",
      "        0.2128, 0.1896, 0.4380, 0.2663, 0.3115, 0.2950, 0.2169, 0.2570, 0.2030]), 'objectness_scores': tensor([0.2093, 0.2137, 0.3384, 0.3702, 0.2066, 0.2446, 0.5137, 0.3900, 0.3749,\n",
      "        0.5467, 0.5111, 0.5765, 0.3849, 0.5065, 0.2957, 0.2742, 0.4836, 0.2654,\n",
      "        0.4983, 0.4137, 0.3522, 0.3054, 0.3902, 0.4649, 0.2324, 0.2510, 0.2389]), 'labels': tensor([12, 11, 11, 12, 11, 11, 11,  2, 12, 12,  3, 12,  4, 12, 10, 11,  2,  7,\n",
      "        11,  3, 11,  7, 11, 12, 11, 11, 12], dtype=torch.int32)}\n",
      "27696\n",
      "{'image_id': 27768, 'boxes': tensor([[256,  39, 312, 166],\n",
      "        [220, 496, 286, 570]], dtype=torch.int32), 'scores': tensor([0.4965, 0.1870]), 'objectness_scores': tensor([0.2381, 0.2849]), 'labels': tensor([ 8, 12], dtype=torch.int32)}\n",
      "27768\n",
      "{'image_id': 27982, 'boxes': tensor([[ 83, 260, 135, 324],\n",
      "        [450, 267, 482, 298],\n",
      "        [444, 219, 469, 250],\n",
      "        [374, 107, 467, 146],\n",
      "        [424,   0, 452,  22],\n",
      "        [454, 210, 486, 243],\n",
      "        [ 26, 182,  53, 249],\n",
      "        [444, 226, 461, 252],\n",
      "        [396,  60, 418, 103],\n",
      "        [433, 232, 451, 262],\n",
      "        [380, 185, 399, 201],\n",
      "        [456, 239, 486, 272],\n",
      "        [443, 249, 460, 279]], dtype=torch.int32), 'scores': tensor([0.9409, 0.1894, 0.2701, 0.3830, 0.5146, 0.3804, 0.3132, 0.3823, 0.2221,\n",
      "        0.2254, 0.1808, 0.2747, 0.3387]), 'objectness_scores': tensor([0.2218, 0.3608, 0.3106, 0.6882, 0.2080, 0.3643, 0.6290, 0.2077, 0.5498,\n",
      "        0.3461, 0.2354, 0.4127, 0.2935]), 'labels': tensor([10, 10,  2, 11,  9,  2, 11, 11, 11,  3,  4,  3,  2], dtype=torch.int32)}\n",
      "27982\n",
      "{'image_id': 29393, 'boxes': tensor([[170, 156, 361, 338]], dtype=torch.int32), 'scores': tensor([0.9820]), 'objectness_scores': tensor([0.4846]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "29393\n",
      "{'image_id': 29596, 'boxes': tensor([[158, 250, 248, 319],\n",
      "        [192, 177, 244, 216],\n",
      "        [314, 260, 446, 371],\n",
      "        [485, 155, 535, 266],\n",
      "        [477, 265, 639, 427],\n",
      "        [326, 253, 338, 260],\n",
      "        [355, 235, 381, 251],\n",
      "        [ 29,  86,  84, 160],\n",
      "        [  0,  36, 108, 202],\n",
      "        [133, 268, 199, 322],\n",
      "        [192, 178, 243, 259],\n",
      "        [383, 258, 401, 270],\n",
      "        [114, 271, 189, 335],\n",
      "        [383, 232, 405, 262],\n",
      "        [156, 251, 191, 263],\n",
      "        [485, 155, 535, 209],\n",
      "        [321, 261, 342, 266],\n",
      "        [405, 262, 426, 267],\n",
      "        [398, 231, 426, 258],\n",
      "        [179, 226, 208, 242],\n",
      "        [  0, 256, 250, 428]], dtype=torch.int32), 'scores': tensor([0.8032, 0.4089, 0.4266, 0.1837, 0.1695, 0.2134, 0.1993, 0.3531, 0.5991,\n",
      "        0.8071, 0.3338, 0.1173, 0.9575, 0.1564, 0.2806, 0.1898, 0.3202, 0.2337,\n",
      "        0.3072, 0.3614, 0.9997]), 'objectness_scores': tensor([0.2583, 0.2056, 0.3533, 0.2897, 0.2816, 0.3008, 0.2197, 0.2206, 0.2196,\n",
      "        0.3390, 0.3393, 0.2256, 0.3193, 0.4149, 0.2040, 0.2994, 0.2212, 0.2125,\n",
      "        0.4875, 0.3303, 0.4599]), 'labels': tensor([13,  8, 10,  8, 15, 14,  3, 10, 10, 13, 13, 11, 13,  7, 11, 13, 11, 11,\n",
      "         3,  4, 13], dtype=torch.int32)}\n",
      "29596\n",
      "{'image_id': 29984, 'boxes': tensor([[319, 163, 616, 426],\n",
      "        [323, 166, 618, 280]], dtype=torch.int32), 'scores': tensor([0.2627, 0.9993]), 'objectness_scores': tensor([0.5700, 0.2221]), 'labels': tensor([11,  6], dtype=torch.int32)}\n",
      "29984\n",
      "{'image_id': 30213, 'boxes': tensor([[588, 326, 639, 450],\n",
      "        [335, 191, 351, 198],\n",
      "        [587, 186, 612, 212],\n",
      "        [342, 164, 474, 218],\n",
      "        [350,  44, 400, 140],\n",
      "        [177, 206, 233, 247],\n",
      "        [187, 343, 249, 411],\n",
      "        [335, 163, 468, 232],\n",
      "        [448, 263, 496, 330],\n",
      "        [509,  56, 558, 114],\n",
      "        [402, 172, 444, 187],\n",
      "        [498, 234, 529, 252],\n",
      "        [346, 166, 368, 194],\n",
      "        [403, 172, 425, 185],\n",
      "        [396,  37, 460, 139],\n",
      "        [566,  58, 633, 112],\n",
      "        [ 35, 146, 101, 198]], dtype=torch.int32), 'scores': tensor([0.2163, 0.4287, 0.2564, 0.4215, 0.3463, 0.6792, 0.6826, 0.6764, 0.5525,\n",
      "        0.3636, 0.3542, 0.3999, 0.3352, 0.2217, 0.5180, 0.2389, 0.4268]), 'objectness_scores': tensor([0.2009, 0.2394, 0.2030, 0.3314, 0.3426, 0.2670, 0.3759, 0.2465, 0.3328,\n",
      "        0.3367, 0.2393, 0.2391, 0.2221, 0.2308, 0.3353, 0.3906, 0.3923]), 'labels': tensor([11, 11, 11, 11,  7, 10, 10, 15, 15, 16,  0, 11,  7, 11,  7, 12, 12],\n",
      "       dtype=torch.int32)}\n",
      "30213\n",
      "{'image_id': 30494, 'boxes': tensor([[349,   2, 637, 301],\n",
      "        [105,  26, 288, 227],\n",
      "        [105,  24, 140, 115]], dtype=torch.int32), 'scores': tensor([0.2569, 0.9775, 0.7220]), 'objectness_scores': tensor([0.3479, 0.4950, 0.2359]), 'labels': tensor([3, 3, 2], dtype=torch.int32)}\n",
      "30494\n",
      "{'image_id': 31093, 'boxes': tensor([[295, 300, 356, 328],\n",
      "        [225, 303, 283, 323],\n",
      "        [291,  82, 341, 115],\n",
      "        [498,  27, 510,  33],\n",
      "        [277, 205, 315, 255],\n",
      "        [240, 314, 355, 356],\n",
      "        [504,  30, 516,  37]], dtype=torch.int32), 'scores': tensor([0.4682, 0.5675, 0.2210, 0.2261, 0.3241, 0.9874, 0.2424]), 'objectness_scores': tensor([0.3674, 0.3032, 0.5964, 0.2078, 0.2485, 0.5574, 0.2302]), 'labels': tensor([ 0, 14, 14, 11,  7,  9, 11], dtype=torch.int32)}\n",
      "31093\n",
      "{'image_id': 31248, 'boxes': tensor([[ 42,  14, 163, 315],\n",
      "        [337, 151, 341, 157],\n",
      "        [225,  70, 304, 134],\n",
      "        [361, 237, 422, 332],\n",
      "        [ 49,  21, 155, 200],\n",
      "        [104, 238, 161, 332],\n",
      "        [363, 152, 421, 245],\n",
      "        [190, 149, 194, 156],\n",
      "        [  0,  70, 105, 320],\n",
      "        [104, 146, 162, 187],\n",
      "        [104, 146, 162, 244],\n",
      "        [170, 166, 362, 316]], dtype=torch.int32), 'scores': tensor([0.7615, 0.3295, 0.3303, 0.2206, 0.6670, 0.2026, 0.4596, 0.3000, 0.4807,\n",
      "        0.3783, 0.3978, 0.9684]), 'objectness_scores': tensor([0.2005, 0.4171, 0.2138, 0.2351, 0.2149, 0.2908, 0.3514, 0.4260, 0.2225,\n",
      "        0.2105, 0.3398, 0.3295]), 'labels': tensor([13, 11, 13, 13, 13,  6,  6,  0, 13,  6,  6, 13], dtype=torch.int32)}\n",
      "31248\n",
      "{'image_id': 31296, 'boxes': tensor([[546, 101, 581, 119],\n",
      "        [407, 173, 437, 255],\n",
      "        [ 83, 112, 129, 140],\n",
      "        [402, 116, 429, 142],\n",
      "        [213, 215, 254, 227],\n",
      "        [226, 186, 258, 195]], dtype=torch.int32), 'scores': tensor([0.2973, 0.8896, 0.2535, 0.4843, 0.2515, 0.3388]), 'objectness_scores': tensor([0.2145, 0.2148, 0.2149, 0.2023, 0.2174, 0.2193]), 'labels': tensor([ 7,  7,  7, 11,  8, 14], dtype=torch.int32)}\n",
      "31296\n",
      "{'image_id': 31620, 'boxes': tensor([[216, 206, 229, 224],\n",
      "        [318,  26, 341,  58],\n",
      "        [161, 275, 181, 292],\n",
      "        [290, 303, 315, 347],\n",
      "        [265, 210, 294, 250],\n",
      "        [219, 314, 228, 332],\n",
      "        [110, 328, 264, 405],\n",
      "        [278,   9, 301,  41],\n",
      "        [354, 286, 402, 366],\n",
      "        [239, 247, 253, 259],\n",
      "        [396, 292, 453, 304],\n",
      "        [267, 253, 306, 352],\n",
      "        [ 76, 307, 117, 353],\n",
      "        [  9, 304, 116, 356],\n",
      "        [304, 292, 470, 361],\n",
      "        [181, 301, 193, 314],\n",
      "        [215, 256, 225, 311],\n",
      "        [110, 329, 263, 442],\n",
      "        [  0,   0, 478, 238],\n",
      "        [146, 297, 189, 329],\n",
      "        [418, 257, 437, 264]], dtype=torch.int32), 'scores': tensor([0.3588, 0.6860, 0.1600, 0.1942, 0.3615, 0.2311, 0.3021, 0.1875, 0.6145,\n",
      "        0.2630, 0.9974, 0.9825, 0.1752, 0.4376, 0.1874, 0.2526, 0.2677, 0.6145,\n",
      "        0.3898, 0.2803, 0.2741]), 'objectness_scores': tensor([0.2047, 0.2003, 0.2083, 0.5194, 0.6854, 0.3424, 0.2039, 0.2136, 0.4950,\n",
      "        0.2103, 0.2042, 0.5349, 0.2446, 0.2959, 0.4019, 0.2165, 0.3058, 0.3413,\n",
      "        0.2337, 0.4817, 0.4248]), 'labels': tensor([11,  7,  4,  7,  7, 11,  7,  7,  6, 11,  5,  9,  7,  7,  2, 14, 11, 12,\n",
      "         6, 13, 11], dtype=torch.int32)}\n",
      "31620\n",
      "{'image_id': 31735, 'boxes': tensor([[ 56, 273, 200, 416],\n",
      "        [362, 282, 411, 335],\n",
      "        [520, 268, 577, 315],\n",
      "        [494, 352, 638, 479],\n",
      "        [298, 232, 638, 460],\n",
      "        [ 18, 114, 225, 291],\n",
      "        [545, 190, 596, 262],\n",
      "        [200, 283, 301, 429],\n",
      "        [323, 236, 452, 324],\n",
      "        [  7, 189,  32, 211],\n",
      "        [561,  94, 639, 192],\n",
      "        [550, 259, 637, 318],\n",
      "        [227, 194, 296, 302]], dtype=torch.int32), 'scores': tensor([0.5435, 0.5954, 0.9928, 0.4094, 0.9969, 0.3339, 0.4677, 0.3849, 0.7477,\n",
      "        0.2326, 0.1735, 0.9771, 0.3989]), 'objectness_scores': tensor([0.2083, 0.2612, 0.2709, 0.2568, 0.4918, 0.2330, 0.2598, 0.2171, 0.2234,\n",
      "        0.2197, 0.2286, 0.2592, 0.2856]), 'labels': tensor([10, 11, 13, 10, 13, 10,  7, 10,  7, 14,  5, 13,  6], dtype=torch.int32)}\n",
      "31735\n",
      "{'image_id': 32861, 'boxes': tensor([[ 29,  53, 364, 312],\n",
      "        [124, 409, 139, 454]], dtype=torch.int32), 'scores': tensor([0.9557, 0.3780]), 'objectness_scores': tensor([0.6015, 0.2417]), 'labels': tensor([10,  7], dtype=torch.int32)}\n",
      "32861\n",
      "{'image_id': 32901, 'boxes': tensor([[211, 379, 316, 411],\n",
      "        [ 82, 369, 193, 397],\n",
      "        [350, 204, 386, 378],\n",
      "        [403,   7, 503,  47],\n",
      "        [547, 429, 554, 434]], dtype=torch.int32), 'scores': tensor([0.2816, 0.7115, 0.9975, 0.3413, 0.1862]), 'objectness_scores': tensor([0.2088, 0.2441, 0.2358, 0.4334, 0.2756]), 'labels': tensor([11, 11,  7, 11, 11], dtype=torch.int32)}\n",
      "32901\n",
      "{'image_id': 32941, 'boxes': tensor([[411,  93, 427, 125],\n",
      "        [188, 231, 266, 397],\n",
      "        [241, 183, 245, 191],\n",
      "        [  6, 428, 376, 627],\n",
      "        [206, 125, 216, 157]], dtype=torch.int32), 'scores': tensor([0.2816, 0.2416, 0.1781, 0.4963, 0.1847]), 'objectness_scores': tensor([0.2186, 0.2214, 0.2256, 0.2088, 0.3736]), 'labels': tensor([11,  8, 11,  5,  8], dtype=torch.int32)}\n",
      "32941\n",
      "{'image_id': 33109, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "33109\n",
      "{'image_id': 33854, 'boxes': tensor([[328, 127, 336, 153],\n",
      "        [475, 146, 638, 243],\n",
      "        [351, 150, 357, 167],\n",
      "        [244, 131, 263, 156],\n",
      "        [292, 173, 323, 186]], dtype=torch.int32), 'scores': tensor([0.1082, 0.9989, 0.1589, 0.2408, 0.5091]), 'objectness_scores': tensor([0.2024, 0.4056, 0.2275, 0.3400, 0.2298]), 'labels': tensor([ 3,  1,  3,  6, 14], dtype=torch.int32)}\n",
      "33854\n",
      "{'image_id': 34417, 'boxes': tensor([[355,  51, 372,  61],\n",
      "        [289,  55, 302,  67],\n",
      "        [  7,   0, 495, 377]], dtype=torch.int32), 'scores': tensor([0.2002, 0.1983, 0.4506]), 'objectness_scores': tensor([0.2143, 0.2318, 0.2162]), 'labels': tensor([11, 11, 15], dtype=torch.int32)}\n",
      "34417\n",
      "{'image_id': 34760, 'boxes': tensor([[137, 340, 159, 395],\n",
      "        [393, 222, 425, 257],\n",
      "        [177, 323, 373, 423],\n",
      "        [274, 305, 295, 321],\n",
      "        [371, 528, 411, 563],\n",
      "        [  0,  90, 100, 384],\n",
      "        [178, 151, 226, 270],\n",
      "        [  0, 408, 129, 507],\n",
      "        [ 82, 360, 108, 382],\n",
      "        [  0, 397,  47, 453],\n",
      "        [183, 325, 202, 335],\n",
      "        [  0, 134,  53, 339],\n",
      "        [179, 294, 199, 307],\n",
      "        [291, 121, 403, 419],\n",
      "        [  2,   3, 421, 634]], dtype=torch.int32), 'scores': tensor([0.3748, 0.2861, 0.9045, 0.3382, 0.4161, 0.5638, 0.3659, 0.9724, 0.1768,\n",
      "        0.5067, 0.7276, 0.5266, 0.5838, 0.7898, 0.9270]), 'objectness_scores': tensor([0.3234, 0.2140, 0.5022, 0.2205, 0.3133, 0.4883, 0.2056, 0.4900, 0.2461,\n",
      "        0.3698, 0.2716, 0.2826, 0.2190, 0.3613, 0.2408]), 'labels': tensor([ 8, 11, 15, 11, 11,  7,  7, 15,  8, 16, 11,  8, 11,  7, 15],\n",
      "       dtype=torch.int32)}\n",
      "34760\n",
      "{'image_id': 34873, 'boxes': tensor([[224, 125, 309, 236],\n",
      "        [305, 193, 329, 265],\n",
      "        [286, 188, 307, 257],\n",
      "        [110, 264, 169, 349],\n",
      "        [135, 256, 294, 381]], dtype=torch.int32), 'scores': tensor([0.9904, 0.3828, 0.3119, 0.5602, 0.2585]), 'objectness_scores': tensor([0.2817, 0.2270, 0.2239, 0.2870, 0.4828]), 'labels': tensor([15, 11,  4,  6, 15], dtype=torch.int32)}\n",
      "34873\n",
      "{'image_id': 35197, 'boxes': tensor([[ 52, 306,  86, 341],\n",
      "        [  0, 345, 190, 452],\n",
      "        [ 38,  38, 183, 244],\n",
      "        [375, 276, 405, 299],\n",
      "        [127, 335, 263, 425],\n",
      "        [ 45, 332, 112, 392],\n",
      "        [396, 312, 413, 319]], dtype=torch.int32), 'scores': tensor([0.2464, 0.6587, 0.4544, 0.3773, 0.7993, 0.4940, 0.2536]), 'objectness_scores': tensor([0.2052, 0.5178, 0.2096, 0.2845, 0.3067, 0.3153, 0.2917]), 'labels': tensor([11,  8,  9,  7,  9,  8, 14], dtype=torch.int32)}\n",
      "35197\n",
      "{'image_id': 35326, 'boxes': tensor([[129, 235, 157, 248],\n",
      "        [544, 134, 633, 421],\n",
      "        [116, 311, 523, 439],\n",
      "        [  1, 306, 630, 479]], dtype=torch.int32), 'scores': tensor([0.3646, 0.9342, 0.2434, 0.4361]), 'objectness_scores': tensor([0.2017, 0.2106, 0.4342, 0.2286]), 'labels': tensor([13,  7, 16, 15], dtype=torch.int32)}\n",
      "35326\n",
      "{'image_id': 35682, 'boxes': tensor([[122, 540, 164, 584],\n",
      "        [159, 321, 325, 383],\n",
      "        [ 49, 428, 449, 586],\n",
      "        [225, 569, 270, 614],\n",
      "        [ 67, 325, 370, 416],\n",
      "        [ 68, 374, 190, 499],\n",
      "        [  0, 413, 475, 641],\n",
      "        [ 91, 282, 162, 379]], dtype=torch.int32), 'scores': tensor([0.2386, 0.8943, 0.9560, 0.7632, 0.4734, 0.9644, 0.6315, 0.4795]), 'objectness_scores': tensor([0.2355, 0.2310, 0.2056, 0.2309, 0.2068, 0.3130, 0.3322, 0.2733]), 'labels': tensor([14, 12, 12, 12, 12, 10, 12, 10], dtype=torch.int32)}\n",
      "35682\n",
      "{'image_id': 35770, 'boxes': tensor([[294, 133, 476, 373],\n",
      "        [265,  18, 347, 100],\n",
      "        [ 34, 134, 476, 397]], dtype=torch.int32), 'scores': tensor([0.5088, 0.2431, 0.9018]), 'objectness_scores': tensor([0.2308, 0.2196, 0.2212]), 'labels': tensor([ 8, 10, 15], dtype=torch.int32)}\n",
      "35770\n",
      "{'image_id': 36494, 'boxes': tensor([[100, 324, 205, 421]], dtype=torch.int32), 'scores': tensor([0.8826]), 'objectness_scores': tensor([0.2398]), 'labels': tensor([10], dtype=torch.int32)}\n",
      "36494\n",
      "{'image_id': 36539, 'boxes': tensor([[ 72, 355,  86, 375],\n",
      "        [197, 296, 225, 317],\n",
      "        [118, 391, 127, 400],\n",
      "        [228, 507, 250, 533],\n",
      "        [173, 498, 204, 526],\n",
      "        [200, 313, 223, 325],\n",
      "        [177, 402, 189, 433],\n",
      "        [ 99, 438, 121, 457],\n",
      "        [ 82, 396,  90, 408],\n",
      "        [238, 400, 255, 431],\n",
      "        [ 82, 434,  98, 450]], dtype=torch.int32), 'scores': tensor([0.1929, 0.3264, 0.1264, 0.7654, 0.7156, 0.8857, 0.2940, 0.2029, 0.1229,\n",
      "        0.6874, 0.3539]), 'objectness_scores': tensor([0.3246, 0.3102, 0.3119, 0.4863, 0.4910, 0.5851, 0.4836, 0.4300, 0.3040,\n",
      "        0.5207, 0.4963]), 'labels': tensor([11,  8, 11, 12, 11,  3, 11,  7, 11,  8,  8], dtype=torch.int32)}\n",
      "36539\n",
      "{'image_id': 36844, 'boxes': tensor([[250,  50, 298,  74],\n",
      "        [496, 208, 560, 282],\n",
      "        [440, 394, 572, 480],\n",
      "        [422, 265, 630, 411],\n",
      "        [584, 297, 614, 355],\n",
      "        [440, 207, 479, 286],\n",
      "        [187,   9, 344,  73]], dtype=torch.int32), 'scores': tensor([0.1354, 0.4145, 0.3561, 0.8224, 0.4144, 0.3252, 0.4478]), 'objectness_scores': tensor([0.2103, 0.2457, 0.2028, 0.2654, 0.2556, 0.3883, 0.5471]), 'labels': tensor([11, 13, 15, 13, 11, 13,  6], dtype=torch.int32)}\n",
      "36844\n",
      "{'image_id': 36936, 'boxes': tensor([[ 77, 296, 438, 403],\n",
      "        [327, 296, 356, 333],\n",
      "        [299, 278, 325, 314],\n",
      "        [  0, 223,  53, 292],\n",
      "        [250, 127, 635, 403],\n",
      "        [  1,   3, 243, 160],\n",
      "        [313, 307, 451, 379],\n",
      "        [320, 329, 371, 374]], dtype=torch.int32), 'scores': tensor([0.5765, 0.9110, 0.2580, 0.1720, 0.7341, 0.4162, 0.3674, 0.6751]), 'objectness_scores': tensor([0.2725, 0.2194, 0.2284, 0.2565, 0.3878, 0.2088, 0.2636, 0.2084]), 'labels': tensor([12, 10, 15, 10, 13,  8,  9, 12], dtype=torch.int32)}\n",
      "36936\n",
      "{'image_id': 37689, 'boxes': tensor([[111, 164, 116, 168],\n",
      "        [160, 195, 166, 200],\n",
      "        [184, 204, 188, 207],\n",
      "        [307, 272, 311, 276],\n",
      "        [ 49, 141,  55, 145],\n",
      "        [262,  68, 272,  81],\n",
      "        [289, 264, 293, 267],\n",
      "        [  0, 136, 636, 427],\n",
      "        [ 84, 143,  89, 148],\n",
      "        [356, 144, 365, 154],\n",
      "        [  7, 125,  16, 131],\n",
      "        [356, 142, 366, 154],\n",
      "        [ 69, 136,  75, 141],\n",
      "        [316, 233, 327, 244],\n",
      "        [ 24, 135,  32, 141],\n",
      "        [ 98, 147, 103, 151],\n",
      "        [ 34, 136,  40, 141],\n",
      "        [135, 170, 139, 174],\n",
      "        [205, 219, 209, 223]], dtype=torch.int32), 'scores': tensor([0.3613, 0.2751, 0.3146, 0.3220, 0.2204, 0.2287, 0.2490, 0.9972, 0.2622,\n",
      "        0.1982, 0.2632, 0.2105, 0.3089, 0.2726, 0.2755, 0.3384, 0.2534, 0.2316,\n",
      "        0.2715]), 'objectness_scores': tensor([0.2830, 0.2078, 0.2124, 0.2139, 0.2699, 0.2907, 0.2104, 0.2289, 0.2398,\n",
      "        0.2137, 0.2648, 0.3578, 0.2852, 0.5942, 0.2226, 0.2219, 0.2771, 0.2102,\n",
      "        0.2215]), 'labels': tensor([11, 11, 11, 11, 14, 14, 11,  8, 11,  0, 11,  8, 11, 11, 11, 11, 11, 11,\n",
      "        11], dtype=torch.int32)}\n",
      "37689\n",
      "{'image_id': 37740, 'boxes': tensor([[271, 223, 364, 251],\n",
      "        [217, 113, 294, 218],\n",
      "        [131, 195, 448, 426],\n",
      "        [458, 200, 624, 381],\n",
      "        [107, 272, 125, 302],\n",
      "        [  1, 331, 138, 480],\n",
      "        [498,  23, 536, 106]], dtype=torch.int32), 'scores': tensor([0.9298, 0.5374, 0.8361, 0.2186, 0.2919, 0.9857, 0.7222]), 'objectness_scores': tensor([0.3934, 0.2059, 0.3401, 0.2100, 0.4239, 0.3870, 0.2309]), 'labels': tensor([14,  6, 14,  2, 11, 13,  8], dtype=torch.int32)}\n",
      "37740\n",
      "{'image_id': 37777, 'boxes': tensor([[277, 111, 289, 127],\n",
      "        [231, 135, 255, 172],\n",
      "        [184,  77, 208, 112],\n",
      "        [208,  83, 227, 114],\n",
      "        [127,  90, 193, 107],\n",
      "        [196, 138, 209, 179],\n",
      "        [208, 136, 221, 175],\n",
      "        [ 80, 126,  84, 129],\n",
      "        [ 99, 135, 109, 174],\n",
      "        [220, 136, 231, 172],\n",
      "        [ 72, 179, 287, 229],\n",
      "        [231, 135, 298, 185],\n",
      "        [186,  77, 197, 110],\n",
      "        [139, 135, 196, 150],\n",
      "        [255, 138, 273, 176],\n",
      "        [126,  59, 188,  97],\n",
      "        [273, 140, 294, 182],\n",
      "        [294, 139, 301, 184],\n",
      "        [ 71,  58,  88,  67],\n",
      "        [ 47,  86,  88, 166],\n",
      "        [227,  85, 242, 114],\n",
      "        [196, 136, 227, 179],\n",
      "        [220, 136, 230, 171],\n",
      "        [195,  80, 208, 113],\n",
      "        [256, 137, 295, 182]], dtype=torch.int32), 'scores': tensor([0.2290, 0.2298, 0.2471, 0.2675, 0.5651, 0.3089, 0.2519, 0.1818, 0.2845,\n",
      "        0.2310, 0.8012, 0.4271, 0.6362, 0.1610, 0.2451, 0.3700, 0.2269, 0.3238,\n",
      "        0.2196, 0.3119, 0.3674, 0.1818, 0.2245, 0.2494, 0.6135]), 'objectness_scores': tensor([0.3389, 0.4092, 0.3316, 0.3784, 0.5837, 0.3211, 0.3049, 0.2141, 0.3084,\n",
      "        0.2089, 0.2303, 0.2006, 0.2641, 0.3709, 0.2578, 0.4540, 0.2194, 0.2261,\n",
      "        0.2856, 0.2468, 0.3986, 0.3413, 0.3324, 0.2365, 0.3894]), 'labels': tensor([11, 11, 11, 11, 11, 14, 11,  0, 11, 11, 12, 11, 11, 11, 11,  8, 11, 11,\n",
      "        11, 11, 11, 13, 11, 11, 13], dtype=torch.int32)}\n",
      "37777\n",
      "{'image_id': 38576, 'boxes': tensor([[117, 158, 206, 190],\n",
      "        [116, 177, 233, 259],\n",
      "        [124, 190, 228, 224],\n",
      "        [  4, 289, 432, 638],\n",
      "        [  0, 355, 433, 637],\n",
      "        [ 13, 279, 352, 395],\n",
      "        [ 44, 380, 425, 511]], dtype=torch.int32), 'scores': tensor([0.3769, 0.9403, 0.2315, 0.9881, 0.9827, 0.3135, 0.9970]), 'objectness_scores': tensor([0.2312, 0.2549, 0.7836, 0.2359, 0.5142, 0.2860, 0.7243]), 'labels': tensor([11, 14,  7, 14, 14, 11, 14], dtype=torch.int32)}\n",
      "38576\n",
      "{'image_id': 38678, 'boxes': tensor([[  5, 361, 151, 451],\n",
      "        [243, 521, 479, 640],\n",
      "        [218, 294, 309, 383],\n",
      "        [ 91, 103, 135, 114]], dtype=torch.int32), 'scores': tensor([0.6677, 0.3565, 0.8335, 0.2409]), 'objectness_scores': tensor([0.3498, 0.3185, 0.3935, 0.2116]), 'labels': tensor([12, 10,  7, 11], dtype=torch.int32)}\n",
      "38678\n",
      "{'image_id': 39477, 'boxes': tensor([[ 90, 288, 256, 421],\n",
      "        [102, 213, 136, 258],\n",
      "        [131,  47, 198, 281],\n",
      "        [ 93,   0, 245,  40],\n",
      "        [  0, 245, 157, 418],\n",
      "        [223, 317, 315, 402],\n",
      "        [275, 271, 301, 308],\n",
      "        [205, 223, 257, 300]], dtype=torch.int32), 'scores': tensor([0.1537, 0.3981, 0.3082, 0.3199, 0.5346, 0.5801, 0.1410, 0.5147]), 'objectness_scores': tensor([0.2382, 0.2189, 0.2275, 0.5718, 0.2107, 0.2840, 0.2021, 0.2009]), 'labels': tensor([11,  8,  7,  7,  8, 12, 14, 10], dtype=torch.int32)}\n",
      "39477\n",
      "{'image_id': 39484, 'boxes': tensor([[559, 223, 623, 261],\n",
      "        [404, 357, 415, 367],\n",
      "        [468, 352, 476, 363],\n",
      "        [113, 161, 193, 210],\n",
      "        [356, 354, 369, 366],\n",
      "        [ 14, 282,  42, 289],\n",
      "        [277, 211, 331, 231],\n",
      "        [417, 141, 444, 163]], dtype=torch.int32), 'scores': tensor([0.3637, 0.1530, 0.1647, 0.9284, 0.2122, 0.3557, 0.2901, 0.2635]), 'objectness_scores': tensor([0.2298, 0.2021, 0.2164, 0.2490, 0.2065, 0.2700, 0.2286, 0.2030]), 'labels': tensor([ 7, 14, 11,  8, 14, 14, 14,  8], dtype=torch.int32)}\n",
      "39484\n",
      "{'image_id': 39769, 'boxes': tensor([[  6,  51, 326, 473],\n",
      "        [341,  23, 642, 371]], dtype=torch.int32), 'scores': tensor([0.9464, 0.2776]), 'objectness_scores': tensor([0.4857, 0.4738]), 'labels': tensor([2, 7], dtype=torch.int32)}\n",
      "39769\n",
      "{'image_id': 40083, 'boxes': tensor([[ 40,   0, 457, 109],\n",
      "        [175, 251, 211, 281],\n",
      "        [272,  51, 383, 104],\n",
      "        [ 29, 207,  59, 305],\n",
      "        [ 44,   0, 458, 269]], dtype=torch.int32), 'scores': tensor([0.3702, 0.2343, 0.1937, 0.1697, 0.9114]), 'objectness_scores': tensor([0.3009, 0.2618, 0.2003, 0.2357, 0.4202]), 'labels': tensor([ 7, 11, 13, 11,  6], dtype=torch.int32)}\n",
      "40083\n",
      "{'image_id': 40471, 'boxes': tensor([[ 96, 209, 112, 225],\n",
      "        [170,  93, 222, 136],\n",
      "        [293, 251, 313, 268],\n",
      "        [314, 355, 346, 401],\n",
      "        [ 98,   7, 319, 123],\n",
      "        [ 11, 235,  32, 261],\n",
      "        [265, 353, 338, 463],\n",
      "        [ 35, 155,  92, 279],\n",
      "        [222,  93, 258, 130],\n",
      "        [ 33, 100,  92, 279],\n",
      "        [ 73, 352, 163, 468],\n",
      "        [170,  91, 258, 136],\n",
      "        [  0,  41,  36, 277],\n",
      "        [  0, 354,  75, 395],\n",
      "        [316, 165, 373, 282],\n",
      "        [  0, 301,  33, 337],\n",
      "        [295, 201, 315, 228]], dtype=torch.int32), 'scores': tensor([0.7709, 0.4167, 0.2690, 0.2129, 0.5739, 0.2882, 0.3620, 0.2097, 0.4636,\n",
      "        0.3097, 0.1541, 0.1917, 0.4970, 0.5230, 0.2414, 0.1520, 0.2390]), 'objectness_scores': tensor([0.2016, 0.2343, 0.2365, 0.2482, 0.7270, 0.2240, 0.3113, 0.2261, 0.2009,\n",
      "        0.2919, 0.3364, 0.2163, 0.2020, 0.3368, 0.2735, 0.2061, 0.2061]), 'labels': tensor([10,  9, 11, 11,  6,  8,  8,  3,  7,  9,  7,  6,  7, 14,  7,  8,  3],\n",
      "       dtype=torch.int32)}\n",
      "40471\n",
      "{'image_id': 42070, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "42070\n",
      "{'image_id': 42102, 'boxes': tensor([[ 30,  97, 223, 330],\n",
      "        [ 72, 565, 119, 635],\n",
      "        [180, 553, 240, 619],\n",
      "        [ 41, 257, 198, 413],\n",
      "        [120, 117, 142, 260]], dtype=torch.int32), 'scores': tensor([0.9952, 0.4936, 0.6157, 0.2820, 0.1791]), 'objectness_scores': tensor([0.2883, 0.2837, 0.2590, 0.3529, 0.4562]), 'labels': tensor([ 7,  7,  7,  9, 14], dtype=torch.int32)}\n",
      "42102\n",
      "{'image_id': 42628, 'boxes': tensor([[263, 226, 299, 263],\n",
      "        [520,  43, 530,  56],\n",
      "        [278,  40, 286,  49],\n",
      "        [  0,  57, 635, 423],\n",
      "        [416,  41, 425,  51],\n",
      "        [548,  77, 563,  97],\n",
      "        [532,  78, 544,  94],\n",
      "        [385, 214, 454, 359]], dtype=torch.int32), 'scores': tensor([0.3521, 0.2114, 0.6639, 0.3555, 0.2450, 0.1592, 0.2403, 0.1974]), 'objectness_scores': tensor([0.2856, 0.2051, 0.2186, 0.2039, 0.2434, 0.2697, 0.2409, 0.3646]), 'labels': tensor([ 8, 11,  2,  8, 11, 11, 14,  0], dtype=torch.int32)}\n",
      "42628\n",
      "{'image_id': 43581, 'boxes': tensor([[  5, 113, 637, 425],\n",
      "        [  3,  70, 637, 243],\n",
      "        [160, 207, 620, 387],\n",
      "        [ 51, 130, 635, 426],\n",
      "        [381, 140, 599, 214]], dtype=torch.int32), 'scores': tensor([0.2708, 0.8513, 0.2826, 0.4134, 0.1780]), 'objectness_scores': tensor([0.2648, 0.3329, 0.4727, 0.4188, 0.3519]), 'labels': tensor([12, 12, 11, 12,  1], dtype=torch.int32)}\n",
      "43581\n",
      "{'image_id': 44195, 'boxes': tensor([[ 74,  97, 127, 122],\n",
      "        [165, 293, 185, 315],\n",
      "        [187, 390, 222, 408],\n",
      "        [161, 207, 213, 302],\n",
      "        [ 74,  87, 126, 120],\n",
      "        [133, 412, 187, 449],\n",
      "        [195, 347, 233, 373],\n",
      "        [ 85, 437, 153, 479]], dtype=torch.int32), 'scores': tensor([0.3394, 0.2937, 0.2512, 0.7889, 0.3132, 0.3364, 0.2807, 0.5498]), 'objectness_scores': tensor([0.2831, 0.2650, 0.2313, 0.2029, 0.2750, 0.2307, 0.2895, 0.2583]), 'labels': tensor([11, 11, 11,  8, 10,  8,  8,  8], dtype=torch.int32)}\n",
      "44195\n",
      "{'image_id': 44279, 'boxes': tensor([[ 33, 346, 134, 371],\n",
      "        [457, 404, 614, 425],\n",
      "        [  4, 293, 102, 317],\n",
      "        [155, 255, 189, 275],\n",
      "        [303, 112, 323, 133],\n",
      "        [466, 104, 486, 125],\n",
      "        [195, 120, 251, 150],\n",
      "        [ 50, 330, 153, 356],\n",
      "        [  4,   0, 290, 105]], dtype=torch.int32), 'scores': tensor([0.5584, 0.3451, 0.8961, 0.7740, 0.2520, 0.3606, 0.1776, 0.4937, 0.2166]), 'objectness_scores': tensor([0.2723, 0.2648, 0.2260, 0.2319, 0.2131, 0.2034, 0.2639, 0.2101, 0.2743]), 'labels': tensor([11,  8,  1, 11, 11, 11,  7, 11,  9], dtype=torch.int32)}\n",
      "44279\n",
      "{'image_id': 45472, 'boxes': tensor([[  2,  -1, 276, 368],\n",
      "        [304, 172, 393, 272]], dtype=torch.int32), 'scores': tensor([0.3852, 0.6825]), 'objectness_scores': tensor([0.3914, 0.2033]), 'labels': tensor([7, 6], dtype=torch.int32)}\n",
      "45472\n",
      "{'image_id': 45596, 'boxes': tensor([[ 10,   7, 395, 634],\n",
      "        [116, 339, 136, 348],\n",
      "        [ 55, 383,  82, 399]], dtype=torch.int32), 'scores': tensor([0.7149, 0.2925, 0.1378]), 'objectness_scores': tensor([0.2151, 0.2676, 0.3549]), 'labels': tensor([ 6, 11,  6], dtype=torch.int32)}\n",
      "45596\n",
      "{'image_id': 45728, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "45728\n",
      "{'image_id': 46031, 'boxes': tensor([[ 37, 220, 236, 452],\n",
      "        [277, 248, 471, 337],\n",
      "        [  0, 292,  72, 381],\n",
      "        [184, 137, 265, 219],\n",
      "        [  5, 178, 639, 478],\n",
      "        [305, 313, 393, 371]], dtype=torch.int32), 'scores': tensor([0.8677, 0.9967, 0.9980, 0.1862, 0.4666, 0.4982]), 'objectness_scores': tensor([0.2679, 0.2188, 0.2482, 0.4087, 0.3164, 0.3275]), 'labels': tensor([14, 14, 14,  7, 14, 14], dtype=torch.int32)}\n",
      "46031\n",
      "{'image_id': 46378, 'boxes': tensor([[ -3,   1, 575, 249],\n",
      "        [  0, 201, 290, 359],\n",
      "        [ -1,   0, 574, 336]], dtype=torch.int32), 'scores': tensor([0.9102, 0.5204, 0.9492]), 'objectness_scores': tensor([0.3730, 0.2092, 0.3641]), 'labels': tensor([2, 3, 2], dtype=torch.int32)}\n",
      "46378\n",
      "{'image_id': 47010, 'boxes': tensor([[ -1, 377, 387, 479]], dtype=torch.int32), 'scores': tensor([0.2232]), 'objectness_scores': tensor([0.2036]), 'labels': tensor([5], dtype=torch.int32)}\n",
      "47010\n",
      "{'image_id': 47112, 'boxes': tensor([[ 54, 113, 361, 215],\n",
      "        [ 46, 209, 639, 478],\n",
      "        [395,  32, 483, 213],\n",
      "        [442, 314, 486, 335],\n",
      "        [  4, 185, 639, 479],\n",
      "        [349, 111, 493, 197],\n",
      "        [294,  12, 385, 212],\n",
      "        [489, 344, 542, 368]], dtype=torch.int32), 'scores': tensor([0.7993, 0.5418, 0.9063, 0.3922, 0.3782, 0.8227, 0.6546, 0.5559]), 'objectness_scores': tensor([0.4192, 0.4013, 0.5482, 0.2336, 0.4683, 0.2064, 0.5614, 0.2169]), 'labels': tensor([ 7, 12, 10, 11, 11, 10, 10, 13], dtype=torch.int32)}\n",
      "47112\n",
      "{'image_id': 47121, 'boxes': tensor([[324,  70, 639, 395],\n",
      "        [228, 128, 363, 290],\n",
      "        [  2, 261, 636, 483]], dtype=torch.int32), 'scores': tensor([0.6969, 0.8704, 0.8233]), 'objectness_scores': tensor([0.5142, 0.5162, 0.5147]), 'labels': tensor([15, 15, 15], dtype=torch.int32)}\n",
      "47121\n",
      "{'image_id': 47585, 'boxes': tensor([[356, 222, 423, 420],\n",
      "        [190, 397, 207, 406],\n",
      "        [ 52, 259, 247, 594],\n",
      "        [242, 207, 272, 336],\n",
      "        [ 25,  19, 361, 259],\n",
      "        [ 69, 407, 115, 452],\n",
      "        [250, 159, 296, 170],\n",
      "        [101, 180, 172, 247]], dtype=torch.int32), 'scores': tensor([0.5984, 0.2739, 0.6946, 0.8778, 0.9941, 0.4124, 0.8054, 0.6763]), 'objectness_scores': tensor([0.2720, 0.3246, 0.3520, 0.4592, 0.5216, 0.2987, 0.2150, 0.2354]), 'labels': tensor([ 7, 14,  7,  7,  6, 10, 11,  7], dtype=torch.int32)}\n",
      "47585\n",
      "{'image_id': 47769, 'boxes': tensor([[223, 292, 229, 303],\n",
      "        [ 63, 331, 146, 374],\n",
      "        [301, 277, 340, 347],\n",
      "        [248, 225, 347, 350],\n",
      "        [277, 179, 319, 232],\n",
      "        [222, 267, 288, 354],\n",
      "        [ 78, 165, 154, 300],\n",
      "        [  0, 266, 197, 375],\n",
      "        [ 77, 165, 154, 242]], dtype=torch.int32), 'scores': tensor([0.2836, 0.2321, 0.7664, 0.2529, 0.5819, 0.2670, 0.1423, 0.9942, 0.3395]), 'objectness_scores': tensor([0.4968, 0.3133, 0.2302, 0.2524, 0.3430, 0.4135, 0.3467, 0.4545, 0.2345]), 'labels': tensor([11, 13,  7, 13,  6,  7, 10, 13,  6], dtype=torch.int32)}\n",
      "47769\n",
      "{'image_id': 47801, 'boxes': tensor([[199, 408, 433, 456],\n",
      "        [248, 163, 403, 217]], dtype=torch.int32), 'scores': tensor([0.2517, 0.1711]), 'objectness_scores': tensor([0.6683, 0.6429]), 'labels': tensor([15,  7], dtype=torch.int32)}\n",
      "47801\n",
      "{'image_id': 48396, 'boxes': tensor([[125, 105, 337, 374],\n",
      "        [273, 120, 310, 286],\n",
      "        [345, 375, 525, 426],\n",
      "        [530, 330, 587, 389],\n",
      "        [288, 257, 293, 267],\n",
      "        [273, 328, 640, 428]], dtype=torch.int32), 'scores': tensor([0.9989, 0.5273, 0.5903, 0.9986, 0.3347, 0.4298]), 'objectness_scores': tensor([0.2146, 0.4675, 0.2086, 0.3608, 0.3408, 0.2033]), 'labels': tensor([ 5,  7,  7, 10, 11, 12], dtype=torch.int32)}\n",
      "48396\n",
      "{'image_id': 48504, 'boxes': tensor([[352, 231, 548, 416],\n",
      "        [255, 330, 331, 384],\n",
      "        [188, 201, 359, 402],\n",
      "        [  1,   2,  53,  57],\n",
      "        [138, 146, 175, 166],\n",
      "        [104, 168, 214, 428],\n",
      "        [528, 309, 587, 404],\n",
      "        [ 22, 301,  51, 333]], dtype=torch.int32), 'scores': tensor([0.9987, 0.6212, 0.2836, 0.2834, 0.2737, 0.2717, 0.5043, 0.1801]), 'objectness_scores': tensor([0.7038, 0.3903, 0.6613, 0.2921, 0.3720, 0.5037, 0.2218, 0.4501]), 'labels': tensor([ 5,  7,  7, 11, 11,  4,  9, 11], dtype=torch.int32)}\n",
      "48504\n",
      "{'image_id': 49269, 'boxes': tensor([[161, 380, 204, 432],\n",
      "        [  6, 317, 274, 589]], dtype=torch.int32), 'scores': tensor([0.1826, 0.9926]), 'objectness_scores': tensor([0.3043, 0.5035]), 'labels': tensor([11,  3], dtype=torch.int32)}\n",
      "49269\n",
      "{'image_id': 49810, 'boxes': tensor([[  0, 181, 172, 425],\n",
      "        [134, 152, 637, 423]], dtype=torch.int32), 'scores': tensor([0.9756, 0.2396]), 'objectness_scores': tensor([0.5611, 0.5562]), 'labels': tensor([2, 7], dtype=torch.int32)}\n",
      "49810\n",
      "{'image_id': 50006, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "50006\n",
      "{'image_id': 50145, 'boxes': tensor([[426, 144, 460, 165],\n",
      "        [174, 143, 249, 165],\n",
      "        [429, 143, 474, 164],\n",
      "        [376,  48, 440, 151],\n",
      "        [ 35, 198,  83, 234]], dtype=torch.int32), 'scores': tensor([0.2576, 0.5494, 0.2095, 0.2645, 0.2296]), 'objectness_scores': tensor([0.2096, 0.6149, 0.2095, 0.3425, 0.7805]), 'labels': tensor([11,  7, 16,  8,  7], dtype=torch.int32)}\n",
      "50145\n",
      "{'image_id': 50811, 'boxes': tensor([[104, 478, 141, 492],\n",
      "        [107, 493, 132, 511],\n",
      "        [  0, 452, 635, 604],\n",
      "        [239, 261, 306, 422],\n",
      "        [388, 431, 416, 478],\n",
      "        [ 79, 476, 139, 495],\n",
      "        [ 80, 477, 138, 511],\n",
      "        [ 35, 477, 137, 511],\n",
      "        [ 91, 489, 132, 511]], dtype=torch.int32), 'scores': tensor([0.7055, 0.5179, 0.5469, 0.5027, 0.3418, 0.3931, 0.3370, 0.4071, 0.2181]), 'objectness_scores': tensor([0.2290, 0.2055, 0.2570, 0.4848, 0.3809, 0.2422, 0.2514, 0.4619, 0.3074]), 'labels': tensor([11, 11, 12,  7, 11, 11, 11, 16,  9], dtype=torch.int32)}\n",
      "50811\n",
      "{'image_id': 51008, 'boxes': tensor([[  1, 129, 406, 483],\n",
      "        [  1,   0, 291, 197],\n",
      "        [288, 355, 582, 481],\n",
      "        [182, 179, 234, 224]], dtype=torch.int32), 'scores': tensor([0.9993, 0.4982, 0.9414, 0.4564]), 'objectness_scores': tensor([0.4973, 0.2943, 0.4416, 0.2112]), 'labels': tensor([ 1, 13, 14,  7], dtype=torch.int32)}\n",
      "51008\n",
      "{'image_id': 51598, 'boxes': tensor([[  0, 433, 142, 533],\n",
      "        [ 15,  87,  36, 126],\n",
      "        [  1, 421,  34, 447],\n",
      "        [  0, 118,  75, 309],\n",
      "        [248, 402, 259, 438],\n",
      "        [268, 407, 284, 422]], dtype=torch.int32), 'scores': tensor([0.9564, 0.1376, 0.1926, 0.2478, 0.4551, 0.2324]), 'objectness_scores': tensor([0.6885, 0.3975, 0.6766, 0.6492, 0.2151, 0.2605]), 'labels': tensor([15,  4, 11,  8,  4, 11], dtype=torch.int32)}\n",
      "51598\n",
      "{'image_id': 52007, 'boxes': tensor([[ 86,  59, 327, 385]], dtype=torch.int32), 'scores': tensor([0.9977]), 'objectness_scores': tensor([0.4582]), 'labels': tensor([1], dtype=torch.int32)}\n",
      "52007\n",
      "{'image_id': 52017, 'boxes': tensor([[ 55,  80, 481, 287],\n",
      "        [451, 130, 474, 253]], dtype=torch.int32), 'scores': tensor([0.9862, 0.2407]), 'objectness_scores': tensor([0.5615, 0.3353]), 'labels': tensor([ 0, 11], dtype=torch.int32)}\n",
      "52017\n",
      "{'image_id': 52412, 'boxes': tensor([[  0,  63, 300, 216]], dtype=torch.int32), 'scores': tensor([0.9627]), 'objectness_scores': tensor([0.5758]), 'labels': tensor([0], dtype=torch.int32)}\n",
      "52412\n",
      "{'image_id': 52413, 'boxes': tensor([[188,  45, 225,  99],\n",
      "        [282, 141, 332, 190],\n",
      "        [175,  32, 205,  86],\n",
      "        [323, 323, 418, 374]], dtype=torch.int32), 'scores': tensor([0.9769, 0.4019, 0.9451, 0.2165]), 'objectness_scores': tensor([0.3653, 0.2669, 0.3671, 0.2116]), 'labels': tensor([10, 12, 10, 14], dtype=torch.int32)}\n",
      "52413\n",
      "{'image_id': 52891, 'boxes': tensor([[  2, 150, 636, 427],\n",
      "        [142, 127, 510, 425]], dtype=torch.int32), 'scores': tensor([0.9368, 0.9490]), 'objectness_scores': tensor([0.2440, 0.5160]), 'labels': tensor([3, 3], dtype=torch.int32)}\n",
      "52891\n",
      "{'image_id': 52996, 'boxes': tensor([[374, 376, 453, 425],\n",
      "        [479, 125, 514, 153],\n",
      "        [177, 106, 196, 129],\n",
      "        [ 22,  76,  81, 105],\n",
      "        [185, 270, 200, 288],\n",
      "        [  0, 283, 120, 326],\n",
      "        [  0, 347, 177, 425],\n",
      "        [206, 288, 375, 422],\n",
      "        [373, 322, 444, 401],\n",
      "        [536, 356, 558, 371],\n",
      "        [  8, 293,  68, 304],\n",
      "        [116, 273, 192, 317],\n",
      "        [166, 276, 190, 312],\n",
      "        [147, 251, 172, 281],\n",
      "        [142, 268, 186, 284],\n",
      "        [129,  65, 177, 102]], dtype=torch.int32), 'scores': tensor([0.1935, 0.2160, 0.4578, 0.3278, 0.2728, 0.9560, 0.2330, 0.4682, 0.2625,\n",
      "        0.5407, 0.3767, 0.1503, 0.8109, 0.2557, 0.2032, 0.2562]), 'objectness_scores': tensor([0.4022, 0.3254, 0.2257, 0.5437, 0.2191, 0.5550, 0.2086, 0.4775, 0.3781,\n",
      "        0.4068, 0.2524, 0.2007, 0.2220, 0.4663, 0.2341, 0.4170]), 'labels': tensor([ 7, 11,  2, 13, 14, 11, 11, 12,  8, 11, 11,  8, 12, 11, 11, 12],\n",
      "       dtype=torch.int32)}\n",
      "52996\n",
      "{'image_id': 53529, 'boxes': tensor([[355,  81, 374, 197],\n",
      "        [138, 154, 252, 275],\n",
      "        [141, 154, 224, 203],\n",
      "        [287,   9, 393, 327],\n",
      "        [133,  77, 202, 131]], dtype=torch.int32), 'scores': tensor([0.3851, 0.9430, 0.2557, 0.5201, 0.2107]), 'objectness_scores': tensor([0.3236, 0.5065, 0.3588, 0.2201, 0.5442]), 'labels': tensor([ 7,  3,  7,  8, 16], dtype=torch.int32)}\n",
      "53529\n",
      "{'image_id': 53624, 'boxes': tensor([[250, 108, 404, 379],\n",
      "        [209,  25, 318,  75]], dtype=torch.int32), 'scores': tensor([0.9995, 0.9334]), 'objectness_scores': tensor([0.5900, 0.2530]), 'labels': tensor([5, 5], dtype=torch.int32)}\n",
      "53624\n",
      "{'image_id': 54605, 'boxes': tensor([[106,  14, 232, 103],\n",
      "        [ 86,  70, 262, 447],\n",
      "        [172, 416, 613, 612],\n",
      "        [548, 221, 588, 253],\n",
      "        [ 93,  78, 252, 366],\n",
      "        [  0, 208,  78, 415],\n",
      "        [  3, 206, 606, 611],\n",
      "        [476,  41, 488,  49],\n",
      "        [299, 313, 515, 413]], dtype=torch.int32), 'scores': tensor([0.5101, 0.9049, 0.9995, 0.2413, 0.9281, 0.2433, 0.9927, 0.1572, 0.7898]), 'objectness_scores': tensor([0.3876, 0.5280, 0.5349, 0.3156, 0.3191, 0.5115, 0.5886, 0.2419, 0.5588]), 'labels': tensor([12, 10, 12, 11, 10, 11, 12, 11, 16], dtype=torch.int32)}\n",
      "54605\n",
      "{'image_id': 54628, 'boxes': tensor([[125,  55, 183, 100],\n",
      "        [146, 274, 264, 355],\n",
      "        [122, 100, 183, 119],\n",
      "        [ 36, 163,  83, 213],\n",
      "        [158,  28, 260, 224],\n",
      "        [133, 262, 279, 481],\n",
      "        [237,   0, 351,  64],\n",
      "        [158, 159, 259, 223],\n",
      "        [ 66,  97, 121, 117],\n",
      "        [132,  24, 276, 484],\n",
      "        [103, 197, 364, 315],\n",
      "        [ 67,  97, 124, 137],\n",
      "        [135, 369, 282, 483]], dtype=torch.int32), 'scores': tensor([0.6121, 0.9986, 0.2817, 0.2793, 0.9941, 0.9998, 0.2421, 0.9295, 0.3664,\n",
      "        0.9996, 0.9909, 0.9838, 0.9992]), 'objectness_scores': tensor([0.3097, 0.3043, 0.2152, 0.2404, 0.3335, 0.3171, 0.3338, 0.2821, 0.2059,\n",
      "        0.3273, 0.2879, 0.2222, 0.3193]), 'labels': tensor([ 6, 12,  7,  8, 12, 12, 12, 12,  8, 12, 13,  6, 12], dtype=torch.int32)}\n",
      "54628\n",
      "{'image_id': 55167, 'boxes': tensor([[145, 205, 159, 224],\n",
      "        [422, 159, 443, 183],\n",
      "        [449, 204, 461, 221],\n",
      "        [395, 103, 424, 180],\n",
      "        [388,  35, 449, 207],\n",
      "        [ 87, 159, 138, 177],\n",
      "        [406, 213, 426, 242],\n",
      "        [ 14, 203,  34, 235],\n",
      "        [414, 121, 436, 196],\n",
      "        [ 89, 162, 102, 172],\n",
      "        [428, 209, 444, 231]], dtype=torch.int32), 'scores': tensor([0.2593, 0.3974, 0.3434, 0.4380, 0.4867, 0.2741, 0.2309, 0.3624, 0.4428,\n",
      "        0.2006, 0.7425]), 'objectness_scores': tensor([0.4071, 0.2354, 0.3572, 0.2109, 0.2405, 0.2305, 0.3437, 0.5220, 0.2285,\n",
      "        0.2373, 0.3516]), 'labels': tensor([14, 14, 11,  8,  8,  9, 14, 11,  1, 14, 14], dtype=torch.int32)}\n",
      "55167\n",
      "{'image_id': 55299, 'boxes': tensor([[ 92, 235, 123, 259],\n",
      "        [ 22, 223, 100, 277],\n",
      "        [ 80, 235, 104, 258]], dtype=torch.int32), 'scores': tensor([0.4284, 0.5179, 0.3204]), 'objectness_scores': tensor([0.5211, 0.4251, 0.2273]), 'labels': tensor([ 5,  6, 11], dtype=torch.int32)}\n",
      "55299\n",
      "{'image_id': 55528, 'boxes': tensor([[472, 286, 528, 326],\n",
      "        [231,  70, 639, 400],\n",
      "        [366, 103, 468, 135]], dtype=torch.int32), 'scores': tensor([0.7663, 0.5857, 0.2187]), 'objectness_scores': tensor([0.4396, 0.2546, 0.2914]), 'labels': tensor([7, 7, 7], dtype=torch.int32)}\n",
      "55528\n",
      "{'image_id': 56127, 'boxes': tensor([[ 88, 112, 207, 190],\n",
      "        [ 49, 282,  73, 307],\n",
      "        [265, 275, 287, 347],\n",
      "        [ 83, 284, 105, 305],\n",
      "        [  0,   0, 540, 629],\n",
      "        [377,  28, 451, 146],\n",
      "        [ 71, 282,  92, 305]], dtype=torch.int32), 'scores': tensor([0.4800, 0.3053, 0.3441, 0.2527, 0.4623, 0.4363, 0.2180]), 'objectness_scores': tensor([0.2128, 0.2486, 0.4501, 0.2442, 0.2053, 0.2943, 0.2534]), 'labels': tensor([ 7,  4,  8, 11,  1,  7,  2], dtype=torch.int32)}\n",
      "56127\n",
      "{'image_id': 56288, 'boxes': tensor([[405, 197, 640, 276],\n",
      "        [109, 307, 291, 416],\n",
      "        [269, 344, 324, 386],\n",
      "        [ 83, 114, 322, 290],\n",
      "        [214, 217, 423, 316],\n",
      "        [  3, 213, 638, 479],\n",
      "        [298, 371, 416, 427],\n",
      "        [264, 316, 520, 415],\n",
      "        [ 53, 245, 153, 351],\n",
      "        [  4, 229, 639, 478]], dtype=torch.int32), 'scores': tensor([0.2114, 0.9995, 0.8319, 0.3050, 0.8399, 0.3590, 0.4194, 0.6340, 0.5904,\n",
      "        0.4472]), 'objectness_scores': tensor([0.4158, 0.2400, 0.2566, 0.2357, 0.2406, 0.2110, 0.2882, 0.2670, 0.4898,\n",
      "        0.3015]), 'labels': tensor([ 7, 12, 12, 14, 12, 11, 11, 11, 12,  7], dtype=torch.int32)}\n",
      "56288\n",
      "{'image_id': 56344, 'boxes': tensor([[183, 387, 379, 450],\n",
      "        [218, 259, 321, 315],\n",
      "        [ 21, 272, 547, 478],\n",
      "        [256, 258, 294, 312],\n",
      "        [199, 332, 233, 365],\n",
      "        [107, 422, 137, 448],\n",
      "        [ 22, 299, 108, 371],\n",
      "        [159, 338, 204, 383],\n",
      "        [218, 262, 252, 313]], dtype=torch.int32), 'scores': tensor([0.9975, 0.1532, 0.9972, 0.8102, 0.7941, 0.5813, 0.1796, 0.7683, 0.3781]), 'objectness_scores': tensor([0.8179, 0.2437, 0.4583, 0.2291, 0.2823, 0.2064, 0.2675, 0.3390, 0.2715]), 'labels': tensor([14,  8, 14, 14, 14,  2, 11, 14, 11], dtype=torch.int32)}\n",
      "56344\n",
      "{'image_id': 57149, 'boxes': tensor([[523, 224, 544, 259],\n",
      "        [378, 146, 392, 161],\n",
      "        [352, 334, 390, 354],\n",
      "        [483, 236, 497, 251],\n",
      "        [270, 170, 281, 182],\n",
      "        [283, 170, 294, 182],\n",
      "        [427, 328, 457, 358],\n",
      "        [601, 228, 624, 234],\n",
      "        [119, 143, 145, 192],\n",
      "        [287, 324, 317, 355],\n",
      "        [520, 203, 545, 234],\n",
      "        [363, 145, 379, 161],\n",
      "        [540, 185, 558, 337],\n",
      "        [519, 184, 544, 203],\n",
      "        [262, 169, 272, 182]], dtype=torch.int32), 'scores': tensor([0.4074, 0.2178, 0.4901, 0.2336, 0.2315, 0.2724, 0.3372, 0.2813, 0.9197,\n",
      "        0.2675, 0.5494, 0.2595, 0.3349, 0.2289, 0.1853]), 'objectness_scores': tensor([0.2243, 0.2357, 0.2201, 0.2179, 0.2552, 0.2437, 0.4254, 0.3446, 0.2791,\n",
      "        0.3986, 0.2734, 0.2298, 0.2145, 0.2314, 0.2133]), 'labels': tensor([ 1,  8, 14, 14, 11,  1,  9, 14,  7,  9, 14, 11, 11,  7, 11],\n",
      "       dtype=torch.int32)}\n",
      "57149\n",
      "{'image_id': 57760, 'boxes': tensor([[292, 211, 300, 216]], dtype=torch.int32), 'scores': tensor([0.4202]), 'objectness_scores': tensor([0.2116]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "57760\n",
      "{'image_id': 58029, 'boxes': tensor([[336,  71, 483, 385],\n",
      "        [377,  28, 485,  79],\n",
      "        [397, 407, 444, 449],\n",
      "        [406,  35, 439,  73],\n",
      "        [446,  28, 479,  64],\n",
      "        [236, 204, 313, 228],\n",
      "        [  5,   2, 610, 475],\n",
      "        [458, 219, 479, 231],\n",
      "        [375,  44, 406,  73],\n",
      "        [ 52, 235,  85, 253],\n",
      "        [308, 419, 460, 478]], dtype=torch.int32), 'scores': tensor([0.2665, 0.1613, 0.6985, 0.2589, 0.2051, 0.2004, 0.9895, 0.2972, 0.1790,\n",
      "        0.2416, 0.9747]), 'objectness_scores': tensor([0.6392, 0.2760, 0.6694, 0.2981, 0.3003, 0.3115, 0.2023, 0.3251, 0.2914,\n",
      "        0.2726, 0.6077]), 'labels': tensor([15,  7, 15, 10,  8, 11, 10, 11, 11,  3, 15], dtype=torch.int32)}\n",
      "58029\n",
      "{'image_id': 58111, 'boxes': tensor([[ 28,  21, 496, 489]], dtype=torch.int32), 'scores': tensor([0.9990]), 'objectness_scores': tensor([0.5032]), 'labels': tensor([4], dtype=torch.int32)}\n",
      "58111\n",
      "{'image_id': 58350, 'boxes': tensor([[549, 375, 554, 386],\n",
      "        [504, 357, 524, 396],\n",
      "        [556, 231, 588, 266],\n",
      "        [555, 386, 560, 394],\n",
      "        [496, 358, 508, 399],\n",
      "        [557, 280, 586, 354]], dtype=torch.int32), 'scores': tensor([0.2060, 0.2395, 0.2257, 0.5723, 0.4107, 0.4237]), 'objectness_scores': tensor([0.3994, 0.4307, 0.4955, 0.3271, 0.4486, 0.2774]), 'labels': tensor([11, 11,  7, 11, 11,  7], dtype=torch.int32)}\n",
      "58350\n",
      "{'image_id': 58384, 'boxes': tensor([[329, 180, 383, 268],\n",
      "        [307, 204, 338, 267],\n",
      "        [328, 180, 356, 211],\n",
      "        [271, 188, 315, 270]], dtype=torch.int32), 'scores': tensor([0.8793, 0.4525, 0.2195, 0.3135]), 'objectness_scores': tensor([0.7566, 0.7692, 0.2204, 0.7531]), 'labels': tensor([0, 7, 3, 7], dtype=torch.int32)}\n",
      "58384\n",
      "{'image_id': 58539, 'boxes': tensor([[487,   0, 532,  57],\n",
      "        [ 78,  60, 132,  79],\n",
      "        [ 74,  18, 165,  88],\n",
      "        [307, 222, 354, 419],\n",
      "        [267,  63, 419, 139],\n",
      "        [ 46,  83, 220, 401],\n",
      "        [450,   0, 487,  56]], dtype=torch.int32), 'scores': tensor([0.3677, 0.1729, 0.1639, 0.9998, 0.4054, 0.4340, 0.2268]), 'objectness_scores': tensor([0.2619, 0.2648, 0.3300, 0.4655, 0.3514, 0.2652, 0.2317]), 'labels': tensor([14, 10, 10,  7,  6,  7, 11], dtype=torch.int32)}\n",
      "58539\n",
      "{'image_id': 58705, 'boxes': tensor([[490, 260, 556, 326],\n",
      "        [  1, 243, 284, 481],\n",
      "        [265, 305, 637, 482],\n",
      "        [441, 144, 485, 194],\n",
      "        [ 30, 344,  85, 391],\n",
      "        [282,   1, 328,  36],\n",
      "        [103,   0, 150,  28],\n",
      "        [340, 293, 419, 396],\n",
      "        [138, 313, 194, 480],\n",
      "        [ 94,  99, 290, 220],\n",
      "        [ 26, 342,  85, 398],\n",
      "        [299, 124, 433, 242],\n",
      "        [442, 291, 483, 317],\n",
      "        [441,   1, 489,  40]], dtype=torch.int32), 'scores': tensor([0.5349, 0.9468, 0.5187, 0.1821, 0.8268, 0.3299, 0.3901, 0.6347, 0.7557,\n",
      "        0.2245, 0.7424, 0.2010, 0.2590, 0.1912]), 'objectness_scores': tensor([0.2624, 0.2190, 0.2222, 0.2697, 0.2311, 0.2692, 0.2561, 0.3987, 0.3310,\n",
      "        0.2897, 0.3017, 0.2722, 0.2202, 0.2764]), 'labels': tensor([ 8,  7,  7,  7,  7, 12,  8, 10,  2,  7,  7, 12, 11,  7],\n",
      "       dtype=torch.int32)}\n",
      "58705\n",
      "{'image_id': 59598, 'boxes': tensor([[444, 101, 592, 188],\n",
      "        [462,  27, 476,  40],\n",
      "        [431, 257, 512, 398],\n",
      "        [254, 310, 338, 380],\n",
      "        [197, 276, 267, 301],\n",
      "        [ 30, 302, 112, 346],\n",
      "        [210, 343, 407, 456],\n",
      "        [595, 203, 627, 232],\n",
      "        [483, 151, 539, 186],\n",
      "        [  1, 218, 636, 479],\n",
      "        [231,   0, 280,  91]], dtype=torch.int32), 'scores': tensor([0.2153, 0.3081, 0.4018, 0.9716, 0.5097, 0.2040, 0.9538, 0.2913, 0.2277,\n",
      "        0.3948, 0.3736]), 'objectness_scores': tensor([0.2702, 0.4311, 0.7056, 0.4906, 0.3006, 0.2640, 0.4034, 0.2327, 0.5198,\n",
      "        0.4474, 0.2487]), 'labels': tensor([ 7, 11, 10, 12, 11, 12, 12,  9, 11, 12, 11], dtype=torch.int32)}\n",
      "59598\n",
      "{'image_id': 60052, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "60052\n",
      "{'image_id': 60449, 'boxes': tensor([[  0, 417, 269, 638],\n",
      "        [ 22, 423,  68, 442]], dtype=torch.int32), 'scores': tensor([0.7152, 0.7997]), 'objectness_scores': tensor([0.3185, 0.2088]), 'labels': tensor([14, 11], dtype=torch.int32)}\n",
      "60449\n",
      "{'image_id': 60823, 'boxes': tensor([[218, 136, 227, 145]], dtype=torch.int32), 'scores': tensor([0.2312]), 'objectness_scores': tensor([0.5346]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "60823\n",
      "{'image_id': 60835, 'boxes': tensor([[209,  45, 504, 416],\n",
      "        [  4,   0, 639, 476],\n",
      "        [229, 431, 288, 480]], dtype=torch.int32), 'scores': tensor([0.6536, 0.9099, 0.3152]), 'objectness_scores': tensor([0.5410, 0.3592, 0.2551]), 'labels': tensor([3, 3, 7], dtype=torch.int32)}\n",
      "60835\n",
      "{'image_id': 60932, 'boxes': tensor([[140, 354, 165, 369],\n",
      "        [338, 146, 390, 178],\n",
      "        [118, 364, 135, 379],\n",
      "        [520, 204, 553, 328],\n",
      "        [ 87, 204,  95, 231],\n",
      "        [397, 210, 405, 231],\n",
      "        [157, 332, 167, 343],\n",
      "        [214, 121, 239, 136],\n",
      "        [241, 229, 257, 243],\n",
      "        [556, 228, 613, 283],\n",
      "        [  0, 245,  66, 334],\n",
      "        [287, 241, 293, 259],\n",
      "        [222, 192, 228, 199],\n",
      "        [176,   0, 528,  84],\n",
      "        [128, 214, 139, 248],\n",
      "        [149, 117, 206, 142],\n",
      "        [148, 115, 239, 145],\n",
      "        [280, 188, 290, 194],\n",
      "        [520, 205, 559, 407],\n",
      "        [ 71, 357,  90, 369]], dtype=torch.int32), 'scores': tensor([0.3546, 0.3867, 0.2911, 0.9322, 0.3092, 0.3952, 0.2427, 0.4677, 0.2554,\n",
      "        0.4375, 0.4421, 0.4759, 0.2968, 0.3286, 0.3692, 0.3482, 0.3274, 0.2871,\n",
      "        0.9207, 0.2822]), 'objectness_scores': tensor([0.3743, 0.2717, 0.3689, 0.2193, 0.5389, 0.2182, 0.3010, 0.2136, 0.5006,\n",
      "        0.5180, 0.2819, 0.5791, 0.2656, 0.4773, 0.5968, 0.2081, 0.4520, 0.2059,\n",
      "        0.5554, 0.3960]), 'labels': tensor([11,  9, 11,  7, 11, 11, 11, 11, 11, 16,  7, 11, 11,  6, 11, 11, 14, 11,\n",
      "         7, 11], dtype=torch.int32)}\n",
      "60932\n",
      "{'image_id': 61108, 'boxes': tensor([[356, 115, 496, 320],\n",
      "        [118, 212, 261, 365],\n",
      "        [135, 178, 227, 295]], dtype=torch.int32), 'scores': tensor([0.4994, 0.8196, 0.9719]), 'objectness_scores': tensor([0.4010, 0.4476, 0.4742]), 'labels': tensor([10,  3,  3], dtype=torch.int32)}\n",
      "61108\n",
      "{'image_id': 61171, 'boxes': tensor([[118,   1, 322, 222],\n",
      "        [  5,   3, 638, 480],\n",
      "        [  0,   0,  21,  30],\n",
      "        [308,   2, 612, 187]], dtype=torch.int32), 'scores': tensor([0.5983, 0.9973, 0.2004, 0.9926]), 'objectness_scores': tensor([0.5203, 0.2199, 0.2228, 0.2396]), 'labels': tensor([12,  4, 11,  4], dtype=torch.int32)}\n",
      "61171\n",
      "{'image_id': 61333, 'boxes': tensor([[ 10,  99, 300, 318],\n",
      "        [ 35,   0, 500, 209]], dtype=torch.int32), 'scores': tensor([0.3741, 0.9567]), 'objectness_scores': tensor([0.5504, 0.3275]), 'labels': tensor([11,  2], dtype=torch.int32)}\n",
      "61333\n",
      "{'image_id': 61471, 'boxes': tensor([[202, 238, 579, 480],\n",
      "        [178,  64, 211, 159],\n",
      "        [270, 199, 423, 480],\n",
      "        [328,  -1, 427, 231]], dtype=torch.int32), 'scores': tensor([0.9393, 0.1506, 0.9695, 0.6840]), 'objectness_scores': tensor([0.4451, 0.5139, 0.4663, 0.3668]), 'labels': tensor([ 3,  8,  3, 14], dtype=torch.int32)}\n",
      "61471\n",
      "{'image_id': 62025, 'boxes': tensor([[337, 402, 437, 480],\n",
      "        [ 72,  56, 126, 245],\n",
      "        [234, 544, 311, 639],\n",
      "        [192, 364, 373, 457],\n",
      "        [215, 357, 242, 388],\n",
      "        [ 43,  40, 172,  87],\n",
      "        [314, 404, 436, 638],\n",
      "        [270, 348, 302, 376],\n",
      "        [125, 281, 150, 321],\n",
      "        [  5,   5, 453, 638],\n",
      "        [129, 383, 176, 400],\n",
      "        [ 81, 285, 108, 327],\n",
      "        [142,  78, 177, 121],\n",
      "        [360, 391, 412, 426],\n",
      "        [  1,  15, 220, 252],\n",
      "        [414, 214, 446, 226],\n",
      "        [ 37, 523,  78, 540]], dtype=torch.int32), 'scores': tensor([0.9461, 0.4520, 0.2700, 0.9866, 0.2682, 0.5631, 0.1970, 0.4734, 0.2627,\n",
      "        0.9668, 0.7670, 0.3608, 0.2867, 0.4335, 0.5088, 0.4244, 0.2385]), 'objectness_scores': tensor([0.3147, 0.2868, 0.5216, 0.5186, 0.3083, 0.2001, 0.3442, 0.3443, 0.2555,\n",
      "        0.2500, 0.2446, 0.2518, 0.2485, 0.2618, 0.4113, 0.2013, 0.2117]), 'labels': tensor([15,  9, 10, 15, 10,  7,  7,  8,  7, 15, 11,  7,  7, 15,  7, 14, 11],\n",
      "       dtype=torch.int32)}\n",
      "62025\n",
      "{'image_id': 62808, 'boxes': tensor([[106, 213, 138, 284],\n",
      "        [165, 276, 574, 447],\n",
      "        [237, 331, 281, 346],\n",
      "        [124, 298, 501, 475],\n",
      "        [189, 350, 249, 366],\n",
      "        [250, 303, 282, 318],\n",
      "        [  0, 374, 171, 466]], dtype=torch.int32), 'scores': tensor([0.1510, 0.3150, 0.4184, 0.5168, 0.3411, 0.3076, 0.2194]), 'objectness_scores': tensor([0.2306, 0.2172, 0.2385, 0.2286, 0.2978, 0.2279, 0.2045]), 'labels': tensor([ 3,  9, 11, 11, 11,  4,  9], dtype=torch.int32)}\n",
      "62808\n",
      "{'image_id': 63047, 'boxes': tensor([[ 91, 320, 345, 562],\n",
      "        [ 95, 352, 145, 432],\n",
      "        [611, 245, 635, 277],\n",
      "        [ 22,  19, 586, 415],\n",
      "        [472, 155, 516, 238],\n",
      "        [373, 374, 414, 431],\n",
      "        [438, 403, 453, 409],\n",
      "        [ 80, 434, 117, 469],\n",
      "        [499, 398, 507, 404],\n",
      "        [574, 137, 610, 253]], dtype=torch.int32), 'scores': tensor([0.5296, 0.4790, 0.6714, 0.7425, 0.4885, 0.3672, 0.2268, 0.2685, 0.1859,\n",
      "        0.5753]), 'objectness_scores': tensor([0.2274, 0.4026, 0.2163, 0.2491, 0.3204, 0.4719, 0.2721, 0.3219, 0.2064,\n",
      "        0.2388]), 'labels': tensor([ 7, 10, 10, 13,  6,  9, 11,  7, 11,  8], dtype=torch.int32)}\n",
      "63047\n",
      "{'image_id': 63602, 'boxes': tensor([[456, 237, 641, 361],\n",
      "        [414, 233, 451, 293],\n",
      "        [450, 155, 638, 409],\n",
      "        [137, 183, 235, 246],\n",
      "        [453, 239, 640, 405]], dtype=torch.int32), 'scores': tensor([0.2306, 0.5421, 0.4488, 0.1915, 0.5519]), 'objectness_scores': tensor([0.2083, 0.2178, 0.3335, 0.2221, 0.2692]), 'labels': tensor([11, 10,  8, 11, 13], dtype=torch.int32)}\n",
      "63602\n",
      "{'image_id': 63740, 'boxes': tensor([[  3, 272, 639, 480],\n",
      "        [626,  64, 640, 103],\n",
      "        [ 89, 212, 153, 302],\n",
      "        [115, 290, 173, 363],\n",
      "        [ 13, 175, 105, 303],\n",
      "        [233, 336, 593, 409],\n",
      "        [ 74, 280,  98, 308],\n",
      "        [241, 313, 262, 326]], dtype=torch.int32), 'scores': tensor([0.9983, 0.2614, 0.2485, 0.9796, 0.3267, 0.9741, 0.2810, 0.2997]), 'objectness_scores': tensor([0.2215, 0.2178, 0.2575, 0.2626, 0.2862, 0.4395, 0.2834, 0.2411]), 'labels': tensor([14, 11, 12, 10,  7, 14,  3, 11], dtype=torch.int32)}\n",
      "63740\n",
      "{'image_id': 63965, 'boxes': tensor([[110, 352, 187, 417],\n",
      "        [206, 121, 467, 277],\n",
      "        [180, 300, 211, 329],\n",
      "        [402, 308, 422, 330],\n",
      "        [186, 216, 522, 297],\n",
      "        [471, 263, 572, 379],\n",
      "        [305, 119, 441, 181]], dtype=torch.int32), 'scores': tensor([0.3364, 0.9979, 0.1886, 0.4286, 0.9907, 0.3061, 0.8999]), 'objectness_scores': tensor([0.3549, 0.5685, 0.5659, 0.5883, 0.6060, 0.6261, 0.2066]), 'labels': tensor([ 7, 12, 11, 11, 12,  7, 12], dtype=torch.int32)}\n",
      "63965\n",
      "{'image_id': 64084, 'boxes': tensor([[186, 249, 617, 436],\n",
      "        [  3,   0, 637, 437],\n",
      "        [  0,   0, 197, 111],\n",
      "        [126, 164, 288, 258]], dtype=torch.int32), 'scores': tensor([0.3757, 0.3419, 0.8022, 0.2524]), 'objectness_scores': tensor([0.4462, 0.3089, 0.4313, 0.2191]), 'labels': tensor([11, 12,  6,  7], dtype=torch.int32)}\n",
      "64084\n",
      "{'image_id': 64868, 'boxes': tensor([[165, 264, 218, 369],\n",
      "        [260,  62, 338, 127],\n",
      "        [365,  70, 418,  89],\n",
      "        [417,  24, 468, 103],\n",
      "        [420,  91, 501, 155]], dtype=torch.int32), 'scores': tensor([0.4990, 0.2828, 0.4511, 0.2002, 0.8792]), 'objectness_scores': tensor([0.2005, 0.2376, 0.2169, 0.2586, 0.2747]), 'labels': tensor([ 7,  9, 11, 12, 14], dtype=torch.int32)}\n",
      "64868\n",
      "{'image_id': 65350, 'boxes': tensor([[375,  45, 402,  85],\n",
      "        [ 14,   7,  53,  24],\n",
      "        [532, 215, 574, 256],\n",
      "        [194, 151, 300, 229],\n",
      "        [585, 208, 634, 255],\n",
      "        [587,  32, 631,  69],\n",
      "        [447, 187, 482, 242],\n",
      "        [194, 151, 251, 215],\n",
      "        [475, 252, 612, 285],\n",
      "        [323,  70, 378, 129],\n",
      "        [532, 214, 637, 259],\n",
      "        [220, 151, 256, 217]], dtype=torch.int32), 'scores': tensor([0.1998, 0.3180, 0.2594, 0.7879, 0.3562, 0.1552, 0.1965, 0.3433, 0.3011,\n",
      "        0.1802, 0.2632, 0.2287]), 'objectness_scores': tensor([0.2216, 0.2553, 0.2066, 0.2201, 0.2023, 0.2573, 0.2176, 0.2219, 0.5948,\n",
      "        0.3634, 0.2880, 0.2313]), 'labels': tensor([ 7, 13, 11,  9,  9, 11, 16,  9,  7, 10, 11, 11], dtype=torch.int32)}\n",
      "65350\n",
      "{'image_id': 65485, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "65485\n",
      "{'image_id': 66038, 'boxes': tensor([[147, 156, 341, 223],\n",
      "        [190, 326, 210, 348],\n",
      "        [151, 157, 345, 335],\n",
      "        [138, 193, 220, 228],\n",
      "        [ 63, 160, 184, 277],\n",
      "        [149, 250, 185, 292],\n",
      "        [327, 157, 521, 342],\n",
      "        [430, 265, 457, 277],\n",
      "        [326, 286, 344, 298],\n",
      "        [465, 162, 603, 285],\n",
      "        [232, 239, 264, 292]], dtype=torch.int32), 'scores': tensor([0.9974, 0.3690, 0.9904, 0.4149, 0.9975, 0.4084, 0.9249, 0.2627, 0.2955,\n",
      "        0.9794, 0.4444]), 'objectness_scores': tensor([0.2480, 0.4770, 0.4196, 0.2561, 0.4747, 0.2075, 0.4044, 0.2897, 0.2845,\n",
      "        0.4845, 0.2190]), 'labels': tensor([ 6, 14,  6,  8,  6, 13,  6, 11, 11,  6,  7], dtype=torch.int32)}\n",
      "66038\n",
      "{'image_id': 66231, 'boxes': tensor([[238, 253, 265, 310],\n",
      "        [165, 379, 311, 426],\n",
      "        [355, 136, 393, 172],\n",
      "        [134, 337, 284, 367],\n",
      "        [248, 145, 275, 167],\n",
      "        [310, 144, 324, 161],\n",
      "        [148, 145, 178, 170],\n",
      "        [455, 155, 478, 175],\n",
      "        [184, 295, 234, 342]], dtype=torch.int32), 'scores': tensor([0.3430, 0.7473, 0.2606, 0.8223, 0.5935, 0.2375, 0.3986, 0.1477, 0.3518]), 'objectness_scores': tensor([0.3292, 0.2104, 0.3243, 0.2547, 0.3721, 0.3439, 0.3062, 0.3400, 0.3548]), 'labels': tensor([11, 10, 12, 11, 11, 11, 11, 11, 15], dtype=torch.int32)}\n",
      "66231\n",
      "{'image_id': 66635, 'boxes': tensor([[235, 342, 500, 463],\n",
      "        [  2, 226, 634, 478]], dtype=torch.int32), 'scores': tensor([0.9721, 0.9980]), 'objectness_scores': tensor([0.6359, 0.4019]), 'labels': tensor([14, 14], dtype=torch.int32)}\n",
      "66635\n",
      "{'image_id': 66706, 'boxes': tensor([[  0,   1, 308, 160],\n",
      "        [351, 277, 607, 606],\n",
      "        [  0,   9, 604, 610],\n",
      "        [110,  66, 309,  95],\n",
      "        [258, 458, 428, 600],\n",
      "        [ 37,   1, 116, 119],\n",
      "        [ 10, 225, 302, 516],\n",
      "        [261, 465, 389, 594],\n",
      "        [ 58, 432, 102, 473],\n",
      "        [500, 330, 609, 455],\n",
      "        [ 23, 357,  58, 408]], dtype=torch.int32), 'scores': tensor([0.4727, 0.6512, 0.3103, 0.7208, 0.9805, 0.2475, 0.6070, 0.9756, 0.3992,\n",
      "        0.3126, 0.1919]), 'objectness_scores': tensor([0.2965, 0.2009, 0.2245, 0.4250, 0.3613, 0.2165, 0.3070, 0.2803, 0.4546,\n",
      "        0.2093, 0.3882]), 'labels': tensor([ 7, 10,  9, 11, 10, 11, 12, 10,  6,  7,  7], dtype=torch.int32)}\n",
      "66706\n",
      "{'image_id': 66771, 'boxes': tensor([[ 71, 406, 134, 439],\n",
      "        [  0,  40, 335, 375],\n",
      "        [  0, 342, 314, 478],\n",
      "        [136, 391, 214, 459],\n",
      "        [446, 391, 559, 478],\n",
      "        [417, 170, 639, 422],\n",
      "        [105, 369, 237, 421],\n",
      "        [117, 331, 242, 399],\n",
      "        [510, 198, 555, 263],\n",
      "        [  2, 344, 619, 478],\n",
      "        [101,   8, 215,  76],\n",
      "        [204, 391, 264, 458],\n",
      "        [153, 431, 219, 480]], dtype=torch.int32), 'scores': tensor([0.4603, 0.9943, 0.9706, 0.8209, 0.9321, 0.2932, 0.8438, 0.9841, 0.1667,\n",
      "        0.8976, 0.3207, 0.6166, 0.5734]), 'objectness_scores': tensor([0.3940, 0.2068, 0.2044, 0.4303, 0.3788, 0.2253, 0.3691, 0.3703, 0.3707,\n",
      "        0.2238, 0.3067, 0.3987, 0.3516]), 'labels': tensor([10,  0, 10, 10, 10, 10, 10, 10,  3, 10,  7, 16, 10], dtype=torch.int32)}\n",
      "66771\n",
      "{'image_id': 67213, 'boxes': tensor([[399,  62, 605, 264],\n",
      "        [621, 337, 640, 352]], dtype=torch.int32), 'scores': tensor([0.9211, 0.3692]), 'objectness_scores': tensor([0.5700, 0.3206]), 'labels': tensor([ 7, 11], dtype=torch.int32)}\n",
      "67213\n",
      "{'image_id': 67310, 'boxes': tensor([[243, 327, 417, 475],\n",
      "        [207, 216, 219, 230],\n",
      "        [141, 475, 187, 487],\n",
      "        [186, 412, 204, 423],\n",
      "        [  0, 367,  75, 471],\n",
      "        [  0, 410,  18, 434],\n",
      "        [122, 289, 230, 380],\n",
      "        [126,  97, 178, 142]], dtype=torch.int32), 'scores': tensor([0.7840, 0.5649, 0.2961, 0.2248, 0.6799, 0.3255, 0.9922, 0.6034]), 'objectness_scores': tensor([0.2802, 0.2333, 0.2011, 0.2246, 0.2416, 0.2463, 0.5709, 0.3840]), 'labels': tensor([ 8, 11, 11, 11,  8,  0,  9,  8], dtype=torch.int32)}\n",
      "67310\n",
      "{'image_id': 67315, 'boxes': tensor([[520,   0, 641, 293],\n",
      "        [  2, 331, 135, 397],\n",
      "        [481,   1, 640, 424],\n",
      "        [  0, 124,  87, 387],\n",
      "        [466,   4, 585, 366],\n",
      "        [132,   0, 326, 425],\n",
      "        [463,   5, 588, 421]], dtype=torch.int32), 'scores': tensor([0.8803, 0.2309, 0.7241, 0.9493, 0.9370, 0.9982, 0.4930]), 'objectness_scores': tensor([0.3188, 0.3683, 0.2019, 0.2072, 0.3206, 0.5145, 0.2034]), 'labels': tensor([ 7, 11,  7,  7,  7,  7,  7], dtype=torch.int32)}\n",
      "67315\n",
      "{'image_id': 67534, 'boxes': tensor([[ 67, 147,  78, 157],\n",
      "        [ 92, 112, 259, 631],\n",
      "        [ -1,  45, 289, 645]], dtype=torch.int32), 'scores': tensor([0.2274, 0.8161, 0.9963]), 'objectness_scores': tensor([0.2133, 0.4935, 0.2905]), 'labels': tensor([ 2, 13,  7], dtype=torch.int32)}\n",
      "67534\n",
      "{'image_id': 68078, 'boxes': tensor([[274, 278, 302, 348],\n",
      "        [  0,   9, 361, 637],\n",
      "        [193,   3, 302, 225],\n",
      "        [217, 291, 269, 331],\n",
      "        [140, 298, 309, 401],\n",
      "        [288, 346, 358, 512],\n",
      "        [ 40, 545,  95, 600],\n",
      "        [ 26, 492, 103, 624],\n",
      "        [ -1,   7, 208, 507]], dtype=torch.int32), 'scores': tensor([0.2185, 0.9483, 0.4407, 0.2801, 0.9943, 0.2056, 0.2295, 0.9391, 0.7305]), 'objectness_scores': tensor([0.4253, 0.2028, 0.3496, 0.4648, 0.4018, 0.2484, 0.2133, 0.4469, 0.2340]), 'labels': tensor([15, 15,  7, 15, 15, 10,  7,  3, 15], dtype=torch.int32)}\n",
      "68078\n",
      "{'image_id': 68409, 'boxes': tensor([[181, 175, 208, 210],\n",
      "        [132, 148, 202, 251],\n",
      "        [364, 141, 477, 220],\n",
      "        [ 95, 154, 134, 204],\n",
      "        [ 34, 154, 119, 225],\n",
      "        [346, 221, 401, 260],\n",
      "        [294,  89, 306, 121],\n",
      "        [236, 161, 350, 247],\n",
      "        [415,  79, 427, 106],\n",
      "        [509, 167, 625, 262],\n",
      "        [301, 211, 348, 243],\n",
      "        [478, 156, 560, 224],\n",
      "        [111, 202, 169, 240],\n",
      "        [  4, 153,  58, 211],\n",
      "        [165, 190, 206, 254],\n",
      "        [ 77,  74,  99,  83],\n",
      "        [ 10, 153, 116, 258],\n",
      "        [192,  81, 205, 117],\n",
      "        [204, 220, 256, 252],\n",
      "        [409, 219, 460, 260]], dtype=torch.int32), 'scores': tensor([0.2854, 0.4218, 0.3415, 0.2990, 0.3279, 0.2248, 0.2052, 0.4839, 0.4615,\n",
      "        0.4317, 0.2608, 0.2487, 0.2056, 0.5073, 0.2315, 0.1791, 0.1900, 0.1954,\n",
      "        0.2577, 0.8560]), 'objectness_scores': tensor([0.2060, 0.2936, 0.5596, 0.2229, 0.2446, 0.3160, 0.6001, 0.2953, 0.5802,\n",
      "        0.3595, 0.2588, 0.3904, 0.3007, 0.2540, 0.3075, 0.3762, 0.3636, 0.5402,\n",
      "        0.2632, 0.3330]), 'labels': tensor([ 7,  7,  7,  7,  7,  3, 11,  7, 11, 16,  3,  7,  7,  7,  7,  0,  9, 11,\n",
      "        13, 10], dtype=torch.int32)}\n",
      "68409\n",
      "{'image_id': 68628, 'boxes': tensor([[337, 182, 400, 222],\n",
      "        [287, 197, 397, 303],\n",
      "        [317, 156, 338, 174],\n",
      "        [236,  80, 346, 142]], dtype=torch.int32), 'scores': tensor([0.6463, 0.9356, 0.3848, 0.5730]), 'objectness_scores': tensor([0.2658, 0.6608, 0.2144, 0.2264]), 'labels': tensor([ 8,  9, 11, 13], dtype=torch.int32)}\n",
      "68628\n",
      "{'image_id': 68765, 'boxes': tensor([[178,  50, 243,  91],\n",
      "        [539,  24, 607,  93],\n",
      "        [  5,   3, 640, 481],\n",
      "        [456,   0, 636,  91],\n",
      "        [  6,  28, 582, 480]], dtype=torch.int32), 'scores': tensor([0.3832, 0.4991, 0.9979, 0.9549, 0.9985]), 'objectness_scores': tensor([0.3117, 0.2719, 0.5056, 0.3609, 0.7035]), 'labels': tensor([ 9, 14, 14, 14, 14], dtype=torch.int32)}\n",
      "68765\n",
      "{'image_id': 68833, 'boxes': tensor([[187,  76, 236, 144],\n",
      "        [288,   0, 401,  69],\n",
      "        [406, 276, 507, 436],\n",
      "        [374, 196, 402, 245]], dtype=torch.int32), 'scores': tensor([0.2140, 0.8145, 0.4004, 0.2221]), 'objectness_scores': tensor([0.2193, 0.2536, 0.2395, 0.2893]), 'labels': tensor([10, 12, 11, 11], dtype=torch.int32)}\n",
      "68833\n",
      "{'image_id': 70048, 'boxes': tensor([[431,  83, 499, 165],\n",
      "        [284,   0, 399, 209],\n",
      "        [302, 135, 642, 434],\n",
      "        [ 76, 219, 275, 369],\n",
      "        [514,  54, 644, 226],\n",
      "        [ 15,  15, 205, 172],\n",
      "        [250,  65, 288, 118],\n",
      "        [370,  84, 444, 181],\n",
      "        [  5,   4, 637, 479],\n",
      "        [180, 162, 274, 226],\n",
      "        [ 38, 202, 328, 430]], dtype=torch.int32), 'scores': tensor([0.3421, 0.7441, 0.9970, 0.6589, 0.2890, 0.2048, 0.4549, 0.1580, 0.5385,\n",
      "        0.4945, 0.8794]), 'objectness_scores': tensor([0.2812, 0.5731, 0.3837, 0.3290, 0.2881, 0.4722, 0.2415, 0.2101, 0.4210,\n",
      "        0.2479, 0.4608]), 'labels': tensor([12, 10, 12, 10, 11, 11, 12, 11,  0,  7, 10], dtype=torch.int32)}\n",
      "70048\n",
      "{'image_id': 71226, 'boxes': tensor([[311,  61, 466, 131],\n",
      "        [188, 147, 519, 412],\n",
      "        [ 70,  56, 228, 218]], dtype=torch.int32), 'scores': tensor([0.8673, 0.9729, 0.9088]), 'objectness_scores': tensor([0.4490, 0.3887, 0.3906]), 'labels': tensor([2, 3, 3], dtype=torch.int32)}\n",
      "71226\n",
      "{'image_id': 71711, 'boxes': tensor([[293, 209, 638, 358],\n",
      "        [378, 209, 635, 337],\n",
      "        [  1, 172, 283, 345],\n",
      "        [  0, 234,  45, 331],\n",
      "        [486,  59, 526, 166],\n",
      "        [180, 236, 263, 325],\n",
      "        [207, 191, 231, 252],\n",
      "        [314, 265, 393, 366],\n",
      "        [316, 283, 330, 353],\n",
      "        [119,  32, 160, 139],\n",
      "        [ 35, 286,  87, 345]], dtype=torch.int32), 'scores': tensor([0.8931, 0.8173, 0.8813, 0.2142, 0.7718, 0.6709, 0.3876, 0.9050, 0.2618,\n",
      "        0.7436, 0.9995]), 'objectness_scores': tensor([0.2136, 0.4651, 0.4574, 0.2184, 0.2469, 0.2582, 0.2093, 0.2675, 0.2316,\n",
      "        0.2313, 0.2081]), 'labels': tensor([ 0,  0,  0, 11,  7,  0,  8,  0, 11,  7,  5], dtype=torch.int32)}\n",
      "71711\n",
      "{'image_id': 71877, 'boxes': tensor([[191, 219, 359, 324],\n",
      "        [179, 275, 211, 320],\n",
      "        [ 25, 274,  78, 408],\n",
      "        [  0, 256,  19, 336],\n",
      "        [275, 230, 327, 269],\n",
      "        [323, 257, 338, 273],\n",
      "        [385,   6, 426,  88],\n",
      "        [ 86,  66, 195, 190],\n",
      "        [193,  43, 259,  78],\n",
      "        [ 17, 262,  66, 368]], dtype=torch.int32), 'scores': tensor([0.9795, 0.4193, 0.2875, 0.2156, 0.7490, 0.1638, 0.2937, 0.5430, 0.1220,\n",
      "        0.2471]), 'objectness_scores': tensor([0.6497, 0.2412, 0.3820, 0.2515, 0.2300, 0.2073, 0.2150, 0.2677, 0.2805,\n",
      "        0.3041]), 'labels': tensor([ 9,  9,  6, 11,  9, 11,  7,  7,  8,  9], dtype=torch.int32)}\n",
      "71877\n",
      "{'image_id': 72281, 'boxes': tensor([[188,  51, 258, 106],\n",
      "        [293, 103, 314, 117],\n",
      "        [194, 278, 290, 292],\n",
      "        [ 96, 437, 361, 542]], dtype=torch.int32), 'scores': tensor([0.1938, 0.3133, 0.2772, 0.8003]), 'objectness_scores': tensor([0.2233, 0.2212, 0.2817, 0.6201]), 'labels': tensor([10, 14, 11,  9], dtype=torch.int32)}\n",
      "72281\n",
      "{'image_id': 72813, 'boxes': tensor([[455, 301, 637, 477],\n",
      "        [232, 133, 495, 320],\n",
      "        [  0, 190, 295, 354],\n",
      "        [150, 142, 454, 203],\n",
      "        [ 49,   0, 112,  35]], dtype=torch.int32), 'scores': tensor([0.8635, 0.9753, 0.1373, 0.9412, 0.4053]), 'objectness_scores': tensor([0.2755, 0.4493, 0.2241, 0.2336, 0.2222]), 'labels': tensor([12,  3, 11,  3,  2], dtype=torch.int32)}\n",
      "72813\n",
      "{'image_id': 73702, 'boxes': tensor([[128, 475, 189, 639],\n",
      "        [ 56, 141, 153, 193],\n",
      "        [120, 154, 329, 227],\n",
      "        [  2, 260, 228, 554]], dtype=torch.int32), 'scores': tensor([0.2704, 0.2019, 0.4156, 0.7345]), 'objectness_scores': tensor([0.2003, 0.2953, 0.2696, 0.2210]), 'labels': tensor([7, 9, 7, 7], dtype=torch.int32)}\n",
      "73702\n",
      "{'image_id': 74058, 'boxes': tensor([[ 82, 287,  99, 310],\n",
      "        [ 13,   0, 253, 225],\n",
      "        [157,  14, 380, 295],\n",
      "        [172, 220, 221, 278],\n",
      "        [168,  27, 378, 145],\n",
      "        [284, 133, 383, 192],\n",
      "        [157,   3, 380, 143],\n",
      "        [327, 145, 385, 202],\n",
      "        [ 65, 153,  99, 186],\n",
      "        [ 16,  -1, 382, 283],\n",
      "        [284, 133, 384, 181],\n",
      "        [ 30,  -1, 258, 109],\n",
      "        [186, 275, 214, 299],\n",
      "        [ 52, 306,  72, 325],\n",
      "        [331, 170, 372, 227],\n",
      "        [283, 133, 385, 262],\n",
      "        [340, 183, 382, 202],\n",
      "        [ 30, 322,  55, 341]], dtype=torch.int32), 'scores': tensor([0.4228, 0.7554, 0.9066, 0.2014, 0.9953, 0.9988, 0.9956, 0.4944, 0.9385,\n",
      "        0.8930, 0.9901, 0.9189, 0.2546, 0.3027, 0.2078, 0.7075, 0.2064, 0.3004]), 'objectness_scores': tensor([0.2650, 0.2087, 0.4129, 0.2978, 0.3420, 0.4014, 0.2868, 0.2321, 0.2998,\n",
      "        0.2249, 0.3128, 0.4389, 0.2480, 0.2665, 0.2885, 0.3871, 0.2090, 0.2713]), 'labels': tensor([ 7,  6,  6, 13,  6,  1,  6,  8,  6,  6,  7,  6, 11, 11,  8,  6,  7, 16],\n",
      "       dtype=torch.int32)}\n",
      "74058\n",
      "{'image_id': 74209, 'boxes': tensor([[305, 255, 410, 283],\n",
      "        [326, 214, 344, 277],\n",
      "        [146,  84, 282, 136],\n",
      "        [416, 238, 428, 268],\n",
      "        [ 41,   1, 123,  94],\n",
      "        [219, 357, 321, 482],\n",
      "        [499, 303, 584, 461],\n",
      "        [246, 266, 327, 291],\n",
      "        [329,   0, 389, 101],\n",
      "        [543, 210, 556, 222],\n",
      "        [379, 223, 407, 273],\n",
      "        [163, 215, 292, 236],\n",
      "        [525,   2, 576, 114],\n",
      "        [316, 338, 408, 481],\n",
      "        [ 21, 207, 124, 317],\n",
      "        [304, 193, 319, 221],\n",
      "        [412, 321, 502, 481]], dtype=torch.int32), 'scores': tensor([0.3494, 0.4291, 0.2092, 0.2671, 0.8582, 0.6297, 0.4859, 0.5718, 0.4844,\n",
      "        0.4525, 0.1769, 0.5137, 0.3810, 0.5609, 0.4998, 0.4086, 0.5962]), 'objectness_scores': tensor([0.3764, 0.3728, 0.5586, 0.3496, 0.2878, 0.3736, 0.3676, 0.3898, 0.2649,\n",
      "        0.2140, 0.2644, 0.4655, 0.2748, 0.3697, 0.3722, 0.2255, 0.3683]), 'labels': tensor([11, 11, 10, 14, 11, 10, 16, 11, 10, 11, 11, 11,  6, 10, 12, 11, 16],\n",
      "       dtype=torch.int32)}\n",
      "74209\n",
      "{'image_id': 74256, 'boxes': tensor([[482, 159, 488, 169],\n",
      "        [425, 473, 432, 480],\n",
      "        [183, 163, 330, 434],\n",
      "        [376, 449, 383, 456],\n",
      "        [ 65, 259, 102, 285],\n",
      "        [175, 336, 213, 354]], dtype=torch.int32), 'scores': tensor([0.1836, 0.1721, 0.4047, 0.2220, 0.6930, 0.7487]), 'objectness_scores': tensor([0.2203, 0.2551, 0.3318, 0.2273, 0.3327, 0.3186]), 'labels': tensor([14, 11, 14, 11, 11, 11], dtype=torch.int32)}\n",
      "74256\n",
      "{'image_id': 74646, 'boxes': tensor([[354, 596, 392, 640]], dtype=torch.int32), 'scores': tensor([0.9300]), 'objectness_scores': tensor([0.6377]), 'labels': tensor([10], dtype=torch.int32)}\n",
      "74646\n",
      "{'image_id': 74733, 'boxes': tensor([[  0, 123, 285, 310],\n",
      "        [487, 272, 613, 485],\n",
      "        [278, 392, 443, 613],\n",
      "        [178,  39, 245, 156],\n",
      "        [ -1, 163, 589, 556],\n",
      "        [183,   8, 293,  42],\n",
      "        [206,  12, 292,  41],\n",
      "        [392, 323, 542, 569],\n",
      "        [296, 215, 328, 246],\n",
      "        [182,   3, 458, 128],\n",
      "        [115,  52, 189, 179],\n",
      "        [357,   0, 385,  34],\n",
      "        [  0,  86,  59, 233],\n",
      "        [  0, 114, 602, 609],\n",
      "        [387, 247, 426, 280],\n",
      "        [346, 202, 379, 230],\n",
      "        [311, 249, 356, 289],\n",
      "        [ 46,  69, 129, 205],\n",
      "        [536, 124, 611, 253]], dtype=torch.int32), 'scores': tensor([0.3246, 0.9525, 0.7174, 0.8438, 0.3542, 0.3717, 0.2621, 0.8694, 0.3030,\n",
      "        0.2707, 0.6792, 0.3515, 0.7511, 0.3750, 0.2839, 0.2148, 0.2001, 0.8179,\n",
      "        0.8678]), 'objectness_scores': tensor([0.3993, 0.4539, 0.4526, 0.4843, 0.3147, 0.3288, 0.2170, 0.4941, 0.5236,\n",
      "        0.2796, 0.4468, 0.3656, 0.3880, 0.3201, 0.4454, 0.5535, 0.3780, 0.4615,\n",
      "        0.4993]), 'labels': tensor([ 9, 10, 10, 10,  9,  9,  7, 10, 11, 10, 10,  7, 10,  9, 11, 11, 12, 10,\n",
      "        10], dtype=torch.int32)}\n",
      "74733\n",
      "{'image_id': 74860, 'boxes': tensor([[198, 239, 216, 254]], dtype=torch.int32), 'scores': tensor([0.2062]), 'objectness_scores': tensor([0.4785]), 'labels': tensor([8], dtype=torch.int32)}\n",
      "74860\n",
      "{'image_id': 76416, 'boxes': tensor([[332,  18, 506, 472],\n",
      "        [ 28, 209,  79, 227],\n",
      "        [573, 105, 609, 229]], dtype=torch.int32), 'scores': tensor([0.9524, 0.2377, 0.4977]), 'objectness_scores': tensor([0.2039, 0.2061, 0.2767]), 'labels': tensor([ 1, 14,  7], dtype=torch.int32)}\n",
      "76416\n",
      "{'image_id': 76417, 'boxes': tensor([[ 73,   6, 131,  97],\n",
      "        [275, 143, 422, 305],\n",
      "        [  8,   0,  68, 128],\n",
      "        [442,  28, 501, 156]], dtype=torch.int32), 'scores': tensor([0.3655, 0.9582, 0.3286, 0.2453]), 'objectness_scores': tensor([0.3761, 0.4963, 0.5563, 0.5161]), 'labels': tensor([14,  3,  8,  9], dtype=torch.int32)}\n",
      "76417\n",
      "{'image_id': 76547, 'boxes': tensor([[372, 303, 402, 307],\n",
      "        [506,  22, 640,  51],\n",
      "        [306, 318, 348, 359],\n",
      "        [411, 437, 470, 463],\n",
      "        [569, 150, 638, 176],\n",
      "        [549, 119, 638, 151],\n",
      "        [590, 210, 635, 235],\n",
      "        [544,  54, 637, 110]], dtype=torch.int32), 'scores': tensor([0.2359, 0.7523, 0.2941, 0.3025, 0.4113, 0.2173, 0.5391, 0.3202]), 'objectness_scores': tensor([0.2485, 0.2526, 0.2026, 0.2075, 0.2963, 0.2797, 0.2705, 0.2798]), 'labels': tensor([ 0, 14, 12, 11, 14,  1, 14,  0], dtype=torch.int32)}\n",
      "76547\n",
      "{'image_id': 77396, 'boxes': tensor([[ 96, 346, 259, 478],\n",
      "        [487, 131, 501, 185],\n",
      "        [251, 192, 345, 211],\n",
      "        [242, 207, 389, 353]], dtype=torch.int32), 'scores': tensor([0.9767, 0.2382, 0.7552, 0.9661]), 'objectness_scores': tensor([0.4705, 0.2072, 0.2015, 0.4120]), 'labels': tensor([ 2, 11, 11,  2], dtype=torch.int32)}\n",
      "77396\n",
      "{'image_id': 77595, 'boxes': tensor([[  3, 271, 269, 425],\n",
      "        [229,  84, 531, 424]], dtype=torch.int32), 'scores': tensor([0.9778, 0.9859]), 'objectness_scores': tensor([0.2656, 0.5288]), 'labels': tensor([14,  2], dtype=torch.int32)}\n",
      "77595\n",
      "{'image_id': 78266, 'boxes': tensor([[229, 200, 243, 217],\n",
      "        [163, 209, 294, 408],\n",
      "        [234, 178, 252, 209]], dtype=torch.int32), 'scores': tensor([0.2940, 0.9888, 0.2450]), 'objectness_scores': tensor([0.2015, 0.2233, 0.4445]), 'labels': tensor([14,  2, 14], dtype=torch.int32)}\n",
      "78266\n",
      "{'image_id': 78420, 'boxes': tensor([[  2, 226, 418, 468],\n",
      "        [303,   8, 322,  28],\n",
      "        [285, 246, 639, 479],\n",
      "        [341,   4, 355,  22]], dtype=torch.int32), 'scores': tensor([0.9988, 0.2651, 0.7555, 0.2911]), 'objectness_scores': tensor([0.4009, 0.4066, 0.4801, 0.3360]), 'labels': tensor([14, 11,  2, 14], dtype=torch.int32)}\n",
      "78420\n",
      "{'image_id': 78565, 'boxes': tensor([[466, 189, 503, 257],\n",
      "        [256, 177, 318, 268],\n",
      "        [512, 189, 552, 259],\n",
      "        [415, 265, 428, 273],\n",
      "        [489, 276, 502, 284],\n",
      "        [497, 263, 509, 269],\n",
      "        [202, 196, 240, 256],\n",
      "        [352, 250, 358, 254],\n",
      "        [334, 248, 339, 251],\n",
      "        [325, 223, 341, 244],\n",
      "        [468, 287, 479, 296],\n",
      "        [315, 251, 320, 254]], dtype=torch.int32), 'scores': tensor([0.7929, 0.3135, 0.2650, 0.2642, 0.1961, 0.1996, 0.3713, 0.1851, 0.2144,\n",
      "        0.6154, 0.1931, 0.1614]), 'objectness_scores': tensor([0.3855, 0.3677, 0.4752, 0.5572, 0.5528, 0.5019, 0.3903, 0.3013, 0.2115,\n",
      "        0.2057, 0.2272, 0.3998]), 'labels': tensor([ 7,  7,  7, 11,  0,  2,  7,  0,  0, 11, 14,  0], dtype=torch.int32)}\n",
      "78565\n",
      "{'image_id': 78823, 'boxes': tensor([[316, 381, 436, 418],\n",
      "        [194, 118, 356, 340],\n",
      "        [ 50, 359, 145, 401],\n",
      "        [256, 164, 324, 241],\n",
      "        [176, 366, 274, 413]], dtype=torch.int32), 'scores': tensor([0.2635, 0.9408, 0.2997, 0.8605, 0.2489]), 'objectness_scores': tensor([0.2632, 0.4557, 0.2434, 0.3808, 0.2861]), 'labels': tensor([14,  3, 11,  3,  8], dtype=torch.int32)}\n",
      "78823\n",
      "{'image_id': 78843, 'boxes': tensor([[412,  28, 528, 103],\n",
      "        [243, 291, 443, 429],\n",
      "        [119,   0, 521, 118]], dtype=torch.int32), 'scores': tensor([0.4066, 0.2286, 0.4361]), 'objectness_scores': tensor([0.2319, 0.3492, 0.3011]), 'labels': tensor([7, 7, 7], dtype=torch.int32)}\n",
      "78843\n",
      "{'image_id': 79229, 'boxes': tensor([[354, 119, 376, 137],\n",
      "        [380, 186, 391, 196],\n",
      "        [310, 196, 380, 239],\n",
      "        [339, 202, 351, 217]], dtype=torch.int32), 'scores': tensor([0.2050, 0.2454, 0.2455, 0.2602]), 'objectness_scores': tensor([0.4782, 0.3410, 0.2048, 0.3462]), 'labels': tensor([ 6, 13, 11, 11], dtype=torch.int32)}\n",
      "79229\n",
      "{'image_id': 80153, 'boxes': tensor([[120, 296, 223, 446],\n",
      "        [200, 146, 288, 318],\n",
      "        [232, 408, 285, 436],\n",
      "        [202, 359, 289, 540],\n",
      "        [189, 153, 206, 164]], dtype=torch.int32), 'scores': tensor([0.7334, 0.2248, 0.9860, 0.9123, 0.2478]), 'objectness_scores': tensor([0.2956, 0.2844, 0.2212, 0.4700, 0.2836]), 'labels': tensor([ 3,  7, 12,  3, 11], dtype=torch.int32)}\n",
      "80153\n",
      "{'image_id': 80273, 'boxes': tensor([[220,  73, 380, 265],\n",
      "        [172, 386, 233, 419],\n",
      "        [253,  45, 319,  92],\n",
      "        [252,  65, 319,  94],\n",
      "        [315, 370, 368, 403],\n",
      "        [323, 251, 357, 296],\n",
      "        [252,  70, 271,  95],\n",
      "        [212, 236, 242, 277]], dtype=torch.int32), 'scores': tensor([0.9988, 0.1445, 0.2910, 0.1503, 0.1552, 0.3946, 0.2591, 0.9905]), 'objectness_scores': tensor([0.3303, 0.2201, 0.2666, 0.3214, 0.2660, 0.4496, 0.2545, 0.4138]), 'labels': tensor([ 1,  1, 11,  3,  9, 11, 11, 15], dtype=torch.int32)}\n",
      "80273\n",
      "{'image_id': 80340, 'boxes': tensor([[184, 152, 207, 224],\n",
      "        [486, 132, 511, 150],\n",
      "        [564,  18, 583,  35],\n",
      "        [336,  38, 427, 114],\n",
      "        [372, 171, 400, 184],\n",
      "        [142, 132, 269, 278],\n",
      "        [492,   0, 548, 138]], dtype=torch.int32), 'scores': tensor([0.9969, 0.3439, 0.5998, 0.8255, 0.2352, 0.2206, 0.6874]), 'objectness_scores': tensor([0.2496, 0.2996, 0.2339, 0.2418, 0.2110, 0.2173, 0.2479]), 'labels': tensor([ 7, 11,  7,  7, 11, 11,  7], dtype=torch.int32)}\n",
      "80340\n",
      "{'image_id': 80666, 'boxes': tensor([[155, 205, 188, 246],\n",
      "        [ 59, 221,  79, 250],\n",
      "        [ 72, 121, 531, 532]], dtype=torch.int32), 'scores': tensor([0.2057, 0.2956, 0.9793]), 'objectness_scores': tensor([0.4188, 0.8625, 0.5563]), 'labels': tensor([10, 11,  2], dtype=torch.int32)}\n",
      "80666\n",
      "{'image_id': 80932, 'boxes': tensor([[ 20, 168,  84, 177],\n",
      "        [343,   0, 480, 124],\n",
      "        [323, 227, 389, 257],\n",
      "        [  0, 146, 130, 300],\n",
      "        [  0, 324,  52, 484],\n",
      "        [448, 128, 475, 173],\n",
      "        [  0, 440, 476, 639],\n",
      "        [381, 188, 450, 199],\n",
      "        [136, 430, 398, 580],\n",
      "        [396, 172, 431, 184]], dtype=torch.int32), 'scores': tensor([0.3796, 0.2409, 0.6385, 0.4075, 0.1727, 0.1435, 0.9895, 0.5101, 0.9969,\n",
      "        0.2632]), 'objectness_scores': tensor([0.2020, 0.2003, 0.2440, 0.2046, 0.4092, 0.2335, 0.3335, 0.2277, 0.4351,\n",
      "        0.3357]), 'labels': tensor([11,  7, 11,  7,  5, 10, 12, 11, 12, 11], dtype=torch.int32)}\n",
      "80932\n",
      "{'image_id': 80949, 'boxes': tensor([[  2, 124, 635, 438],\n",
      "        [ 13, 131, 639, 363]], dtype=torch.int32), 'scores': tensor([0.5496, 0.5384]), 'objectness_scores': tensor([0.2401, 0.4937]), 'labels': tensor([2, 2], dtype=torch.int32)}\n",
      "80949\n",
      "{'image_id': 81061, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "81061\n",
      "{'image_id': 81594, 'boxes': tensor([[  1,   2, 472, 421],\n",
      "        [181, 603, 205, 630],\n",
      "        [168, 308, 303, 494],\n",
      "        [192, 205, 393, 397],\n",
      "        [267, 606, 293, 634]], dtype=torch.int32), 'scores': tensor([0.9994, 0.2787, 0.7733, 0.9967, 0.1687]), 'objectness_scores': tensor([0.2009, 0.2670, 0.2989, 0.5315, 0.2747]), 'labels': tensor([6, 7, 6, 6, 9], dtype=torch.int32)}\n",
      "81594\n",
      "{'image_id': 81738, 'boxes': tensor([[332, 138, 499, 238],\n",
      "        [ 96, 179, 564, 426],\n",
      "        [105, 136, 534, 385]], dtype=torch.int32), 'scores': tensor([0.9365, 0.9995, 0.8958]), 'objectness_scores': tensor([0.4490, 0.4408, 0.5587]), 'labels': tensor([12, 12,  7], dtype=torch.int32)}\n",
      "81738\n",
      "{'image_id': 82696, 'boxes': tensor([[121,  59, 140,  85],\n",
      "        [  0, 143, 395, 382]], dtype=torch.int32), 'scores': tensor([0.2792, 0.4309]), 'objectness_scores': tensor([0.2033, 0.2905]), 'labels': tensor([11,  3], dtype=torch.int32)}\n",
      "82696\n",
      "{'image_id': 82807, 'boxes': tensor([[146,  14, 187,  51],\n",
      "        [282, 483, 442, 601],\n",
      "        [  1, 396, 635, 602],\n",
      "        [358, 128, 402, 175],\n",
      "        [121,  68, 515, 479]], dtype=torch.int32), 'scores': tensor([0.1588, 0.9472, 0.6995, 0.1543, 0.9985]), 'objectness_scores': tensor([0.2808, 0.5085, 0.3536, 0.3529, 0.5024]), 'labels': tensor([10, 12, 12, 11,  5], dtype=torch.int32)}\n",
      "82807\n",
      "{'image_id': 83531, 'boxes': tensor([[353, 145, 377, 159],\n",
      "        [258, 146, 317, 157],\n",
      "        [216,  67, 261, 129],\n",
      "        [ 34, 124, 479, 225],\n",
      "        [336, 209, 415, 224],\n",
      "        [229, 127, 300, 144],\n",
      "        [ 35, 155, 148, 179],\n",
      "        [408, 202, 472, 220],\n",
      "        [ 40, 177, 176, 215],\n",
      "        [370, 246, 393, 270],\n",
      "        [242, 199, 335, 222],\n",
      "        [396, 192, 454, 212],\n",
      "        [394, 236, 414, 272],\n",
      "        [288, 170, 358, 192],\n",
      "        [259, 153, 324, 164],\n",
      "        [299, 134, 355, 146],\n",
      "        [329, 107, 494, 193],\n",
      "        [ 36, 167, 172, 196],\n",
      "        [328, 182, 405, 203],\n",
      "        [404,  13, 438,  48],\n",
      "        [306, 176, 365, 199],\n",
      "        [157, 142, 263, 171],\n",
      "        [120, 129, 230, 156],\n",
      "        [282, 164, 349, 179],\n",
      "        [155, 140, 246, 163],\n",
      "        [415, 210, 485, 225],\n",
      "        [246, 138, 298, 149],\n",
      "        [113, 121, 215, 143],\n",
      "        [114, 122, 228, 156],\n",
      "        [169, 159, 275, 185],\n",
      "        [307, 141, 374, 159],\n",
      "        [328, 198, 401, 217],\n",
      "        [305, 237, 428, 274],\n",
      "        [262, 155, 331, 172],\n",
      "        [342, 157, 404, 175],\n",
      "        [190, 122, 214, 138],\n",
      "        [ 35, 157, 172, 189],\n",
      "        [196, 175, 303, 208],\n",
      "        [204, 171, 293, 191]], dtype=torch.int32), 'scores': tensor([0.6290, 0.2679, 0.2194, 0.5459, 0.2141, 0.4583, 0.3954, 0.2809, 0.4891,\n",
      "        0.3436, 0.5974, 0.5535, 0.4123, 0.5664, 0.2764, 0.2225, 0.2792, 0.5385,\n",
      "        0.3191, 0.8134, 0.3905, 0.9942, 0.4523, 0.3683, 0.5288, 0.7187, 0.3065,\n",
      "        0.5462, 0.5460, 0.3405, 0.6577, 0.3282, 0.3655, 0.2908, 0.6368, 0.2789,\n",
      "        0.3668, 0.3210, 0.5579]), 'objectness_scores': tensor([0.2001, 0.4930, 0.3224, 0.2442, 0.5234, 0.5217, 0.2772, 0.5494, 0.4904,\n",
      "        0.2856, 0.5399, 0.5530, 0.3304, 0.4317, 0.2303, 0.4752, 0.2003, 0.3731,\n",
      "        0.5267, 0.2805, 0.4313, 0.4532, 0.2733, 0.4669, 0.3823, 0.5369, 0.4024,\n",
      "        0.3859, 0.3848, 0.4862, 0.5306, 0.5291, 0.2128, 0.4057, 0.4801, 0.2615,\n",
      "        0.4797, 0.4799, 0.2571]), 'labels': tensor([11,  7, 10,  3, 14,  2, 11,  7, 11, 11, 11, 11, 11, 11,  7, 14, 14, 11,\n",
      "        11, 10, 11, 13, 11, 11,  7,  7, 14, 11,  7,  7, 11,  7, 11, 11, 11, 11,\n",
      "        11, 11,  7], dtype=torch.int32)}\n",
      "83531\n",
      "{'image_id': 84170, 'boxes': tensor([[546,  75, 612, 142],\n",
      "        [ 10, 218,  19, 233],\n",
      "        [516, 155, 595, 227],\n",
      "        [ 85, 206,  96, 224]], dtype=torch.int32), 'scores': tensor([0.3969, 0.2154, 0.4284, 0.2245]), 'objectness_scores': tensor([0.2807, 0.2290, 0.2594, 0.2184]), 'labels': tensor([ 6,  0,  9, 14], dtype=torch.int32)}\n",
      "84170\n",
      "{'image_id': 84241, 'boxes': tensor([[168,   5, 189,  97],\n",
      "        [ 31, 115,  41, 183],\n",
      "        [ 85, 292, 218, 396],\n",
      "        [405, 165, 444, 197],\n",
      "        [444,  18, 461,  44],\n",
      "        [  0, 290, 108, 377],\n",
      "        [303,  14, 321,  40],\n",
      "        [518,  59, 549, 102],\n",
      "        [ 23, 292, 214, 393],\n",
      "        [342, 286, 439, 360],\n",
      "        [239, 326, 365, 395],\n",
      "        [210, 292, 290, 336]], dtype=torch.int32), 'scores': tensor([0.4188, 0.2055, 0.9657, 0.2705, 0.2338, 0.5286, 0.3519, 0.2474, 0.4760,\n",
      "        0.9523, 0.8795, 0.1886]), 'objectness_scores': tensor([0.2040, 0.2808, 0.2757, 0.2523, 0.2071, 0.2850, 0.2009, 0.2350, 0.3564,\n",
      "        0.2787, 0.2593, 0.2472]), 'labels': tensor([11, 11, 12, 14, 11,  7, 16,  7, 10, 14, 10,  3], dtype=torch.int32)}\n",
      "84241\n",
      "{'image_id': 84270, 'boxes': tensor([[194, 349, 207, 372],\n",
      "        [186, 348, 199, 372],\n",
      "        [203, 349, 217, 373]], dtype=torch.int32), 'scores': tensor([0.1697, 0.1862, 0.2257]), 'objectness_scores': tensor([0.3852, 0.3669, 0.3820]), 'labels': tensor([ 7,  7, 11], dtype=torch.int32)}\n",
      "84270\n",
      "{'image_id': 84362, 'boxes': tensor([[ 80, 271, 323, 420],\n",
      "        [365, 182, 407, 254],\n",
      "        [469, 137, 637, 301],\n",
      "        [441, 175, 483, 251],\n",
      "        [273, 246, 553, 448],\n",
      "        [  1, 113,  78, 218],\n",
      "        [  7, 191, 200, 278]], dtype=torch.int32), 'scores': tensor([0.9324, 0.6405, 0.5802, 0.5527, 0.8834, 0.5348, 0.5517]), 'objectness_scores': tensor([0.3292, 0.2651, 0.2828, 0.3552, 0.5286, 0.2427, 0.2493]), 'labels': tensor([ 7,  7, 13,  7,  2,  7, 13], dtype=torch.int32)}\n",
      "84362\n",
      "{'image_id': 84477, 'boxes': tensor([[209, 279, 253, 354],\n",
      "        [  4, 246, 639, 424],\n",
      "        [232,  36, 628, 361],\n",
      "        [289, 224, 297, 233]], dtype=torch.int32), 'scores': tensor([0.3683, 0.3835, 0.3883, 0.5434]), 'objectness_scores': tensor([0.2777, 0.2074, 0.4533, 0.2792]), 'labels': tensor([ 7, 13,  3, 11], dtype=torch.int32)}\n",
      "84477\n",
      "{'image_id': 84492, 'boxes': tensor([[ 83, 177, 158, 517],\n",
      "        [269, 274, 349, 394],\n",
      "        [137, 456, 168, 501]], dtype=torch.int32), 'scores': tensor([0.2775, 0.8819, 0.2128]), 'objectness_scores': tensor([0.2040, 0.6217, 0.2246]), 'labels': tensor([7, 8, 8], dtype=torch.int32)}\n",
      "84492\n",
      "{'image_id': 84650, 'boxes': tensor([[273, 174, 527, 347]], dtype=torch.int32), 'scores': tensor([0.9323]), 'objectness_scores': tensor([0.5329]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "84650\n",
      "{'image_id': 84674, 'boxes': tensor([[242, 237, 256, 269],\n",
      "        [  0, 268, 189, 520],\n",
      "        [241, 238, 262, 270],\n",
      "        [417, 558, 426, 565]], dtype=torch.int32), 'scores': tensor([0.2636, 0.5778, 0.2809, 0.3114]), 'objectness_scores': tensor([0.2212, 0.2150, 0.2054, 0.3420]), 'labels': tensor([11,  9,  9, 11], dtype=torch.int32)}\n",
      "84674\n",
      "{'image_id': 84752, 'boxes': tensor([[ 12, 189,  73, 377],\n",
      "        [ 30, 103, 615, 324]], dtype=torch.int32), 'scores': tensor([0.2376, 0.8727]), 'objectness_scores': tensor([0.2089, 0.5515]), 'labels': tensor([7, 0], dtype=torch.int32)}\n",
      "84752\n",
      "{'image_id': 85157, 'boxes': tensor([[ -1, 197, 218, 481]], dtype=torch.int32), 'scores': tensor([0.7496]), 'objectness_scores': tensor([0.2133]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "85157\n",
      "{'image_id': 85195, 'boxes': tensor([[  0,  96, 634, 479],\n",
      "        [  3,  96, 636, 493],\n",
      "        [263, 104, 473, 292]], dtype=torch.int32), 'scores': tensor([0.9955, 0.1801, 0.9973]), 'objectness_scores': tensor([0.4723, 0.2590, 0.5550]), 'labels': tensor([12, 11, 12], dtype=torch.int32)}\n",
      "85195\n",
      "{'image_id': 85329, 'boxes': tensor([[358, 271, 460, 408],\n",
      "        [356, 279, 465, 405]], dtype=torch.int32), 'scores': tensor([0.9307, 0.9536]), 'objectness_scores': tensor([0.4626, 0.2056]), 'labels': tensor([7, 7], dtype=torch.int32)}\n",
      "85329\n",
      "{'image_id': 86220, 'boxes': tensor([[435, 187, 470, 208],\n",
      "        [149, 250, 187, 264]], dtype=torch.int32), 'scores': tensor([0.2141, 0.1607]), 'objectness_scores': tensor([0.2547, 0.2508]), 'labels': tensor([14,  2], dtype=torch.int32)}\n",
      "86220\n",
      "{'image_id': 86956, 'boxes': tensor([[331, 342, 352, 373]], dtype=torch.int32), 'scores': tensor([0.3521]), 'objectness_scores': tensor([0.4372]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "86956\n",
      "{'image_id': 87038, 'boxes': tensor([[357, 203, 376, 218]], dtype=torch.int32), 'scores': tensor([0.2408]), 'objectness_scores': tensor([0.2126]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "87038\n",
      "{'image_id': 87470, 'boxes': tensor([[173, 140, 198, 153],\n",
      "        [270, 166, 332, 306],\n",
      "        [452, 146, 500, 227],\n",
      "        [ 42, 265, 104, 367],\n",
      "        [456, 100, 464, 104],\n",
      "        [607, 146, 641, 220],\n",
      "        [320, 153, 420, 243],\n",
      "        [ 75, 141, 228, 410],\n",
      "        [  0, 134,  85, 467],\n",
      "        [416, 146, 468, 257],\n",
      "        [220, 165, 267, 186],\n",
      "        [  1, 111, 632, 460],\n",
      "        [582, 149, 614, 223],\n",
      "        [321, 154, 409, 190],\n",
      "        [ 37,  78,  45,  82]], dtype=torch.int32), 'scores': tensor([0.2547, 0.4699, 0.3045, 0.4859, 0.2739, 0.4936, 0.9628, 0.9994, 0.3122,\n",
      "        0.3222, 0.3659, 0.9983, 0.5664, 0.2675, 0.1871]), 'objectness_scores': tensor([0.2163, 0.2800, 0.5499, 0.4098, 0.2788, 0.2074, 0.2775, 0.6249, 0.4749,\n",
      "        0.2702, 0.2389, 0.2624, 0.2047, 0.2983, 0.3689]), 'labels': tensor([11,  4,  8,  5, 11,  2,  4,  4,  7, 11, 11,  4,  7,  2, 11],\n",
      "       dtype=torch.int32)}\n",
      "87470\n",
      "{'image_id': 87476, 'boxes': tensor([[265,  49, 351, 150],\n",
      "        [205, 257, 288, 333],\n",
      "        [348,  64, 364,  73],\n",
      "        [142,  36, 158,  48],\n",
      "        [ 21, 505,  57, 526],\n",
      "        [120, 570, 368, 639],\n",
      "        [375,  64, 394,  75],\n",
      "        [393, 145, 427, 216]], dtype=torch.int32), 'scores': tensor([0.3807, 0.2407, 0.2696, 0.3241, 0.9172, 0.8355, 0.3940, 0.2552]), 'objectness_scores': tensor([0.3489, 0.3499, 0.2545, 0.2003, 0.2247, 0.5700, 0.2233, 0.2034]), 'labels': tensor([ 8,  3, 11, 11, 11,  8, 11,  7], dtype=torch.int32)}\n",
      "87476\n",
      "{'image_id': 88040, 'boxes': tensor([[203, 481, 213, 492],\n",
      "        [100, 402, 116, 438],\n",
      "        [359, 196, 387, 227],\n",
      "        [ 77, 511,  88, 522],\n",
      "        [123, 413, 197, 466],\n",
      "        [310, 544, 345, 582],\n",
      "        [114, 502, 135, 526],\n",
      "        [274, 503, 310, 545],\n",
      "        [186, 451, 209, 484],\n",
      "        [119, 513, 155, 535],\n",
      "        [ 69, 418,  95, 451],\n",
      "        [308, 534, 342, 559],\n",
      "        [  1, 333, 241, 626],\n",
      "        [200, 156, 371, 323],\n",
      "        [361, 432, 391, 458],\n",
      "        [237, 145, 297, 215],\n",
      "        [342, 414, 370, 440],\n",
      "        [106, 447, 170, 526],\n",
      "        [154, 459, 175, 484],\n",
      "        [ 83, 431, 114, 462],\n",
      "        [242, 183, 301, 234],\n",
      "        [ 77, 458, 110, 506],\n",
      "        [136, 415, 168, 454],\n",
      "        [333, 436, 360, 461],\n",
      "        [317, 403, 340, 430],\n",
      "        [186,  66, 224, 109],\n",
      "        [  0,   0,  64,  75],\n",
      "        [  0,  60, 147, 345],\n",
      "        [324, 273, 352, 298],\n",
      "        [140, 439, 171, 462],\n",
      "        [119, 425, 140, 454],\n",
      "        [346, 398, 370, 417],\n",
      "        [  0,  63,  53, 256],\n",
      "        [ 63, 404, 213, 537],\n",
      "        [221, 290, 248, 312],\n",
      "        [273, 544, 308, 580],\n",
      "        [298, 150, 327, 177],\n",
      "        [367, 383, 395, 409],\n",
      "        [121, 467, 170, 525],\n",
      "        [118, 415, 169, 459],\n",
      "        [ 30, 363, 251, 592],\n",
      "        [160, 417, 198, 467],\n",
      "        [332, 384, 358, 407],\n",
      "        [367, 409, 389, 432],\n",
      "        [162, 452, 185, 517],\n",
      "        [198, 231, 217, 265],\n",
      "        [ 94, 486, 123, 531],\n",
      "        [ 62,  80, 170, 181],\n",
      "        [ 69, 429,  95, 451],\n",
      "        [109, 414, 126, 434],\n",
      "        [231, 184, 304, 280],\n",
      "        [385, 405, 409, 432],\n",
      "        [328, 379, 413, 461]], dtype=torch.int32), 'scores': tensor([0.1903, 0.2169, 0.2561, 0.1695, 0.2397, 0.2851, 0.1787, 0.2561, 0.3901,\n",
      "        0.3180, 0.2831, 0.1918, 0.5908, 0.8725, 0.1732, 0.4915, 0.4383, 0.2932,\n",
      "        0.9986, 0.1902, 0.5720, 0.3606, 0.2126, 0.2109, 0.2140, 0.1464, 0.4135,\n",
      "        0.8112, 0.4737, 0.2741, 0.9922, 0.2865, 0.7902, 0.5679, 0.1154, 0.2515,\n",
      "        0.5120, 0.1796, 0.4465, 0.2404, 0.2100, 0.2015, 0.1972, 0.2827, 0.2505,\n",
      "        0.2073, 0.4717, 0.9808, 0.4713, 0.3380, 0.5412, 0.1566, 0.4731]), 'objectness_scores': tensor([0.2108, 0.2959, 0.2875, 0.2876, 0.2166, 0.6480, 0.3748, 0.6309, 0.3055,\n",
      "        0.2885, 0.2379, 0.5261, 0.3809, 0.2692, 0.4106, 0.5547, 0.4268, 0.4267,\n",
      "        0.3737, 0.3245, 0.2424, 0.6004, 0.3420, 0.4255, 0.4211, 0.2866, 0.2815,\n",
      "        0.2098, 0.2825, 0.2331, 0.2834, 0.3985, 0.3589, 0.3281, 0.2235, 0.6850,\n",
      "        0.2491, 0.4213, 0.2022, 0.2022, 0.2585, 0.3320, 0.4242, 0.4121, 0.3693,\n",
      "        0.2784, 0.3516, 0.2354, 0.2728, 0.4121, 0.5272, 0.4194, 0.2128]), 'labels': tensor([14, 11, 12, 14, 11,  6, 11,  7, 13, 11,  4, 14, 11,  2,  2, 11,  2,  7,\n",
      "        12,  7,  6,  7, 11, 11, 11, 11, 10, 10, 12, 11, 12, 11, 11,  7,  8, 11,\n",
      "        12, 12, 11,  9, 14,  7, 10, 11,  8, 11, 11, 10, 12, 12,  7,  3, 12],\n",
      "       dtype=torch.int32)}\n",
      "88040\n",
      "{'image_id': 88462, 'boxes': tensor([[194, 195, 202, 202],\n",
      "        [307,  46, 638, 273],\n",
      "        [337, 165, 349, 187]], dtype=torch.int32), 'scores': tensor([0.1890, 0.9989, 0.2432]), 'objectness_scores': tensor([0.2005, 0.5017, 0.2209]), 'labels': tensor([0, 1, 8], dtype=torch.int32)}\n",
      "88462\n",
      "{'image_id': 88951, 'boxes': tensor([[ 11, 325, 159, 344],\n",
      "        [159, 242, 195, 322],\n",
      "        [140, 187, 166, 201],\n",
      "        [263, 302, 280, 319],\n",
      "        [241, 296, 292, 338]], dtype=torch.int32), 'scores': tensor([0.1957, 0.3094, 0.1607, 0.5687, 0.9575]), 'objectness_scores': tensor([0.2633, 0.4369, 0.3208, 0.3232, 0.4703]), 'labels': tensor([11,  6,  4,  7,  3], dtype=torch.int32)}\n",
      "88951\n",
      "{'image_id': 89045, 'boxes': tensor([[344, 135, 404, 194],\n",
      "        [272, 136, 329, 207],\n",
      "        [175,  16, 247,  89],\n",
      "        [111, 211, 611, 370],\n",
      "        [512, 149, 638, 241],\n",
      "        [314, 149, 360, 198],\n",
      "        [256,  15, 329, 105],\n",
      "        [589, 207, 640, 278],\n",
      "        [104, 177, 165, 238],\n",
      "        [340,  33, 383,  91],\n",
      "        [ 76, 132, 466, 359],\n",
      "        [194, 132, 464, 229],\n",
      "        [  0, 259,  80, 311],\n",
      "        [242, 163, 303, 208],\n",
      "        [456,  35, 554, 213]], dtype=torch.int32), 'scores': tensor([0.9577, 0.9480, 0.2655, 0.3202, 0.1725, 0.5553, 0.2040, 0.9963, 0.1730,\n",
      "        0.3480, 0.8751, 0.9942, 0.4750, 0.9934, 0.2524]), 'objectness_scores': tensor([0.2198, 0.2179, 0.2115, 0.2643, 0.2026, 0.2104, 0.2252, 0.2287, 0.2852,\n",
      "        0.2174, 0.3586, 0.3487, 0.3193, 0.2062, 0.2222]), 'labels': tensor([13, 13, 10, 14,  3, 13, 13, 13, 11,  7, 13, 13, 14, 13, 10],\n",
      "       dtype=torch.int32)}\n",
      "89045\n",
      "{'image_id': 89078, 'boxes': tensor([[267, 533, 328, 574],\n",
      "        [233,  28, 307,  96],\n",
      "        [312, 284, 353, 341],\n",
      "        [169, 254, 213, 325],\n",
      "        [153,  92, 340, 318],\n",
      "        [235,  32, 308,  68],\n",
      "        [201, 530, 286, 581]], dtype=torch.int32), 'scores': tensor([0.7368, 0.9741, 0.5067, 0.3167, 0.9844, 0.3401, 0.7549]), 'objectness_scores': tensor([0.3491, 0.4744, 0.6103, 0.6112, 0.2288, 0.7021, 0.3360]), 'labels': tensor([8, 8, 8, 7, 8, 8, 8], dtype=torch.int32)}\n",
      "89078\n",
      "{'image_id': 89670, 'boxes': tensor([[120, 118, 515, 276],\n",
      "        [  0, 178, 119, 253],\n",
      "        [ 83, 227, 563, 390]], dtype=torch.int32), 'scores': tensor([0.9984, 0.2038, 0.9990]), 'objectness_scores': tensor([0.2764, 0.2347, 0.4889]), 'labels': tensor([12, 11, 12], dtype=torch.int32)}\n",
      "89670\n",
      "{'image_id': 90003, 'boxes': tensor([[274, 255, 299, 291],\n",
      "        [222, 211, 488, 364],\n",
      "        [137, 201, 328, 329]], dtype=torch.int32), 'scores': tensor([0.4042, 0.9820, 0.9211]), 'objectness_scores': tensor([0.3492, 0.5625, 0.5317]), 'labels': tensor([11,  3,  3], dtype=torch.int32)}\n",
      "90003\n",
      "{'image_id': 90108, 'boxes': tensor([[450, 258, 480, 271],\n",
      "        [ 90,  -1, 246, 158],\n",
      "        [204, 304, 261, 331],\n",
      "        [258, 266, 516, 474],\n",
      "        [257, 264, 512, 335],\n",
      "        [465, 260, 480, 271],\n",
      "        [244, 107, 278, 184],\n",
      "        [245, 107, 279, 140],\n",
      "        [176, 235, 189, 260],\n",
      "        [448,  54, 510, 289],\n",
      "        [104, 255, 252, 461],\n",
      "        [214, 224, 230, 256],\n",
      "        [105, 255, 252, 302]], dtype=torch.int32), 'scores': tensor([0.2615, 0.1381, 0.5854, 0.9558, 0.1796, 0.2052, 0.2393, 0.1858, 0.2470,\n",
      "        0.3170, 0.8970, 0.1933, 0.4403]), 'objectness_scores': tensor([0.2735, 0.2700, 0.2224, 0.2678, 0.5063, 0.2227, 0.3000, 0.2941, 0.5140,\n",
      "        0.2676, 0.2490, 0.4639, 0.5357]), 'labels': tensor([14,  8, 11, 15, 11,  8, 16,  9,  7,  8, 15,  9, 15], dtype=torch.int32)}\n",
      "90108\n",
      "{'image_id': 91406, 'boxes': tensor([[431, 247, 436, 251],\n",
      "        [388, 352, 449, 401],\n",
      "        [357, 128, 389, 154],\n",
      "        [406, 285, 411, 289],\n",
      "        [400, 352, 451, 395],\n",
      "        [ 65,  36,  83,  61],\n",
      "        [362,  98, 395, 108],\n",
      "        [354, 127, 386, 236],\n",
      "        [403, 258, 416, 264],\n",
      "        [597,  34, 640, 144],\n",
      "        [529, 321, 534, 325]], dtype=torch.int32), 'scores': tensor([0.2074, 0.8129, 0.6842, 0.1616, 0.8904, 0.3340, 0.3122, 0.1762, 0.1924,\n",
      "        0.2533, 0.2194]), 'objectness_scores': tensor([0.2850, 0.2447, 0.4029, 0.2731, 0.3420, 0.4523, 0.2319, 0.2412, 0.2128,\n",
      "        0.2018, 0.4077]), 'labels': tensor([11, 11,  7,  4, 11, 11, 11, 11, 10,  8, 11], dtype=torch.int32)}\n",
      "91406\n",
      "{'image_id': 91500, 'boxes': tensor([[ 75,  68,  89,  90],\n",
      "        [340,  79, 360, 120],\n",
      "        [289,  79, 317, 129],\n",
      "        [381, 183, 452, 203]], dtype=torch.int32), 'scores': tensor([0.3234, 0.1759, 0.1623, 0.1921]), 'objectness_scores': tensor([0.2155, 0.3075, 0.3000, 0.2168]), 'labels': tensor([11, 11,  7,  7], dtype=torch.int32)}\n",
      "91500\n",
      "{'image_id': 91615, 'boxes': tensor([[584, 213, 640, 371],\n",
      "        [ 36,  63,  93, 183],\n",
      "        [ 81, 278, 235, 322],\n",
      "        [454, 178, 611, 224],\n",
      "        [117, 245, 234, 282],\n",
      "        [249,  92, 298, 155],\n",
      "        [326, 134, 332, 152],\n",
      "        [585, 249, 639, 370],\n",
      "        [327,   0, 476, 114],\n",
      "        [327, 196, 367, 339],\n",
      "        [525, 161, 561, 194],\n",
      "        [ 75, 189, 156, 282],\n",
      "        [369, 195, 452, 330],\n",
      "        [ 77, 245, 236, 323]], dtype=torch.int32), 'scores': tensor([0.1952, 0.8038, 0.6332, 0.2134, 0.7271, 0.4526, 0.1340, 0.3048, 0.2157,\n",
      "        0.3716, 0.5557, 0.3449, 0.2177, 0.5062]), 'objectness_scores': tensor([0.2584, 0.2149, 0.4422, 0.2297, 0.3770, 0.2529, 0.3905, 0.2369, 0.2563,\n",
      "        0.2212, 0.3544, 0.4393, 0.2685, 0.3059]), 'labels': tensor([ 7,  8, 11, 11, 11, 10, 11,  8,  7,  7, 10, 10,  7, 11],\n",
      "       dtype=torch.int32)}\n",
      "91615\n",
      "{'image_id': 91779, 'boxes': tensor([[438, 199, 506, 238],\n",
      "        [526, 152, 588, 210],\n",
      "        [263,  46, 325,  92],\n",
      "        [298, 299, 400, 358],\n",
      "        [421, 186, 495, 230],\n",
      "        [529, 150, 605, 207],\n",
      "        [142, 107, 427, 266],\n",
      "        [  8,  58, 272, 145],\n",
      "        [  9,  76, 637, 479],\n",
      "        [  2,  14, 635, 483],\n",
      "        [  0, 116,  93, 174],\n",
      "        [222, 360, 390, 448],\n",
      "        [279, 150, 634, 423],\n",
      "        [339, 291, 383, 328],\n",
      "        [489, 169, 545, 196],\n",
      "        [455, 261, 540, 324],\n",
      "        [526, 205, 573, 246],\n",
      "        [404,   0, 507, 100],\n",
      "        [157,  58, 248, 108],\n",
      "        [505, 193, 563, 227],\n",
      "        [393, 388, 482, 429],\n",
      "        [386, 267, 462, 301],\n",
      "        [383, 272, 471, 330],\n",
      "        [432, 232, 512, 268],\n",
      "        [311, 353, 424, 403]], dtype=torch.int32), 'scores': tensor([0.3190, 0.3675, 0.5307, 0.9294, 0.7243, 0.2692, 0.1863, 0.4058, 0.4926,\n",
      "        0.6392, 0.3835, 0.3417, 0.4341, 0.2317, 0.4063, 0.9965, 0.4576, 0.9620,\n",
      "        0.4181, 0.4525, 0.2129, 0.2098, 0.5545, 0.6277, 0.2426]), 'objectness_scores': tensor([0.2209, 0.2653, 0.2558, 0.3417, 0.2238, 0.2266, 0.2558, 0.2138, 0.2405,\n",
      "        0.3800, 0.2314, 0.2223, 0.2197, 0.2186, 0.2142, 0.3025, 0.2020, 0.5627,\n",
      "        0.2159, 0.2268, 0.2833, 0.2723, 0.3378, 0.2731, 0.2211]), 'labels': tensor([11, 12, 12, 13,  3, 11, 12, 11,  3,  3, 14, 11, 11, 11, 11, 13, 11, 10,\n",
      "        12, 11, 12, 11, 12, 12,  7], dtype=torch.int32)}\n",
      "91779\n",
      "{'image_id': 92053, 'boxes': tensor([[424, 166, 568, 223],\n",
      "        [ 94, 171, 485, 427],\n",
      "        [444, 169, 561, 212],\n",
      "        [271,   0, 316, 107],\n",
      "        [367,  82, 639, 250],\n",
      "        [  7,  60, 633, 423],\n",
      "        [  0, 139,  81, 264],\n",
      "        [  5,   4, 635, 429],\n",
      "        [423, 166, 478, 216],\n",
      "        [428, 168, 564, 221],\n",
      "        [ 67,  73, 307, 211],\n",
      "        [428, 134, 552, 178],\n",
      "        [ 82, 116, 157, 181],\n",
      "        [308,   1, 393, 180]], dtype=torch.int32), 'scores': tensor([0.5076, 0.8129, 0.1885, 0.3156, 0.6051, 0.2506, 0.5461, 0.2731, 0.2050,\n",
      "        0.7041, 0.2869, 0.8352, 0.2290, 0.5784]), 'objectness_scores': tensor([0.3727, 0.3440, 0.2526, 0.4456, 0.3481, 0.2318, 0.3263, 0.2710, 0.2296,\n",
      "        0.2257, 0.3886, 0.2204, 0.3320, 0.4678]), 'labels': tensor([11, 12, 11, 11, 11, 12,  7, 11,  8, 11,  7, 12, 11, 10],\n",
      "       dtype=torch.int32)}\n",
      "92053\n",
      "{'image_id': 92091, 'boxes': tensor([[389, 160, 488, 235],\n",
      "        [250, 263, 401, 480],\n",
      "        [301, 237, 315, 260],\n",
      "        [426, 242, 639, 385],\n",
      "        [245, 158, 454, 480],\n",
      "        [318, 129, 641, 348]], dtype=torch.int32), 'scores': tensor([0.3654, 0.3716, 0.2230, 0.6048, 0.5668, 0.1208]), 'objectness_scores': tensor([0.2078, 0.2264, 0.3251, 0.4442, 0.2796, 0.3044]), 'labels': tensor([ 8,  7, 11,  5,  3, 11], dtype=torch.int32)}\n",
      "92091\n",
      "{'image_id': 92124, 'boxes': tensor([[ 31, 371,  66, 411],\n",
      "        [213, 353, 355, 425],\n",
      "        [277, 345, 320, 376],\n",
      "        [ 30,  34, 267, 518],\n",
      "        [324, 329, 347, 386],\n",
      "        [  1,   6, 357, 634],\n",
      "        [257, 115, 346, 286]], dtype=torch.int32), 'scores': tensor([0.5233, 0.9866, 0.2434, 0.7498, 0.2062, 0.9656, 0.5699]), 'objectness_scores': tensor([0.4569, 0.3179, 0.2867, 0.4425, 0.3840, 0.2586, 0.3764]), 'labels': tensor([11, 15,  8, 15, 11, 15,  7], dtype=torch.int32)}\n",
      "92124\n",
      "{'image_id': 92177, 'boxes': tensor([[  5,  10, 623, 633],\n",
      "        [476, 428, 540, 529],\n",
      "        [137, 179, 510, 523],\n",
      "        [132, 511, 253, 584],\n",
      "        [ 58, 335, 562, 632]], dtype=torch.int32), 'scores': tensor([0.9986, 0.3396, 0.9924, 0.2700, 0.9425]), 'objectness_scores': tensor([0.2270, 0.2128, 0.2896, 0.5790, 0.3168]), 'labels': tensor([12, 11, 12,  4, 12], dtype=torch.int32)}\n",
      "92177\n",
      "{'image_id': 92416, 'boxes': tensor([[250, 289, 323, 609],\n",
      "        [ 66, 235, 367, 644]], dtype=torch.int32), 'scores': tensor([0.2533, 0.9946]), 'objectness_scores': tensor([0.3175, 0.2418]), 'labels': tensor([10,  7], dtype=torch.int32)}\n",
      "92416\n",
      "{'image_id': 92660, 'boxes': tensor([[104,   0, 195,  95],\n",
      "        [  2,  54, 636, 427],\n",
      "        [296,  69, 546, 129],\n",
      "        [  3, 108, 637, 402],\n",
      "        [328,  51, 431,  85],\n",
      "        [360,  52, 382,  65],\n",
      "        [ 67,   0, 119,  71],\n",
      "        [177,   0, 233,  68],\n",
      "        [ 78,  59, 118, 119]], dtype=torch.int32), 'scores': tensor([0.9075, 0.4634, 0.6627, 0.3121, 0.3370, 0.4096, 0.2606, 0.6118, 0.3046]), 'objectness_scores': tensor([0.3855, 0.3208, 0.6259, 0.4094, 0.2186, 0.2041, 0.3018, 0.2821, 0.2550]), 'labels': tensor([10, 11, 11, 11, 12, 11, 10, 10,  7], dtype=torch.int32)}\n",
      "92660\n",
      "{'image_id': 92939, 'boxes': tensor([[178, 256, 390, 507],\n",
      "        [277, 135, 302, 177],\n",
      "        [250, 205, 287, 267],\n",
      "        [219, 427, 246, 457],\n",
      "        [ 93, 541, 176, 610],\n",
      "        [203, 495, 357, 624]], dtype=torch.int32), 'scores': tensor([0.5301, 0.3131, 0.2720, 0.7128, 0.1835, 0.9998]), 'objectness_scores': tensor([0.2550, 0.2934, 0.2662, 0.4569, 0.2642, 0.4788]), 'labels': tensor([ 7, 11,  7, 11, 13, 12], dtype=torch.int32)}\n",
      "92939\n",
      "{'image_id': 93437, 'boxes': tensor([[243,   4, 364, 110],\n",
      "        [580, 169, 592, 189]], dtype=torch.int32), 'scores': tensor([0.6277, 0.3297]), 'objectness_scores': tensor([0.2399, 0.2641]), 'labels': tensor([10, 14], dtype=torch.int32)}\n",
      "93437\n",
      "{'image_id': 93717, 'boxes': tensor([[ 48, 168,  59, 180],\n",
      "        [312,  53, 353,  92],\n",
      "        [254, 368, 260, 372],\n",
      "        [532, 164, 567, 187],\n",
      "        [169, 335, 177, 340],\n",
      "        [580, 223, 601, 241],\n",
      "        [167, 359, 179, 374],\n",
      "        [ 30, 242,  35, 247],\n",
      "        [238, 309, 261, 316],\n",
      "        [222, 404, 232, 409],\n",
      "        [125, 310, 134, 318],\n",
      "        [  0,   3, 124,  85],\n",
      "        [ 24, 338,  34, 347],\n",
      "        [236, 395, 251, 407],\n",
      "        [249, 276, 256, 281],\n",
      "        [ 87, 344,  95, 349],\n",
      "        [231, 345, 240, 352],\n",
      "        [220, 247, 229, 255]], dtype=torch.int32), 'scores': tensor([0.1551, 0.1669, 0.1503, 0.1744, 0.3668, 0.1176, 0.2681, 0.1912, 0.1838,\n",
      "        0.3169, 0.2528, 0.5032, 0.2592, 0.1869, 0.2915, 0.1526, 0.2920, 0.1852]), 'objectness_scores': tensor([0.2321, 0.2726, 0.2123, 0.3443, 0.3536, 0.2429, 0.2029, 0.2607, 0.2143,\n",
      "        0.2396, 0.2610, 0.2092, 0.2738, 0.2067, 0.3231, 0.3102, 0.2868, 0.2822]), 'labels': tensor([11, 11, 14,  8, 11, 11, 11, 11, 14, 11, 11,  9, 11, 11, 11, 11, 11, 14],\n",
      "       dtype=torch.int32)}\n",
      "93717\n",
      "{'image_id': 94944, 'boxes': tensor([[411, 238, 437, 251],\n",
      "        [408, 222, 439, 250],\n",
      "        [558, 235, 567, 245],\n",
      "        [570, 281, 594, 293],\n",
      "        [188, 257, 200, 264]], dtype=torch.int32), 'scores': tensor([0.3055, 0.3074, 0.2720, 0.3768, 0.3671]), 'objectness_scores': tensor([0.4249, 0.2368, 0.2129, 0.2596, 0.2171]), 'labels': tensor([14,  8, 11, 13, 10], dtype=torch.int32)}\n",
      "94944\n",
      "{'image_id': 95155, 'boxes': tensor([[171,  67, 183,  73],\n",
      "        [198, 356, 221, 377],\n",
      "        [128, 249, 149, 269],\n",
      "        [444, 221, 470, 241],\n",
      "        [114, 313, 123, 322],\n",
      "        [511,  98, 521, 107],\n",
      "        [483,  53, 501,  61],\n",
      "        [543, 354, 578, 388],\n",
      "        [131, 261, 149, 271],\n",
      "        [444, 213, 470, 242],\n",
      "        [482,  43, 501,  61],\n",
      "        [174, 319, 185, 328],\n",
      "        [439, 301, 449, 318],\n",
      "        [446,  94, 454, 105],\n",
      "        [481, 304, 499, 316],\n",
      "        [544, 353, 577, 381],\n",
      "        [172, 354, 200, 369],\n",
      "        [140,  92, 146, 100],\n",
      "        [170,  59, 184,  73],\n",
      "        [176, 105, 186, 113],\n",
      "        [445, 138, 462, 147]], dtype=torch.int32), 'scores': tensor([0.4412, 0.4694, 0.6681, 0.2291, 0.1796, 0.1964, 0.4567, 0.3830, 0.2628,\n",
      "        0.8294, 0.6565, 0.2631, 0.1816, 0.1630, 0.2747, 0.3162, 0.4209, 0.3405,\n",
      "        0.2979, 0.2647, 0.2087]), 'objectness_scores': tensor([0.4641, 0.3138, 0.2286, 0.5133, 0.3251, 0.4225, 0.4884, 0.2260, 0.4731,\n",
      "        0.2595, 0.2888, 0.2771, 0.3610, 0.4248, 0.2234, 0.2902, 0.3100, 0.3176,\n",
      "        0.2317, 0.4009, 0.2625]), 'labels': tensor([14, 12,  8, 11, 11, 11, 16,  9, 14,  8,  8,  7, 11, 11, 11, 11, 11,  8,\n",
      "        14, 11, 11], dtype=torch.int32)}\n",
      "95155\n",
      "{'image_id': 95707, 'boxes': tensor([[537, 211, 639, 311],\n",
      "        [489, 183, 537, 360],\n",
      "        [277,  10, 379, 131],\n",
      "        [164,  51, 271, 118],\n",
      "        [  2,  24, 509, 359],\n",
      "        [  1,   1, 632, 359]], dtype=torch.int32), 'scores': tensor([0.7339, 0.1934, 0.9539, 0.3957, 0.9885, 0.9977]), 'objectness_scores': tensor([0.3981, 0.4881, 0.2285, 0.2138, 0.2992, 0.2890]), 'labels': tensor([12, 11, 12, 12, 12, 12], dtype=torch.int32)}\n",
      "95707\n",
      "{'image_id': 95786, 'boxes': tensor([[  0, 117, 496, 335]], dtype=torch.int32), 'scores': tensor([0.9920]), 'objectness_scores': tensor([0.2447]), 'labels': tensor([10], dtype=torch.int32)}\n",
      "95786\n",
      "{'image_id': 96001, 'boxes': tensor([[393, 289, 641, 386],\n",
      "        [ 72,   0, 117,  61],\n",
      "        [-11,  -8, 594, 405],\n",
      "        [588,  51, 638,  79],\n",
      "        [589,  51, 638, 114],\n",
      "        [401, 109, 509, 265],\n",
      "        [110, 179, 258, 249],\n",
      "        [ -2, 183, 407, 322]], dtype=torch.int32), 'scores': tensor([0.8811, 0.6102, 0.4272, 0.2659, 0.4493, 0.9490, 0.2724, 0.6624]), 'objectness_scores': tensor([0.2927, 0.3097, 0.3171, 0.2386, 0.2226, 0.5130, 0.2378, 0.2107]), 'labels': tensor([11,  2, 11, 11,  9,  2,  7,  7], dtype=torch.int32)}\n",
      "96001\n",
      "{'image_id': 96493, 'boxes': tensor([[  0, 243, 299, 637],\n",
      "        [151, 149, 416, 367],\n",
      "        [  1,   1, 387, 161],\n",
      "        [147, 311, 422, 637]], dtype=torch.int32), 'scores': tensor([0.6021, 0.4194, 0.3553, 0.8989]), 'objectness_scores': tensor([0.3674, 0.2199, 0.3608, 0.2156]), 'labels': tensor([13, 13,  7, 13], dtype=torch.int32)}\n",
      "96493\n",
      "{'image_id': 97022, 'boxes': tensor([[336,  16, 436, 192],\n",
      "        [294, 193, 323, 251],\n",
      "        [230,  37, 279, 152],\n",
      "        [497,   1, 638, 173],\n",
      "        [564,   0, 639, 164],\n",
      "        [515, 195, 531, 208],\n",
      "        [150, 221, 165, 256],\n",
      "        [409, 270, 477, 406],\n",
      "        [467, 272, 557, 420],\n",
      "        [169,  55, 274, 211],\n",
      "        [ 36, 260, 103, 282],\n",
      "        [ 35, 267, 161, 394],\n",
      "        [554, 274, 640, 426],\n",
      "        [231,  20, 336, 156],\n",
      "        [495,   0, 568, 172],\n",
      "        [225, 266, 325, 382],\n",
      "        [166,  70, 253, 210],\n",
      "        [261, 251, 335, 261],\n",
      "        [273,  22, 336, 146],\n",
      "        [164, 287, 180, 327],\n",
      "        [175, 288, 202, 337],\n",
      "        [196, 289, 224, 334],\n",
      "        [435,   1, 506, 178],\n",
      "        [ 10, 115, 130, 176],\n",
      "        [330,   2, 637, 197],\n",
      "        [ 35, 258, 127, 283],\n",
      "        [106, 269, 158, 373],\n",
      "        [144, 266, 173, 354]], dtype=torch.int32), 'scores': tensor([0.2552, 0.2210, 0.4673, 0.1603, 0.3051, 0.2275, 0.4860, 0.9978, 0.3351,\n",
      "        0.1715, 0.2132, 0.3241, 0.1788, 0.2360, 0.2146, 0.2628, 0.2301, 0.4257,\n",
      "        0.5879, 0.3255, 0.7262, 0.4901, 0.3798, 0.2637, 0.1851, 0.2905, 0.2231,\n",
      "        0.4225]), 'objectness_scores': tensor([0.2618, 0.3496, 0.2076, 0.2962, 0.2308, 0.2026, 0.4348, 0.2744, 0.2304,\n",
      "        0.2164, 0.2260, 0.2761, 0.2426, 0.2896, 0.2290, 0.3337, 0.2667, 0.2594,\n",
      "        0.2096, 0.2429, 0.2056, 0.2974, 0.2337, 0.7232, 0.2198, 0.2774, 0.2147,\n",
      "        0.2729]), 'labels': tensor([ 7, 11,  8,  7,  7, 10, 11, 10, 16,  2,  9, 16,  7,  8,  7, 16,  8, 11,\n",
      "         8,  7,  7,  7, 15, 15, 15, 14,  7,  7], dtype=torch.int32)}\n",
      "97022\n",
      "{'image_id': 97278, 'boxes': tensor([[221, 514, 293, 564],\n",
      "        [ 78, 498, 134, 577],\n",
      "        [ 96, 147, 327, 355]], dtype=torch.int32), 'scores': tensor([0.8366, 0.9632, 0.8189]), 'objectness_scores': tensor([0.2281, 0.2347, 0.2873]), 'labels': tensor([8, 8, 8], dtype=torch.int32)}\n",
      "97278\n",
      "{'image_id': 97337, 'boxes': tensor([[  1,  50,  68, 169],\n",
      "        [  0,  53,  69, 108],\n",
      "        [437, 149, 499, 210],\n",
      "        [  2, 164, 207, 293],\n",
      "        [212, 228, 428, 374],\n",
      "        [169, 187, 283, 253],\n",
      "        [  1, 266, 127, 375],\n",
      "        [345, 147, 499, 307],\n",
      "        [431, 244, 497, 316],\n",
      "        [336,  85, 362, 131],\n",
      "        [  0, 170, 139, 374],\n",
      "        [  0, 211,  60, 273]], dtype=torch.int32), 'scores': tensor([0.3005, 0.3056, 0.6137, 0.9930, 0.2943, 0.2565, 0.7642, 0.9350, 0.2931,\n",
      "        0.3417, 0.9344, 0.5451]), 'objectness_scores': tensor([0.3631, 0.2313, 0.2066, 0.3185, 0.4295, 0.2405, 0.2050, 0.3869, 0.2705,\n",
      "        0.2093, 0.3899, 0.2370]), 'labels': tensor([ 6, 13, 13, 13, 15,  8, 13, 13,  7, 11, 13,  3], dtype=torch.int32)}\n",
      "97337\n",
      "{'image_id': 97679, 'boxes': tensor([[512, 309, 523, 331],\n",
      "        [105, 232, 114, 259],\n",
      "        [589, 238, 628, 259]], dtype=torch.int32), 'scores': tensor([0.3132, 0.1705, 0.3917]), 'objectness_scores': tensor([0.2570, 0.4317, 0.2579]), 'labels': tensor([11, 11,  9], dtype=torch.int32)}\n",
      "97679\n",
      "{'image_id': 97994, 'boxes': tensor([[511, 282, 545, 328],\n",
      "        [177, 274, 205, 308],\n",
      "        [  0, 274, 619, 428],\n",
      "        [218, 308, 399, 353],\n",
      "        [156,  13, 207,  84],\n",
      "        [207, 239, 238, 292],\n",
      "        [244,  35, 297, 169]], dtype=torch.int32), 'scores': tensor([0.9266, 0.2247, 0.9871, 0.9982, 0.5183, 0.1980, 0.5961]), 'objectness_scores': tensor([0.2737, 0.2184, 0.3812, 0.4638, 0.2147, 0.5862, 0.2308]), 'labels': tensor([10,  7, 14, 14,  7,  7,  6], dtype=torch.int32)}\n",
      "97994\n",
      "{'image_id': 98392, 'boxes': tensor([[101, 372, 123, 427],\n",
      "        [143, 487, 157, 496]], dtype=torch.int32), 'scores': tensor([0.3852, 0.4402]), 'objectness_scores': tensor([0.3003, 0.2038]), 'labels': tensor([11, 14], dtype=torch.int32)}\n",
      "98392\n",
      "{'image_id': 98520, 'boxes': tensor([[168, 211, 233, 220],\n",
      "        [295, 240, 360, 271],\n",
      "        [ 92, 127, 615, 282],\n",
      "        [489, 130, 588, 222],\n",
      "        [455, 154, 483, 184]], dtype=torch.int32), 'scores': tensor([0.2185, 0.2213, 0.9751, 0.4940, 0.2618]), 'objectness_scores': tensor([0.2149, 0.3723, 0.6016, 0.3433, 0.2054]), 'labels': tensor([14, 14,  0,  0,  7], dtype=torch.int32)}\n",
      "98520\n",
      "{'image_id': 98839, 'boxes': tensor([[  3, 396, 633, 478],\n",
      "        [483, 394, 606, 427],\n",
      "        [101, 116, 397, 479]], dtype=torch.int32), 'scores': tensor([0.8352, 0.5242, 0.9668]), 'objectness_scores': tensor([0.3123, 0.2240, 0.5114]), 'labels': tensor([12, 14,  2], dtype=torch.int32)}\n",
      "98839\n",
      "{'image_id': 99024, 'boxes': tensor([[289, 120, 375, 288],\n",
      "        [602, 360, 638, 459],\n",
      "        [ 38, 359, 106, 449],\n",
      "        [132, 135, 426, 271]], dtype=torch.int32), 'scores': tensor([0.5123, 0.5672, 0.4696, 0.5784]), 'objectness_scores': tensor([0.2299, 0.6410, 0.2567, 0.2225]), 'labels': tensor([7, 9, 6, 6], dtype=torch.int32)}\n",
      "99024\n",
      "{'image_id': 99039, 'boxes': tensor([[281, 228, 345, 346],\n",
      "        [175, 283, 252, 312],\n",
      "        [419, 228, 481, 352],\n",
      "        [  4, 310, 592, 478],\n",
      "        [129, 324, 229, 384]], dtype=torch.int32), 'scores': tensor([0.7244, 0.2647, 0.7472, 0.3580, 0.7033]), 'objectness_scores': tensor([0.3108, 0.2038, 0.3580, 0.2496, 0.3620]), 'labels': tensor([10,  7, 10, 10, 11], dtype=torch.int32)}\n",
      "99039\n",
      "{'image_id': 99054, 'boxes': tensor([[ 33, 596,  89, 616],\n",
      "        [ 61,  57, 420, 349],\n",
      "        [312, 254, 397, 270],\n",
      "        [  5,  81, 426, 583]], dtype=torch.int32), 'scores': tensor([0.4520, 0.2407, 0.2572, 0.9825]), 'objectness_scores': tensor([0.2697, 0.2018, 0.2119, 0.4202]), 'labels': tensor([9, 3, 7, 0], dtype=torch.int32)}\n",
      "99054\n",
      "{'image_id': 100428, 'boxes': tensor([[288, 228, 603, 491],\n",
      "        [183, 244, 241, 420],\n",
      "        [183, 230, 479, 412],\n",
      "        [118, 201, 225, 488],\n",
      "        [ 84,  -1, 230, 487]], dtype=torch.int32), 'scores': tensor([0.6684, 0.2110, 0.4166, 0.4102, 0.9356]), 'objectness_scores': tensor([0.2918, 0.2932, 0.3287, 0.2642, 0.3268]), 'labels': tensor([ 7, 10,  7, 11,  7], dtype=torch.int32)}\n",
      "100428\n",
      "{'image_id': 101762, 'boxes': tensor([[128,   0, 514, 344],\n",
      "        [ 40,  30, 126, 275],\n",
      "        [422,  77, 637, 336]], dtype=torch.int32), 'scores': tensor([0.6090, 0.2626, 0.9760]), 'objectness_scores': tensor([0.2268, 0.2219, 0.5766]), 'labels': tensor([2, 6, 2], dtype=torch.int32)}\n",
      "101762\n",
      "{'image_id': 102707, 'boxes': tensor([[193, 463, 293, 531],\n",
      "        [478, 366, 601, 609],\n",
      "        [ 45,  45, 143, 147],\n",
      "        [  6, 431, 313, 604],\n",
      "        [  7, 503, 182, 601]], dtype=torch.int32), 'scores': tensor([0.6581, 0.3144, 0.3539, 0.9241, 0.6703]), 'objectness_scores': tensor([0.3135, 0.4740, 0.2001, 0.3285, 0.2032]), 'labels': tensor([11,  7,  9, 15, 15], dtype=torch.int32)}\n",
      "102707\n",
      "{'image_id': 102820, 'boxes': tensor([[ 10, 520, 309, 596],\n",
      "        [ 77, 406, 324, 456],\n",
      "        [ 45, 484, 254, 576],\n",
      "        [ 93, 190, 363, 408]], dtype=torch.int32), 'scores': tensor([0.9968, 0.2887, 0.9960, 0.6319]), 'objectness_scores': tensor([0.2401, 0.2014, 0.6018, 0.3008]), 'labels': tensor([12, 11, 12,  7], dtype=torch.int32)}\n",
      "102820\n",
      "{'image_id': 103585, 'boxes': tensor([[  0,   2, 424, 629],\n",
      "        [ 71, 399, 153, 581],\n",
      "        [  0, 342,  23, 390],\n",
      "        [145, 356, 231, 528],\n",
      "        [230, 329, 293, 460],\n",
      "        [171, 103, 201, 130],\n",
      "        [190, 294, 214, 325],\n",
      "        [215, 294, 227, 317],\n",
      "        [  0, 574,  29, 618],\n",
      "        [155, 103, 200, 135],\n",
      "        [192, 321, 257, 341],\n",
      "        [112, 269, 139, 310],\n",
      "        [  1, 332, 297, 624],\n",
      "        [148, 414, 231, 528],\n",
      "        [  0, 381,  90, 429],\n",
      "        [244, 271, 254, 290],\n",
      "        [  1, 432,  90, 630],\n",
      "        [257, 257, 290, 316],\n",
      "        [ 70, 336, 108, 372],\n",
      "        [146, 359, 230, 466],\n",
      "        [147, 157, 200, 253],\n",
      "        [  0,  43,  15,  85],\n",
      "        [  0, 137,  35, 274],\n",
      "        [168, 237, 181, 250],\n",
      "        [ 53, 145, 133, 266],\n",
      "        [256, 240, 283, 261]], dtype=torch.int32), 'scores': tensor([0.9208, 0.1876, 0.1776, 0.3096, 0.2474, 0.1831, 0.2518, 0.2896, 0.1730,\n",
      "        0.3333, 0.2087, 0.3545, 0.3380, 0.3181, 0.9960, 0.1478, 0.1558, 0.9018,\n",
      "        0.1824, 0.2566, 0.4227, 0.2535, 0.6005, 0.4185, 0.4420, 0.2342]), 'objectness_scores': tensor([0.2002, 0.2812, 0.3863, 0.2923, 0.3334, 0.2624, 0.4265, 0.4394, 0.2018,\n",
      "        0.3888, 0.4254, 0.2700, 0.2356, 0.2166, 0.5239, 0.5143, 0.3374, 0.4782,\n",
      "        0.3597, 0.2199, 0.4951, 0.2069, 0.2012, 0.2593, 0.4784, 0.2979]), 'labels': tensor([15,  7, 11, 11,  8, 10, 11, 11, 11, 10, 11,  6, 11, 15,  5, 11,  7,  7,\n",
      "         7,  7, 11, 11,  7, 11, 11, 16], dtype=torch.int32)}\n",
      "103585\n",
      "{'image_id': 103723, 'boxes': tensor([[157, 225, 382, 572]], dtype=torch.int32), 'scores': tensor([0.9998]), 'objectness_scores': tensor([0.7530]), 'labels': tensor([5], dtype=torch.int32)}\n",
      "103723\n",
      "{'image_id': 104572, 'boxes': tensor([[410, 193, 441, 207],\n",
      "        [  0,  68, 188, 267],\n",
      "        [399, 192, 407, 199],\n",
      "        [394, 197, 431, 214],\n",
      "        [266, 157, 300, 339],\n",
      "        [364, 139, 405, 186],\n",
      "        [341, 106, 471, 304],\n",
      "        [  1,  12, 177,  69],\n",
      "        [135, 275, 159, 307],\n",
      "        [371, 204, 418, 224],\n",
      "        [ 90, 291, 234, 367],\n",
      "        [383, 198, 391, 206],\n",
      "        [414, 188, 421, 194]], dtype=torch.int32), 'scores': tensor([0.2787, 0.6626, 0.4056, 0.2255, 0.2248, 0.1698, 0.3183, 0.3102, 0.5923,\n",
      "        0.5190, 0.9969, 0.1632, 0.1824]), 'objectness_scores': tensor([0.5394, 0.5900, 0.4815, 0.6095, 0.2170, 0.3022, 0.4653, 0.2214, 0.5739,\n",
      "        0.5004, 0.6374, 0.3787, 0.3430]), 'labels': tensor([14, 15,  8, 11,  7,  7, 10,  8,  8, 11, 15,  0, 14], dtype=torch.int32)}\n",
      "104572\n",
      "{'image_id': 104666, 'boxes': tensor([[474,  95, 495, 141],\n",
      "        [428, 137, 527, 256],\n",
      "        [126, 113, 159, 156],\n",
      "        [232, 216, 285, 425],\n",
      "        [179, 253, 218, 426],\n",
      "        [563, 385, 641, 426],\n",
      "        [203, 197, 235, 330],\n",
      "        [187, 227, 299, 310]], dtype=torch.int32), 'scores': tensor([0.2705, 0.1980, 0.7913, 0.9591, 0.3230, 0.5063, 0.3501, 0.2017]), 'objectness_scores': tensor([0.2003, 0.2560, 0.2542, 0.4038, 0.4027, 0.2198, 0.2500, 0.3969]), 'labels': tensor([ 7, 12, 11,  3,  7, 11, 11,  7], dtype=torch.int32)}\n",
      "104666\n",
      "{'image_id': 104669, 'boxes': tensor([[243,  48, 295, 100],\n",
      "        [ 96,  83, 236, 244],\n",
      "        [235, 123, 289, 172],\n",
      "        [403, 190, 498, 365],\n",
      "        [282, 126, 342, 181],\n",
      "        [ 95,  27, 253, 244],\n",
      "        [227, 211, 257, 264],\n",
      "        [179,  23, 250, 137],\n",
      "        [ 45,  22, 410, 373],\n",
      "        [  0,  72, 495, 373],\n",
      "        [  1, 153,  79, 376],\n",
      "        [145, 234, 184, 251],\n",
      "        [279,  76, 335, 134]], dtype=torch.int32), 'scores': tensor([0.5322, 0.6615, 0.6505, 0.9318, 0.7568, 0.5738, 0.5551, 0.5551, 0.5015,\n",
      "        0.5128, 0.6171, 0.1575, 0.4343]), 'objectness_scores': tensor([0.4506, 0.3038, 0.4702, 0.6170, 0.3694, 0.4525, 0.2230, 0.3009, 0.3291,\n",
      "        0.4619, 0.5227, 0.4075, 0.4616]), 'labels': tensor([12,  4,  3,  7,  4,  4, 11, 12,  4,  4, 11, 11, 12], dtype=torch.int32)}\n",
      "104669\n",
      "{'image_id': 105249, 'boxes': tensor([[136, 182, 153, 201],\n",
      "        [295,   0, 317, 289],\n",
      "        [137, 191, 216, 254],\n",
      "        [266, 160, 279, 171],\n",
      "        [253, 189, 265, 196]], dtype=torch.int32), 'scores': tensor([0.4707, 0.5802, 0.9536, 0.3088, 0.1829]), 'objectness_scores': tensor([0.2877, 0.2006, 0.6026, 0.2178, 0.2459]), 'labels': tensor([11, 11, 15, 14, 14], dtype=torch.int32)}\n",
      "105249\n",
      "{'image_id': 105264, 'boxes': tensor([[402, 199, 451, 269],\n",
      "        [ 60, 124, 346, 407],\n",
      "        [407, 196, 415, 206]], dtype=torch.int32), 'scores': tensor([0.5817, 0.9670, 0.2331]), 'objectness_scores': tensor([0.2203, 0.6723, 0.3162]), 'labels': tensor([ 7,  4, 11], dtype=torch.int32)}\n",
      "105264\n",
      "{'image_id': 105912, 'boxes': tensor([[110,  96, 208, 319]], dtype=torch.int32), 'scores': tensor([0.1515]), 'objectness_scores': tensor([0.5806]), 'labels': tensor([6], dtype=torch.int32)}\n",
      "105912\n",
      "{'image_id': 105923, 'boxes': tensor([[ 29, 180,  36, 187],\n",
      "        [419,  92, 547, 332],\n",
      "        [328,  89, 548, 330]], dtype=torch.int32), 'scores': tensor([0.1981, 0.9936, 0.9939]), 'objectness_scores': tensor([0.2609, 0.3223, 0.4793]), 'labels': tensor([14,  5,  5], dtype=torch.int32)}\n",
      "105923\n",
      "{'image_id': 106235, 'boxes': tensor([[136, 124, 520, 351],\n",
      "        [455, 114, 564, 185],\n",
      "        [326, 309, 640, 480],\n",
      "        [ 57, 279, 226, 381],\n",
      "        [328, 117, 452, 210],\n",
      "        [368, 236, 592, 414],\n",
      "        [  0, 276, 112, 472],\n",
      "        [425, 141, 495, 207],\n",
      "        [200, 153, 270, 252],\n",
      "        [538, 179, 596, 246],\n",
      "        [103, 377, 348, 480],\n",
      "        [472, 244, 498, 281],\n",
      "        [  0,  35,  81, 284],\n",
      "        [208, 139, 340, 231],\n",
      "        [ 11, 229, 187, 310]], dtype=torch.int32), 'scores': tensor([0.9963, 0.2056, 0.2088, 0.3894, 0.9010, 0.4999, 0.4582, 0.4562, 0.1139,\n",
      "        0.2130, 0.1548, 0.2885, 0.2211, 0.9443, 0.7972]), 'objectness_scores': tensor([0.4902, 0.2208, 0.2074, 0.2430, 0.2717, 0.4974, 0.2895, 0.3410, 0.3287,\n",
      "        0.2408, 0.3013, 0.2345, 0.2280, 0.2340, 0.3877]), 'labels': tensor([13,  2, 10, 13, 13, 10, 13, 12, 11,  5,  8,  7, 11, 13, 15],\n",
      "       dtype=torch.int32)}\n",
      "106235\n",
      "{'image_id': 106389, 'boxes': tensor([[322,  26, 638, 330],\n",
      "        [599,  94, 618, 131],\n",
      "        [ 90,  82, 238, 275],\n",
      "        [462, 137, 641, 384],\n",
      "        [ -1,  81, 321, 382],\n",
      "        [  0,   0, 272,  77]], dtype=torch.int32), 'scores': tensor([0.1667, 0.4705, 0.9675, 0.1402, 0.5397, 0.7790]), 'objectness_scores': tensor([0.2938, 0.2051, 0.4284, 0.2012, 0.2473, 0.5688]), 'labels': tensor([13, 11,  2, 14, 13, 13], dtype=torch.int32)}\n",
      "106389\n",
      "{'image_id': 106757, 'boxes': tensor([[  0,  34, 305, 641]], dtype=torch.int32), 'scores': tensor([0.9954]), 'objectness_scores': tensor([0.5527]), 'labels': tensor([5], dtype=torch.int32)}\n",
      "106757\n",
      "{'image_id': 106912, 'boxes': tensor([[219, 385, 285, 406],\n",
      "        [236, 380, 263, 397],\n",
      "        [250, 231, 280, 252],\n",
      "        [251, 376, 272, 393]], dtype=torch.int32), 'scores': tensor([0.3280, 0.1971, 0.1274, 0.6943]), 'objectness_scores': tensor([0.6128, 0.2477, 0.3718, 0.2140]), 'labels': tensor([ 7, 11, 11,  2], dtype=torch.int32)}\n",
      "106912\n",
      "{'image_id': 107087, 'boxes': tensor([[ 53,  78, 261, 410]], dtype=torch.int32), 'scores': tensor([0.9857]), 'objectness_scores': tensor([0.5572]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "107087\n",
      "{'image_id': 107226, 'boxes': tensor([[230, 129, 253, 152],\n",
      "        [ -2,  27, 252, 167],\n",
      "        [220, 127, 303, 159],\n",
      "        [  1, 283, 155, 588],\n",
      "        [ -1,  28, 230, 123],\n",
      "        [161, 222, 185, 245],\n",
      "        [ 58, 279, 158, 504],\n",
      "        [ 69,  79, 267, 178],\n",
      "        [115, 159, 136, 181],\n",
      "        [ 20, 155,  57, 185],\n",
      "        [  0, 370,  81, 589],\n",
      "        [ 36, 148,  71, 171],\n",
      "        [348, 139, 371, 150],\n",
      "        [ 44,  74, 203, 158],\n",
      "        [138, 121, 171, 146],\n",
      "        [ 28, 229,  49, 244],\n",
      "        [261, 308, 287, 355],\n",
      "        [314, 104, 409, 148],\n",
      "        [146, 289, 252, 498],\n",
      "        [323, 128, 350, 147],\n",
      "        [272, 217, 299, 240],\n",
      "        [  0, 239, 144, 395],\n",
      "        [167,  76, 264, 129],\n",
      "        [240, 128, 272, 155],\n",
      "        [169, 162, 198, 177],\n",
      "        [161, 128, 208, 166],\n",
      "        [ 96, 127, 114, 142],\n",
      "        [189, 124, 215, 140]], dtype=torch.int32), 'scores': tensor([0.3212, 0.9985, 0.1849, 0.8535, 0.8022, 0.2465, 0.2448, 0.9580, 0.3463,\n",
      "        0.2743, 0.5545, 0.1838, 0.2843, 0.9896, 0.3633, 0.3882, 0.2698, 0.3343,\n",
      "        0.9676, 0.2226, 0.3320, 0.7380, 0.5596, 0.2221, 0.2047, 0.1882, 0.2026,\n",
      "        0.2560]), 'objectness_scores': tensor([0.2222, 0.4597, 0.3320, 0.4685, 0.3405, 0.4600, 0.2827, 0.2523, 0.2604,\n",
      "        0.4522, 0.2938, 0.4378, 0.3051, 0.3051, 0.2956, 0.2415, 0.2275, 0.4293,\n",
      "        0.5686, 0.3792, 0.4950, 0.2152, 0.3605, 0.2553, 0.2284, 0.3740, 0.2296,\n",
      "        0.2590]), 'labels': tensor([11,  6,  7,  4,  6, 11, 14,  6, 11,  7,  2, 11, 14,  6,  7, 12,  7,  8,\n",
      "         3, 14,  2,  2,  6, 11, 11,  3, 11, 11], dtype=torch.int32)}\n",
      "107226\n",
      "{'image_id': 107339, 'boxes': tensor([[ 92,  98, 140, 139],\n",
      "        [  1, 120, 238, 180],\n",
      "        [119, 102, 175, 153]], dtype=torch.int32), 'scores': tensor([0.3781, 0.1500, 0.3284]), 'objectness_scores': tensor([0.5154, 0.2934, 0.4093]), 'labels': tensor([13, 13,  9], dtype=torch.int32)}\n",
      "107339\n",
      "{'image_id': 107851, 'boxes': tensor([[376, 241, 390, 251],\n",
      "        [303, 290, 403, 466],\n",
      "        [ 40, 226,  51, 235]], dtype=torch.int32), 'scores': tensor([0.1925, 0.9953, 0.5455]), 'objectness_scores': tensor([0.2437, 0.6800, 0.2199]), 'labels': tensor([11,  5,  7], dtype=torch.int32)}\n",
      "107851\n",
      "{'image_id': 108026, 'boxes': tensor([[  0, 159, 239, 428],\n",
      "        [ -4,  91, 616, 428]], dtype=torch.int32), 'scores': tensor([0.9976, 0.4092]), 'objectness_scores': tensor([0.4233, 0.2634]), 'labels': tensor([14, 12], dtype=torch.int32)}\n",
      "108026\n",
      "{'image_id': 108253, 'boxes': tensor([[200, 377, 406, 535],\n",
      "        [362, 216, 402, 236],\n",
      "        [  3,   1,  81, 117],\n",
      "        [137, 348, 480, 619],\n",
      "        [  1, 242, 482, 640],\n",
      "        [ 10, 301, 118, 318],\n",
      "        [100, 239, 263, 284],\n",
      "        [  7, 315, 336, 413]], dtype=torch.int32), 'scores': tensor([0.7593, 0.2582, 0.7652, 0.5975, 0.5085, 0.4320, 0.5199, 0.3647]), 'objectness_scores': tensor([0.2010, 0.2627, 0.4054, 0.2502, 0.2501, 0.3326, 0.2709, 0.2313]), 'labels': tensor([12, 11, 10, 12, 12,  2, 13, 12], dtype=torch.int32)}\n",
      "108253\n",
      "{'image_id': 108495, 'boxes': tensor([[100, 203, 321, 436],\n",
      "        [102, 303, 310, 442],\n",
      "        [121, 434, 219, 499],\n",
      "        [186,  80, 333, 305],\n",
      "        [ 74, 355, 165, 412]], dtype=torch.int32), 'scores': tensor([0.9857, 0.9860, 0.8409, 0.3170, 0.8322]), 'objectness_scores': tensor([0.2646, 0.6383, 0.2135, 0.3447, 0.2364]), 'labels': tensor([9, 9, 9, 4, 9], dtype=torch.int32)}\n",
      "108495\n",
      "{'image_id': 109055, 'boxes': tensor([[131,  95, 494, 446]], dtype=torch.int32), 'scores': tensor([0.9812]), 'objectness_scores': tensor([0.5286]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "109055\n",
      "{'image_id': 109313, 'boxes': tensor([[333, 407, 481, 529]], dtype=torch.int32), 'scores': tensor([0.3948]), 'objectness_scores': tensor([0.2151]), 'labels': tensor([6], dtype=torch.int32)}\n",
      "109313\n",
      "{'image_id': 109900, 'boxes': tensor([[  0, 135, 114, 168],\n",
      "        [ 72, 176, 100, 194],\n",
      "        [306, 196, 315, 203],\n",
      "        [111, 170, 121, 233],\n",
      "        [221, 250, 228, 255],\n",
      "        [102, 136, 357, 240],\n",
      "        [ 93, 363, 126, 374],\n",
      "        [ 28, 176,  57, 188],\n",
      "        [576,  68, 583, 239],\n",
      "        [  0, 135, 115, 231]], dtype=torch.int32), 'scores': tensor([0.7383, 0.9990, 0.1828, 0.1878, 0.1791, 0.7677, 0.4199, 0.4152, 0.7386,\n",
      "        0.6932]), 'objectness_scores': tensor([0.2445, 0.2736, 0.2615, 0.2210, 0.2955, 0.5126, 0.2101, 0.2689, 0.3626,\n",
      "        0.2579]), 'labels': tensor([11,  5,  8, 11, 11,  0, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "109900\n",
      "{'image_id': 109916, 'boxes': tensor([[275, 192, 585, 477]], dtype=torch.int32), 'scores': tensor([0.9974]), 'objectness_scores': tensor([0.3705]), 'labels': tensor([12], dtype=torch.int32)}\n",
      "109916\n",
      "{'image_id': 109992, 'boxes': tensor([[ 26, 307,  48, 317]], dtype=torch.int32), 'scores': tensor([0.3026]), 'objectness_scores': tensor([0.2396]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "109992\n",
      "{'image_id': 110721, 'boxes': tensor([[188,   3, 262,  42],\n",
      "        [  9,  -1, 637, 357]], dtype=torch.int32), 'scores': tensor([0.8001, 0.9618]), 'objectness_scores': tensor([0.4293, 0.4769]), 'labels': tensor([0, 0], dtype=torch.int32)}\n",
      "110721\n",
      "{'image_id': 110784, 'boxes': tensor([[316, 331, 409, 415],\n",
      "        [187, 314, 204, 326],\n",
      "        [341, 174, 434, 238]], dtype=torch.int32), 'scores': tensor([0.6644, 0.2755, 0.5021]), 'objectness_scores': tensor([0.3391, 0.2119, 0.2296]), 'labels': tensor([ 9, 11,  3], dtype=torch.int32)}\n",
      "110784\n",
      "{'image_id': 110884, 'boxes': tensor([[214, 363, 325, 430],\n",
      "        [ 20,  18, 306, 248],\n",
      "        [236, 168, 259, 210],\n",
      "        [279, 468, 309, 525],\n",
      "        [140, 299, 169, 371],\n",
      "        [ 18, 304,  65, 379],\n",
      "        [ 16,   9, 626, 622]], dtype=torch.int32), 'scores': tensor([0.2140, 0.5974, 0.3169, 0.3778, 0.5003, 0.3025, 0.9860]), 'objectness_scores': tensor([0.3609, 0.2967, 0.2327, 0.2332, 0.6108, 0.2095, 0.2162]), 'labels': tensor([ 7, 15, 11, 11,  8,  8, 15], dtype=torch.int32)}\n",
      "110884\n",
      "{'image_id': 110999, 'boxes': tensor([[ 98, 502, 204, 584],\n",
      "        [ 34, 396, 249, 491],\n",
      "        [ 40, 337, 173, 436],\n",
      "        [  0, 483, 213, 582],\n",
      "        [157, 368, 177, 388],\n",
      "        [ 84, 509, 112, 536],\n",
      "        [ 38,  20, 348, 371],\n",
      "        [146, 375, 173, 401],\n",
      "        [ 40, 367,  66, 386]], dtype=torch.int32), 'scores': tensor([0.7332, 0.3085, 0.2689, 0.5746, 0.9972, 0.3717, 0.2874, 0.1947, 0.4779]), 'objectness_scores': tensor([0.4299, 0.4945, 0.2002, 0.2787, 0.2045, 0.2072, 0.3009, 0.2230, 0.2162]), 'labels': tensor([11, 10, 10, 11,  8, 11, 12, 11, 11], dtype=torch.int32)}\n",
      "110999\n",
      "{'image_id': 111207, 'boxes': tensor([[114,  31, 145,  57],\n",
      "        [340, 183, 392, 224],\n",
      "        [156, 552, 233, 580],\n",
      "        [415, 116, 479, 264],\n",
      "        [126, 269, 174, 289]], dtype=torch.int32), 'scores': tensor([0.4124, 0.1485, 0.8533, 0.8785, 0.3216]), 'objectness_scores': tensor([0.2007, 0.2125, 0.5224, 0.2332, 0.4172]), 'labels': tensor([11, 14,  9,  8,  7], dtype=torch.int32)}\n",
      "111207\n",
      "{'image_id': 111951, 'boxes': tensor([[393, 218, 425, 241],\n",
      "        [319, 265, 494, 330],\n",
      "        [ 54, 207,  81, 236],\n",
      "        [ 41, 234, 155, 298],\n",
      "        [220, 199, 289, 235],\n",
      "        [146, 153, 202, 256],\n",
      "        [  0,   0, 251, 189],\n",
      "        [219, 179, 237, 198],\n",
      "        [393, 227, 413, 239],\n",
      "        [322,   2, 567, 321],\n",
      "        [142,  37, 242, 154],\n",
      "        [392, 230, 438, 267],\n",
      "        [ 30, 211,  48, 226],\n",
      "        [335,  86, 353, 132],\n",
      "        [  0, 283,  86, 331],\n",
      "        [415, 235, 427, 241],\n",
      "        [177,  96, 193, 131],\n",
      "        [  1, 224, 324, 422],\n",
      "        [263, 175, 271, 191],\n",
      "        [ 21, 287,  54, 306],\n",
      "        [287, 209, 322, 226],\n",
      "        [325, 174, 372, 188],\n",
      "        [401, 218, 423, 239]], dtype=torch.int32), 'scores': tensor([0.2194, 0.2739, 0.5372, 0.9224, 0.6994, 0.4003, 0.3128, 0.4584, 0.2720,\n",
      "        0.6880, 0.2984, 0.3481, 0.2567, 0.2389, 0.2701, 0.1678, 0.4031, 0.9884,\n",
      "        0.1604, 0.3896, 0.3329, 0.1959, 0.1984]), 'objectness_scores': tensor([0.2392, 0.3221, 0.5633, 0.6465, 0.6110, 0.3045, 0.4871, 0.4848, 0.2249,\n",
      "        0.2980, 0.3288, 0.3235, 0.2039, 0.3771, 0.4433, 0.2128, 0.2860, 0.2260,\n",
      "        0.4289, 0.4380, 0.3708, 0.2178, 0.2002]), 'labels': tensor([11,  9, 11, 15, 10,  6,  7, 11, 11, 15,  7,  7, 11, 11, 12, 11, 11, 15,\n",
      "        14, 11,  8,  7, 11], dtype=torch.int32)}\n",
      "111951\n",
      "{'image_id': 112626, 'boxes': tensor([[265, 171, 411, 283],\n",
      "        [  9, 301, 118, 407],\n",
      "        [  0, 147,  13, 176],\n",
      "        [261, 172, 421, 471],\n",
      "        [331, 281, 423, 467]], dtype=torch.int32), 'scores': tensor([0.8735, 0.2139, 0.3513, 0.6397, 0.3557]), 'objectness_scores': tensor([0.2240, 0.2075, 0.3940, 0.3907, 0.2079]), 'labels': tensor([13,  8, 11, 13, 11], dtype=torch.int32)}\n",
      "112626\n",
      "{'image_id': 112798, 'boxes': tensor([[416, 119, 422, 139],\n",
      "        [505, 292, 612, 359],\n",
      "        [257, 110, 294, 138],\n",
      "        [ 70, 135, 495, 301],\n",
      "        [283, 110, 323, 141],\n",
      "        [336,  96, 373, 148],\n",
      "        [504, 280, 640, 359],\n",
      "        [589, 302, 640, 331],\n",
      "        [ 96,   0, 233, 151],\n",
      "        [419,  96, 429, 128],\n",
      "        [  5, 174, 639, 358],\n",
      "        [427, 105, 435, 126]], dtype=torch.int32), 'scores': tensor([0.3097, 0.3413, 0.2017, 0.2163, 0.2960, 0.3107, 0.3145, 0.8034, 0.1735,\n",
      "        0.3718, 0.9021, 0.4076]), 'objectness_scores': tensor([0.2078, 0.4162, 0.2052, 0.4904, 0.3224, 0.2079, 0.2088, 0.2079, 0.2283,\n",
      "        0.2033, 0.3344, 0.2114]), 'labels': tensor([11,  7,  8, 11,  7,  6,  7, 11, 11, 11,  2, 12], dtype=torch.int32)}\n",
      "112798\n",
      "{'image_id': 113720, 'boxes': tensor([[ 46, 212, 208, 283],\n",
      "        [  0, 310, 259, 427],\n",
      "        [589, 222, 639, 290],\n",
      "        [239, 218, 288, 311],\n",
      "        [  1, 335, 119, 413],\n",
      "        [195, 204, 252, 324],\n",
      "        [  1, 216, 629, 427],\n",
      "        [273, 379, 409, 424],\n",
      "        [332, 251, 461, 293],\n",
      "        [144, 171, 175, 218],\n",
      "        [128, 174, 162, 221],\n",
      "        [279, 211, 325, 286],\n",
      "        [  4, 337,  72, 380],\n",
      "        [275, 284, 560, 397],\n",
      "        [ 20, 215,  53, 250]], dtype=torch.int32), 'scores': tensor([0.5042, 0.6425, 0.3409, 0.2278, 0.8755, 0.7679, 0.2563, 0.1763, 0.4836,\n",
      "        0.4155, 0.3403, 0.4699, 0.8003, 0.4459, 0.3882]), 'objectness_scores': tensor([0.2060, 0.2251, 0.2679, 0.3877, 0.4209, 0.2961, 0.2751, 0.2918, 0.2284,\n",
      "        0.2657, 0.4014, 0.2906, 0.2017, 0.2391, 0.2453]), 'labels': tensor([12, 12,  7,  8, 12, 10, 12, 11, 12, 10, 10, 10, 12, 11, 12],\n",
      "       dtype=torch.int32)}\n",
      "113720\n",
      "{'image_id': 114770, 'boxes': tensor([[  0, 164, 149, 197],\n",
      "        [  0, 160, 147, 360],\n",
      "        [305,   1, 636, 192]], dtype=torch.int32), 'scores': tensor([0.2159, 0.1307, 0.8147]), 'objectness_scores': tensor([0.2481, 0.2190, 0.4745]), 'labels': tensor([3, 3, 0], dtype=torch.int32)}\n",
      "114770\n",
      "{'image_id': 114884, 'boxes': tensor([[175,  67, 221, 125],\n",
      "        [220,  70, 262, 130],\n",
      "        [319, 274, 328, 280],\n",
      "        [392, 278, 460, 316],\n",
      "        [347, 263, 356, 277]], dtype=torch.int32), 'scores': tensor([0.5265, 0.8801, 0.1867, 0.4609, 0.2038]), 'objectness_scores': tensor([0.3111, 0.4549, 0.2232, 0.4932, 0.3282]), 'labels': tensor([ 1,  1, 11,  7, 11], dtype=torch.int32)}\n",
      "114884\n",
      "{'image_id': 114907, 'boxes': tensor([[328,  39, 571, 285],\n",
      "        [357, 202, 407, 218],\n",
      "        [345, 138, 384, 208],\n",
      "        [383, 156, 389, 169],\n",
      "        [293, 260, 338, 291],\n",
      "        [380,  77, 396,  92]], dtype=torch.int32), 'scores': tensor([0.9955, 0.4923, 0.5515, 0.1762, 0.2099, 0.4038]), 'objectness_scores': tensor([0.5920, 0.2038, 0.2529, 0.2846, 0.2178, 0.2335]), 'labels': tensor([ 4, 11,  7, 13,  7, 11], dtype=torch.int32)}\n",
      "114907\n",
      "{'image_id': 115870, 'boxes': tensor([[ 19, 315,  94, 346],\n",
      "        [  0, 183, 356, 341],\n",
      "        [  2, 189, 157, 318],\n",
      "        [271, 189, 640, 421],\n",
      "        [158, 197, 623, 423],\n",
      "        [143, 181, 345, 341]], dtype=torch.int32), 'scores': tensor([0.3770, 0.8931, 0.7594, 0.9668, 0.9557, 0.9226]), 'objectness_scores': tensor([0.2104, 0.2277, 0.2424, 0.2972, 0.2753, 0.2166]), 'labels': tensor([14, 13, 13, 13, 13, 16], dtype=torch.int32)}\n",
      "115870\n",
      "{'image_id': 115885, 'boxes': tensor([[253, 322, 369, 368],\n",
      "        [  0, 264, 268, 362],\n",
      "        [344,   0, 498, 250]], dtype=torch.int32), 'scores': tensor([0.5061, 0.9719, 0.8030]), 'objectness_scores': tensor([0.2734, 0.3982, 0.4853]), 'labels': tensor([11, 15,  2], dtype=torch.int32)}\n",
      "115885\n",
      "{'image_id': 116206, 'boxes': tensor([[402, 127, 641, 372],\n",
      "        [437, 320, 459, 350],\n",
      "        [305, 313, 325, 342],\n",
      "        [  3,  15, 638, 486],\n",
      "        [228, 285, 256, 318],\n",
      "        [385, 310, 421, 352],\n",
      "        [286, 143, 308, 160],\n",
      "        [457, 259, 483, 279],\n",
      "        [209, 128, 471, 372],\n",
      "        [326, 329, 352, 367],\n",
      "        [215, 320, 244, 346],\n",
      "        [324, 215, 341, 243],\n",
      "        [256, 177, 287, 201],\n",
      "        [ 15, 119, 612, 442],\n",
      "        [293, 192, 320, 218],\n",
      "        [325, 307, 357, 337],\n",
      "        [451, 144, 468, 156],\n",
      "        [443, 375, 473, 404],\n",
      "        [209, 132, 349, 366],\n",
      "        [293, 135, 472, 362],\n",
      "        [300, 293, 324, 316],\n",
      "        [234, 333, 260, 362],\n",
      "        [488, 173, 509, 187],\n",
      "        [262, 330, 293, 362],\n",
      "        [292, 125, 318, 145],\n",
      "        [245, 312, 278, 340]], dtype=torch.int32), 'scores': tensor([0.9517, 0.2513, 0.2208, 0.7897, 0.3137, 0.4847, 0.4223, 0.2052, 0.7437,\n",
      "        0.4312, 0.3161, 0.1781, 0.4557, 0.7466, 0.1965, 0.2701, 0.1911, 0.2478,\n",
      "        0.5165, 0.4129, 0.3038, 0.3239, 0.3133, 0.2852, 0.5343, 0.2414]), 'objectness_scores': tensor([0.5789, 0.2558, 0.2071, 0.3085, 0.2303, 0.2419, 0.2124, 0.2488, 0.2609,\n",
      "        0.2972, 0.2025, 0.2072, 0.2240, 0.6839, 0.2016, 0.2022, 0.2081, 0.3028,\n",
      "        0.3024, 0.2147, 0.2125, 0.2691, 0.2404, 0.2346, 0.2111, 0.2252]), 'labels': tensor([11, 12, 11, 11, 11, 12, 11,  8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "116206\n",
      "{'image_id': 116208, 'boxes': tensor([[309,  86, 350, 135],\n",
      "        [467, 262, 509, 285],\n",
      "        [218,  88, 280, 146],\n",
      "        [296, 262, 338, 293],\n",
      "        [423, 198, 452, 217],\n",
      "        [334, 178, 360, 192],\n",
      "        [280, 171, 309, 207],\n",
      "        [311, 239, 350, 256],\n",
      "        [294,  86, 339, 135],\n",
      "        [246, 248, 309, 299],\n",
      "        [  1,  17, 227,  91],\n",
      "        [413, 200, 452, 251],\n",
      "        [  0, 322, 244, 452],\n",
      "        [271, 123, 317, 140],\n",
      "        [201, 249, 257, 268],\n",
      "        [559, 163, 639, 247],\n",
      "        [322, 237, 359, 256],\n",
      "        [293, 203, 319, 231],\n",
      "        [276, 249, 309, 288],\n",
      "        [448,  77, 509, 153],\n",
      "        [298, 275, 338, 308],\n",
      "        [292, 213, 313, 231],\n",
      "        [309, 237, 350, 256],\n",
      "        [504, 355, 639, 481]], dtype=torch.int32), 'scores': tensor([0.4749, 0.3107, 0.9184, 0.9891, 0.2344, 0.2892, 0.2670, 0.3381, 0.9525,\n",
      "        0.5456, 0.4744, 0.2488, 0.6779, 0.9744, 0.2848, 0.3736, 0.5066, 0.4805,\n",
      "        0.4969, 0.8341, 0.3315, 0.4270, 0.4002, 0.8634]), 'objectness_scores': tensor([0.2377, 0.3186, 0.2900, 0.2923, 0.2562, 0.2042, 0.5572, 0.2734, 0.2395,\n",
      "        0.2779, 0.3265, 0.2714, 0.2838, 0.2421, 0.4994, 0.2167, 0.2043, 0.2546,\n",
      "        0.4189, 0.2891, 0.3482, 0.2100, 0.2633, 0.2854]), 'labels': tensor([10, 11,  3,  3,  7, 11,  7, 11, 10, 12,  9, 14, 12,  3, 11, 12, 11,  7,\n",
      "         7, 10, 12, 11, 11, 10], dtype=torch.int32)}\n",
      "116208\n",
      "{'image_id': 116479, 'boxes': tensor([[ 42, 342, 120, 457],\n",
      "        [163, 309, 199, 402],\n",
      "        [183,   1, 332,  92],\n",
      "        [267,  48, 317,  85],\n",
      "        [ 63,  78, 336, 604]], dtype=torch.int32), 'scores': tensor([0.5614, 0.4481, 0.7010, 0.3661, 0.6201]), 'objectness_scores': tensor([0.3633, 0.2141, 0.6120, 0.2587, 0.3242]), 'labels': tensor([ 7,  8, 10, 10,  6], dtype=torch.int32)}\n",
      "116479\n",
      "{'image_id': 116825, 'boxes': tensor([[ 77,   5, 394, 361],\n",
      "        [201,  25, 636, 361],\n",
      "        [384, 246, 401, 274]], dtype=torch.int32), 'scores': tensor([0.9063, 0.4943, 0.2777]), 'objectness_scores': tensor([0.5395, 0.5746, 0.2126]), 'labels': tensor([ 2, 11, 11], dtype=torch.int32)}\n",
      "116825\n",
      "{'image_id': 117374, 'boxes': tensor([[ 71, 219, 161, 281],\n",
      "        [467, 274, 546, 375],\n",
      "        [106,   0, 301, 266],\n",
      "        [423, 132, 466, 168]], dtype=torch.int32), 'scores': tensor([0.8981, 0.5961, 0.9996, 0.3288]), 'objectness_scores': tensor([0.5309, 0.5175, 0.2109, 0.2103]), 'labels': tensor([ 2, 10,  5, 11], dtype=torch.int32)}\n",
      "117374\n",
      "{'image_id': 117425, 'boxes': tensor([[  0, 193,  80, 321],\n",
      "        [  2, 189, 454, 426],\n",
      "        [318, 122, 572, 382],\n",
      "        [143, 240, 154, 300]], dtype=torch.int32), 'scores': tensor([0.5355, 0.9995, 0.3458, 0.7995]), 'objectness_scores': tensor([0.2307, 0.2014, 0.2653, 0.4081]), 'labels': tensor([10, 12, 11,  7], dtype=torch.int32)}\n",
      "117425\n",
      "{'image_id': 117492, 'boxes': tensor([[450, 279, 466, 285],\n",
      "        [217, 281, 289, 370],\n",
      "        [  0, 285,  94, 359],\n",
      "        [302, 299, 320, 309],\n",
      "        [370, 142, 471, 203],\n",
      "        [181, 278, 240, 365],\n",
      "        [225, 157, 268, 182],\n",
      "        [229, 280, 289, 366],\n",
      "        [438, 200, 461, 232],\n",
      "        [ 30, 140,  37, 146],\n",
      "        [417, 229, 448, 252],\n",
      "        [ 90, 164, 103, 172],\n",
      "        [373, 144, 470, 168]], dtype=torch.int32), 'scores': tensor([0.2549, 0.3900, 0.3432, 0.2408, 0.4102, 0.6605, 0.2484, 0.3100, 0.1885,\n",
      "        0.2705, 0.2168, 0.1846, 0.1597]), 'objectness_scores': tensor([0.2094, 0.4559, 0.2123, 0.2847, 0.2823, 0.3728, 0.3433, 0.2125, 0.4507,\n",
      "        0.2352, 0.2428, 0.3367, 0.2909]), 'labels': tensor([14,  7,  8, 11,  7,  3,  7,  7, 11, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "117492\n",
      "{'image_id': 117525, 'boxes': tensor([[217,  28, 266, 103],\n",
      "        [174,  84, 416, 283],\n",
      "        [ 31, 306, 209, 500],\n",
      "        [399,  89, 484, 240],\n",
      "        [200, 258, 358, 388],\n",
      "        [  2,  -2, 491, 487],\n",
      "        [200, 219, 343, 250]], dtype=torch.int32), 'scores': tensor([0.2210, 0.6861, 0.9622, 0.8278, 0.6101, 0.9106, 0.3542]), 'objectness_scores': tensor([0.3034, 0.4203, 0.4493, 0.2059, 0.2600, 0.3536, 0.2789]), 'labels': tensor([14,  7,  3,  3,  7,  3,  7], dtype=torch.int32)}\n",
      "117525\n",
      "{'image_id': 117645, 'boxes': tensor([[396, 166, 403, 173]], dtype=torch.int32), 'scores': tensor([0.2644]), 'objectness_scores': tensor([0.2580]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "117645\n",
      "{'image_id': 117719, 'boxes': tensor([[324, 287, 346, 337],\n",
      "        [395, 159, 534, 263],\n",
      "        [449, 245, 501, 286],\n",
      "        [231,  21, 285,  88],\n",
      "        [159,   0, 176,  35],\n",
      "        [321,  23, 532, 269]], dtype=torch.int32), 'scores': tensor([0.1883, 0.3830, 0.5176, 0.2624, 0.5264, 0.2089]), 'objectness_scores': tensor([0.2127, 0.2513, 0.3048, 0.2257, 0.2397, 0.3295]), 'labels': tensor([11,  7, 10,  8, 11,  7], dtype=torch.int32)}\n",
      "117719\n",
      "{'image_id': 117908, 'boxes': tensor([[348, 141, 498, 319],\n",
      "        [321, 168, 351, 181]], dtype=torch.int32), 'scores': tensor([0.9194, 0.8819]), 'objectness_scores': tensor([0.4966, 0.2155]), 'labels': tensor([2, 7], dtype=torch.int32)}\n",
      "117908\n",
      "{'image_id': 117914, 'boxes': tensor([[255, 138, 296, 173],\n",
      "        [126, 197, 150, 217],\n",
      "        [119, 268, 134, 284],\n",
      "        [138, 408, 162, 448],\n",
      "        [155, 192, 177, 228],\n",
      "        [173, 291, 205, 307],\n",
      "        [166, 233, 310, 306],\n",
      "        [  0,   1, 332, 495],\n",
      "        [100, 251, 130, 280],\n",
      "        [123, 190, 151, 224],\n",
      "        [ 91, 278, 180, 373],\n",
      "        [101, 425, 130, 470],\n",
      "        [166,  45, 318, 306],\n",
      "        [137, 268, 149, 289],\n",
      "        [206, 127, 254, 173],\n",
      "        [  0, 351,  26, 421],\n",
      "        [130, 162, 145, 180]], dtype=torch.int32), 'scores': tensor([0.1984, 0.2776, 0.2251, 0.2321, 0.1239, 0.2881, 0.5668, 0.9582, 0.3380,\n",
      "        0.2053, 0.7757, 0.3539, 0.5247, 0.2146, 0.9685, 0.1820, 0.9941]), 'objectness_scores': tensor([0.2029, 0.2001, 0.2963, 0.2351, 0.2477, 0.2994, 0.3948, 0.2063, 0.3302,\n",
      "        0.2651, 0.3157, 0.2284, 0.3294, 0.3134, 0.4023, 0.2797, 0.2287]), 'labels': tensor([ 8, 11, 11, 11, 16, 11,  3, 15,  2, 11, 15,  7,  2, 16,  0, 11,  4],\n",
      "       dtype=torch.int32)}\n",
      "117914\n",
      "{'image_id': 118515, 'boxes': tensor([[268, 119, 397, 279]], dtype=torch.int32), 'scores': tensor([0.9907]), 'objectness_scores': tensor([0.5488]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "118515\n",
      "{'image_id': 119233, 'boxes': tensor([[  2,  90, 497, 333],\n",
      "        [  7,  93, 482, 330],\n",
      "        [ 18,  37,  61,  91]], dtype=torch.int32), 'scores': tensor([0.8219, 0.8174, 0.3226]), 'objectness_scores': tensor([0.2266, 0.4868, 0.2648]), 'labels': tensor([2, 2, 8], dtype=torch.int32)}\n",
      "119233\n",
      "{'image_id': 119365, 'boxes': tensor([[265,   0, 400,  58],\n",
      "        [258,  52, 388, 184],\n",
      "        [146,   0, 262, 104],\n",
      "        [  0,   0, 104,  95]], dtype=torch.int32), 'scores': tensor([0.2202, 0.3241, 0.2402, 0.2529]), 'objectness_scores': tensor([0.2213, 0.2395, 0.2340, 0.2277]), 'labels': tensor([16, 14,  7, 12], dtype=torch.int32)}\n",
      "119365\n",
      "{'image_id': 119641, 'boxes': tensor([[284, 344, 294, 350],\n",
      "        [520, 356, 527, 360],\n",
      "        [263, 342, 273, 349],\n",
      "        [116, 395, 184, 473],\n",
      "        [345, 389, 401, 450],\n",
      "        [604, 384, 639, 430],\n",
      "        [498, 383, 537, 437],\n",
      "        [616, 387, 640, 430],\n",
      "        [302, 392, 404, 452],\n",
      "        [341, 372, 352, 378],\n",
      "        [381, 365, 391, 372],\n",
      "        [248, 388, 298, 455],\n",
      "        [385, 384, 423, 443]], dtype=torch.int32), 'scores': tensor([0.1204, 0.1404, 0.1832, 0.9993, 0.9655, 0.1900, 0.7675, 0.3307, 0.9994,\n",
      "        0.1193, 0.1679, 0.9995, 0.1961]), 'objectness_scores': tensor([0.2656, 0.2038, 0.2533, 0.7288, 0.2637, 0.6734, 0.6983, 0.3829, 0.6717,\n",
      "        0.2237, 0.2153, 0.7123, 0.6287]), 'labels': tensor([11, 13, 10,  5,  5,  3,  3, 11,  5, 10, 11,  5,  2], dtype=torch.int32)}\n",
      "119641\n",
      "{'image_id': 119677, 'boxes': tensor([[ 51,  71, 550, 422],\n",
      "        [  4,  -1, 639, 480],\n",
      "        [195,  42, 378, 259]], dtype=torch.int32), 'scores': tensor([0.9503, 0.9474, 0.4230]), 'objectness_scores': tensor([0.6206, 0.3726, 0.5346]), 'labels': tensor([12, 12,  6], dtype=torch.int32)}\n",
      "119677\n",
      "{'image_id': 119828, 'boxes': tensor([[ 57, 115, 212, 170],\n",
      "        [259,   5, 321, 149],\n",
      "        [341, 117, 405, 165],\n",
      "        [315, 104, 351, 153],\n",
      "        [363,  70, 406, 128],\n",
      "        [114, 139, 438, 375],\n",
      "        [  3, 111, 497, 375],\n",
      "        [422, 142, 500, 193]], dtype=torch.int32), 'scores': tensor([0.9815, 0.2776, 0.9779, 0.2911, 0.5989, 0.9966, 0.8749, 0.5220]), 'objectness_scores': tensor([0.4195, 0.6581, 0.3439, 0.2367, 0.3277, 0.5586, 0.4618, 0.3463]), 'labels': tensor([14,  7, 10,  7, 10, 15,  2,  2], dtype=torch.int32)}\n",
      "119828\n",
      "{'image_id': 119911, 'boxes': tensor([[243,  26, 274,  33],\n",
      "        [277, 299, 383, 335],\n",
      "        [330,  97, 368, 132]], dtype=torch.int32), 'scores': tensor([0.3306, 0.6312, 0.2362]), 'objectness_scores': tensor([0.2043, 0.5977, 0.2037]), 'labels': tensor([14,  8, 14], dtype=torch.int32)}\n",
      "119911\n",
      "{'image_id': 120420, 'boxes': tensor([[162, 188, 423, 260],\n",
      "        [269, 304, 297, 440],\n",
      "        [292, 203, 387, 251],\n",
      "        [393,  87, 436, 119],\n",
      "        [408, 367, 497, 441],\n",
      "        [272, 335, 379, 479]], dtype=torch.int32), 'scores': tensor([0.2154, 0.5579, 0.4720, 0.4013, 0.4461, 0.3254]), 'objectness_scores': tensor([0.5124, 0.2514, 0.2290, 0.2483, 0.4631, 0.3123]), 'labels': tensor([ 3, 11,  8,  6,  7,  7], dtype=torch.int32)}\n",
      "120420\n",
      "{'image_id': 120777, 'boxes': tensor([[ 57, 111, 245, 270],\n",
      "        [343, 210, 376, 243],\n",
      "        [ 32, 256, 183, 373],\n",
      "        [253, 142, 448, 312],\n",
      "        [ 73, 173, 133, 210],\n",
      "        [ 82, 141, 122, 170],\n",
      "        [  3,  87, 476, 374],\n",
      "        [ 59, 127, 197, 258],\n",
      "        [390, 205, 439, 256],\n",
      "        [360, 262, 382, 298],\n",
      "        [336, 177, 439, 300],\n",
      "        [137, 205, 189, 243],\n",
      "        [409, 230, 437, 257],\n",
      "        [285,  15, 374, 145],\n",
      "        [378, 255, 417, 293],\n",
      "        [369, 186, 392, 229],\n",
      "        [ 91, 216, 148, 253]], dtype=torch.int32), 'scores': tensor([0.5147, 0.3062, 0.2109, 0.7187, 0.4580, 0.3864, 0.7655, 0.4249, 0.5431,\n",
      "        0.1820, 0.3683, 0.3184, 0.4114, 0.9875, 0.4032, 0.1509, 0.2872]), 'objectness_scores': tensor([0.2686, 0.2176, 0.5034, 0.2657, 0.2069, 0.2145, 0.4401, 0.2561, 0.2218,\n",
      "        0.2278, 0.2411, 0.2255, 0.2003, 0.3995, 0.2461, 0.2176, 0.2090]), 'labels': tensor([12,  7, 12, 12, 12, 12, 12, 12, 12,  7, 12, 12, 12, 10, 12,  2, 12],\n",
      "       dtype=torch.int32)}\n",
      "120777\n",
      "{'image_id': 120853, 'boxes': tensor([[353,  69, 490, 126],\n",
      "        [  2, 135, 634, 427],\n",
      "        [  2,  54, 636, 428],\n",
      "        [481,  64, 642, 190],\n",
      "        [335, 115, 627, 264],\n",
      "        [203,   0, 327, 145]], dtype=torch.int32), 'scores': tensor([0.3140, 0.2358, 0.4220, 0.4158, 0.4539, 0.8725]), 'objectness_scores': tensor([0.4149, 0.2973, 0.2708, 0.3246, 0.3057, 0.3966]), 'labels': tensor([11, 11, 11, 11, 11, 10], dtype=torch.int32)}\n",
      "120853\n",
      "{'image_id': 121417, 'boxes': tensor([[236, 187, 269, 211],\n",
      "        [107, 592, 213, 628],\n",
      "        [383,   8, 410,  35],\n",
      "        [235,  37, 261,  55],\n",
      "        [319,  52, 353,  63],\n",
      "        [224, 213, 442, 540],\n",
      "        [156,  85, 442, 530],\n",
      "        [345,  40, 379,  52],\n",
      "        [217, 550, 250, 575],\n",
      "        [160,  83, 436, 321],\n",
      "        [255,  29, 279,  60],\n",
      "        [163,  44, 197,  53]], dtype=torch.int32), 'scores': tensor([0.3570, 0.4908, 0.1656, 0.2751, 0.2600, 0.6865, 0.9682, 0.3018, 0.3454,\n",
      "        0.9967, 0.2255, 0.3093]), 'objectness_scores': tensor([0.2384, 0.2866, 0.2637, 0.2132, 0.2226, 0.2196, 0.2645, 0.2094, 0.2673,\n",
      "        0.3376, 0.2246, 0.2171]), 'labels': tensor([11,  9,  2, 11, 11,  7,  6, 11, 11,  6,  9, 11], dtype=torch.int32)}\n",
      "121417\n",
      "{'image_id': 121506, 'boxes': tensor([[ 95,  54, 577, 249],\n",
      "        [ 20, 526, 268, 592],\n",
      "        [ 92,  54, 576, 496],\n",
      "        [171, 434, 413, 587],\n",
      "        [ 48, 437, 412, 589],\n",
      "        [245, 473, 300, 491],\n",
      "        [269, 335, 428, 443],\n",
      "        [ 20, 360, 148, 454]], dtype=torch.int32), 'scores': tensor([0.8209, 0.3283, 0.9984, 0.4755, 0.2429, 0.3943, 0.6179, 0.4491]), 'objectness_scores': tensor([0.3100, 0.2095, 0.4676, 0.3672, 0.2442, 0.2901, 0.4038, 0.4302]), 'labels': tensor([ 6, 10,  6,  6, 10, 11, 13,  9], dtype=torch.int32)}\n",
      "121506\n",
      "{'image_id': 121586, 'boxes': tensor([[  9, 336,  29, 375],\n",
      "        [ 16, 352, 284, 477],\n",
      "        [389, 347, 627, 478],\n",
      "        [ 89, 109, 102, 146],\n",
      "        [198, 328, 274, 364],\n",
      "        [391, 307, 480, 371],\n",
      "        [420,   9, 613, 105],\n",
      "        [187, 101, 237, 149]], dtype=torch.int32), 'scores': tensor([0.4005, 0.2217, 0.2373, 0.2572, 0.6323, 0.2435, 0.3871, 0.9490]), 'objectness_scores': tensor([0.2598, 0.2440, 0.2082, 0.2203, 0.2844, 0.2296, 0.2027, 0.4849]), 'labels': tensor([11, 13, 11, 11, 11, 14, 14,  2], dtype=torch.int32)}\n",
      "121586\n",
      "{'image_id': 121591, 'boxes': tensor([[  9, 199,  84, 252],\n",
      "        [256, 142, 281, 185],\n",
      "        [238, 253, 340, 319],\n",
      "        [  8, 118,  99, 252],\n",
      "        [282, 139, 294, 146],\n",
      "        [254, 111, 343, 181],\n",
      "        [ 28, 151,  69, 188],\n",
      "        [  2,  10, 468, 399],\n",
      "        [303, 121, 321, 153]], dtype=torch.int32), 'scores': tensor([0.3581, 0.2684, 0.5649, 0.2067, 0.1905, 0.6789, 0.2174, 0.8923, 0.3355]), 'objectness_scores': tensor([0.2365, 0.2550, 0.2938, 0.2153, 0.2838, 0.5542, 0.2093, 0.2688, 0.2853]), 'labels': tensor([ 7,  7,  9,  9, 11,  9,  4,  9, 11], dtype=torch.int32)}\n",
      "121591\n",
      "{'image_id': 122046, 'boxes': tensor([[109, 264, 274, 498],\n",
      "        [116,  81, 361, 285],\n",
      "        [222, 557, 269, 612],\n",
      "        [205, 530, 268, 612],\n",
      "        [204, 529, 233, 592]], dtype=torch.int32), 'scores': tensor([0.5363, 0.9996, 0.5634, 0.5256, 0.3294]), 'objectness_scores': tensor([0.2673, 0.4828, 0.2324, 0.2482, 0.2265]), 'labels': tensor([7, 6, 9, 9, 7], dtype=torch.int32)}\n",
      "122046\n",
      "{'image_id': 122217, 'boxes': tensor([[ 98, 354, 118, 364],\n",
      "        [ 98, 358, 122, 373],\n",
      "        [190, 358, 204, 368],\n",
      "        [180, 364, 203, 380],\n",
      "        [182, 360, 204, 370]], dtype=torch.int32), 'scores': tensor([0.3963, 0.3914, 0.5008, 0.2530, 0.4249]), 'objectness_scores': tensor([0.2996, 0.5763, 0.2200, 0.5796, 0.2729]), 'labels': tensor([11, 11, 14, 11, 11], dtype=torch.int32)}\n",
      "122217\n",
      "{'image_id': 122606, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "122606\n",
      "{'image_id': 123633, 'boxes': tensor([[112,  44, 264, 197],\n",
      "        [125,   8, 151,  31],\n",
      "        [512,  49, 543, 119],\n",
      "        [  1, 322, 151, 477],\n",
      "        [548, 398, 637, 458]], dtype=torch.int32), 'scores': tensor([0.4964, 0.4390, 0.2341, 0.6639, 0.3863]), 'objectness_scores': tensor([0.2017, 0.3080, 0.2121, 0.2427, 0.2777]), 'labels': tensor([ 7, 11,  2,  7,  7], dtype=torch.int32)}\n",
      "123633\n",
      "{'image_id': 124659, 'boxes': tensor([[146, 243, 535, 411],\n",
      "        [197, 163, 360, 228]], dtype=torch.int32), 'scores': tensor([0.1658, 0.9856]), 'objectness_scores': tensor([0.2278, 0.3916]), 'labels': tensor([ 8, 13], dtype=torch.int32)}\n",
      "124659\n",
      "{'image_id': 124798, 'boxes': tensor([[ 37, 272,  86, 289],\n",
      "        [ 87, 275, 143, 292],\n",
      "        [327, 107, 539, 198],\n",
      "        [  0, 270,  43, 289],\n",
      "        [ 72, 273, 117, 291],\n",
      "        [121, 278, 173, 317],\n",
      "        [166, 237, 383, 363],\n",
      "        [148, 201, 170, 251],\n",
      "        [526, 135, 542, 165],\n",
      "        [128, 279, 174, 293],\n",
      "        [  0, 269,  85, 298],\n",
      "        [358, 226, 378, 236],\n",
      "        [ 78, 275, 141, 307]], dtype=torch.int32), 'scores': tensor([0.3222, 0.2955, 0.7683, 0.4846, 0.3645, 0.5032, 0.9974, 0.2544, 0.2433,\n",
      "        0.5201, 0.4701, 0.2281, 0.6528]), 'objectness_scores': tensor([0.2211, 0.3213, 0.2732, 0.2764, 0.2671, 0.2168, 0.6131, 0.3996, 0.2024,\n",
      "        0.3490, 0.3013, 0.2875, 0.2477]), 'labels': tensor([11,  9,  7, 11, 11, 15,  1,  7,  7, 11, 11, 11,  6], dtype=torch.int32)}\n",
      "124798\n",
      "{'image_id': 125257, 'boxes': tensor([[350,  89, 371, 106],\n",
      "        [343, 153, 354, 167],\n",
      "        [351,  97, 369, 109],\n",
      "        [  1,   3, 637, 485],\n",
      "        [352, 216, 373, 225]], dtype=torch.int32), 'scores': tensor([0.1885, 0.1719, 0.2933, 0.9953, 0.3151]), 'objectness_scores': tensor([0.3051, 0.2692, 0.2646, 0.2018, 0.2211]), 'labels': tensor([11,  2, 11,  8, 14], dtype=torch.int32)}\n",
      "125257\n",
      "{'image_id': 125405, 'boxes': tensor([[251, 241, 276, 259],\n",
      "        [222, 113, 382, 403],\n",
      "        [447,   4, 576, 167]], dtype=torch.int32), 'scores': tensor([0.1842, 0.2011, 0.2846]), 'objectness_scores': tensor([0.2433, 0.4566, 0.4878]), 'labels': tensor([11, 13,  6], dtype=torch.int32)}\n",
      "125405\n",
      "{'image_id': 125472, 'boxes': tensor([[291, 392, 400, 462],\n",
      "        [122,  64, 299, 289],\n",
      "        [  0, 490, 285, 571],\n",
      "        [ 85, 404, 168, 495],\n",
      "        [186, 519, 246, 555],\n",
      "        [350, 284, 368, 307]], dtype=torch.int32), 'scores': tensor([0.7014, 0.8332, 0.4901, 0.2926, 0.2261, 0.8322]), 'objectness_scores': tensor([0.2588, 0.2425, 0.5746, 0.2662, 0.2035, 0.2168]), 'labels': tensor([ 8,  9, 11,  8,  9, 12], dtype=torch.int32)}\n",
      "125472\n",
      "{'image_id': 125572, 'boxes': tensor([[ 21,   8, 116, 318],\n",
      "        [536, 348, 540, 354],\n",
      "        [529, 347, 533, 355],\n",
      "        [213, 313, 222, 326],\n",
      "        [422, 304, 434, 326],\n",
      "        [157, 289, 165, 322],\n",
      "        [ 17, 320,  51, 352],\n",
      "        [530, 142, 546, 153],\n",
      "        [  0, 314,  20, 357]], dtype=torch.int32), 'scores': tensor([0.3730, 0.2102, 0.2092, 0.3838, 0.3854, 0.4285, 0.9756, 0.7192, 0.2401]), 'objectness_scores': tensor([0.3368, 0.2523, 0.2528, 0.2511, 0.2012, 0.2809, 0.3240, 0.3016, 0.2091]), 'labels': tensor([ 7, 10, 11, 11,  8, 11,  1,  8,  7], dtype=torch.int32)}\n",
      "125572\n",
      "{'image_id': 125778, 'boxes': tensor([[130, 257, 241, 356],\n",
      "        [122, 229, 269, 308],\n",
      "        [495, 170, 640, 340],\n",
      "        [ 34, 232, 148, 368],\n",
      "        [  0, 232, 295, 481],\n",
      "        [567,  13, 639, 134],\n",
      "        [426, 245, 499, 340],\n",
      "        [310, 187, 399, 263],\n",
      "        [100, 374, 260, 438],\n",
      "        [208, 162, 231, 228],\n",
      "        [447, 198, 486, 250],\n",
      "        [433, 325, 637, 481],\n",
      "        [503,  37, 531,  82]], dtype=torch.int32), 'scores': tensor([0.9587, 0.7425, 0.8498, 0.4091, 0.9944, 0.2180, 0.2095, 0.9054, 0.1460,\n",
      "        0.4932, 0.1891, 0.4161, 0.2031]), 'objectness_scores': tensor([0.2984, 0.2041, 0.2096, 0.2264, 0.4437, 0.2731, 0.2260, 0.2088, 0.2697,\n",
      "        0.2236, 0.2373, 0.2536, 0.2940]), 'labels': tensor([13, 13,  7, 10, 13,  7,  7, 13, 11,  8, 11,  7,  7], dtype=torch.int32)}\n",
      "125778\n",
      "{'image_id': 125850, 'boxes': tensor([[  5,   0, 638, 487],\n",
      "        [108,  23, 572, 443]], dtype=torch.int32), 'scores': tensor([0.8880, 0.9034]), 'objectness_scores': tensor([0.2195, 0.5459]), 'labels': tensor([2, 2], dtype=torch.int32)}\n",
      "125850\n",
      "{'image_id': 126110, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "126110\n",
      "{'image_id': 127182, 'boxes': tensor([[113,  42, 187, 275],\n",
      "        [118,  47, 184, 132],\n",
      "        [168, 308, 187, 321],\n",
      "        [186,  61, 254, 133],\n",
      "        [117, 126, 186, 278],\n",
      "        [ 86,  19, 114, 166],\n",
      "        [256,  59, 327, 131],\n",
      "        [207, 377, 260, 525],\n",
      "        [182, 374, 210, 524],\n",
      "        [ 10, 359, 189, 412],\n",
      "        [377, 384, 426, 543],\n",
      "        [  0,  29,  57, 280],\n",
      "        [186, 128, 325, 276],\n",
      "        [191, 282, 240, 306],\n",
      "        [ 51,   0, 117, 162],\n",
      "        [253, 132, 327, 276],\n",
      "        [314, 265, 385, 362],\n",
      "        [320, 348, 364, 376],\n",
      "        [186, 135, 255, 274],\n",
      "        [237, 309, 256, 320]], dtype=torch.int32), 'scores': tensor([0.4252, 0.1083, 0.7876, 0.5529, 0.1980, 0.6453, 0.2212, 0.3077, 0.2820,\n",
      "        0.2234, 0.1944, 0.1736, 0.2764, 0.5409, 0.1680, 0.1722, 0.2107, 0.1251,\n",
      "        0.3086, 0.4492]), 'objectness_scores': tensor([0.2433, 0.2688, 0.4549, 0.2457, 0.2596, 0.2366, 0.2339, 0.3480, 0.3307,\n",
      "        0.5755, 0.3592, 0.2658, 0.2093, 0.5132, 0.2924, 0.2192, 0.2447, 0.2712,\n",
      "        0.2161, 0.3063]), 'labels': tensor([ 7,  2, 14, 14,  7, 14, 14,  7, 11, 14, 11,  7, 11, 11, 11, 11, 14, 11,\n",
      "        11, 14], dtype=torch.int32)}\n",
      "127182\n",
      "{'image_id': 127394, 'boxes': tensor([[233, 215, 246, 227],\n",
      "        [244, 167, 267, 200],\n",
      "        [228, 334, 250, 364],\n",
      "        [308, 412, 374, 455],\n",
      "        [323, 122, 336, 146],\n",
      "        [242, 378, 407, 545],\n",
      "        [109, 438, 243, 528],\n",
      "        [298, 148, 313, 175],\n",
      "        [297, 137, 312, 173],\n",
      "        [255, 195, 303, 212],\n",
      "        [161, 200, 187, 242],\n",
      "        [381, 153, 396, 178],\n",
      "        [333, 226, 358, 259],\n",
      "        [392, 174, 408, 208],\n",
      "        [353, 306, 396, 356],\n",
      "        [ 30, 339,  67, 403],\n",
      "        [373, 179, 393, 214],\n",
      "        [247, 204, 260, 216],\n",
      "        [204, 146, 406, 239]], dtype=torch.int32), 'scores': tensor([0.3339, 0.6109, 0.3468, 0.3388, 0.5815, 0.6998, 0.2849, 0.1625, 0.2918,\n",
      "        0.3489, 0.4863, 0.2272, 0.7280, 0.3752, 0.9945, 0.9011, 0.6370, 0.3612,\n",
      "        0.2495]), 'objectness_scores': tensor([0.2850, 0.2635, 0.3249, 0.2009, 0.2988, 0.2052, 0.2629, 0.2370, 0.2610,\n",
      "        0.2495, 0.2265, 0.3719, 0.2715, 0.3381, 0.2811, 0.2875, 0.3583, 0.2897,\n",
      "        0.2405]), 'labels': tensor([11, 10, 11, 12, 11, 12, 10, 11, 10, 11, 10, 11,  7, 11, 10, 10, 12, 11,\n",
      "        10], dtype=torch.int32)}\n",
      "127394\n",
      "{'image_id': 127517, 'boxes': tensor([[399,   0, 641, 175]], dtype=torch.int32), 'scores': tensor([0.5591]), 'objectness_scores': tensor([0.3320]), 'labels': tensor([9], dtype=torch.int32)}\n",
      "127517\n",
      "{'image_id': 127987, 'boxes': tensor([[534, 211, 623, 291],\n",
      "        [125, 249, 176, 310],\n",
      "        [  0, 279, 631, 425],\n",
      "        [103,  97, 229, 373]], dtype=torch.int32), 'scores': tensor([0.4902, 0.6123, 0.3388, 0.7318]), 'objectness_scores': tensor([0.2034, 0.3388, 0.2862, 0.3999]), 'labels': tensor([ 9, 12,  7,  7], dtype=torch.int32)}\n",
      "127987\n",
      "{'image_id': 128051, 'boxes': tensor([[127, 196, 138, 226],\n",
      "        [ 87,  53, 107, 108],\n",
      "        [ 38, 241,  69, 255]], dtype=torch.int32), 'scores': tensor([0.9618, 0.2946, 0.4166]), 'objectness_scores': tensor([0.2710, 0.3797, 0.2519]), 'labels': tensor([12,  8, 14], dtype=torch.int32)}\n",
      "128051\n",
      "{'image_id': 128148, 'boxes': tensor([[270, 193, 502, 325],\n",
      "        [ 47, 204, 261, 367]], dtype=torch.int32), 'scores': tensor([0.9969, 0.9997]), 'objectness_scores': tensor([0.4395, 0.4573]), 'labels': tensor([13, 13], dtype=torch.int32)}\n",
      "128148\n",
      "{'image_id': 128372, 'boxes': tensor([[535, 140, 563, 179],\n",
      "        [447, 319, 463, 326],\n",
      "        [495, 135, 566, 153],\n",
      "        [466, 310, 477, 324],\n",
      "        [434, 219, 446, 227]], dtype=torch.int32), 'scores': tensor([0.7021, 0.1746, 0.6471, 0.3793, 0.1932]), 'objectness_scores': tensor([0.2430, 0.2213, 0.2169, 0.2412, 0.2436]), 'labels': tensor([ 8, 11, 14, 11, 11], dtype=torch.int32)}\n",
      "128372\n",
      "{'image_id': 128476, 'boxes': tensor([[  1, 251, 238, 423],\n",
      "        [145, 138, 334, 238],\n",
      "        [  0, 127, 631, 427],\n",
      "        [367, 134, 568, 236],\n",
      "        [536,  62, 570,  95],\n",
      "        [359,  28, 448,  94],\n",
      "        [241, 225, 487, 425],\n",
      "        [309, 136, 578, 336],\n",
      "        [ 27, 146, 288, 316],\n",
      "        [238, 131, 366, 236],\n",
      "        [576, 191, 638, 284],\n",
      "        [  0, 143, 121, 268],\n",
      "        [496, 268, 639, 424]], dtype=torch.int32), 'scores': tensor([0.9995, 0.9941, 0.1644, 0.9980, 0.9856, 0.1847, 0.9995, 0.9987, 0.9431,\n",
      "        0.9861, 0.9748, 0.9972, 0.9995]), 'objectness_scores': tensor([0.4372, 0.2866, 0.2692, 0.2840, 0.2137, 0.2005, 0.4328, 0.3604, 0.4635,\n",
      "        0.3955, 0.3132, 0.4397, 0.4049]), 'labels': tensor([12, 12,  7, 12, 10, 14, 12, 12, 10, 12, 12, 12, 12], dtype=torch.int32)}\n",
      "128476\n",
      "{'image_id': 128699, 'boxes': tensor([[247, 296, 259, 313],\n",
      "        [248, 293, 268, 310],\n",
      "        [121, 182, 171, 211],\n",
      "        [113, 202, 185, 233],\n",
      "        [141, 353, 152, 359],\n",
      "        [331, 264, 345, 276],\n",
      "        [333, 271, 344, 277],\n",
      "        [259, 300, 266, 310],\n",
      "        [155, 181, 203, 209],\n",
      "        [245, 299, 254, 309],\n",
      "        [202, 325, 215, 330],\n",
      "        [124, 352, 135, 357],\n",
      "        [235, 324, 245, 329],\n",
      "        [125,  47, 173,  78]], dtype=torch.int32), 'scores': tensor([0.2294, 0.2826, 0.2324, 0.6295, 0.2420, 0.2126, 0.1380, 0.1825, 0.2096,\n",
      "        0.1641, 0.1679, 0.2681, 0.1781, 0.2364]), 'objectness_scores': tensor([0.2805, 0.2146, 0.2276, 0.6161, 0.2436, 0.3681, 0.2139, 0.2776, 0.2383,\n",
      "        0.3166, 0.3323, 0.3207, 0.3100, 0.3631]), 'labels': tensor([11, 11,  4,  9, 11, 11, 11, 14,  8, 11, 10, 11, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "128699\n",
      "{'image_id': 129062, 'boxes': tensor([[ 95, 115, 119, 191],\n",
      "        [245, 373, 287, 433],\n",
      "        [450, 306, 584, 346],\n",
      "        [143, 382, 162, 479],\n",
      "        [  1, 196, 106, 479],\n",
      "        [308, 289, 440, 365]], dtype=torch.int32), 'scores': tensor([0.4551, 0.4982, 0.2285, 0.4585, 0.2028, 0.2635]), 'objectness_scores': tensor([0.2543, 0.2291, 0.2411, 0.2002, 0.2578, 0.2728]), 'labels': tensor([11,  8, 10, 11, 14, 10], dtype=torch.int32)}\n",
      "129062\n",
      "{'image_id': 129756, 'boxes': tensor([[243, 253, 261, 352],\n",
      "        [ 61, 326, 123, 357]], dtype=torch.int32), 'scores': tensor([0.2883, 0.8016]), 'objectness_scores': tensor([0.4767, 0.5139]), 'labels': tensor([11,  3], dtype=torch.int32)}\n",
      "129756\n",
      "{'image_id': 130613, 'boxes': tensor([[548, 106, 612, 274],\n",
      "        [210,  73, 492, 351],\n",
      "        [455, 142, 553, 204],\n",
      "        [  0,   0, 303,  67],\n",
      "        [  3,  25, 639, 407],\n",
      "        [  1,  54, 263, 333],\n",
      "        [ 21,  85, 396, 358],\n",
      "        [471, 202, 612, 302],\n",
      "        [123,   2, 314,  45],\n",
      "        [  6,   0, 639, 425]], dtype=torch.int32), 'scores': tensor([0.5823, 0.3798, 0.4633, 0.6880, 0.4102, 0.3566, 0.3849, 0.5415, 0.3300,\n",
      "        0.2743]), 'objectness_scores': tensor([0.4624, 0.5624, 0.3431, 0.2513, 0.4250, 0.5363, 0.5568, 0.4248, 0.2156,\n",
      "        0.2414]), 'labels': tensor([11, 11, 11, 12, 11, 11, 12, 11, 11, 11], dtype=torch.int32)}\n",
      "130613\n",
      "{'image_id': 131131, 'boxes': tensor([[  4, 415, 627, 480],\n",
      "        [ 71, 186, 384, 479],\n",
      "        [291, 171, 457, 317]], dtype=torch.int32), 'scores': tensor([0.4359, 0.9425, 0.9704]), 'objectness_scores': tensor([0.2116, 0.4370, 0.4222]), 'labels': tensor([2, 2, 2], dtype=torch.int32)}\n",
      "131131\n",
      "{'image_id': 131138, 'boxes': tensor([[  0, 142, 140, 368],\n",
      "        [223, 375, 265, 432],\n",
      "        [  0, 139, 134, 207],\n",
      "        [418, 203, 559, 263],\n",
      "        [226, 464, 300, 479],\n",
      "        [558, 267, 638, 305],\n",
      "        [123, 320, 166, 382],\n",
      "        [116, 385, 207, 429],\n",
      "        [510,  98, 575, 171],\n",
      "        [270, 316, 350, 371],\n",
      "        [  0,   1,  70, 157],\n",
      "        [506, 291, 527, 307],\n",
      "        [  7, 277, 543, 491],\n",
      "        [557, 224, 582, 245],\n",
      "        [177, 338, 219, 388],\n",
      "        [ 51,  90,  69, 126],\n",
      "        [443, 225, 461, 282],\n",
      "        [125, 333, 168, 387]], dtype=torch.int32), 'scores': tensor([0.2410, 0.9917, 0.2231, 0.3654, 0.6614, 0.3847, 0.3486, 0.6105, 0.7496,\n",
      "        0.9967, 0.2079, 0.5526, 0.5494, 0.2863, 0.9811, 0.2945, 0.4238, 0.3337]), 'objectness_scores': tensor([0.2065, 0.3483, 0.2376, 0.6577, 0.3635, 0.5326, 0.2599, 0.2107, 0.2279,\n",
      "        0.3768, 0.2707, 0.2056, 0.2997, 0.2040, 0.2815, 0.2425, 0.3140, 0.2252]), 'labels': tensor([ 7, 10,  6,  7, 11,  9, 10, 15,  3, 14, 14, 11, 10, 11, 10,  7,  7, 11],\n",
      "       dtype=torch.int32)}\n",
      "131138\n",
      "{'image_id': 131444, 'boxes': tensor([[ 70, 236, 476, 637],\n",
      "        [ 87,   1, 397, 153],\n",
      "        [169, 355, 263, 638]], dtype=torch.int32), 'scores': tensor([0.9989, 0.5744, 0.9872]), 'objectness_scores': tensor([0.2534, 0.3409, 0.5524]), 'labels': tensor([7, 7, 7], dtype=torch.int32)}\n",
      "131444\n",
      "{'image_id': 132544, 'boxes': tensor([[244, 196, 287, 221],\n",
      "        [294,  70, 458, 177],\n",
      "        [ 14, 115,  41, 157],\n",
      "        [457,  83, 504, 144],\n",
      "        [478,  74, 533, 132],\n",
      "        [ 28,  69, 137, 229],\n",
      "        [379, 148, 422, 202],\n",
      "        [374, 192, 498, 221],\n",
      "        [458,  76, 531, 145],\n",
      "        [338, 166, 362, 174],\n",
      "        [224, 217, 277, 227],\n",
      "        [353, 235, 373, 255],\n",
      "        [485, 176, 517, 206]], dtype=torch.int32), 'scores': tensor([0.3108, 0.3018, 0.2463, 0.2317, 0.1373, 0.5430, 0.3897, 0.6722, 0.9994,\n",
      "        0.2765, 0.2858, 0.1557, 0.3295]), 'objectness_scores': tensor([0.2614, 0.4924, 0.2308, 0.2172, 0.2271, 0.2517, 0.3061, 0.5654, 0.2989,\n",
      "        0.2726, 0.2198, 0.6033, 0.2336]), 'labels': tensor([ 8,  6, 11,  8, 13,  7,  8, 11,  5, 11, 11,  6, 11], dtype=torch.int32)}\n",
      "132544\n",
      "{'image_id': 132703, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "132703\n",
      "{'image_id': 132796, 'boxes': tensor([[  0, 317, 163, 426],\n",
      "        [319, 192, 331, 205],\n",
      "        [311,  85, 326, 107],\n",
      "        [  1, 233, 167, 425],\n",
      "        [ 99, 162, 122, 169],\n",
      "        [342, 362, 382, 399],\n",
      "        [443, 209, 462, 229]], dtype=torch.int32), 'scores': tensor([0.5937, 0.2651, 0.1938, 0.9958, 0.1911, 0.2089, 0.2077]), 'objectness_scores': tensor([0.2127, 0.2433, 0.3042, 0.2019, 0.3195, 0.4678, 0.2084]), 'labels': tensor([ 5,  7, 14,  5, 14, 11, 11], dtype=torch.int32)}\n",
      "132796\n",
      "{'image_id': 133343, 'boxes': tensor([[ 51, 189,  59, 196],\n",
      "        [ 55, 119, 247, 211],\n",
      "        [ 28, 191, 230, 477],\n",
      "        [ 71, 301, 164, 468]], dtype=torch.int32), 'scores': tensor([0.2611, 0.2297, 0.9937, 0.9877]), 'objectness_scores': tensor([0.3092, 0.4175, 0.2068, 0.5183]), 'labels': tensor([11,  7,  7, 15], dtype=torch.int32)}\n",
      "133343\n",
      "{'image_id': 133819, 'boxes': tensor([[155,  81, 500, 357],\n",
      "        [  0, 247,  54, 325],\n",
      "        [ 72, 116,  90, 178],\n",
      "        [471, 125, 638, 259],\n",
      "        [194, 215, 247, 235],\n",
      "        [614, 158, 639, 266],\n",
      "        [ 98, 128, 116, 179],\n",
      "        [ 64, 127,  87, 180],\n",
      "        [ 99, 127, 121, 178]], dtype=torch.int32), 'scores': tensor([0.9997, 0.1891, 0.3419, 0.9973, 0.3458, 0.2589, 0.4660, 0.5175, 0.7096]), 'objectness_scores': tensor([0.5378, 0.2853, 0.4081, 0.5635, 0.2090, 0.3060, 0.4154, 0.3890, 0.3170]), 'labels': tensor([ 1,  1, 11,  1, 11,  7, 11, 11, 11], dtype=torch.int32)}\n",
      "133819\n",
      "{'image_id': 134096, 'boxes': tensor([[231, 112, 640, 483],\n",
      "        [540,   0, 582,  36],\n",
      "        [ -2, 410, 358, 479],\n",
      "        [110, 141, 292, 432]], dtype=torch.int32), 'scores': tensor([0.8921, 0.1832, 0.9490, 0.9988]), 'objectness_scores': tensor([0.5197, 0.3094, 0.2906, 0.4224]), 'labels': tensor([15, 11, 15,  1], dtype=torch.int32)}\n",
      "134096\n",
      "{'image_id': 134112, 'boxes': tensor([[227, 234, 320, 304],\n",
      "        [  0,   0, 216,  79],\n",
      "        [299,   1, 499,  98],\n",
      "        [195,  65, 485, 269]], dtype=torch.int32), 'scores': tensor([0.9724, 0.8269, 0.1737, 0.3079]), 'objectness_scores': tensor([0.2069, 0.2102, 0.2334, 0.5120]), 'labels': tensor([14,  3,  7,  7], dtype=torch.int32)}\n",
      "134112\n",
      "{'image_id': 134882, 'boxes': tensor([[194, 282, 236, 303],\n",
      "        [230, 261, 287, 312],\n",
      "        [ 18,  77, 249, 348],\n",
      "        [140,  65, 202, 111],\n",
      "        [269, 329, 424, 393],\n",
      "        [163, 301, 314, 363]], dtype=torch.int32), 'scores': tensor([0.4090, 0.2407, 0.1901, 0.2344, 0.3422, 0.1736]), 'objectness_scores': tensor([0.2394, 0.6681, 0.2634, 0.2517, 0.5178, 0.4486]), 'labels': tensor([11,  3,  8, 11,  2,  7], dtype=torch.int32)}\n",
      "134882\n",
      "{'image_id': 134886, 'boxes': tensor([[142, 183, 368, 251],\n",
      "        [436, 393, 442, 404]], dtype=torch.int32), 'scores': tensor([0.9744, 0.1939]), 'objectness_scores': tensor([0.5952, 0.2083]), 'labels': tensor([ 0, 14], dtype=torch.int32)}\n",
      "134886\n",
      "{'image_id': 135561, 'boxes': tensor([[377,  78, 404, 116],\n",
      "        [253, 199, 309, 271],\n",
      "        [411,  91, 444, 126],\n",
      "        [ 41,  78, 238, 327],\n",
      "        [238, 117, 342, 229],\n",
      "        [326,  68, 361, 108],\n",
      "        [178, 332, 224, 422],\n",
      "        [316,  51, 448, 127]], dtype=torch.int32), 'scores': tensor([0.6552, 0.5720, 0.6375, 0.2289, 0.2237, 0.9459, 0.8312, 0.3474]), 'objectness_scores': tensor([0.2550, 0.3118, 0.2980, 0.3027, 0.2553, 0.2758, 0.4503, 0.2466]), 'labels': tensor([11,  6, 11,  7,  6, 11, 10,  7], dtype=torch.int32)}\n",
      "135561\n",
      "{'image_id': 135872, 'boxes': tensor([[223, 181, 288, 220],\n",
      "        [501,   0, 542,  50],\n",
      "        [307, 166, 370, 196],\n",
      "        [  2, 286, 155, 378],\n",
      "        [333, 174, 403, 205],\n",
      "        [  1, 299, 186, 428],\n",
      "        [376,  66, 469, 160],\n",
      "        [113, 144, 495, 426]], dtype=torch.int32), 'scores': tensor([0.9670, 0.3868, 0.7292, 0.8523, 0.9784, 0.2723, 0.6406, 0.1932]), 'objectness_scores': tensor([0.3192, 0.2759, 0.2533, 0.2013, 0.2249, 0.2582, 0.4281, 0.2941]), 'labels': tensor([14,  3, 14,  0, 14,  0, 14, 11], dtype=torch.int32)}\n",
      "135872\n",
      "{'image_id': 136633, 'boxes': tensor([[118, 205, 217, 238],\n",
      "        [157, 327, 209, 381],\n",
      "        [103, 372, 142, 385],\n",
      "        [ 68, 401, 117, 442],\n",
      "        [171, 337, 200, 381],\n",
      "        [ 70, 400, 166, 444],\n",
      "        [ 99, 334, 153, 362],\n",
      "        [217, 526, 286, 597],\n",
      "        [ 98, 359, 137, 375],\n",
      "        [119, 204, 216, 279],\n",
      "        [195, 350, 239, 381]], dtype=torch.int32), 'scores': tensor([0.2460, 0.1541, 0.2037, 0.1707, 0.2995, 0.2567, 0.1856, 0.1374, 0.3109,\n",
      "        0.9311, 0.4671]), 'objectness_scores': tensor([0.2821, 0.2251, 0.2782, 0.2053, 0.2087, 0.2543, 0.2299, 0.2408, 0.2444,\n",
      "        0.2682, 0.2848]), 'labels': tensor([ 9, 10, 11,  2, 11,  2,  7,  7, 11,  6, 11], dtype=torch.int32)}\n",
      "136633\n",
      "{'image_id': 136915, 'boxes': tensor([[  0, 284,  99, 372],\n",
      "        [518,   0, 598,  49],\n",
      "        [250, 323, 355, 385],\n",
      "        [113,   0, 186,  72]], dtype=torch.int32), 'scores': tensor([0.4932, 0.5146, 0.7998, 0.2126]), 'objectness_scores': tensor([0.4924, 0.2073, 0.4525, 0.3299]), 'labels': tensor([14,  9, 14, 14], dtype=torch.int32)}\n",
      "136915\n",
      "{'image_id': 137246, 'boxes': tensor([[131,  73, 170,  88],\n",
      "        [ 96,  20, 264,  83],\n",
      "        [267, 281, 293, 300],\n",
      "        [169, 185, 283, 333],\n",
      "        [  3,  54, 102, 166],\n",
      "        [ 99,  18, 263, 145],\n",
      "        [369, 167, 375, 170],\n",
      "        [ 10,  54, 102,  91],\n",
      "        [ 21, 138,  84, 186]], dtype=torch.int32), 'scores': tensor([0.1602, 0.7085, 0.3758, 0.2654, 0.5056, 0.7082, 0.1978, 0.1881, 0.2656]), 'objectness_scores': tensor([0.2010, 0.4225, 0.3466, 0.5758, 0.4651, 0.2685, 0.2258, 0.2142, 0.2206]), 'labels': tensor([ 7,  6,  7, 11,  6,  6, 11,  1,  7], dtype=torch.int32)}\n",
      "137246\n",
      "{'image_id': 138492, 'boxes': tensor([[117,  48, 387, 604]], dtype=torch.int32), 'scores': tensor([0.5564]), 'objectness_scores': tensor([0.5273]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "138492\n",
      "{'image_id': 138819, 'boxes': tensor([[127,  25, 465, 228],\n",
      "        [479, 280, 529, 319],\n",
      "        [265,   9, 305,  56],\n",
      "        [417, 317, 535, 466],\n",
      "        [458, 262, 543, 319]], dtype=torch.int32), 'scores': tensor([0.9677, 0.1332, 0.3398, 0.2374, 0.2756]), 'objectness_scores': tensor([0.6163, 0.7402, 0.5301, 0.4726, 0.2247]), 'labels': tensor([15, 14, 11, 11, 14], dtype=torch.int32)}\n",
      "138819\n",
      "{'image_id': 138979, 'boxes': tensor([[ 52,  28,  77,  45],\n",
      "        [120,  81, 637, 404],\n",
      "        [432, 229, 516, 299]], dtype=torch.int32), 'scores': tensor([0.6878, 0.9975, 0.2996]), 'objectness_scores': tensor([0.2668, 0.4361, 0.2930]), 'labels': tensor([11,  1,  7], dtype=torch.int32)}\n",
      "138979\n",
      "{'image_id': 139099, 'boxes': tensor([[ 42, 388, 102, 415],\n",
      "        [ 37, 405, 179, 432],\n",
      "        [563,  95, 596, 116],\n",
      "        [162, 264, 254, 402],\n",
      "        [401,  59, 516, 149],\n",
      "        [ 57, 350, 196, 404],\n",
      "        [527, 379, 562, 424],\n",
      "        [139, 388, 180, 412],\n",
      "        [250,  89, 295, 117],\n",
      "        [517, 106, 542, 122],\n",
      "        [324, 110, 351, 131]], dtype=torch.int32), 'scores': tensor([0.3182, 0.2171, 0.3477, 0.2844, 0.2881, 0.6494, 0.2839, 0.4498, 0.3542,\n",
      "        0.2478, 0.1409]), 'objectness_scores': tensor([0.2322, 0.3781, 0.2498, 0.3235, 0.2265, 0.4854, 0.2945, 0.2189, 0.2322,\n",
      "        0.2414, 0.2095]), 'labels': tensor([11, 14,  4,  9,  5,  9, 11, 11,  8, 14,  8], dtype=torch.int32)}\n",
      "139099\n",
      "{'image_id': 139684, 'boxes': tensor([[  1,  39,  35,  94],\n",
      "        [  2, 213, 410, 328],\n",
      "        [ 13, 102,  48, 140],\n",
      "        [ 84,  16, 109,  67],\n",
      "        [  4, 252, 222, 328],\n",
      "        [ 33,  13,  74,  62],\n",
      "        [ 76, 200,  82, 214],\n",
      "        [  0,   0, 494, 331],\n",
      "        [101, 214, 446, 325],\n",
      "        [  4, 238, 128, 283],\n",
      "        [446,  10, 470, 129],\n",
      "        [205, 289, 349, 329],\n",
      "        [190, 241, 332, 295],\n",
      "        [413, 101, 442, 196],\n",
      "        [ 54,  70, 104, 133],\n",
      "        [379, 173, 436, 209],\n",
      "        [172, 202, 271, 261],\n",
      "        [  2, 205,  50, 246]], dtype=torch.int32), 'scores': tensor([0.3327, 0.9725, 0.2322, 0.3466, 0.9967, 0.6324, 0.1790, 0.9564, 0.8767,\n",
      "        0.8758, 0.3425, 0.2845, 0.2127, 0.2682, 0.8579, 0.3606, 0.5260, 0.4118]), 'objectness_scores': tensor([0.2248, 0.4198, 0.2028, 0.2263, 0.2066, 0.2442, 0.3846, 0.2126, 0.2091,\n",
      "        0.2456, 0.2925, 0.2224, 0.2834, 0.2456, 0.2199, 0.2204, 0.3813, 0.2155]), 'labels': tensor([ 8, 13, 10, 11, 13, 12,  0, 13,  2, 13, 11, 11, 11, 11,  6, 10, 13,  7],\n",
      "       dtype=torch.int32)}\n",
      "139684\n",
      "{'image_id': 139872, 'boxes': tensor([[ 49, 436, 103, 480],\n",
      "        [ 63,  33, 471, 421]], dtype=torch.int32), 'scores': tensor([0.3143, 0.9806]), 'objectness_scores': tensor([0.2167, 0.5192]), 'labels': tensor([4, 3], dtype=torch.int32)}\n",
      "139872\n",
      "{'image_id': 140203, 'boxes': tensor([[  5,  19,  19,  29],\n",
      "        [530, 229, 547, 248],\n",
      "        [512, 110, 571, 151],\n",
      "        [401, 219, 465, 242],\n",
      "        [505,  49, 574, 111],\n",
      "        [251, 242, 331, 284],\n",
      "        [  3, 319,  38, 337],\n",
      "        [  6, 307,  34, 319],\n",
      "        [484,  43, 532, 101],\n",
      "        [538,  35, 555,  43]], dtype=torch.int32), 'scores': tensor([0.3416, 0.3599, 0.3078, 0.2800, 0.3161, 0.3389, 0.4736, 0.2965, 0.5088,\n",
      "        0.1992]), 'objectness_scores': tensor([0.2171, 0.2027, 0.2003, 0.2196, 0.2502, 0.2004, 0.3997, 0.2055, 0.3608,\n",
      "        0.2027]), 'labels': tensor([11, 11,  9,  8,  3,  1, 11, 11,  3, 11], dtype=torch.int32)}\n",
      "140203\n",
      "{'image_id': 140583, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "140583\n",
      "{'image_id': 140640, 'boxes': tensor([[450, 384, 484, 404],\n",
      "        [  0, 309,  42, 426],\n",
      "        [500,  87, 599, 150],\n",
      "        [571, 244, 582, 352],\n",
      "        [311,  54, 459, 121],\n",
      "        [477, 364, 591, 425],\n",
      "        [446, 397, 470, 421],\n",
      "        [177, 162, 291, 392],\n",
      "        [413, 394, 451, 425],\n",
      "        [146,  66, 293, 161],\n",
      "        [481, 395, 515, 425],\n",
      "        [265, 405, 271, 414],\n",
      "        [448, 402, 488, 426],\n",
      "        [ 68, 198,  98, 425],\n",
      "        [404, 351, 413, 358],\n",
      "        [501, 156, 534, 218]], dtype=torch.int32), 'scores': tensor([0.2463, 0.2799, 0.4893, 0.4882, 0.4011, 0.9937, 0.2109, 0.8958, 0.9863,\n",
      "        0.3530, 0.6757, 0.3750, 0.1788, 0.8334, 0.3161, 0.2326]), 'objectness_scores': tensor([0.2997, 0.5666, 0.2515, 0.5774, 0.2386, 0.3838, 0.2078, 0.2324, 0.2707,\n",
      "        0.2594, 0.2950, 0.2373, 0.2209, 0.2202, 0.2122, 0.2783]), 'labels': tensor([11,  8,  7, 11,  6, 12,  4,  7, 12,  7, 12, 11, 11, 10, 11,  9],\n",
      "       dtype=torch.int32)}\n",
      "140640\n",
      "{'image_id': 140987, 'boxes': tensor([[ 57, 413, 337, 523],\n",
      "        [117, 139, 243, 236],\n",
      "        [141, 341, 212, 392],\n",
      "        [  0, 519, 258, 638],\n",
      "        [283, 466, 422, 639],\n",
      "        [282, 195, 314, 232],\n",
      "        [118, 277, 124, 283],\n",
      "        [  0, 422, 417, 639],\n",
      "        [ 17, 219,  46, 258],\n",
      "        [385, 341, 424, 471],\n",
      "        [  9, 461,  19, 497],\n",
      "        [402, 259, 420, 345]], dtype=torch.int32), 'scores': tensor([0.3438, 0.5790, 0.2068, 0.4398, 0.9717, 0.2798, 0.1575, 0.2100, 0.2103,\n",
      "        0.1958, 0.2742, 0.1770]), 'objectness_scores': tensor([0.2728, 0.2208, 0.2245, 0.2998, 0.4572, 0.3961, 0.3625, 0.2961, 0.4338,\n",
      "        0.2550, 0.3075, 0.3561]), 'labels': tensor([12,  7, 10, 11, 10,  7, 11, 14, 11,  8, 14,  2], dtype=torch.int32)}\n",
      "140987\n",
      "{'image_id': 142472, 'boxes': tensor([[357, 313, 405, 345],\n",
      "        [ 60, 381,  87, 427],\n",
      "        [298, 303, 380, 343],\n",
      "        [367, 382, 389, 426],\n",
      "        [ 29, 392,  57, 428],\n",
      "        [ 55, 380,  63, 400]], dtype=torch.int32), 'scores': tensor([0.4633, 0.1880, 0.1833, 0.3785, 0.2589, 0.2514]), 'objectness_scores': tensor([0.2169, 0.4098, 0.2123, 0.2291, 0.2775, 0.2503]), 'labels': tensor([ 1,  8,  4,  8,  8, 11], dtype=torch.int32)}\n",
      "142472\n",
      "{'image_id': 142585, 'boxes': tensor([[249, 198, 308, 253],\n",
      "        [143,   4, 373,  78],\n",
      "        [264, 392, 320, 411],\n",
      "        [217, 330, 230, 361],\n",
      "        [223, 233, 241, 266],\n",
      "        [ 93, 225, 108, 256],\n",
      "        [134, 376, 156, 389],\n",
      "        [346, 325, 357, 355],\n",
      "        [ 89, 400, 112, 412],\n",
      "        [197, 187, 244, 229]], dtype=torch.int32), 'scores': tensor([0.4202, 0.3663, 0.5151, 0.3465, 0.2585, 0.1929, 0.8052, 0.2335, 0.2602,\n",
      "        0.1892]), 'objectness_scores': tensor([0.2275, 0.2385, 0.2098, 0.3246, 0.4486, 0.4569, 0.2252, 0.3316, 0.2243,\n",
      "        0.2542]), 'labels': tensor([ 7,  1, 14,  8,  7, 11, 14, 14, 11,  7], dtype=torch.int32)}\n",
      "142585\n",
      "{'image_id': 142620, 'boxes': tensor([[213, 209, 251, 230],\n",
      "        [251, 268, 302, 281],\n",
      "        [ 55, 227, 123, 353],\n",
      "        [354,  70, 632, 393],\n",
      "        [164, 377, 214, 425],\n",
      "        [ 55, 226, 124, 354]], dtype=torch.int32), 'scores': tensor([0.2361, 0.9227, 0.6287, 0.3264, 0.9877, 0.6070]), 'objectness_scores': tensor([0.2379, 0.2368, 0.3240, 0.2418, 0.2210, 0.2825]), 'labels': tensor([11, 11, 15,  9, 10, 15], dtype=torch.int32)}\n",
      "142620\n",
      "{'image_id': 142790, 'boxes': tensor([[259, 194, 280, 212],\n",
      "        [273, 248, 296, 260],\n",
      "        [341, 218, 368, 250],\n",
      "        [299, 186, 318, 204],\n",
      "        [263, 256, 296, 276],\n",
      "        [162, 173, 200, 203],\n",
      "        [386, 227, 426, 256],\n",
      "        [263, 149, 295, 183]], dtype=torch.int32), 'scores': tensor([0.2042, 0.1633, 0.4465, 0.2018, 0.2255, 0.2167, 0.3059, 0.2911]), 'objectness_scores': tensor([0.4557, 0.2138, 0.2118, 0.2037, 0.3243, 0.4819, 0.4250, 0.3173]), 'labels': tensor([11, 11,  2, 11, 11,  8,  8, 11], dtype=torch.int32)}\n",
      "142790\n",
      "{'image_id': 143931, 'boxes': tensor([[528,   0, 615, 479],\n",
      "        [  0,  56,  45, 110]], dtype=torch.int32), 'scores': tensor([0.6603, 0.6637]), 'objectness_scores': tensor([0.2040, 0.3391]), 'labels': tensor([1, 7], dtype=torch.int32)}\n",
      "143931\n",
      "{'image_id': 143961, 'boxes': tensor([[357,  26, 381,  46],\n",
      "        [276,  36, 291,  44],\n",
      "        [ 51, 124,  96, 151],\n",
      "        [303, 279, 339, 291],\n",
      "        [104, 264, 113, 278],\n",
      "        [459,   0, 485,  11],\n",
      "        [190, 183, 229, 200],\n",
      "        [  8,  31,  26,  39],\n",
      "        [  0, 188,  22, 229],\n",
      "        [595, 275, 639, 295],\n",
      "        [  0, 139,  52, 168],\n",
      "        [147,  77, 157,  83],\n",
      "        [ 25, 167,  46, 178],\n",
      "        [219, 203, 292, 294],\n",
      "        [169, 148, 240, 191],\n",
      "        [324, 212, 354, 223],\n",
      "        [282, 243, 328, 290],\n",
      "        [112,  27, 129,  34],\n",
      "        [ 81, 164, 107, 177]], dtype=torch.int32), 'scores': tensor([0.5056, 0.1818, 0.1753, 0.2082, 0.2561, 0.3637, 0.5220, 0.1671, 0.5516,\n",
      "        0.3255, 0.2335, 0.1593, 0.2228, 0.5731, 0.3629, 0.3124, 0.2506, 0.1994,\n",
      "        0.2162]), 'objectness_scores': tensor([0.2594, 0.2976, 0.2518, 0.2168, 0.2579, 0.2600, 0.3437, 0.3146, 0.2329,\n",
      "        0.2345, 0.3416, 0.2725, 0.2909, 0.2132, 0.2835, 0.2857, 0.2005, 0.3113,\n",
      "        0.2996]), 'labels': tensor([ 8, 11, 15, 14,  0, 11, 11, 14, 11, 11, 14, 11, 14,  7,  8, 11, 16,  0,\n",
      "        11], dtype=torch.int32)}\n",
      "143961\n",
      "{'image_id': 143998, 'boxes': tensor([[363, 127, 610, 323],\n",
      "        [378,   0, 544, 128],\n",
      "        [259,   0, 613, 129]], dtype=torch.int32), 'scores': tensor([0.5349, 0.5216, 0.3713]), 'objectness_scores': tensor([0.3194, 0.2402, 0.3916]), 'labels': tensor([8, 7, 7], dtype=torch.int32)}\n",
      "143998\n",
      "{'image_id': 144003, 'boxes': tensor([[208, 227, 216, 237],\n",
      "        [125, 182, 373, 376],\n",
      "        [230, 277, 241, 291],\n",
      "        [217, 205, 221, 211],\n",
      "        [267, 224, 283, 235],\n",
      "        [195, 238, 207, 245],\n",
      "        [160, 260, 260, 370],\n",
      "        [264, 237, 280, 247],\n",
      "        [243, 215, 252, 225],\n",
      "        [224,  83, 261, 123],\n",
      "        [257, 252, 271, 261],\n",
      "        [261, 218, 273, 229],\n",
      "        [244, 268, 256, 278],\n",
      "        [254, 213, 263, 221],\n",
      "        [337,  75, 442, 107],\n",
      "        [370, 319, 409, 363],\n",
      "        [223, 220, 232, 229],\n",
      "        [199,  78, 317, 192],\n",
      "        [181, 250, 196, 257]], dtype=torch.int32), 'scores': tensor([0.1424, 0.9830, 0.1877, 0.1422, 0.9585, 0.1958, 0.4990, 0.2123, 0.3107,\n",
      "        0.3325, 0.3902, 0.2025, 0.2577, 0.4832, 0.2259, 0.2796, 0.1960, 0.5418,\n",
      "        0.1800]), 'objectness_scores': tensor([0.3255, 0.2558, 0.3391, 0.3961, 0.3557, 0.2827, 0.4259, 0.3729, 0.3567,\n",
      "        0.3419, 0.3593, 0.3441, 0.3337, 0.2394, 0.2742, 0.2830, 0.3411, 0.2031,\n",
      "        0.3577]), 'labels': tensor([11, 12, 11, 11,  2, 11, 10, 11, 11,  7, 11, 11,  4, 11,  7, 11, 11,  7,\n",
      "        13], dtype=torch.int32)}\n",
      "144003\n",
      "{'image_id': 144114, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "144114\n",
      "{'image_id': 144300, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "144300\n",
      "{'image_id': 144798, 'boxes': tensor([[  9, 374,  52, 418],\n",
      "        [144, 168, 171, 214],\n",
      "        [363, 233, 383, 253],\n",
      "        [  0, 547, 108, 639],\n",
      "        [388, 155, 413, 185],\n",
      "        [ -1, 186, 424, 385],\n",
      "        [  2,   0, 424, 374],\n",
      "        [319,  72, 332,  89],\n",
      "        [385, 155, 424, 253],\n",
      "        [180, 190, 230, 266],\n",
      "        [  0, 369,  86, 416],\n",
      "        [ 46, 216,  84, 245]], dtype=torch.int32), 'scores': tensor([0.5217, 0.3292, 0.1813, 0.2881, 0.4051, 0.6544, 0.9637, 0.2230, 0.2494,\n",
      "        0.9706, 0.2376, 0.2650]), 'objectness_scores': tensor([0.2442, 0.3437, 0.2674, 0.2863, 0.3084, 0.6534, 0.2083, 0.2896, 0.5273,\n",
      "        0.5087, 0.3608, 0.3475]), 'labels': tensor([10, 10, 11,  5, 11, 15, 15, 14,  8, 10,  9, 14], dtype=torch.int32)}\n",
      "144798\n",
      "{'image_id': 144984, 'boxes': tensor([[  0, 310, 423, 639],\n",
      "        [120, 325, 397, 597]], dtype=torch.int32), 'scores': tensor([0.1905, 0.4203]), 'objectness_scores': tensor([0.4754, 0.2696]), 'labels': tensor([10,  7], dtype=torch.int32)}\n",
      "144984\n",
      "{'image_id': 145597, 'boxes': tensor([[ 61,  55, 130, 146],\n",
      "        [462, 270, 482, 286],\n",
      "        [402,  77, 423,  92],\n",
      "        [  0, 334, 152, 468],\n",
      "        [300, 270, 323, 302],\n",
      "        [ 50, 140, 159, 200],\n",
      "        [382,  69, 451, 154],\n",
      "        [395, 153, 405, 171]], dtype=torch.int32), 'scores': tensor([0.1988, 0.1902, 0.2162, 0.2622, 0.3075, 0.1771, 0.5187, 0.3788]), 'objectness_scores': tensor([0.3008, 0.2274, 0.2089, 0.2015, 0.2024, 0.2069, 0.2080, 0.2043]), 'labels': tensor([ 9, 11, 11,  7,  7, 12,  7, 11], dtype=torch.int32)}\n",
      "145597\n",
      "{'image_id': 145665, 'boxes': tensor([[383, 262, 428, 307],\n",
      "        [104, 476, 179, 535],\n",
      "        [  1, 280, 139, 339]], dtype=torch.int32), 'scores': tensor([0.9644, 0.2341, 0.3143]), 'objectness_scores': tensor([0.6012, 0.3020, 0.2401]), 'labels': tensor([ 9,  9, 13], dtype=torch.int32)}\n",
      "145665\n",
      "{'image_id': 145781, 'boxes': tensor([[ 37, 133, 143, 242],\n",
      "        [  2,   0, 609, 343]], dtype=torch.int32), 'scores': tensor([0.2225, 0.9497]), 'objectness_scores': tensor([0.2329, 0.5068]), 'labels': tensor([5, 3], dtype=torch.int32)}\n",
      "145781\n",
      "{'image_id': 146358, 'boxes': tensor([[207, 384, 225, 406],\n",
      "        [337, 166, 341, 173],\n",
      "        [179, 208, 189, 238],\n",
      "        [104, 222, 115, 259],\n",
      "        [301, 196, 316, 217],\n",
      "        [267, 187, 286, 257],\n",
      "        [108, 418, 126, 444],\n",
      "        [115, 225, 184, 264],\n",
      "        [ 30, 269, 164, 415],\n",
      "        [309, 182, 340, 216],\n",
      "        [117, 246, 132, 266],\n",
      "        [189, 383, 207, 410],\n",
      "        [ 90, 420, 110, 449],\n",
      "        [ 45, 221,  99, 268],\n",
      "        [  1, 378, 269, 608],\n",
      "        [251, 228, 387, 606],\n",
      "        [  0, 258, 196, 386]], dtype=torch.int32), 'scores': tensor([0.1658, 0.2629, 0.2979, 0.1626, 0.1837, 0.3798, 0.1677, 0.1890, 0.9993,\n",
      "        0.3558, 0.3071, 0.1929, 0.2093, 0.2558, 0.6731, 0.5740, 0.9992]), 'objectness_scores': tensor([0.3026, 0.2320, 0.3274, 0.3566, 0.2177, 0.2652, 0.2716, 0.2245, 0.5370,\n",
      "        0.3717, 0.2537, 0.2644, 0.2847, 0.2306, 0.3392, 0.2040, 0.3477]), 'labels': tensor([11, 11, 11, 11, 11, 11, 11, 12, 12, 11, 12, 11, 11, 12, 10, 12, 12],\n",
      "       dtype=torch.int32)}\n",
      "146358\n",
      "{'image_id': 146363, 'boxes': tensor([[  2, 184, 498, 375],\n",
      "        [219,  83, 477, 232]], dtype=torch.int32), 'scores': tensor([0.3711, 0.9940]), 'objectness_scores': tensor([0.2063, 0.5512]), 'labels': tensor([13,  6], dtype=torch.int32)}\n",
      "146363\n",
      "{'image_id': 146831, 'boxes': tensor([[ 46, 168, 614, 425],\n",
      "        [296, 308, 357, 371],\n",
      "        [312, 339, 341, 358]], dtype=torch.int32), 'scores': tensor([0.9825, 0.9043, 0.2197]), 'objectness_scores': tensor([0.2999, 0.6558, 0.2066]), 'labels': tensor([ 9,  9, 11], dtype=torch.int32)}\n",
      "146831\n",
      "{'image_id': 147223, 'boxes': tensor([[212, 258, 264, 274],\n",
      "        [111,   0, 132,  75],\n",
      "        [260,   5, 279,  56]], dtype=torch.int32), 'scores': tensor([0.3259, 0.9911, 0.1534]), 'objectness_scores': tensor([0.2458, 0.3024, 0.2372]), 'labels': tensor([14,  7,  7], dtype=torch.int32)}\n",
      "147223\n",
      "{'image_id': 147415, 'boxes': tensor([[321,  46, 336,  64],\n",
      "        [  0, 357, 116, 415],\n",
      "        [390, 328, 495, 421]], dtype=torch.int32), 'scores': tensor([0.2155, 0.3446, 0.5107]), 'objectness_scores': tensor([0.2023, 0.2247, 0.2184]), 'labels': tensor([ 3,  7, 11], dtype=torch.int32)}\n",
      "147415\n",
      "{'image_id': 147518, 'boxes': tensor([[ 24,   2, 174, 555],\n",
      "        [415, 335, 480, 388],\n",
      "        [318, 368, 357, 420],\n",
      "        [339, 330, 479, 638],\n",
      "        [392,   2, 478, 273],\n",
      "        [ 27, 441, 102, 608],\n",
      "        [162, 319, 310, 447],\n",
      "        [185,  20, 274, 198],\n",
      "        [263, 440, 355, 616]], dtype=torch.int32), 'scores': tensor([0.6753, 0.9298, 0.2677, 0.1624, 0.2396, 0.1841, 0.2981, 0.2334, 0.4776]), 'objectness_scores': tensor([0.3546, 0.4459, 0.7008, 0.2707, 0.2443, 0.4529, 0.2020, 0.2466, 0.2312]), 'labels': tensor([ 7, 15, 11, 15,  7,  7, 12,  8,  7], dtype=torch.int32)}\n",
      "147518\n",
      "{'image_id': 147725, 'boxes': tensor([[302,  67, 336, 109],\n",
      "        [154, 110, 379, 258]], dtype=torch.int32), 'scores': tensor([0.4105, 0.9955]), 'objectness_scores': tensor([0.2030, 0.6177]), 'labels': tensor([7, 1], dtype=torch.int32)}\n",
      "147725\n",
      "{'image_id': 148508, 'boxes': tensor([[209,  72, 228,  79],\n",
      "        [535,   6, 640,  45],\n",
      "        [531,  47, 606,  83],\n",
      "        [534,  81, 597, 105],\n",
      "        [457, 204, 480, 214],\n",
      "        [541, 143, 621, 155]], dtype=torch.int32), 'scores': tensor([0.2015, 0.6292, 0.4461, 0.3058, 0.1854, 0.3598]), 'objectness_scores': tensor([0.2036, 0.3665, 0.3580, 0.3645, 0.2679, 0.2168]), 'labels': tensor([14, 14, 11, 14, 11, 14], dtype=torch.int32)}\n",
      "148508\n",
      "{'image_id': 148620, 'boxes': tensor([[100,  73, 216, 106],\n",
      "        [  1, 132, 124, 182],\n",
      "        [220, 232, 423, 281],\n",
      "        [  1, 131, 124, 225],\n",
      "        [152, 147, 202, 175],\n",
      "        [176, 194, 219, 216],\n",
      "        [156, 169, 202, 201],\n",
      "        [112, 125, 202, 154],\n",
      "        [  3, 172, 497, 377],\n",
      "        [110, 100, 205, 130]], dtype=torch.int32), 'scores': tensor([0.3398, 0.4458, 0.9931, 0.4869, 0.2601, 0.1732, 0.1987, 0.5228, 0.3528,\n",
      "        0.1781]), 'objectness_scores': tensor([0.3373, 0.2104, 0.6888, 0.2962, 0.2906, 0.2587, 0.3366, 0.3434, 0.3373,\n",
      "        0.3322]), 'labels': tensor([ 8, 14, 14, 14, 11, 13, 13, 14, 11, 13], dtype=torch.int32)}\n",
      "148620\n",
      "{'image_id': 149222, 'boxes': tensor([[ 45, 215, 262, 354],\n",
      "        [  3, 154, 492, 382],\n",
      "        [ 80, 295, 390, 382],\n",
      "        [279, 175, 499, 291],\n",
      "        [ 85, 244, 139, 357],\n",
      "        [234, 210, 262, 246],\n",
      "        [353, 276, 495, 360],\n",
      "        [445,  65, 497, 190]], dtype=torch.int32), 'scores': tensor([0.4246, 0.3991, 0.9863, 0.2196, 0.3269, 0.9056, 0.8280, 0.1976]), 'objectness_scores': tensor([0.3106, 0.2288, 0.7926, 0.2713, 0.2524, 0.2542, 0.3103, 0.2143]), 'labels': tensor([14,  8, 14, 12, 12, 10, 12,  7], dtype=torch.int32)}\n",
      "149222\n",
      "{'image_id': 149375, 'boxes': tensor([[516, 210, 532, 216],\n",
      "        [304, 101, 345, 143],\n",
      "        [527, 194, 543, 213],\n",
      "        [515, 195, 544, 217],\n",
      "        [217, 298, 261, 327],\n",
      "        [217, 299, 323, 381]], dtype=torch.int32), 'scores': tensor([0.2367, 0.1694, 0.3316, 0.2813, 0.4412, 0.2653]), 'objectness_scores': tensor([0.2535, 0.2618, 0.2792, 0.2060, 0.2242, 0.6117]), 'labels': tensor([11, 11, 11, 11, 15,  7], dtype=torch.int32)}\n",
      "149375\n",
      "{'image_id': 149568, 'boxes': tensor([[124, 118, 458, 477],\n",
      "        [ 84, 116, 193, 281],\n",
      "        [135, 216, 168, 246],\n",
      "        [100, 114, 340, 290]], dtype=torch.int32), 'scores': tensor([0.9882, 0.8311, 0.2257, 0.7760]), 'objectness_scores': tensor([0.4664, 0.2174, 0.2114, 0.2178]), 'labels': tensor([ 3,  3, 11,  3], dtype=torch.int32)}\n",
      "149568\n",
      "{'image_id': 150224, 'boxes': tensor([[ 40, 112, 320, 201],\n",
      "        [  0, 388,  36, 418]], dtype=torch.int32), 'scores': tensor([0.9965, 0.2495]), 'objectness_scores': tensor([0.2607, 0.2243]), 'labels': tensor([ 6, 14], dtype=torch.int32)}\n",
      "150224\n",
      "{'image_id': 150417, 'boxes': tensor([[500, 165, 530, 224],\n",
      "        [315, 290, 320, 327],\n",
      "        [ 73, 311, 201, 480],\n",
      "        [326, 312, 332, 348],\n",
      "        [357, 281, 362, 322],\n",
      "        [478, 190, 505, 234],\n",
      "        [321, 307, 327, 346],\n",
      "        [322, 292, 328, 334],\n",
      "        [292, 280, 299, 320],\n",
      "        [315, 276, 322, 312],\n",
      "        [283, 307, 382, 401],\n",
      "        [357, 290, 361, 331],\n",
      "        [444, 184, 478, 244],\n",
      "        [351, 237, 387, 278],\n",
      "        [347, 300, 352, 338],\n",
      "        [341, 282, 347, 326],\n",
      "        [365, 291, 371, 333]], dtype=torch.int32), 'scores': tensor([0.2336, 0.1635, 0.5099, 0.2019, 0.1486, 0.4696, 0.1621, 0.1569, 0.1819,\n",
      "        0.2143, 0.9992, 0.1697, 0.2147, 0.9946, 0.2545, 0.1589, 0.1492]), 'objectness_scores': tensor([0.3513, 0.2169, 0.2766, 0.2093, 0.2557, 0.3089, 0.2103, 0.2620, 0.2580,\n",
      "        0.2470, 0.4652, 0.2207, 0.3298, 0.2059, 0.2327, 0.2532, 0.2346]), 'labels': tensor([14, 10,  8, 11, 11,  7,  7,  8,  7,  8, 12, 14,  3, 10, 16, 14, 11],\n",
      "       dtype=torch.int32)}\n",
      "150417\n",
      "{'image_id': 150638, 'boxes': tensor([[277,  72, 395, 160],\n",
      "        [245, 185, 313, 239],\n",
      "        [  1,  66, 148, 366],\n",
      "        [308,  38, 339,  73],\n",
      "        [415,  61, 452,  96],\n",
      "        [277,  71, 388, 114],\n",
      "        [283, 115, 333, 191],\n",
      "        [496,  19, 512,  37],\n",
      "        [358, 248, 408, 318],\n",
      "        [511, 172, 550, 200],\n",
      "        [366, 139, 393, 181],\n",
      "        [191,  72, 297, 244],\n",
      "        [513, 195, 553, 251],\n",
      "        [  7, 157, 634, 468],\n",
      "        [455,  17, 500,  81]], dtype=torch.int32), 'scores': tensor([0.3383, 0.3006, 0.3238, 0.3230, 0.3368, 0.4042, 0.2532, 0.2942, 0.9975,\n",
      "        0.8737, 0.3371, 0.9343, 0.9907, 0.3765, 0.2011]), 'objectness_scores': tensor([0.2447, 0.2001, 0.4109, 0.2294, 0.2463, 0.2233, 0.2917, 0.2074, 0.3590,\n",
      "        0.3228, 0.2490, 0.3864, 0.3385, 0.2438, 0.2085]), 'labels': tensor([10,  9,  7,  8, 10, 15, 10, 11, 10, 10, 11, 10, 10, 10, 14],\n",
      "       dtype=torch.int32)}\n",
      "150638\n",
      "{'image_id': 150649, 'boxes': tensor([[328, 119, 377, 130],\n",
      "        [109, 227, 129, 238],\n",
      "        [196, 117, 242, 127],\n",
      "        [115, 120, 160, 132],\n",
      "        [113, 231, 146, 274],\n",
      "        [468, 254, 498, 300],\n",
      "        [  1, 120, 495, 311]], dtype=torch.int32), 'scores': tensor([0.2936, 0.3894, 0.4593, 0.4717, 0.6472, 0.6623, 0.7513]), 'objectness_scores': tensor([0.4281, 0.2258, 0.4808, 0.4361, 0.4761, 0.3611, 0.3239]), 'labels': tensor([14, 11, 11, 11,  9,  9,  9], dtype=torch.int32)}\n",
      "150649\n",
      "{'image_id': 151000, 'boxes': tensor([[213, 299, 219, 308],\n",
      "        [303,  76, 341, 108],\n",
      "        [485, 292, 494, 302],\n",
      "        [491, 265, 523, 282],\n",
      "        [400, 356, 423, 369],\n",
      "        [465, 224, 503, 245]], dtype=torch.int32), 'scores': tensor([0.8301, 0.2714, 0.1437, 0.1833, 0.5165, 0.3043]), 'objectness_scores': tensor([0.2187, 0.2060, 0.2068, 0.2488, 0.3626, 0.2384]), 'labels': tensor([ 3,  2,  3, 11, 11, 11], dtype=torch.int32)}\n",
      "151000\n",
      "{'image_id': 151657, 'boxes': tensor([[127, 596, 215, 639],\n",
      "        [  7,  17, 364, 641],\n",
      "        [ 38, 392,  48, 398],\n",
      "        [242, 605, 274, 638],\n",
      "        [187, 225, 324, 484],\n",
      "        [178, 187, 377, 612],\n",
      "        [136, 140, 179, 337],\n",
      "        [ 76,  16, 189,  74],\n",
      "        [203, 145, 260, 161]], dtype=torch.int32), 'scores': tensor([0.1728, 0.6509, 0.1763, 0.1497, 0.7614, 0.3081, 0.9861, 0.4548, 0.1893]), 'objectness_scores': tensor([0.2556, 0.2061, 0.4172, 0.2011, 0.2008, 0.2191, 0.5728, 0.3237, 0.2670]), 'labels': tensor([ 3,  7, 11, 11,  7,  7,  7,  7,  7], dtype=torch.int32)}\n",
      "151657\n",
      "{'image_id': 151820, 'boxes': tensor([[286, 229, 332, 242],\n",
      "        [162, 232, 389, 365],\n",
      "        [331, 221, 347, 252],\n",
      "        [348, 237, 364, 272],\n",
      "        [406, 182, 423, 210],\n",
      "        [332, 221, 347, 251],\n",
      "        [356, 264, 380, 281],\n",
      "        [299, 245, 328, 254],\n",
      "        [244, 235, 262, 252],\n",
      "        [201, 262, 219, 273],\n",
      "        [188, 235, 243, 250],\n",
      "        [228, 242, 244, 274],\n",
      "        [212, 227, 229, 261],\n",
      "        [303, 234, 321, 250],\n",
      "        [132, 170, 152, 179]], dtype=torch.int32), 'scores': tensor([0.2711, 0.3740, 0.2110, 0.1676, 0.4016, 0.5710, 0.4760, 0.2182, 0.9431,\n",
      "        0.3488, 0.2484, 0.2130, 0.2295, 0.1833, 0.3409]), 'objectness_scores': tensor([0.2628, 0.2811, 0.2880, 0.2904, 0.2615, 0.2185, 0.2376, 0.2285, 0.3057,\n",
      "        0.2207, 0.2441, 0.2849, 0.3442, 0.2782, 0.2024]), 'labels': tensor([11, 12, 10, 10,  7, 10,  7, 11, 10, 11, 11,  2, 14, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "151820\n",
      "{'image_id': 151938, 'boxes': tensor([[236,  96, 382, 165],\n",
      "        [250, 211, 263, 227],\n",
      "        [220, 438, 269, 525],\n",
      "        [168, 223, 341, 446]], dtype=torch.int32), 'scores': tensor([0.9995, 0.1892, 0.5863, 0.8466]), 'objectness_scores': tensor([0.4587, 0.2286, 0.3827, 0.2719]), 'labels': tensor([ 6, 11, 10,  9], dtype=torch.int32)}\n",
      "151938\n",
      "{'image_id': 151962, 'boxes': tensor([[344, 240, 450, 359]], dtype=torch.int32), 'scores': tensor([0.9727]), 'objectness_scores': tensor([0.5501]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "151962\n",
      "{'image_id': 152214, 'boxes': tensor([[190, 362, 287, 635],\n",
      "        [333, 185, 339, 195],\n",
      "        [144, 106, 322, 160],\n",
      "        [ 72, 277, 477, 636]], dtype=torch.int32), 'scores': tensor([0.7446, 0.2145, 0.2298, 0.9996]), 'objectness_scores': tensor([0.6895, 0.3923, 0.4203, 0.2728]), 'labels': tensor([ 7, 11,  7,  7], dtype=torch.int32)}\n",
      "152214\n",
      "{'image_id': 153011, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "153011\n",
      "{'image_id': 153217, 'boxes': tensor([[221, 107, 253, 141],\n",
      "        [ 23, 282, 158, 493],\n",
      "        [141,  75, 202, 139],\n",
      "        [262, 349, 294, 405],\n",
      "        [ 92,  80, 122, 111]], dtype=torch.int32), 'scores': tensor([0.3231, 0.9615, 0.3176, 0.2808, 0.2520]), 'objectness_scores': tensor([0.3101, 0.5645, 0.2646, 0.2494, 0.2789]), 'labels': tensor([ 6,  2, 10, 11, 11], dtype=torch.int32)}\n",
      "153217\n",
      "{'image_id': 153527, 'boxes': tensor([[ 99, 176, 141, 183],\n",
      "        [211, 190, 259, 197],\n",
      "        [328, 240, 387, 256],\n",
      "        [ 47, 227,  79, 238],\n",
      "        [139, 215, 186, 222],\n",
      "        [141, 219, 193, 229],\n",
      "        [130, 272, 153, 319],\n",
      "        [ 41,   0,  88,  36],\n",
      "        [191, 243, 224, 251],\n",
      "        [414, 160, 498, 177],\n",
      "        [236, 105, 260, 128],\n",
      "        [246, 227, 293, 239],\n",
      "        [391, 152, 499, 179],\n",
      "        [199, 185, 258, 197],\n",
      "        [136, 140, 182, 169],\n",
      "        [115, 207, 174, 216],\n",
      "        [172, 246, 219, 272],\n",
      "        [143, 218, 191, 228],\n",
      "        [115, 187, 151, 199]], dtype=torch.int32), 'scores': tensor([0.9996, 0.3162, 0.2704, 0.6464, 0.6801, 0.4582, 0.4717, 0.2201, 0.4283,\n",
      "        0.7907, 0.2626, 0.4240, 0.3242, 0.3732, 0.2136, 0.5064, 0.7540, 0.3715,\n",
      "        0.5410]), 'objectness_scores': tensor([0.2412, 0.2496, 0.2300, 0.2226, 0.2250, 0.2306, 0.2439, 0.3917, 0.2016,\n",
      "        0.2346, 0.2598, 0.2489, 0.2233, 0.2229, 0.2600, 0.2830, 0.3184, 0.2012,\n",
      "        0.2628]), 'labels': tensor([12, 11, 11, 11, 11, 11, 11,  6, 11, 11, 10, 11, 11, 11, 10, 11, 11, 11,\n",
      "        11], dtype=torch.int32)}\n",
      "153527\n",
      "{'image_id': 153632, 'boxes': tensor([[326, 132, 414, 189],\n",
      "        [348, 202, 414, 273],\n",
      "        [168,   2, 187,  17],\n",
      "        [124,  51, 546, 455],\n",
      "        [ 14,   3, 327, 185],\n",
      "        [127,   2, 146,  21],\n",
      "        [110,  14, 135,  32],\n",
      "        [ 95,   2, 112,  24],\n",
      "        [399, 167, 483, 233],\n",
      "        [ 80,   0, 196,  32],\n",
      "        [264, 245, 337, 364],\n",
      "        [  4,   3, 638, 473],\n",
      "        [ 80,   1,  98,  21],\n",
      "        [206, 105, 482, 369],\n",
      "        [352, 269, 422, 365],\n",
      "        [108,   0, 130,  15],\n",
      "        [134,  18, 158,  32],\n",
      "        [153,   5, 175,  26]], dtype=torch.int32), 'scores': tensor([0.4162, 0.2818, 0.3379, 0.5368, 0.8234, 0.3644, 0.3298, 0.3434, 0.3515,\n",
      "        0.3109, 0.9991, 0.5821, 0.2453, 0.2922, 0.2052, 0.1677, 0.2845, 0.2724]), 'objectness_scores': tensor([0.2079, 0.2251, 0.2103, 0.2248, 0.5170, 0.2241, 0.2519, 0.2307, 0.2156,\n",
      "        0.2116, 0.2418, 0.3368, 0.2287, 0.2488, 0.2033, 0.2011, 0.2459, 0.2500]), 'labels': tensor([12,  4, 11,  4, 11, 11, 11, 11, 11, 14,  1,  4, 11, 11,  4, 11, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "153632\n",
      "{'image_id': 154705, 'boxes': tensor([[ 40, 249, 181, 309],\n",
      "        [257, 273, 631, 457],\n",
      "        [  6, 276, 247, 463],\n",
      "        [277, 369, 318, 437],\n",
      "        [538,  79, 613, 198],\n",
      "        [428, 244, 449, 292],\n",
      "        [  0, 370,  24, 408],\n",
      "        [454, 338, 473, 365],\n",
      "        [ 55, 242,  80, 257],\n",
      "        [493, 276, 588, 307],\n",
      "        [322, 237, 339, 280],\n",
      "        [202, 274, 302, 291],\n",
      "        [322, 280, 439, 306],\n",
      "        [  3, 270, 620, 460]], dtype=torch.int32), 'scores': tensor([0.4008, 0.9523, 0.4320, 0.7836, 0.1314, 0.4681, 0.2701, 0.4444, 0.2552,\n",
      "        0.3723, 0.4236, 0.9501, 0.9091, 0.9931]), 'objectness_scores': tensor([0.5582, 0.2296, 0.2392, 0.2087, 0.2280, 0.4620, 0.3317, 0.2332, 0.2179,\n",
      "        0.2299, 0.3896, 0.3683, 0.2544, 0.2420]), 'labels': tensor([14, 14,  2,  7, 12,  8,  9, 11, 14, 11,  8, 14, 14, 14],\n",
      "       dtype=torch.int32)}\n",
      "154705\n",
      "{'image_id': 155145, 'boxes': tensor([[330, 175, 343, 183],\n",
      "        [118, 219, 136, 226]], dtype=torch.int32), 'scores': tensor([0.3042, 0.3353]), 'objectness_scores': tensor([0.3002, 0.2838]), 'labels': tensor([11, 11], dtype=torch.int32)}\n",
      "155145\n",
      "{'image_id': 156076, 'boxes': tensor([[403, 138, 430, 185],\n",
      "        [258, 179, 292, 245],\n",
      "        [472, 158, 503, 205],\n",
      "        [452, 125, 489, 160],\n",
      "        [164,  82, 263, 211]], dtype=torch.int32), 'scores': tensor([0.2883, 0.3795, 0.3176, 0.2148, 0.1307]), 'objectness_scores': tensor([0.3716, 0.3925, 0.2595, 0.2038, 0.3624]), 'labels': tensor([ 8,  8,  7, 12,  9], dtype=torch.int32)}\n",
      "156076\n",
      "{'image_id': 156278, 'boxes': tensor([[538, 183, 571, 189],\n",
      "        [330, 161, 385, 167],\n",
      "        [552, 131, 572, 160],\n",
      "        [527, 131, 548, 160],\n",
      "        [527,  90, 536, 129],\n",
      "        [341, 172, 383, 177],\n",
      "        [302, 215, 327, 264],\n",
      "        [109,  93, 147, 127],\n",
      "        [121, 228, 154, 258],\n",
      "        [388, 262, 468, 276],\n",
      "        [375, 381, 634, 425],\n",
      "        [451, 216, 464, 258],\n",
      "        [568, 228, 625, 258],\n",
      "        [463, 263, 547, 276],\n",
      "        [535, 170, 572, 177],\n",
      "        [536, 184, 571, 190],\n",
      "        [537,  77, 565, 127],\n",
      "        [332, 164, 385, 169],\n",
      "        [347, 186, 384, 193],\n",
      "        [520, 208, 524, 242],\n",
      "        [ 98, 178, 118, 221],\n",
      "        [187, 338, 236, 369],\n",
      "        [335, 159, 385, 164],\n",
      "        [341, 172, 383, 177],\n",
      "        [539, 182, 573, 188],\n",
      "        [347,  71, 375, 124],\n",
      "        [339, 240, 407, 272],\n",
      "        [534, 160, 576, 167]], dtype=torch.int32), 'scores': tensor([0.3014, 0.2267, 0.2396, 0.2927, 0.1848, 0.4933, 0.4580, 0.2869, 0.3646,\n",
      "        0.2957, 0.4625, 0.3156, 0.3917, 0.1931, 0.2101, 0.2582, 0.2274, 0.4192,\n",
      "        0.1764, 0.1761, 0.9153, 0.7905, 0.2033, 0.3578, 0.2234, 0.2224, 0.2613,\n",
      "        0.2948]), 'objectness_scores': tensor([0.2290, 0.2288, 0.2240, 0.2068, 0.2598, 0.2530, 0.5260, 0.2041, 0.2215,\n",
      "        0.3758, 0.2689, 0.4001, 0.2686, 0.3935, 0.2861, 0.2436, 0.2957, 0.3333,\n",
      "        0.2708, 0.2389, 0.2368, 0.3784, 0.2191, 0.3142, 0.2222, 0.3635, 0.2933,\n",
      "        0.3062]), 'labels': tensor([11,  0, 11, 11, 11, 11, 11, 14, 13, 11,  7, 11,  9, 11, 14, 11,  6, 11,\n",
      "        11, 11, 10, 10, 11, 11, 14,  7,  9, 14], dtype=torch.int32)}\n",
      "156278\n",
      "{'image_id': 156643, 'boxes': tensor([[333, 372, 348, 384],\n",
      "        [451, 253, 530, 318],\n",
      "        [233, 327, 403, 434],\n",
      "        [247, 114, 263, 173],\n",
      "        [487, 312, 560, 421],\n",
      "        [338, 241, 365, 293],\n",
      "        [318, 361, 327, 372],\n",
      "        [307, 359, 319, 370],\n",
      "        [249, 219, 275, 247],\n",
      "        [340, 131, 408, 171],\n",
      "        [414, 429, 525, 478],\n",
      "        [321, 314, 329, 322],\n",
      "        [  5, 327, 641, 481],\n",
      "        [279, 347, 291, 358],\n",
      "        [ 34,   8, 174, 263],\n",
      "        [368, 354, 379, 366],\n",
      "        [354, 350, 367, 363],\n",
      "        [269, 245, 278, 254],\n",
      "        [380, 356, 402, 374],\n",
      "        [345, 371, 363, 389],\n",
      "        [256, 104, 285, 185],\n",
      "        [236, 136, 247, 166],\n",
      "        [175, 272, 187, 334],\n",
      "        [290, 351, 303, 364],\n",
      "        [296, 354, 309, 365]], dtype=torch.int32), 'scores': tensor([0.2849, 0.1958, 0.9860, 0.4476, 0.9187, 0.3091, 0.1626, 0.2206, 0.1528,\n",
      "        0.1762, 0.2918, 0.2758, 0.9944, 0.1929, 0.3102, 0.5128, 0.2001, 0.2518,\n",
      "        0.2342, 0.1787, 0.9250, 0.2688, 0.2482, 0.2467, 0.2044]), 'objectness_scores': tensor([0.2561, 0.2112, 0.5311, 0.4356, 0.3889, 0.4258, 0.2075, 0.2771, 0.2464,\n",
      "        0.3766, 0.2341, 0.4036, 0.3417, 0.2514, 0.2246, 0.2396, 0.2944, 0.2973,\n",
      "        0.3418, 0.3627, 0.3627, 0.5029, 0.2171, 0.2250, 0.2693]), 'labels': tensor([11,  7, 12, 11, 10,  7,  4, 11,  7,  7,  3, 15, 12, 11,  8, 14,  4,  5,\n",
      "        11, 12,  7,  7, 11, 11, 11], dtype=torch.int32)}\n",
      "156643\n",
      "{'image_id': 157138, 'boxes': tensor([[  0,  22, 414, 314],\n",
      "        [145,  34, 261, 123],\n",
      "        [141,  31, 267, 186],\n",
      "        [ 78,  31, 268, 236],\n",
      "        [  1,   0, 497, 354]], dtype=torch.int32), 'scores': tensor([0.9989, 0.9782, 0.9965, 0.9995, 0.9977]), 'objectness_scores': tensor([0.4543, 0.2184, 0.5435, 0.3325, 0.2736]), 'labels': tensor([12, 12, 12, 12, 12], dtype=torch.int32)}\n",
      "157138\n",
      "{'image_id': 157365, 'boxes': tensor([[259, 181, 273, 200],\n",
      "        [142, 466, 207, 494],\n",
      "        [111, 297, 128, 307]], dtype=torch.int32), 'scores': tensor([0.1669, 0.6374, 0.4602]), 'objectness_scores': tensor([0.2369, 0.4025, 0.5278]), 'labels': tensor([11,  1, 11], dtype=torch.int32)}\n",
      "157365\n",
      "{'image_id': 157418, 'boxes': tensor([[  2, 258, 479, 638],\n",
      "        [154, 179, 212, 269],\n",
      "        [196, 253, 451, 317],\n",
      "        [  0, 306, 221, 523],\n",
      "        [360, 380, 458, 614],\n",
      "        [ 71,  26, 118,  69]], dtype=torch.int32), 'scores': tensor([0.6113, 0.7375, 0.2572, 0.7986, 0.2028, 0.4738]), 'objectness_scores': tensor([0.2383, 0.3440, 0.3079, 0.2867, 0.3757, 0.3885]), 'labels': tensor([11, 10, 11, 12,  7,  7], dtype=torch.int32)}\n",
      "157418\n",
      "{'image_id': 157601, 'boxes': tensor([[196, 266, 607, 607],\n",
      "        [194, 300, 400, 589],\n",
      "        [  7, 172,  54, 262],\n",
      "        [375, 266, 612, 610],\n",
      "        [ 12, 114,  53, 150]], dtype=torch.int32), 'scores': tensor([0.9953, 0.3005, 0.3895, 0.2787, 0.1596]), 'objectness_scores': tensor([0.2269, 0.5030, 0.4051, 0.4712, 0.2080]), 'labels': tensor([10, 10, 11,  7, 11], dtype=torch.int32)}\n",
      "157601\n",
      "{'image_id': 157767, 'boxes': tensor([[337, 287, 420, 313],\n",
      "        [407, 283, 501, 308],\n",
      "        [324, 277, 533, 425],\n",
      "        [342, 267, 396, 282],\n",
      "        [427, 271, 486, 282],\n",
      "        [462, 279, 500, 291],\n",
      "        [330, 281, 354, 289],\n",
      "        [394, 257, 414, 271],\n",
      "        [280, 226, 295, 253],\n",
      "        [338, 271, 352, 286]], dtype=torch.int32), 'scores': tensor([0.6162, 0.3434, 0.7362, 0.3089, 0.4271, 0.1991, 0.2556, 0.2750, 0.2248,\n",
      "        0.2501]), 'objectness_scores': tensor([0.2646, 0.2615, 0.2951, 0.2598, 0.2490, 0.2558, 0.2237, 0.3722, 0.2287,\n",
      "        0.3122]), 'labels': tensor([12, 11, 10, 14, 11, 11, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "157767\n",
      "{'image_id': 157807, 'boxes': tensor([[ 98, 156, 477, 374],\n",
      "        [195,  20, 228,  67],\n",
      "        [358, 225, 482, 408],\n",
      "        [543,  97, 640, 218],\n",
      "        [470, 369, 497, 427]], dtype=torch.int32), 'scores': tensor([0.9904, 0.2577, 0.9259, 0.5035, 0.2463]), 'objectness_scores': tensor([0.4963, 0.2080, 0.2237, 0.5193, 0.3390]), 'labels': tensor([ 2, 11,  2, 15, 11], dtype=torch.int32)}\n",
      "157807\n",
      "{'image_id': 158744, 'boxes': tensor([[376, 116, 383, 126],\n",
      "        [518, 106, 531, 125],\n",
      "        [494, 163, 532, 223]], dtype=torch.int32), 'scores': tensor([0.2614, 0.2122, 0.5369]), 'objectness_scores': tensor([0.3308, 0.2268, 0.2080]), 'labels': tensor([11,  8, 11], dtype=torch.int32)}\n",
      "158744\n",
      "{'image_id': 158945, 'boxes': tensor([[129, 180, 412, 586]], dtype=torch.int32), 'scores': tensor([0.9993]), 'objectness_scores': tensor([0.7579]), 'labels': tensor([5], dtype=torch.int32)}\n",
      "158945\n",
      "{'image_id': 158956, 'boxes': tensor([[306, 146, 489, 426],\n",
      "        [133, 337, 305, 424],\n",
      "        [322, 158, 363, 219],\n",
      "        [124, 330, 322, 361]], dtype=torch.int32), 'scores': tensor([0.6069, 0.6839, 0.8032, 0.2767]), 'objectness_scores': tensor([0.4323, 0.2508, 0.5946, 0.2046]), 'labels': tensor([ 7, 12,  7,  9], dtype=torch.int32)}\n",
      "158956\n",
      "{'image_id': 159458, 'boxes': tensor([[518, 292, 525, 315],\n",
      "        [265, 174, 345, 234],\n",
      "        [192, 176, 272, 236],\n",
      "        [284, 200, 349, 240],\n",
      "        [138, 159, 372, 250],\n",
      "        [250,   0, 339,  14],\n",
      "        [217, 217, 311, 252],\n",
      "        [215, 193, 285, 239]], dtype=torch.int32), 'scores': tensor([0.2429, 0.2067, 0.2419, 0.3095, 0.8964, 0.3001, 0.9397, 0.6726]), 'objectness_scores': tensor([0.2821, 0.3505, 0.3557, 0.3687, 0.5263, 0.2934, 0.5219, 0.4230]), 'labels': tensor([11, 12, 12,  7,  3, 11,  3,  3], dtype=torch.int32)}\n",
      "159458\n",
      "{'image_id': 160012, 'boxes': tensor([[316,  72, 332, 116],\n",
      "        [  2, 178, 636, 460],\n",
      "        [261, 205, 324, 238],\n",
      "        [357, 223, 427, 249],\n",
      "        [375, 326, 471, 378],\n",
      "        [108, 245, 621, 459],\n",
      "        [511, 163, 542, 180],\n",
      "        [534, 192, 581, 210],\n",
      "        [223, 309, 317, 361],\n",
      "        [182, 224, 252, 257],\n",
      "        [434, 158, 470, 182],\n",
      "        [441, 244, 512, 276],\n",
      "        [471, 299, 548, 337],\n",
      "        [430, 180, 477, 195],\n",
      "        [153, 237, 185, 257],\n",
      "        [349, 276, 437, 320],\n",
      "        [541, 179, 591, 196],\n",
      "        [264, 239, 331, 274],\n",
      "        [488, 193, 541, 208],\n",
      "        [ -2, 414, 250, 460]], dtype=torch.int32), 'scores': tensor([0.2917, 0.2459, 0.4366, 0.2912, 0.1809, 0.2349, 0.2895, 0.2564, 0.2899,\n",
      "        0.2500, 0.7124, 0.2036, 0.3371, 0.2211, 0.3178, 0.3124, 0.4752, 0.2181,\n",
      "        0.2438, 0.2670]), 'objectness_scores': tensor([0.5123, 0.3336, 0.5331, 0.4921, 0.5167, 0.3130, 0.2463, 0.3239, 0.5483,\n",
      "        0.5474, 0.4206, 0.4808, 0.4690, 0.2039, 0.2130, 0.5103, 0.3024, 0.5608,\n",
      "        0.2526, 0.2125]), 'labels': tensor([ 7, 12, 12,  7, 12, 11, 11,  7, 11,  8, 13,  7, 11, 14, 11, 11,  7, 10,\n",
      "         7, 11], dtype=torch.int32)}\n",
      "160012\n",
      "{'image_id': 160556, 'boxes': tensor([[ 11,  55,  94, 127],\n",
      "        [349, 279, 462, 326],\n",
      "        [  3, 276, 523, 428]], dtype=torch.int32), 'scores': tensor([0.1638, 0.9966, 0.2659]), 'objectness_scores': tensor([0.5357, 0.2465, 0.2504]), 'labels': tensor([ 3, 14,  7], dtype=torch.int32)}\n",
      "160556\n",
      "{'image_id': 161032, 'boxes': tensor([[453, 367, 486, 400],\n",
      "        [395, 365, 431, 396],\n",
      "        [330, 146, 478, 215]], dtype=torch.int32), 'scores': tensor([0.1598, 0.6183, 0.9495]), 'objectness_scores': tensor([0.3738, 0.3636, 0.4254]), 'labels': tensor([7, 7, 6], dtype=torch.int32)}\n",
      "161032\n",
      "{'image_id': 161128, 'boxes': tensor([[108, 151, 249, 289],\n",
      "        [360, 397, 365, 409],\n",
      "        [285, 297, 332, 404],\n",
      "        [152,   1, 202, 496]], dtype=torch.int32), 'scores': tensor([0.3747, 0.2779, 0.3435, 0.2267]), 'objectness_scores': tensor([0.4830, 0.2936, 0.2244, 0.2035]), 'labels': tensor([ 9, 11,  0, 11], dtype=torch.int32)}\n",
      "161128\n",
      "{'image_id': 161609, 'boxes': tensor([[163, 164, 232, 192],\n",
      "        [245, 263, 377, 347],\n",
      "        [444,  63, 584, 141],\n",
      "        [125,  53, 430, 159]], dtype=torch.int32), 'scores': tensor([0.1619, 0.1717, 0.4404, 0.2437]), 'objectness_scores': tensor([0.2143, 0.5185, 0.3470, 0.2462]), 'labels': tensor([14, 11,  7,  8], dtype=torch.int32)}\n",
      "161609\n",
      "{'image_id': 161799, 'boxes': tensor([[273, 227, 291, 241],\n",
      "        [589, 281, 597, 287],\n",
      "        [589, 283, 604, 290],\n",
      "        [327, 272, 336, 280],\n",
      "        [224, 186, 244, 204],\n",
      "        [218, 200, 292, 243],\n",
      "        [590, 280, 605, 287],\n",
      "        [592, 219, 601, 225]], dtype=torch.int32), 'scores': tensor([0.3153, 0.3134, 0.2498, 0.9996, 0.2019, 0.5353, 0.2611, 0.3544]), 'objectness_scores': tensor([0.3084, 0.2393, 0.4579, 0.2174, 0.3079, 0.4854, 0.2943, 0.2551]), 'labels': tensor([11, 11, 14,  5,  8,  9, 11,  8], dtype=torch.int32)}\n",
      "161799\n",
      "{'image_id': 161875, 'boxes': tensor([[182, 251, 252, 280],\n",
      "        [223, 125, 241, 170],\n",
      "        [170, 117, 277, 267],\n",
      "        [201, 366, 251, 387],\n",
      "        [194, 360, 226, 381],\n",
      "        [265, 243, 275, 249]], dtype=torch.int32), 'scores': tensor([0.9962, 0.3931, 0.3656, 0.4140, 0.1939, 0.1596]), 'objectness_scores': tensor([0.3639, 0.3331, 0.2730, 0.3291, 0.2758, 0.4045]), 'labels': tensor([ 1, 11,  7, 11, 11, 11], dtype=torch.int32)}\n",
      "161875\n",
      "{'image_id': 161879, 'boxes': tensor([[ 55, 300,  95, 329],\n",
      "        [ 12, 301, 173, 347],\n",
      "        [151, 319, 185, 344]], dtype=torch.int32), 'scores': tensor([0.4271, 0.6013, 0.3310]), 'objectness_scores': tensor([0.4566, 0.6250, 0.4077]), 'labels': tensor([ 2,  9, 11], dtype=torch.int32)}\n",
      "161879\n",
      "{'image_id': 161978, 'boxes': tensor([[196,  72, 220,  87],\n",
      "        [256, 248, 308, 262],\n",
      "        [434, 326, 582, 373],\n",
      "        [ 53, 245, 112, 269],\n",
      "        [ 15, 344,  87, 363],\n",
      "        [510, 255, 537, 267],\n",
      "        [199,  59, 215,  76],\n",
      "        [274, 372, 411, 408],\n",
      "        [538, 104, 626, 147],\n",
      "        [379, 257, 485, 280],\n",
      "        [237,  78, 323, 102],\n",
      "        [160, 362, 241, 384]], dtype=torch.int32), 'scores': tensor([0.1906, 0.2518, 0.9511, 0.2056, 0.3750, 0.2471, 0.2522, 0.7530, 0.8172,\n",
      "        0.3183, 0.5256, 0.5216]), 'objectness_scores': tensor([0.3485, 0.3958, 0.3380, 0.3995, 0.4177, 0.2221, 0.2020, 0.4120, 0.3621,\n",
      "        0.3822, 0.4473, 0.4094]), 'labels': tensor([11,  5,  9, 11,  9,  9,  8,  9,  9, 10, 14,  9], dtype=torch.int32)}\n",
      "161978\n",
      "{'image_id': 162092, 'boxes': tensor([[153, 478, 195, 503],\n",
      "        [125, 492, 181, 557],\n",
      "        [177, 487, 222, 536],\n",
      "        [201, 471, 245, 525],\n",
      "        [232, 494, 320, 550],\n",
      "        [362, 258, 605, 641],\n",
      "        [ 98, 549, 112, 563],\n",
      "        [ 89, 491, 184, 561],\n",
      "        [155, 471, 245, 535],\n",
      "        [ 88, 506, 129, 561],\n",
      "        [ 91, 529, 196, 573],\n",
      "        [113, 548, 127, 563],\n",
      "        [428, 506, 458, 556],\n",
      "        [588, 131, 639, 192],\n",
      "        [156, 478, 201, 530],\n",
      "        [212, 553, 366, 617]], dtype=torch.int32), 'scores': tensor([0.2885, 0.5459, 0.9847, 0.4179, 0.3445, 0.5251, 0.7160, 0.9919, 0.6731,\n",
      "        0.2588, 0.4338, 0.5142, 0.2780, 0.3003, 0.4949, 0.1817]), 'objectness_scores': tensor([0.2548, 0.2376, 0.3521, 0.3075, 0.2519, 0.2356, 0.2073, 0.3708, 0.2057,\n",
      "        0.2942, 0.2388, 0.2046, 0.3802, 0.2715, 0.2169, 0.3053]), 'labels': tensor([12, 12, 15, 12,  7,  7, 11, 12, 10,  7,  2, 11,  7,  7, 12,  5],\n",
      "       dtype=torch.int32)}\n",
      "162092\n",
      "{'image_id': 163257, 'boxes': tensor([[ 58,  77, 352, 312],\n",
      "        [386, 120, 424, 209],\n",
      "        [162, 293, 298, 620],\n",
      "        [316, 162, 426, 328]], dtype=torch.int32), 'scores': tensor([0.8331, 0.2552, 0.9005, 0.4170]), 'objectness_scores': tensor([0.3004, 0.2276, 0.2156, 0.5833]), 'labels': tensor([9, 7, 7, 6], dtype=torch.int32)}\n",
      "163257\n",
      "{'image_id': 163258, 'boxes': tensor([[583, 199, 619, 229],\n",
      "        [444,   2, 518, 404],\n",
      "        [ 41, 139, 129, 246],\n",
      "        [546, 218, 640, 282],\n",
      "        [609, 221, 635, 229],\n",
      "        [200,   4, 560, 479]], dtype=torch.int32), 'scores': tensor([0.2243, 0.4393, 0.2059, 0.8683, 0.2584, 0.1438]), 'objectness_scores': tensor([0.6381, 0.2539, 0.2695, 0.6320, 0.4388, 0.2872]), 'labels': tensor([11, 14,  8, 15, 11, 11], dtype=torch.int32)}\n",
      "163258\n",
      "{'image_id': 163611, 'boxes': tensor([[167,   0, 277, 130],\n",
      "        [  1,   3, 191, 133],\n",
      "        [548,  73, 639, 103]], dtype=torch.int32), 'scores': tensor([0.3830, 0.4664, 0.6251]), 'objectness_scores': tensor([0.2898, 0.2257, 0.2348]), 'labels': tensor([13, 11, 11], dtype=torch.int32)}\n",
      "163611\n",
      "{'image_id': 163682, 'boxes': tensor([[ 48, 234, 364, 520],\n",
      "        [189, 279, 251, 486],\n",
      "        [  6, 369, 426, 641],\n",
      "        [299, 431, 322, 463],\n",
      "        [274, 500, 288, 509]], dtype=torch.int32), 'scores': tensor([0.9783, 0.9997, 0.9295, 0.2487, 0.2437]), 'objectness_scores': tensor([0.2825, 0.3785, 0.2082, 0.2170, 0.3711]), 'labels': tensor([ 7,  7,  7, 11, 11], dtype=torch.int32)}\n",
      "163682\n",
      "{'image_id': 163746, 'boxes': tensor([[ 56, 249, 109, 312],\n",
      "        [347, 289, 363, 295],\n",
      "        [400, 304, 432, 320],\n",
      "        [489, 199, 514, 245],\n",
      "        [518,   0, 575,  61],\n",
      "        [165, 198, 188, 244],\n",
      "        [348, 266, 364, 278],\n",
      "        [  6, 265,  23, 278],\n",
      "        [463, 198, 570, 319],\n",
      "        [387, 250, 441, 311],\n",
      "        [345, 262, 365, 294],\n",
      "        [  3, 286,  22, 294],\n",
      "        [  4, 263,  24, 293],\n",
      "        [134, 199, 243, 318]], dtype=torch.int32), 'scores': tensor([0.2341, 0.1724, 0.5684, 0.7967, 0.8828, 0.7947, 0.2288, 0.1464, 0.2402,\n",
      "        0.2686, 0.1554, 0.1788, 0.1812, 0.4594]), 'objectness_scores': tensor([0.2865, 0.2741, 0.2571, 0.2060, 0.5428, 0.2201, 0.2311, 0.2403, 0.2656,\n",
      "        0.2756, 0.2398, 0.3158, 0.2642, 0.2606]), 'labels': tensor([ 9, 10, 11,  7,  0,  7, 11, 11,  7,  9,  9, 14,  7,  7],\n",
      "       dtype=torch.int32)}\n",
      "163746\n",
      "{'image_id': 164602, 'boxes': tensor([[432, 234, 463, 272],\n",
      "        [ 55, 143, 333, 475],\n",
      "        [306, 284, 484, 480],\n",
      "        [  7,  11,  52,  55],\n",
      "        [  4,   3, 634, 476],\n",
      "        [391, 116, 461, 160],\n",
      "        [253, 309, 552, 441],\n",
      "        [434, 235, 461, 271],\n",
      "        [  0, 301, 560, 461],\n",
      "        [336, 236, 377, 267]], dtype=torch.int32), 'scores': tensor([0.7778, 0.3424, 0.3953, 0.2557, 0.2364, 0.2406, 0.7507, 0.6827, 0.4414,\n",
      "        0.1384]), 'objectness_scores': tensor([0.4363, 0.2118, 0.2813, 0.2773, 0.2291, 0.4228, 0.4590, 0.2049, 0.2111,\n",
      "        0.2233]), 'labels': tensor([ 7,  5, 15,  7, 15, 15,  7,  7,  7,  7], dtype=torch.int32)}\n",
      "164602\n",
      "{'image_id': 165039, 'boxes': tensor([[579, 112, 619, 168],\n",
      "        [438,  98, 449, 120],\n",
      "        [349,  11, 375,  84],\n",
      "        [400,  98, 413, 130],\n",
      "        [481,  91, 515, 127],\n",
      "        [538,   0, 578,  46],\n",
      "        [544,  75, 582, 125],\n",
      "        [  8, 144,  16, 167],\n",
      "        [444, 120, 453, 130],\n",
      "        [188, 139, 244, 243],\n",
      "        [400, 100, 411, 131],\n",
      "        [255, 128, 322, 229]], dtype=torch.int32), 'scores': tensor([0.2988, 0.3158, 0.3015, 0.2332, 0.3940, 0.6320, 0.2069, 0.3803, 0.2157,\n",
      "        0.2806, 0.1716, 0.4360]), 'objectness_scores': tensor([0.2574, 0.4766, 0.5180, 0.4533, 0.3962, 0.5091, 0.3659, 0.4451, 0.2138,\n",
      "        0.2553, 0.3026, 0.2701]), 'labels': tensor([14, 11,  9, 11,  9,  8, 14, 14, 11,  1,  7, 11], dtype=torch.int32)}\n",
      "165039\n",
      "{'image_id': 166287, 'boxes': tensor([[221, 193, 361, 310],\n",
      "        [152, 222, 262, 310]], dtype=torch.int32), 'scores': tensor([0.9990, 0.2879]), 'objectness_scores': tensor([0.6289, 0.6559]), 'labels': tensor([4, 0], dtype=torch.int32)}\n",
      "166287\n",
      "{'image_id': 166426, 'boxes': tensor([[248,  52, 446, 122],\n",
      "        [186, 415, 248, 440],\n",
      "        [163, 409, 353, 527],\n",
      "        [128, 131, 473, 302],\n",
      "        [162, 437, 204, 470],\n",
      "        [250, 415, 301, 450],\n",
      "        [202,  64, 239, 134],\n",
      "        [500, 350, 542, 545],\n",
      "        [  5, 337, 583, 626],\n",
      "        [316, 165, 404, 277],\n",
      "        [ 95, 321, 495, 608],\n",
      "        [266,  43, 432, 107],\n",
      "        [167, 414, 295, 473],\n",
      "        [  0,  47, 585, 627],\n",
      "        [194, 429, 282, 474],\n",
      "        [176, 466, 235, 504],\n",
      "        [221, 473, 350, 527]], dtype=torch.int32), 'scores': tensor([0.4093, 0.3367, 0.3319, 0.8090, 0.8912, 0.1820, 0.6280, 0.7995, 0.4258,\n",
      "        0.9821, 0.5041, 0.3799, 0.5352, 0.3481, 0.3083, 0.1687, 0.1802]), 'objectness_scores': tensor([0.2501, 0.2847, 0.2615, 0.2005, 0.2600, 0.2601, 0.3057, 0.4680, 0.2830,\n",
      "        0.3209, 0.2633, 0.2036, 0.2523, 0.2357, 0.2080, 0.2679, 0.3010]), 'labels': tensor([10, 11, 12, 10, 12, 14, 10, 11, 11, 10, 11, 11, 11, 11, 11, 11, 12],\n",
      "       dtype=torch.int32)}\n",
      "166426\n",
      "{'image_id': 166478, 'boxes': tensor([[591, 121, 641, 187],\n",
      "        [  1, 170, 634, 425],\n",
      "        [167, 138, 200, 183]], dtype=torch.int32), 'scores': tensor([0.3835, 0.8264, 0.2783]), 'objectness_scores': tensor([0.2363, 0.4785, 0.2201]), 'labels': tensor([10, 13, 11], dtype=torch.int32)}\n",
      "166478\n",
      "{'image_id': 166521, 'boxes': tensor([[416, 253, 443, 271],\n",
      "        [  2,  56, 162, 420],\n",
      "        [152, 285, 212, 346]], dtype=torch.int32), 'scores': tensor([0.1584, 0.2603, 0.8981]), 'objectness_scores': tensor([0.2067, 0.3075, 0.2169]), 'labels': tensor([11, 13, 10], dtype=torch.int32)}\n",
      "166521\n",
      "{'image_id': 166664, 'boxes': tensor([[ 98, 226, 138, 251],\n",
      "        [ 41, 248,  94, 305],\n",
      "        [381,  50, 557, 291]], dtype=torch.int32), 'scores': tensor([0.8486, 0.2894, 0.9993]), 'objectness_scores': tensor([0.2213, 0.2785, 0.7420]), 'labels': tensor([11,  9,  5], dtype=torch.int32)}\n",
      "166664\n",
      "{'image_id': 166768, 'boxes': tensor([[ 77, 195, 424, 636],\n",
      "        [ 17, 314,  85, 369],\n",
      "        [312, 228, 418, 626],\n",
      "        [  5, 249,  11, 262],\n",
      "        [275,  69, 418, 105]], dtype=torch.int32), 'scores': tensor([0.9571, 0.3751, 0.4691, 0.8633, 0.4048]), 'objectness_scores': tensor([0.2080, 0.3716, 0.4347, 0.2536, 0.2044]), 'labels': tensor([ 7,  7,  7, 13, 14], dtype=torch.int32)}\n",
      "166768\n",
      "{'image_id': 166918, 'boxes': tensor([[410, 240, 450, 267],\n",
      "        [149, 277, 184, 302],\n",
      "        [247, 242, 284, 286],\n",
      "        [ -1, 332, 466, 641],\n",
      "        [376, 544, 432, 639],\n",
      "        [ 72, 445, 174, 613],\n",
      "        [128, 471, 161, 487],\n",
      "        [252, 272, 266, 293],\n",
      "        [309, 349, 323, 390],\n",
      "        [ 52, 404,  80, 476],\n",
      "        [ 24, 259,  77, 299],\n",
      "        [275, 278, 285, 291],\n",
      "        [201, 364, 251, 431],\n",
      "        [390, 438, 419, 538],\n",
      "        [144, 260, 186, 303]], dtype=torch.int32), 'scores': tensor([0.1649, 0.2739, 0.2838, 0.5617, 0.6709, 0.9066, 0.3542, 0.3468, 0.3521,\n",
      "        0.5788, 0.2424, 0.2802, 0.9795, 0.5908, 0.3333]), 'objectness_scores': tensor([0.2166, 0.2114, 0.2216, 0.2354, 0.2162, 0.4301, 0.2043, 0.6503, 0.2358,\n",
      "        0.2299, 0.2388, 0.5660, 0.3561, 0.2390, 0.4738]), 'labels': tensor([14, 11, 11,  7, 10, 10, 11, 11, 11, 10,  7, 11, 10, 10, 12],\n",
      "       dtype=torch.int32)}\n",
      "166918\n",
      "{'image_id': 167067, 'boxes': tensor([[189, 280, 329, 346]], dtype=torch.int32), 'scores': tensor([0.9786]), 'objectness_scores': tensor([0.6961]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "167067\n",
      "{'image_id': 167122, 'boxes': tensor([[552, 178, 563, 220],\n",
      "        [157, 145, 169, 216],\n",
      "        [402, 169, 413, 222],\n",
      "        [220, 154, 232, 216]], dtype=torch.int32), 'scores': tensor([0.2951, 0.3657, 0.2014, 0.2836]), 'objectness_scores': tensor([0.2172, 0.2329, 0.2725, 0.2338]), 'labels': tensor([11, 14, 11, 11], dtype=torch.int32)}\n",
      "167122\n",
      "{'image_id': 167572, 'boxes': tensor([[562, 156, 623, 352],\n",
      "        [282, 184, 331, 285],\n",
      "        [350, 219, 455, 326],\n",
      "        [ 74, 116, 600, 424],\n",
      "        [268,  70, 334, 219],\n",
      "        [116,  70, 271, 340],\n",
      "        [447, 289, 599, 323],\n",
      "        [253, 261, 313, 371],\n",
      "        [351,  40, 454, 158]], dtype=torch.int32), 'scores': tensor([0.5187, 0.3477, 0.5189, 0.6623, 0.1819, 0.5983, 0.8038, 0.3648, 0.3893]), 'objectness_scores': tensor([0.4340, 0.2316, 0.6414, 0.2698, 0.2213, 0.3199, 0.4627, 0.3157, 0.6451]), 'labels': tensor([ 7, 12, 12, 12,  4,  7, 11, 12, 11], dtype=torch.int32)}\n",
      "167572\n",
      "{'image_id': 167898, 'boxes': tensor([[247, 181, 465, 480],\n",
      "        [  0,   0, 267, 421],\n",
      "        [327,   0, 448,  46],\n",
      "        [  0, 276, 260, 480],\n",
      "        [600,  79, 639, 139],\n",
      "        [414, 127, 476, 180],\n",
      "        [434,  78, 462, 153],\n",
      "        [251, 181, 466, 276],\n",
      "        [  2,   0, 634, 482],\n",
      "        [315, 107, 368, 155],\n",
      "        [332, 170, 409, 208],\n",
      "        [364, 396, 445, 479]], dtype=torch.int32), 'scores': tensor([0.8884, 0.3261, 0.3877, 0.1959, 0.2091, 0.8263, 0.4917, 0.9119, 0.9327,\n",
      "        0.3886, 0.1860, 0.8610]), 'objectness_scores': tensor([0.2128, 0.3716, 0.3241, 0.5414, 0.5137, 0.2176, 0.5202, 0.5093, 0.2067,\n",
      "        0.3133, 0.3549, 0.5081]), 'labels': tensor([15,  7,  7,  7, 11, 15,  8, 15, 15, 10, 11, 10], dtype=torch.int32)}\n",
      "167898\n",
      "{'image_id': 169076, 'boxes': tensor([[ 59, 266, 273, 453],\n",
      "        [173, 174, 184, 203],\n",
      "        [ 46, 452, 267, 591],\n",
      "        [323,  60, 593, 365]], dtype=torch.int32), 'scores': tensor([0.9907, 0.1688, 0.1096, 0.2382]), 'objectness_scores': tensor([0.4606, 0.7435, 0.2118, 0.5308]), 'labels': tensor([13, 11, 13,  0], dtype=torch.int32)}\n",
      "169076\n",
      "{'image_id': 169356, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "169356\n",
      "{'image_id': 170099, 'boxes': tensor([[470, 262, 550, 357],\n",
      "        [ 98, 203, 190, 474],\n",
      "        [504, 319, 549, 357],\n",
      "        [452, 250, 539, 293],\n",
      "        [378, 261, 457, 361],\n",
      "        [371, 259, 454, 305],\n",
      "        [ 71, 448, 256, 478],\n",
      "        [ -2,   0, 626, 475],\n",
      "        [533, 258, 602, 354],\n",
      "        [333, 285, 396, 375],\n",
      "        [ 10, 171, 339, 467],\n",
      "        [314, 249, 604, 475]], dtype=torch.int32), 'scores': tensor([0.3913, 0.9991, 0.5109, 0.1604, 0.3613, 0.3218, 0.2802, 0.6186, 0.3768,\n",
      "        0.8605, 0.2279, 0.9911]), 'objectness_scores': tensor([0.2295, 0.4034, 0.2036, 0.2092, 0.2346, 0.2081, 0.2002, 0.2086, 0.2050,\n",
      "        0.2086, 0.3249, 0.3658]), 'labels': tensor([ 4,  7, 12, 11, 11, 13,  8,  7, 13, 13, 11, 13], dtype=torch.int32)}\n",
      "170099\n",
      "{'image_id': 170278, 'boxes': tensor([[101,   0, 326, 163],\n",
      "        [108, 143, 578, 475]], dtype=torch.int32), 'scores': tensor([0.3703, 0.7220]), 'objectness_scores': tensor([0.2495, 0.4922]), 'labels': tensor([3, 3], dtype=torch.int32)}\n",
      "170278\n",
      "{'image_id': 170670, 'boxes': tensor([[ 33, 115, 205, 216],\n",
      "        [ 74, 205, 160, 352],\n",
      "        [230, 106, 303, 179],\n",
      "        [  2,  77, 633, 427],\n",
      "        [460,  78, 526, 195],\n",
      "        [511, 296, 540, 315],\n",
      "        [398, 228, 476, 378]], dtype=torch.int32), 'scores': tensor([0.2473, 0.6613, 0.4059, 0.6194, 0.9606, 0.2350, 0.7401]), 'objectness_scores': tensor([0.2305, 0.3073, 0.2022, 0.2222, 0.2344, 0.2042, 0.2735]), 'labels': tensor([10, 10, 12,  9,  0, 11, 10], dtype=torch.int32)}\n",
      "170670\n",
      "{'image_id': 170893, 'boxes': tensor([[  1, 174, 145, 481],\n",
      "        [275,  85, 641, 481],\n",
      "        [277,  71, 350, 156],\n",
      "        [306, 236, 422, 290],\n",
      "        [263,  56, 386, 168]], dtype=torch.int32), 'scores': tensor([0.6864, 0.7624, 0.2733, 0.4290, 0.6817]), 'objectness_scores': tensor([0.2415, 0.4744, 0.5247, 0.4517, 0.2042]), 'labels': tensor([ 0,  3, 13, 16,  3], dtype=torch.int32)}\n",
      "170893\n",
      "{'image_id': 170955, 'boxes': tensor([[465, 119, 486, 214],\n",
      "        [492, 145, 499, 150],\n",
      "        [446,  86, 638, 428],\n",
      "        [413, 296, 422, 304]], dtype=torch.int32), 'scores': tensor([0.9056, 0.2161, 0.9496, 0.9997]), 'objectness_scores': tensor([0.4445, 0.2032, 0.3025, 0.3228]), 'labels': tensor([ 7, 11,  7, 13], dtype=torch.int32)}\n",
      "170955\n",
      "{'image_id': 171190, 'boxes': tensor([[400, 138, 415, 173],\n",
      "        [588, 192, 607, 232],\n",
      "        [342, 268, 394, 369],\n",
      "        [450, 226, 458, 239],\n",
      "        [146, 265, 628, 478],\n",
      "        [542, 173, 555, 204],\n",
      "        [449, 265, 477, 333],\n",
      "        [162, 199, 170, 212],\n",
      "        [443, 330, 474, 387],\n",
      "        [ 40, 187,  50, 207],\n",
      "        [343, 162, 362, 181],\n",
      "        [  0, 156,  26, 201]], dtype=torch.int32), 'scores': tensor([0.4073, 0.2777, 0.2454, 0.2304, 0.2895, 0.2521, 0.2369, 0.2030, 0.7882,\n",
      "        0.2321, 0.2269, 0.4384]), 'objectness_scores': tensor([0.3403, 0.2756, 0.2011, 0.2058, 0.2752, 0.2703, 0.2650, 0.2171, 0.2998,\n",
      "        0.2366, 0.2538, 0.2915]), 'labels': tensor([ 7, 11,  8, 11,  7, 11,  7, 11, 10, 11, 11, 11], dtype=torch.int32)}\n",
      "171190\n",
      "{'image_id': 171382, 'boxes': tensor([[560, 164, 564, 172],\n",
      "        [539, 148, 544, 156],\n",
      "        [545, 206, 591, 285],\n",
      "        [116, 271, 131, 281],\n",
      "        [110,  99, 126, 108],\n",
      "        [108,  62, 124,  74],\n",
      "        [232,  29, 263,  61],\n",
      "        [114,  76, 124,  93],\n",
      "        [520, 137, 536, 142],\n",
      "        [596, 158, 601, 171],\n",
      "        [399, 129, 459, 153],\n",
      "        [376, 275, 393, 282],\n",
      "        [596, 152, 602, 161],\n",
      "        [145, 272, 157, 283]], dtype=torch.int32), 'scores': tensor([0.1511, 0.1812, 0.5548, 0.2202, 0.3066, 0.2259, 0.2452, 0.2836, 0.1613,\n",
      "        0.4029, 0.2061, 0.2024, 0.1773, 0.1269]), 'objectness_scores': tensor([0.2840, 0.2189, 0.3862, 0.2073, 0.2232, 0.2399, 0.2241, 0.2221, 0.2423,\n",
      "        0.2137, 0.2110, 0.2133, 0.2993, 0.2298]), 'labels': tensor([11, 14,  7, 14, 11,  2, 11, 11, 11, 14,  7, 11, 14, 14],\n",
      "       dtype=torch.int32)}\n",
      "171382\n",
      "{'image_id': 171611, 'boxes': tensor([[137, 216, 160, 270],\n",
      "        [191, 233, 203, 273]], dtype=torch.int32), 'scores': tensor([0.2553, 0.2879]), 'objectness_scores': tensor([0.3792, 0.2463]), 'labels': tensor([7, 0], dtype=torch.int32)}\n",
      "171611\n",
      "{'image_id': 171740, 'boxes': tensor([[254,  83, 274, 131],\n",
      "        [307,  19, 357,  92],\n",
      "        [452, 208, 482, 249],\n",
      "        [313, 269, 392, 333],\n",
      "        [443, 297, 637, 477],\n",
      "        [200,  83, 224, 110],\n",
      "        [560,   0, 609,  30],\n",
      "        [343, 118, 416, 217],\n",
      "        [191,  71, 231, 112],\n",
      "        [198, 133, 227, 175],\n",
      "        [234, 138, 243, 177],\n",
      "        [382,  41, 506, 100],\n",
      "        [599, 117, 617, 145],\n",
      "        [234,  78, 245, 112],\n",
      "        [451, 178, 482, 200],\n",
      "        [ 12,   0, 250, 260],\n",
      "        [233, 188, 242, 222],\n",
      "        [ 30,  96,  86, 138],\n",
      "        [418, 180, 451, 204],\n",
      "        [224,   4, 257,  66],\n",
      "        [306, 109, 390, 275],\n",
      "        [587,  69, 612, 108],\n",
      "        [499, 212, 534, 295]], dtype=torch.int32), 'scores': tensor([0.3480, 0.3020, 0.9989, 0.1920, 0.2199, 0.2503, 0.1811, 0.1610, 0.1862,\n",
      "        0.1632, 0.6640, 0.4763, 0.2241, 0.2127, 0.2040, 0.4282, 0.2332, 0.2524,\n",
      "        0.2745, 0.1658, 0.1812, 0.1925, 0.3898]), 'objectness_scores': tensor([0.3003, 0.2970, 0.2673, 0.2227, 0.3257, 0.2315, 0.2386, 0.2897, 0.2611,\n",
      "        0.2096, 0.2165, 0.3635, 0.2010, 0.2523, 0.2124, 0.3350, 0.2286, 0.2057,\n",
      "        0.2335, 0.2351, 0.3863, 0.2041, 0.3775]), 'labels': tensor([11,  7,  4, 15, 15,  2,  3,  3,  9,  3, 15,  7,  3, 11, 11,  8, 11,  3,\n",
      "        11,  7, 10, 11, 14], dtype=torch.int32)}\n",
      "171740\n",
      "{'image_id': 171757, 'boxes': tensor([[276, 301, 366, 376],\n",
      "        [298, 344, 359, 457],\n",
      "        [268, 172, 274, 179],\n",
      "        [  0,  18,  52,  47]], dtype=torch.int32), 'scores': tensor([0.2242, 0.2317, 0.8022, 0.7004]), 'objectness_scores': tensor([0.2127, 0.5103, 0.2099, 0.2698]), 'labels': tensor([ 7,  7, 10, 11], dtype=torch.int32)}\n",
      "171757\n",
      "{'image_id': 172330, 'boxes': tensor([[519, 271, 576, 311],\n",
      "        [101, 164, 151, 200],\n",
      "        [258, 221, 393, 331]], dtype=torch.int32), 'scores': tensor([0.4000, 0.2467, 0.8794]), 'objectness_scores': tensor([0.2581, 0.2327, 0.4282]), 'labels': tensor([14, 11,  2], dtype=torch.int32)}\n",
      "172330\n",
      "{'image_id': 172571, 'boxes': tensor([[ 88,  71, 632, 360],\n",
      "        [413,  54, 639, 132],\n",
      "        [486,   0, 624, 209],\n",
      "        [315,  33, 428, 202],\n",
      "        [ 84, 148, 547, 361],\n",
      "        [180,   0, 266, 134]], dtype=torch.int32), 'scores': tensor([0.7870, 0.6456, 0.2778, 0.5064, 0.9573, 0.8152]), 'objectness_scores': tensor([0.3434, 0.2914, 0.4534, 0.4332, 0.3324, 0.4049]), 'labels': tensor([12, 12,  7, 11, 12, 10], dtype=torch.int32)}\n",
      "172571\n",
      "{'image_id': 172595, 'boxes': tensor([[ 52,  17, 193,  58],\n",
      "        [129,  41, 194, 104],\n",
      "        [  8, 111, 246, 244],\n",
      "        [515, 164, 572, 196],\n",
      "        [131,  76, 162, 122],\n",
      "        [ 13,  47,  28,  87],\n",
      "        [485,  69, 510, 108],\n",
      "        [185,  17, 306, 104],\n",
      "        [268, 144, 339, 194],\n",
      "        [292,  75, 605, 356],\n",
      "        [ 52,  17, 198, 104]], dtype=torch.int32), 'scores': tensor([0.1942, 0.2715, 0.3321, 0.3879, 0.7738, 0.2509, 0.2034, 0.6564, 0.9950,\n",
      "        0.6524, 0.3778]), 'objectness_scores': tensor([0.2067, 0.2236, 0.2860, 0.3008, 0.4145, 0.2828, 0.2213, 0.3033, 0.3989,\n",
      "        0.2946, 0.2073]), 'labels': tensor([12, 10,  8,  1, 10, 11, 10, 14, 14, 14, 14], dtype=torch.int32)}\n",
      "172595\n",
      "{'image_id': 172649, 'boxes': tensor([[410, 117, 433, 154],\n",
      "        [439, 130, 456, 159],\n",
      "        [  2,  -1, 614, 425],\n",
      "        [414, 111, 453, 160],\n",
      "        [419, 111, 440, 143]], dtype=torch.int32), 'scores': tensor([0.3973, 0.5990, 0.2810, 0.3756, 0.3986]), 'objectness_scores': tensor([0.2413, 0.2127, 0.3082, 0.3196, 0.2240]), 'labels': tensor([ 9, 11,  3, 11, 11], dtype=torch.int32)}\n",
      "172649\n",
      "{'image_id': 172877, 'boxes': tensor([[286, 184, 321, 358],\n",
      "        [  0, 282, 559, 481],\n",
      "        [367, 286, 391, 319],\n",
      "        [112, 168, 483, 352]], dtype=torch.int32), 'scores': tensor([0.9991, 0.1432, 0.2476, 0.7078]), 'objectness_scores': tensor([0.2775, 0.3796, 0.4228, 0.2062]), 'labels': tensor([ 7,  7, 11, 16], dtype=torch.int32)}\n",
      "172877\n",
      "{'image_id': 173004, 'boxes': tensor([[140,  52, 435, 181],\n",
      "        [215,  41, 419, 124],\n",
      "        [ 12, 193, 628, 480],\n",
      "        [130,   9, 203, 148],\n",
      "        [423,  83, 639, 261],\n",
      "        [  0,  49, 632, 481],\n",
      "        [162, 170, 521, 404],\n",
      "        [ 86,  84, 115, 118]], dtype=torch.int32), 'scores': tensor([0.6477, 0.7988, 0.8012, 0.7034, 0.6435, 0.8631, 0.7429, 0.2363]), 'objectness_scores': tensor([0.2159, 0.2152, 0.2693, 0.3292, 0.2386, 0.2838, 0.2336, 0.3992]), 'labels': tensor([12, 12, 12, 14, 12, 12, 12,  4], dtype=torch.int32)}\n",
      "173004\n",
      "{'image_id': 173008, 'boxes': tensor([[390, 378, 413, 431],\n",
      "        [ 88,   0, 253, 232],\n",
      "        [413,   0, 481, 206],\n",
      "        [ 48, 275,  74, 313],\n",
      "        [228,   0, 336, 208],\n",
      "        [247, 137, 311, 177],\n",
      "        [  0, 410, 168, 479],\n",
      "        [434,   0, 638, 201],\n",
      "        [503, 175, 513, 185]], dtype=torch.int32), 'scores': tensor([0.2423, 0.3172, 0.3036, 0.5676, 0.1838, 0.1746, 0.2395, 0.2847, 0.2110]), 'objectness_scores': tensor([0.2446, 0.2389, 0.2241, 0.5666, 0.2164, 0.2115, 0.3926, 0.2109, 0.2006]), 'labels': tensor([11,  2,  7, 11,  7,  2,  2,  8, 11], dtype=torch.int32)}\n",
      "173008\n",
      "{'image_id': 173371, 'boxes': tensor([[407, 168, 612, 414],\n",
      "        [586,  84, 611, 140],\n",
      "        [553,  44, 609, 165],\n",
      "        [484, 360, 506, 381],\n",
      "        [346,   0, 580, 149],\n",
      "        [ 94,  73, 402, 379],\n",
      "        [450, 218, 613, 334],\n",
      "        [421,   4, 610, 162],\n",
      "        [517, 279, 537, 303],\n",
      "        [528, 197, 548, 216],\n",
      "        [249, 367, 492, 612],\n",
      "        [476, 236, 570, 309],\n",
      "        [438, 288, 457, 315],\n",
      "        [  3,   4, 604, 606],\n",
      "        [  0, 328, 173, 569]], dtype=torch.int32), 'scores': tensor([0.4071, 0.4058, 0.6305, 0.3310, 0.4076, 0.2652, 0.3294, 0.3665, 0.5850,\n",
      "        0.4277, 0.3408, 0.4822, 0.2345, 0.2588, 0.5253]), 'objectness_scores': tensor([0.2065, 0.2594, 0.2048, 0.2484, 0.2285, 0.2305, 0.2815, 0.4837, 0.2410,\n",
      "        0.2230, 0.2008, 0.2062, 0.3812, 0.2438, 0.2438]), 'labels': tensor([11, 11, 12, 11, 12,  5, 11, 11,  3, 11, 11, 11,  7, 11, 12],\n",
      "       dtype=torch.int32)}\n",
      "173371\n",
      "{'image_id': 173799, 'boxes': tensor([[352, 213, 494, 271],\n",
      "        [288, 176, 372, 252],\n",
      "        [514, 177, 537, 225],\n",
      "        [486, 218, 540, 295],\n",
      "        [355, 176, 379, 204],\n",
      "        [489, 218, 562, 288],\n",
      "        [446, 208, 470, 222],\n",
      "        [452, 237, 511, 326],\n",
      "        [248, 268, 455, 410],\n",
      "        [ 59, 163, 139, 226],\n",
      "        [473, 172, 537, 225],\n",
      "        [352, 260, 473, 393],\n",
      "        [498, 195, 526, 222],\n",
      "        [509, 222, 627, 296],\n",
      "        [377, 274, 468, 392],\n",
      "        [271, 165, 619, 403],\n",
      "        [519, 166, 580, 229],\n",
      "        [234, 304, 338, 407],\n",
      "        [307, 175, 368, 206],\n",
      "        [423, 179, 456, 209],\n",
      "        [472, 173, 494, 194],\n",
      "        [246, 257, 324, 309],\n",
      "        [ 67, 133, 143, 221],\n",
      "        [283, 175, 365, 246],\n",
      "        [136,  61, 167, 517],\n",
      "        [459, 192, 489, 212],\n",
      "        [348, 213, 442, 278],\n",
      "        [239, 259, 327, 402],\n",
      "        [413, 201, 458, 218],\n",
      "        [253, 269, 408, 404],\n",
      "        [ 67, 134, 142, 175],\n",
      "        [467, 197, 525, 230],\n",
      "        [345, 230, 404, 283],\n",
      "        [234, 119, 286, 474],\n",
      "        [226, 166, 270, 231],\n",
      "        [187, 212, 216, 234],\n",
      "        [385, 218, 505, 325],\n",
      "        [372, 199, 407, 215],\n",
      "        [400, 220, 495, 262]], dtype=torch.int32), 'scores': tensor([0.6212, 0.1883, 0.3720, 0.9994, 0.3057, 0.9974, 0.2318, 0.2478, 0.9981,\n",
      "        0.7903, 0.9156, 0.9995, 0.2670, 0.9995, 0.9996, 0.9998, 0.9995, 0.9985,\n",
      "        0.2461, 0.1798, 0.4325, 0.4581, 0.7045, 0.9996, 0.3969, 0.2882, 0.7335,\n",
      "        0.9973, 0.4022, 0.4957, 0.8567, 0.2122, 0.8122, 0.9954, 0.2811, 0.1237,\n",
      "        0.9981, 0.3925, 0.3126]), 'objectness_scores': tensor([0.3944, 0.6305, 0.2561, 0.4257, 0.4199, 0.2587, 0.3349, 0.5402, 0.5857,\n",
      "        0.6478, 0.6241, 0.2811, 0.2838, 0.6096, 0.2234, 0.2825, 0.6207, 0.3308,\n",
      "        0.2348, 0.5955, 0.3077, 0.4230, 0.2336, 0.2145, 0.5483, 0.4920, 0.3939,\n",
      "        0.4111, 0.5245, 0.2283, 0.5301, 0.5930, 0.4158, 0.4838, 0.6551, 0.2639,\n",
      "        0.2639, 0.5346, 0.3411]), 'labels': tensor([10, 14,  3,  5,  4,  5,  3, 11,  5,  5,  5,  5,  3,  5,  5,  5,  5,  5,\n",
      "        11,  6,  7,  5,  4,  5, 11,  9,  5,  5, 11, 12,  5,  3,  5,  5, 11,  3,\n",
      "         5, 11,  5], dtype=torch.int32)}\n",
      "173799\n",
      "{'image_id': 174123, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "174123\n",
      "{'image_id': 174231, 'boxes': tensor([[ 97, 224, 375, 498],\n",
      "        [ 76, 175, 275, 285],\n",
      "        [271, 190, 375, 227]], dtype=torch.int32), 'scores': tensor([0.1806, 0.9604, 0.2341]), 'objectness_scores': tensor([0.4135, 0.4876, 0.2263]), 'labels': tensor([ 0,  2, 14], dtype=torch.int32)}\n",
      "174231\n",
      "{'image_id': 175364, 'boxes': tensor([[283, 256, 357, 329],\n",
      "        [423, 191, 483, 211],\n",
      "        [  0,  31, 126, 161],\n",
      "        [127,  89, 243, 110],\n",
      "        [ 64, 237, 260, 297],\n",
      "        [140,  75, 156,  90],\n",
      "        [ 91, 282, 163, 436],\n",
      "        [427, 123, 446, 139],\n",
      "        [449,  82, 571, 110],\n",
      "        [458,  77, 467,  89],\n",
      "        [367, 254, 432, 306],\n",
      "        [259, 229, 333, 244],\n",
      "        [596, 328, 613, 365],\n",
      "        [425,  77, 467,  92],\n",
      "        [449, 124, 467, 140],\n",
      "        [238,  62, 259,  91],\n",
      "        [593, 123, 612, 143],\n",
      "        [ 41, 217,  64, 264],\n",
      "        [601,  64, 612,  85],\n",
      "        [431, 238, 587, 292],\n",
      "        [294, 204, 315, 230],\n",
      "        [198,  43, 273, 148],\n",
      "        [393,   0, 467,  28],\n",
      "        [158, 339, 251, 430],\n",
      "        [  0, 212,  82, 237],\n",
      "        [ 46, 211,  82, 228],\n",
      "        [  1, 216,  33, 236],\n",
      "        [425,  80, 434,  93],\n",
      "        [236, 306, 610, 460],\n",
      "        [407,  39, 502,  97],\n",
      "        [ 86, 106, 106, 147],\n",
      "        [364, 253, 434, 324],\n",
      "        [445, 122, 458, 140],\n",
      "        [408,  40, 503, 147],\n",
      "        [368, 290, 431, 324],\n",
      "        [259, 266, 284, 330],\n",
      "        [447,  78, 460,  91],\n",
      "        [582,  69, 594,  84],\n",
      "        [280,  50, 325,  74],\n",
      "        [432,  79, 444,  92],\n",
      "        [440, 193, 479, 241],\n",
      "        [233, 116, 255, 141]], dtype=torch.int32), 'scores': tensor([0.9681, 0.2382, 0.2416, 0.2625, 0.3795, 0.2104, 0.2949, 0.2086, 0.3436,\n",
      "        0.2123, 0.6246, 0.2704, 0.3306, 0.3722, 0.2646, 0.3506, 0.2512, 0.2608,\n",
      "        0.2583, 0.3887, 0.5154, 0.2427, 0.5212, 0.2150, 0.1650, 0.2069, 0.4103,\n",
      "        0.1880, 0.6788, 0.5924, 0.4424, 0.3300, 0.2332, 0.2106, 0.2164, 0.3668,\n",
      "        0.1747, 0.3104, 0.2881, 0.2593, 0.5271, 0.5481]), 'objectness_scores': tensor([0.4058, 0.2748, 0.2891, 0.2333, 0.2792, 0.2658, 0.3329, 0.3444, 0.4989,\n",
      "        0.2215, 0.2821, 0.5652, 0.2314, 0.2530, 0.3585, 0.3395, 0.2900, 0.4154,\n",
      "        0.2528, 0.4095, 0.4755, 0.3076, 0.3670, 0.3176, 0.3698, 0.2151, 0.5313,\n",
      "        0.2249, 0.2708, 0.2023, 0.2806, 0.3070, 0.2338, 0.3258, 0.2100, 0.3014,\n",
      "        0.2270, 0.2980, 0.3023, 0.2266, 0.5070, 0.3558]), 'labels': tensor([ 2,  9, 10, 11, 14, 11,  8, 11, 14, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 14, 11, 11, 11,  7, 14, 11, 14, 11, 11, 11, 11, 11, 14, 10,  7,  7,\n",
      "        11, 11, 11, 11, 10, 11], dtype=torch.int32)}\n",
      "175364\n",
      "{'image_id': 175535, 'boxes': tensor([[  3,  33, 477, 449],\n",
      "        [  1,   0, 192,  51],\n",
      "        [205, 260, 219, 303],\n",
      "        [  0, 540, 149, 638],\n",
      "        [  0, 205, 214, 305],\n",
      "        [195, 215, 206, 234],\n",
      "        [200, 218, 219, 303],\n",
      "        [127,   0, 281,  53],\n",
      "        [179, 454, 379, 641],\n",
      "        [208, 234, 477, 445],\n",
      "        [  0,   6, 477, 632]], dtype=torch.int32), 'scores': tensor([0.6467, 0.2464, 0.2859, 0.5128, 0.4217, 0.4114, 0.3676, 0.4745, 0.5555,\n",
      "        0.5897, 0.2063]), 'objectness_scores': tensor([0.4076, 0.2936, 0.3457, 0.2094, 0.2012, 0.2203, 0.2047, 0.2316, 0.2918,\n",
      "        0.6768, 0.2081]), 'labels': tensor([12,  7, 11, 10, 12,  9, 11,  8, 12, 12, 12], dtype=torch.int32)}\n",
      "175535\n",
      "{'image_id': 176037, 'boxes': tensor([[272, 130, 510, 327]], dtype=torch.int32), 'scores': tensor([0.9990]), 'objectness_scores': tensor([0.5054]), 'labels': tensor([1], dtype=torch.int32)}\n",
      "176037\n",
      "{'image_id': 176778, 'boxes': tensor([[252,  76, 287, 125],\n",
      "        [194, 202, 426, 361],\n",
      "        [254, 182, 313, 206],\n",
      "        [  0, 403, 116, 640],\n",
      "        [190, 202, 427, 491],\n",
      "        [262, 397, 335, 638],\n",
      "        [ 10, 213, 188, 381],\n",
      "        [ 21, 287,  49, 305],\n",
      "        [  0, 358,  32, 431]], dtype=torch.int32), 'scores': tensor([0.2775, 0.2222, 0.2655, 0.1950, 0.6192, 0.3714, 0.7455, 0.6144, 0.2782]), 'objectness_scores': tensor([0.3494, 0.5618, 0.4231, 0.2056, 0.2431, 0.4737, 0.2017, 0.2275, 0.2375]), 'labels': tensor([11,  8,  9,  7, 15,  3, 15, 11,  7], dtype=torch.int32)}\n",
      "176778\n",
      "{'image_id': 176799, 'boxes': tensor([[ 94, 185, 102, 190],\n",
      "        [576,   0, 594,  23],\n",
      "        [336, 231, 638, 420]], dtype=torch.int32), 'scores': tensor([0.1771, 0.4045, 0.3908]), 'objectness_scores': tensor([0.2205, 0.2044, 0.2317]), 'labels': tensor([11,  7,  9], dtype=torch.int32)}\n",
      "176799\n",
      "{'image_id': 176857, 'boxes': tensor([[231,  59, 239,  63],\n",
      "        [399, 173, 407, 185],\n",
      "        [262, 152, 273, 168],\n",
      "        [282,  45, 298,  57],\n",
      "        [128, 207, 157, 235],\n",
      "        [215, 139, 264, 221],\n",
      "        [270,  84, 278,  96],\n",
      "        [123, 129, 132, 139],\n",
      "        [249,  28, 262,  39]], dtype=torch.int32), 'scores': tensor([0.2065, 0.3898, 0.3388, 0.2346, 0.2185, 0.9646, 0.2149, 0.1892, 0.2157]), 'objectness_scores': tensor([0.3372, 0.2392, 0.3874, 0.2867, 0.4821, 0.5563, 0.3504, 0.2991, 0.5034]), 'labels': tensor([11, 14, 11, 11, 14,  2, 11, 14, 11], dtype=torch.int32)}\n",
      "176857\n",
      "{'image_id': 177015, 'boxes': tensor([[333, 182, 394, 260],\n",
      "        [302, 336, 316, 358],\n",
      "        [296, 175, 603, 365],\n",
      "        [338, 227, 611, 362],\n",
      "        [  0, 154,  89, 302]], dtype=torch.int32), 'scores': tensor([0.9569, 0.2399, 0.8798, 0.8017, 0.1925]), 'objectness_scores': tensor([0.2219, 0.4902, 0.3252, 0.3545, 0.2011]), 'labels': tensor([ 2, 11,  2,  2,  7], dtype=torch.int32)}\n",
      "177015\n",
      "{'image_id': 177213, 'boxes': tensor([[  1,  99, 633, 358],\n",
      "        [406, 109, 581, 189],\n",
      "        [595, 165, 638, 360],\n",
      "        [563, 111, 639, 263],\n",
      "        [ 90, 128, 513, 338],\n",
      "        [410, 135, 579, 165],\n",
      "        [196, 329, 491, 356],\n",
      "        [496, 154, 569, 191]], dtype=torch.int32), 'scores': tensor([0.4639, 0.4843, 0.2020, 0.7219, 0.3753, 0.5557, 0.2958, 0.4621]), 'objectness_scores': tensor([0.5505, 0.3633, 0.3288, 0.5559, 0.5553, 0.6176, 0.3177, 0.2503]), 'labels': tensor([12, 11,  8, 10, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "177213\n",
      "{'image_id': 177861, 'boxes': tensor([[155, 346, 173, 398],\n",
      "        [ 86, 274, 162, 297],\n",
      "        [289, 377, 319, 456],\n",
      "        [269, 247, 415, 331],\n",
      "        [397, 294, 476, 352],\n",
      "        [ 85, 275, 162, 317]], dtype=torch.int32), 'scores': tensor([0.3341, 0.6351, 0.3326, 0.9983, 0.5563, 0.3558]), 'objectness_scores': tensor([0.2329, 0.2022, 0.2086, 0.2755, 0.2729, 0.2214]), 'labels': tensor([ 7,  6,  7,  6,  1, 11], dtype=torch.int32)}\n",
      "177861\n",
      "{'image_id': 177893, 'boxes': tensor([[  4, 230,  26, 266]], dtype=torch.int32), 'scores': tensor([0.1562]), 'objectness_scores': tensor([0.2154]), 'labels': tensor([9], dtype=torch.int32)}\n",
      "177893\n",
      "{'image_id': 177935, 'boxes': tensor([[ 64, 430, 133, 573],\n",
      "        [295, 311, 436, 404],\n",
      "        [ 41, 273, 210, 345],\n",
      "        [100, 156, 122, 195],\n",
      "        [ 24, 203,  77, 268],\n",
      "        [103,   0, 461,  53],\n",
      "        [ 14, 161, 112, 251],\n",
      "        [ 13, 264, 458, 437],\n",
      "        [228, 490, 316, 641]], dtype=torch.int32), 'scores': tensor([0.7026, 0.7113, 0.3046, 0.3112, 0.1583, 0.1568, 0.4053, 0.8740, 0.6527]), 'objectness_scores': tensor([0.3699, 0.2390, 0.2219, 0.4374, 0.2792, 0.2551, 0.2070, 0.2951, 0.3450]), 'labels': tensor([ 7, 16, 16, 14, 10, 11, 14, 12,  7], dtype=torch.int32)}\n",
      "177935\n",
      "{'image_id': 178028, 'boxes': tensor([[ 60, 231, 109, 269],\n",
      "        [117, 249, 189, 318],\n",
      "        [125, 308, 282, 392],\n",
      "        [275, 217, 302, 265],\n",
      "        [253, 211, 279, 264],\n",
      "        [203, 201, 231, 231],\n",
      "        [132, 240, 168, 252],\n",
      "        [349,   3, 374, 107],\n",
      "        [ 68,  87, 116, 210],\n",
      "        [185,   6, 225,  77],\n",
      "        [211, 263, 240, 283],\n",
      "        [ 98, 481, 121, 499]], dtype=torch.int32), 'scores': tensor([0.2586, 0.9657, 0.3271, 0.2892, 0.6561, 0.1168, 0.5704, 0.1542, 0.7022,\n",
      "        0.3611, 0.4005, 0.1709]), 'objectness_scores': tensor([0.4601, 0.4203, 0.4938, 0.3179, 0.3143, 0.2157, 0.2057, 0.2091, 0.3815,\n",
      "        0.2883, 0.2612, 0.2000]), 'labels': tensor([ 8, 15, 11,  7, 12,  2, 11, 11,  9,  9, 11, 11], dtype=torch.int32)}\n",
      "178028\n",
      "{'image_id': 178469, 'boxes': tensor([[505, 146, 513, 172],\n",
      "        [279,   0, 321,  78],\n",
      "        [505, 139, 513, 172],\n",
      "        [537,  39, 552,  83],\n",
      "        [506, 198, 638, 312],\n",
      "        [ -5, 257, 591, 426],\n",
      "        [ 92, 144, 143, 267],\n",
      "        [458, 163, 537, 255],\n",
      "        [455, 118, 473, 159],\n",
      "        [472, 147, 479, 169],\n",
      "        [573, 169, 639, 223],\n",
      "        [496, 136, 505, 171],\n",
      "        [486, 142, 496, 171],\n",
      "        [479, 144, 486, 170]], dtype=torch.int32), 'scores': tensor([0.3510, 0.2237, 0.2838, 0.1718, 0.9770, 0.9940, 0.2740, 0.9376, 0.2849,\n",
      "        0.4153, 0.8746, 0.2413, 0.2486, 0.2259]), 'objectness_scores': tensor([0.2586, 0.2235, 0.2127, 0.2162, 0.2413, 0.2466, 0.5079, 0.3192, 0.2123,\n",
      "        0.2248, 0.3054, 0.2468, 0.2312, 0.2287]), 'labels': tensor([11, 14, 11, 11, 14, 14,  8, 10,  7, 11, 12, 11, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "178469\n",
      "{'image_id': 179141, 'boxes': tensor([[607, 156, 618, 178],\n",
      "        [292, 274, 331, 337],\n",
      "        [580, 195, 637, 314],\n",
      "        [164, 287, 473, 472],\n",
      "        [101, 384, 408, 478],\n",
      "        [ 89, 148, 110, 200]], dtype=torch.int32), 'scores': tensor([0.3746, 0.1743, 0.2103, 0.4210, 0.2684, 0.3018]), 'objectness_scores': tensor([0.3718, 0.5120, 0.4671, 0.2835, 0.2394, 0.2179]), 'labels': tensor([11,  3,  7, 10, 12, 11], dtype=torch.int32)}\n",
      "179141\n",
      "{'image_id': 179174, 'boxes': tensor([[ 83,  70, 198, 107],\n",
      "        [416,  54, 422,  71]], dtype=torch.int32), 'scores': tensor([0.9165, 0.1855]), 'objectness_scores': tensor([0.2681, 0.2152]), 'labels': tensor([ 2, 11], dtype=torch.int32)}\n",
      "179174\n",
      "{'image_id': 179265, 'boxes': tensor([[545, 128, 555, 142],\n",
      "        [376, 133, 394, 153],\n",
      "        [278, 133, 287, 152],\n",
      "        [428,  83, 437,  98],\n",
      "        [542, 123, 635, 200],\n",
      "        [542, 143, 552, 157],\n",
      "        [292, 147, 434, 264],\n",
      "        [ 68, 229, 100, 260]], dtype=torch.int32), 'scores': tensor([0.1834, 0.1683, 0.2331, 0.3659, 0.3271, 0.2732, 0.9993, 0.7794]), 'objectness_scores': tensor([0.2728, 0.2709, 0.2826, 0.2183, 0.5149, 0.2397, 0.5925, 0.3067]), 'labels': tensor([14, 16, 14, 14,  1, 14,  1,  8], dtype=torch.int32)}\n",
      "179265\n",
      "{'image_id': 179392, 'boxes': tensor([[171, 262, 295, 366],\n",
      "        [104, 326, 314, 464],\n",
      "        [  1, 210, 479, 639],\n",
      "        [  2, 111, 126, 250],\n",
      "        [119,  47, 482, 562]], dtype=torch.int32), 'scores': tensor([0.7121, 0.4193, 0.8742, 0.4345, 0.9318]), 'objectness_scores': tensor([0.3944, 0.2984, 0.4300, 0.2152, 0.4671]), 'labels': tensor([ 3,  3,  2, 11,  2], dtype=torch.int32)}\n",
      "179392\n",
      "{'image_id': 180101, 'boxes': tensor([[177, 184, 186, 239],\n",
      "        [198, 173, 206, 221],\n",
      "        [ 97, 405, 225, 479],\n",
      "        [116, 251, 375, 376],\n",
      "        [207, 198, 216, 259],\n",
      "        [ 91,  84, 171, 144],\n",
      "        [241, 197, 250, 263],\n",
      "        [293, 157, 301, 215],\n",
      "        [179, 160, 186, 213],\n",
      "        [  3, 196, 572, 481],\n",
      "        [  0, 192,  30, 274],\n",
      "        [176, 179, 186, 240],\n",
      "        [270, 194, 279, 258],\n",
      "        [ 48, 202, 178, 282],\n",
      "        [185, 186, 194, 243],\n",
      "        [207, 202, 218, 263],\n",
      "        [300, 197, 308, 253],\n",
      "        [197, 158, 206, 211],\n",
      "        [165, 202, 329, 328],\n",
      "        [185, 191, 196, 252],\n",
      "        [300, 186, 309, 253]], dtype=torch.int32), 'scores': tensor([0.2425, 0.1976, 0.5311, 0.9978, 0.1982, 0.4212, 0.4621, 0.7637, 0.2047,\n",
      "        0.9991, 0.4177, 0.2524, 0.2004, 0.5983, 0.9983, 0.2483, 0.8352, 0.6238,\n",
      "        0.9978, 0.4112, 0.4131]), 'objectness_scores': tensor([0.2549, 0.2287, 0.2225, 0.2882, 0.2147, 0.6065, 0.6763, 0.7324, 0.4658,\n",
      "        0.4350, 0.2229, 0.6156, 0.6534, 0.2724, 0.5774, 0.6964, 0.2358, 0.7122,\n",
      "        0.6004, 0.3711, 0.3759]), 'labels': tensor([ 7, 11, 16, 12, 11, 11,  7,  7, 11, 12,  8,  7, 11, 12,  4, 11,  7, 12,\n",
      "        12,  7,  7], dtype=torch.int32)}\n",
      "180101\n",
      "{'image_id': 180135, 'boxes': tensor([[193, 107, 239, 209],\n",
      "        [ 21, 386,  60, 413],\n",
      "        [198, 208, 229, 227],\n",
      "        [  4, 106, 192, 394]], dtype=torch.int32), 'scores': tensor([0.7525, 0.5951, 0.5304, 0.9236]), 'objectness_scores': tensor([0.6457, 0.5315, 0.3748, 0.3382]), 'labels': tensor([11, 11, 11,  6], dtype=torch.int32)}\n",
      "180135\n",
      "{'image_id': 180383, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "180383\n",
      "{'image_id': 180487, 'boxes': tensor([[533, 335, 601, 352],\n",
      "        [416, 296, 490, 344],\n",
      "        [122, 100, 203, 129],\n",
      "        [233, 339, 638, 427],\n",
      "        [628, 261, 634, 269],\n",
      "        [ 49,  55, 292, 197],\n",
      "        [356, 345, 613, 376]], dtype=torch.int32), 'scores': tensor([0.2742, 0.2655, 0.3780, 0.3886, 0.1876, 0.9701, 0.1902]), 'objectness_scores': tensor([0.2375, 0.2732, 0.3407, 0.2804, 0.3200, 0.4836, 0.2456]), 'labels': tensor([11,  8,  7, 11, 14,  6, 13], dtype=torch.int32)}\n",
      "180487\n",
      "{'image_id': 180560, 'boxes': tensor([[ 44, 190, 119, 209],\n",
      "        [255, 309, 347, 397],\n",
      "        [302, 309, 317, 345],\n",
      "        [494, 189, 508, 209],\n",
      "        [259, 334, 348, 397],\n",
      "        [254, 309, 318, 349],\n",
      "        [287, 318, 296, 344],\n",
      "        [153, 107, 195, 132],\n",
      "        [355, 148, 443, 178],\n",
      "        [114, 146, 121, 155],\n",
      "        [257, 312, 268, 347]], dtype=torch.int32), 'scores': tensor([0.5192, 0.9764, 0.5294, 0.3136, 0.9663, 0.8109, 0.2525, 0.2238, 0.2082,\n",
      "        0.2845, 0.2227]), 'objectness_scores': tensor([0.4656, 0.2288, 0.4797, 0.2182, 0.4976, 0.2290, 0.5027, 0.2859, 0.3573,\n",
      "        0.3164, 0.4953]), 'labels': tensor([11, 12, 11, 11, 12, 12, 11, 11,  7, 11, 11], dtype=torch.int32)}\n",
      "180560\n",
      "{'image_id': 180878, 'boxes': tensor([[275, 209, 377, 343],\n",
      "        [120, 260, 166, 304],\n",
      "        [ 52, 253, 582, 404],\n",
      "        [ 57,  31, 566, 399],\n",
      "        [120, 261, 206, 321]], dtype=torch.int32), 'scores': tensor([0.2138, 0.5107, 0.8175, 0.9976, 0.7270]), 'objectness_scores': tensor([0.5194, 0.2058, 0.2937, 0.2796, 0.2177]), 'labels': tensor([12, 10, 12, 12, 10], dtype=torch.int32)}\n",
      "180878\n",
      "{'image_id': 181421, 'boxes': tensor([[418, 165, 456, 195],\n",
      "        [338, 165, 372, 188],\n",
      "        [275, 108, 469, 228],\n",
      "        [397, 235, 531, 291]], dtype=torch.int32), 'scores': tensor([0.1752, 0.2354, 0.9900, 0.3698]), 'objectness_scores': tensor([0.6098, 0.5944, 0.6722, 0.7477]), 'labels': tensor([ 8, 11,  6,  9], dtype=torch.int32)}\n",
      "181421\n",
      "{'image_id': 181499, 'boxes': tensor([[259, 266, 622, 413],\n",
      "        [  3, 187, 638, 517]], dtype=torch.int32), 'scores': tensor([0.9792, 0.8028]), 'objectness_scores': tensor([0.3301, 0.2823]), 'labels': tensor([14, 14], dtype=torch.int32)}\n",
      "181499\n",
      "{'image_id': 181542, 'boxes': tensor([[597, 125, 609, 133],\n",
      "        [448, 119, 501, 153],\n",
      "        [565, 148, 630, 182],\n",
      "        [ 47, 161,  82, 186],\n",
      "        [249, 450, 267, 460],\n",
      "        [233, 429, 246, 443],\n",
      "        [ 11, 121,  23, 128],\n",
      "        [164, 352, 212, 387],\n",
      "        [122, 113, 169, 148],\n",
      "        [561, 147, 634, 206]], dtype=torch.int32), 'scores': tensor([0.1775, 0.2439, 0.1570, 0.2344, 0.3910, 0.2476, 0.2286, 0.4109, 0.3020,\n",
      "        0.1436]), 'objectness_scores': tensor([0.2095, 0.4238, 0.3747, 0.3559, 0.2700, 0.2584, 0.2177, 0.2326, 0.4868,\n",
      "        0.2217]), 'labels': tensor([11, 11,  9, 11,  1, 11, 11, 11,  8,  9], dtype=torch.int32)}\n",
      "181542\n",
      "{'image_id': 181753, 'boxes': tensor([[431, 253, 556, 329],\n",
      "        [235, 343, 488, 423],\n",
      "        [569, 276, 638, 396],\n",
      "        [103, 292, 171, 354],\n",
      "        [ 25,  30, 115, 215],\n",
      "        [379, 247, 459, 322],\n",
      "        [214,   2, 336, 292],\n",
      "        [328, 227, 590, 411],\n",
      "        [162, 274, 253, 357],\n",
      "        [134, 305, 200, 372],\n",
      "        [247, 161, 354, 264]], dtype=torch.int32), 'scores': tensor([0.5316, 0.7181, 0.8576, 0.4078, 0.3698, 0.7585, 0.9422, 0.9958, 0.3774,\n",
      "        0.8386, 0.1912]), 'objectness_scores': tensor([0.3130, 0.4029, 0.2576, 0.2216, 0.2264, 0.2911, 0.2266, 0.4816, 0.2803,\n",
      "        0.2823, 0.2913]), 'labels': tensor([13, 10, 11,  7,  5, 12,  2, 13,  7,  7, 11], dtype=torch.int32)}\n",
      "181753\n",
      "{'image_id': 181796, 'boxes': tensor([[106,   0, 241, 194],\n",
      "        [  0,   0, 629, 363],\n",
      "        [349,  28, 605, 119],\n",
      "        [363, 265, 469, 335],\n",
      "        [360, 245, 427, 300],\n",
      "        [414, 233, 444, 255],\n",
      "        [215,  60, 296, 153],\n",
      "        [228,   0, 285,  37],\n",
      "        [476, 199, 639, 359],\n",
      "        [437, 173, 635, 356],\n",
      "        [277, 189, 356, 362],\n",
      "        [522,  28, 564,  58],\n",
      "        [166, 137, 486, 363],\n",
      "        [356, 217, 416, 271]], dtype=torch.int32), 'scores': tensor([0.8811, 0.2393, 0.5931, 0.6683, 0.3341, 0.4860, 0.9539, 0.2395, 0.7708,\n",
      "        0.5092, 0.6317, 0.9069, 0.2197, 0.3307]), 'objectness_scores': tensor([0.3700, 0.2951, 0.2204, 0.4106, 0.2585, 0.2594, 0.3244, 0.2048, 0.2546,\n",
      "        0.2436, 0.2512, 0.2179, 0.2246, 0.2990]), 'labels': tensor([10, 11, 10, 11, 12, 11, 10, 11, 11, 11,  4, 10, 14, 11],\n",
      "       dtype=torch.int32)}\n",
      "181796\n",
      "{'image_id': 182155, 'boxes': tensor([[338, 167, 502, 421],\n",
      "        [  4, 265, 539, 426],\n",
      "        [432, 164, 461, 179],\n",
      "        [  2, 388,  62, 425],\n",
      "        [218, 150, 249, 259],\n",
      "        [503, 182, 528, 200],\n",
      "        [100, 138, 280, 426]], dtype=torch.int32), 'scores': tensor([0.7734, 0.7589, 0.3164, 0.2801, 0.2499, 0.4967, 0.6710]), 'objectness_scores': tensor([0.2966, 0.4385, 0.2213, 0.2063, 0.2099, 0.2468, 0.2201]), 'labels': tensor([ 7,  7, 11,  7,  8, 11,  7], dtype=torch.int32)}\n",
      "182155\n",
      "{'image_id': 182162, 'boxes': tensor([[520, 156, 528, 162],\n",
      "        [273, 215, 297, 241],\n",
      "        [477,  78, 486,  96],\n",
      "        [ 23, 161, 293, 340],\n",
      "        [ 78, 271, 102, 279],\n",
      "        [459, 170, 478, 249],\n",
      "        [  0, 320, 257, 424],\n",
      "        [  0, 245, 136, 381],\n",
      "        [ 59, 192, 136, 232],\n",
      "        [ 54, 210,  90, 235],\n",
      "        [349,  83, 388, 108],\n",
      "        [278, 163, 328, 234],\n",
      "        [154,  37, 238, 118],\n",
      "        [ 23,  55, 117, 204],\n",
      "        [ 67,  36,  91,  55],\n",
      "        [127, 209, 177, 266],\n",
      "        [274, 232, 340, 323],\n",
      "        [466,  77, 476,  96]], dtype=torch.int32), 'scores': tensor([0.2929, 0.2898, 0.3684, 0.9909, 0.6736, 0.3811, 0.6371, 0.5053, 0.7493,\n",
      "        0.5810, 0.2173, 0.3465, 0.2201, 0.2717, 0.6696, 0.3757, 0.2579, 0.5189]), 'objectness_scores': tensor([0.2269, 0.3134, 0.2245, 0.5609, 0.2590, 0.3041, 0.2662, 0.3719, 0.4365,\n",
      "        0.2945, 0.2596, 0.3896, 0.2841, 0.2701, 0.2322, 0.3687, 0.3030, 0.2296]), 'labels': tensor([11, 12, 11, 13, 10, 11,  8, 14,  7,  7, 11, 12,  5, 13, 14,  2, 10, 11],\n",
      "       dtype=torch.int32)}\n",
      "182162\n",
      "{'image_id': 182202, 'boxes': tensor([[ 74, 238, 331, 333],\n",
      "        [253,   6, 636,  87],\n",
      "        [  2,  28, 637, 384]], dtype=torch.int32), 'scores': tensor([0.2792, 0.9852, 0.8565]), 'objectness_scores': tensor([0.2601, 0.3275, 0.4397]), 'labels': tensor([ 7, 14, 14], dtype=torch.int32)}\n",
      "182202\n",
      "{'image_id': 182417, 'boxes': tensor([[  4, 102, 638, 477],\n",
      "        [  0, 158,  94, 215],\n",
      "        [518,  -4, 635, 164]], dtype=torch.int32), 'scores': tensor([0.9867, 0.7853, 0.2296]), 'objectness_scores': tensor([0.2132, 0.2314, 0.3386]), 'labels': tensor([12, 12, 11], dtype=torch.int32)}\n",
      "182417\n",
      "{'image_id': 182611, 'boxes': tensor([[378, 404, 480, 518],\n",
      "        [182, 365, 387, 487],\n",
      "        [351, 488, 404, 553],\n",
      "        [350, 108, 366, 123]], dtype=torch.int32), 'scores': tensor([0.3008, 0.7428, 0.3692, 0.2398]), 'objectness_scores': tensor([0.2849, 0.2070, 0.3028, 0.2094]), 'labels': tensor([10, 12,  7, 11], dtype=torch.int32)}\n",
      "182611\n",
      "{'image_id': 182805, 'boxes': tensor([[282,   1, 638, 209],\n",
      "        [ 69,  73, 296, 355],\n",
      "        [321, 189, 585, 360],\n",
      "        [221,  98, 243, 176],\n",
      "        [279, 131, 372, 346]], dtype=torch.int32), 'scores': tensor([0.9526, 0.2324, 0.5917, 0.2466, 0.3437]), 'objectness_scores': tensor([0.6333, 0.2041, 0.4929, 0.2081, 0.4894]), 'labels': tensor([ 6,  4,  3,  7, 11], dtype=torch.int32)}\n",
      "182805\n",
      "{'image_id': 182923, 'boxes': tensor([[226,  17, 242,  22],\n",
      "        [200,  61, 216,  66],\n",
      "        [239, 150, 247, 160],\n",
      "        [103,  36, 110,  44],\n",
      "        [336,  52, 354,  58],\n",
      "        [ 22, 159,  31, 164],\n",
      "        [143, 118, 161, 135],\n",
      "        [226, 120, 244, 140],\n",
      "        [ 44,   0,  65,  12],\n",
      "        [ 92, 122, 232, 255],\n",
      "        [ 64,  42,  80,  48],\n",
      "        [138, 105, 169, 123],\n",
      "        [118, 390, 163, 430],\n",
      "        [ 34, 111,  49, 155],\n",
      "        [222, 224, 244, 241],\n",
      "        [273,  22, 288,  27],\n",
      "        [242,  59, 258,  64],\n",
      "        [133, 214, 225, 264],\n",
      "        [149,   0, 167,  13],\n",
      "        [ 25,  49,  40,  54],\n",
      "        [320,  29, 335,  35],\n",
      "        [311, 117, 328, 133],\n",
      "        [218,  26, 227,  33],\n",
      "        [267, 227, 284, 243],\n",
      "        [122,  48, 138,  55],\n",
      "        [241, 377, 267, 427],\n",
      "        [148,  11, 159,  22],\n",
      "        [336,  42, 359,  56],\n",
      "        [222,  66, 228,  73],\n",
      "        [177, 119, 197, 137]], dtype=torch.int32), 'scores': tensor([0.1871, 0.1824, 0.1582, 0.2238, 0.2535, 0.1548, 0.2730, 0.2359, 0.2672,\n",
      "        0.3217, 0.2298, 0.1567, 0.2278, 0.2272, 0.2129, 0.2387, 0.1984, 0.2767,\n",
      "        0.2839, 0.2429, 0.3227, 0.2859, 0.1496, 0.2346, 0.3682, 0.2389, 0.1883,\n",
      "        0.2443, 0.1912, 0.3399]), 'objectness_scores': tensor([0.2466, 0.2618, 0.2541, 0.2718, 0.3137, 0.3783, 0.4874, 0.5111, 0.3510,\n",
      "        0.2516, 0.3023, 0.3064, 0.2002, 0.4861, 0.2975, 0.2251, 0.2522, 0.2109,\n",
      "        0.2484, 0.2471, 0.3081, 0.5065, 0.2023, 0.2393, 0.2892, 0.2061, 0.4051,\n",
      "        0.2967, 0.3251, 0.4977]), 'labels': tensor([10, 10, 11, 11, 10, 11, 11, 11, 11,  4, 10, 11,  9, 11,  4, 10, 11,  7,\n",
      "         3, 10, 10, 14, 13,  0, 11, 11, 14, 11, 11, 11], dtype=torch.int32)}\n",
      "182923\n",
      "{'image_id': 183437, 'boxes': tensor([[282, 297, 328, 351],\n",
      "        [ 74, 296, 378, 617],\n",
      "        [203, 212, 212, 220],\n",
      "        [ 79, 252, 138, 316],\n",
      "        [ 80, 250, 198, 319]], dtype=torch.int32), 'scores': tensor([0.9770, 0.9990, 0.2355, 0.4740, 0.3963]), 'objectness_scores': tensor([0.4167, 0.5892, 0.2106, 0.4369, 0.2961]), 'labels': tensor([ 3,  5, 14,  5,  7], dtype=torch.int32)}\n",
      "183437\n",
      "{'image_id': 183500, 'boxes': tensor([[151, 148, 189, 261],\n",
      "        [ 93,  73, 540, 342],\n",
      "        [ 95, 161, 494, 340]], dtype=torch.int32), 'scores': tensor([0.1889, 0.9714, 0.9430]), 'objectness_scores': tensor([0.3164, 0.5056, 0.2199]), 'labels': tensor([9, 0, 0], dtype=torch.int32)}\n",
      "183500\n",
      "{'image_id': 183648, 'boxes': tensor([[134, 209, 219, 258],\n",
      "        [262, 197, 314, 227]], dtype=torch.int32), 'scores': tensor([0.2213, 0.2878]), 'objectness_scores': tensor([0.2220, 0.2146]), 'labels': tensor([ 7, 10], dtype=torch.int32)}\n",
      "183648\n",
      "{'image_id': 183716, 'boxes': tensor([[218, 221, 273, 475],\n",
      "        [ 82,  58, 103,  69],\n",
      "        [ 44, 431,  74, 464],\n",
      "        [ 12, 424, 130, 466],\n",
      "        [ 84, 259, 118, 300],\n",
      "        [  3,  17, 348, 497],\n",
      "        [  4, 221, 225, 493]], dtype=torch.int32), 'scores': tensor([0.9998, 0.4593, 0.3044, 0.5635, 0.9955, 0.4207, 0.9882]), 'objectness_scores': tensor([0.6227, 0.2418, 0.2093, 0.3944, 0.5320, 0.2409, 0.2489]), 'labels': tensor([ 7, 14, 14,  7,  7, 12,  7], dtype=torch.int32)}\n",
      "183716\n",
      "{'image_id': 183965, 'boxes': tensor([[159,  97, 294, 229],\n",
      "        [ 70,  78, 363, 431],\n",
      "        [  4,   5, 635, 481],\n",
      "        [134,  90, 300, 236],\n",
      "        [309, 151, 591, 398],\n",
      "        [100, 193, 350, 410]], dtype=torch.int32), 'scores': tensor([0.9299, 0.5235, 0.7562, 0.9761, 0.9465, 0.6381]), 'objectness_scores': tensor([0.2875, 0.2940, 0.2623, 0.2842, 0.2400, 0.2423]), 'labels': tensor([10, 10, 12, 10, 12, 12], dtype=torch.int32)}\n",
      "183965\n",
      "{'image_id': 184324, 'boxes': tensor([[372, 182, 392, 210],\n",
      "        [ 28, 148,  86, 184],\n",
      "        [514, 170, 623, 211],\n",
      "        [  0, 157,  88, 214],\n",
      "        [307, 218, 316, 228]], dtype=torch.int32), 'scores': tensor([0.2928, 0.2887, 0.2946, 0.4681, 0.2012]), 'objectness_scores': tensor([0.2010, 0.2078, 0.2363, 0.2081, 0.2133]), 'labels': tensor([ 8,  9,  7, 12, 11], dtype=torch.int32)}\n",
      "184324\n",
      "{'image_id': 184384, 'boxes': tensor([[440,  98, 494, 134],\n",
      "        [ 94,   2, 214, 212],\n",
      "        [392,  56, 637, 182],\n",
      "        [607,  75, 639, 286],\n",
      "        [  2, 167, 635, 478],\n",
      "        [108, 217, 640, 481],\n",
      "        [255,  54, 639, 183],\n",
      "        [406,  59, 627, 161],\n",
      "        [237, 249, 488, 457]], dtype=torch.int32), 'scores': tensor([0.2028, 0.8206, 0.3460, 0.3398, 0.9564, 0.9967, 0.9165, 0.3710, 0.6353]), 'objectness_scores': tensor([0.3155, 0.5728, 0.4386, 0.2301, 0.4191, 0.4266, 0.2576, 0.2325, 0.2348]), 'labels': tensor([11, 12, 11,  7, 12,  3, 12, 11, 12], dtype=torch.int32)}\n",
      "184384\n",
      "{'image_id': 184978, 'boxes': tensor([[  1,   7, 479, 637],\n",
      "        [175, 467, 204, 484],\n",
      "        [203, 308, 226, 319],\n",
      "        [157, 313, 254, 400],\n",
      "        [201, 294, 225, 312],\n",
      "        [152, 465, 177, 483],\n",
      "        [232, 378, 248, 399],\n",
      "        [157, 391, 233, 477],\n",
      "        [145, 382, 163, 405]], dtype=torch.int32), 'scores': tensor([0.9837, 0.1788, 0.7732, 0.9829, 0.4444, 0.2763, 0.1822, 0.9835, 0.3671]), 'objectness_scores': tensor([0.2649, 0.2230, 0.4865, 0.2465, 0.2170, 0.2235, 0.3738, 0.2312, 0.3029]), 'labels': tensor([ 8, 11, 15,  8,  8,  8,  8,  8,  8], dtype=torch.int32)}\n",
      "184978\n",
      "{'image_id': 185250, 'boxes': tensor([[165, 388, 279, 567]], dtype=torch.int32), 'scores': tensor([0.9751]), 'objectness_scores': tensor([0.4901]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "185250\n",
      "{'image_id': 185802, 'boxes': tensor([[342, 342, 396, 367],\n",
      "        [313, 337, 396, 369],\n",
      "        [384, 323, 427, 368]], dtype=torch.int32), 'scores': tensor([0.3369, 0.6062, 0.2962]), 'objectness_scores': tensor([0.2242, 0.2062, 0.3209]), 'labels': tensor([8, 9, 6], dtype=torch.int32)}\n",
      "185802\n",
      "{'image_id': 185950, 'boxes': tensor([[162, 281, 204, 300],\n",
      "        [138, 288, 195, 317],\n",
      "        [154, 307, 196, 355],\n",
      "        [121, 178, 254, 295]], dtype=torch.int32), 'scores': tensor([0.7566, 0.7097, 0.2323, 0.7667]), 'objectness_scores': tensor([0.2096, 0.2069, 0.5174, 0.2146]), 'labels': tensor([11,  9, 14,  9], dtype=torch.int32)}\n",
      "185950\n",
      "{'image_id': 186282, 'boxes': tensor([[605, 192, 639, 347],\n",
      "        [424, 198, 509, 308],\n",
      "        [116, 253, 637, 427],\n",
      "        [516, 187, 620, 331],\n",
      "        [229, 327, 638, 427]], dtype=torch.int32), 'scores': tensor([0.1295, 0.5132, 0.4708, 0.2537, 0.2058]), 'objectness_scores': tensor([0.2924, 0.2445, 0.4336, 0.7134, 0.3591]), 'labels': tensor([11, 14, 14,  7, 16], dtype=torch.int32)}\n",
      "186282\n",
      "{'image_id': 186632, 'boxes': tensor([[204, 368, 238, 390],\n",
      "        [142, 361, 181, 414],\n",
      "        [248, 339, 352, 379],\n",
      "        [229, 343, 252, 398],\n",
      "        [413, 386, 439, 440],\n",
      "        [441, 379, 480, 460],\n",
      "        [174,   2, 479, 177],\n",
      "        [313, 476, 480, 578],\n",
      "        [ 16, 378, 479, 641],\n",
      "        [163, 405, 193, 453],\n",
      "        [326, 398, 377, 412],\n",
      "        [186, 372, 203, 400],\n",
      "        [371, 423, 433, 534],\n",
      "        [326, 379, 375, 409],\n",
      "        [366, 411, 412, 443],\n",
      "        [205, 430, 316, 500]], dtype=torch.int32), 'scores': tensor([0.6328, 0.3891, 0.4039, 0.4188, 0.1134, 0.4190, 0.4002, 0.9778, 0.7831,\n",
      "        0.1607, 0.1999, 0.4307, 0.4087, 0.4978, 0.2059, 0.3742]), 'objectness_scores': tensor([0.2323, 0.4423, 0.3257, 0.3650, 0.3838, 0.4040, 0.3577, 0.3877, 0.2282,\n",
      "        0.2595, 0.2036, 0.2029, 0.3014, 0.3147, 0.2570, 0.3940]), 'labels': tensor([ 2, 15, 12, 11,  9, 15, 14, 15, 15,  7, 11, 11,  9,  9, 13, 12],\n",
      "       dtype=torch.int32)}\n",
      "186632\n",
      "{'image_id': 186980, 'boxes': tensor([[320, 183, 351, 217],\n",
      "        [174, 187, 202, 206],\n",
      "        [164,  90, 174, 108],\n",
      "        [207, 265, 214, 303],\n",
      "        [155, 189, 184, 250],\n",
      "        [251, 176, 287, 216],\n",
      "        [145,   0, 315, 187],\n",
      "        [ 12, 318, 409, 636]], dtype=torch.int32), 'scores': tensor([0.2224, 0.4298, 0.3439, 0.2229, 0.1811, 0.2131, 0.2005, 0.3421]), 'objectness_scores': tensor([0.2179, 0.2488, 0.2014, 0.2177, 0.2845, 0.2461, 0.2416, 0.2837]), 'labels': tensor([ 7, 14, 11, 11,  8, 11,  6, 15], dtype=torch.int32)}\n",
      "186980\n",
      "{'image_id': 187144, 'boxes': tensor([[133, 288, 162, 345],\n",
      "        [  0, 123, 391, 381],\n",
      "        [346, 225, 379, 239],\n",
      "        [363, 232, 405, 248],\n",
      "        [333, 224, 402, 248]], dtype=torch.int32), 'scores': tensor([0.4531, 0.9984, 0.3413, 0.1957, 0.4973]), 'objectness_scores': tensor([0.2470, 0.5119, 0.2224, 0.2030, 0.2677]), 'labels': tensor([ 1,  1, 14,  1,  1], dtype=torch.int32)}\n",
      "187144\n",
      "{'image_id': 187236, 'boxes': tensor([[207,   0, 488, 165],\n",
      "        [  0, 221, 408, 480],\n",
      "        [253,  50, 560, 224]], dtype=torch.int32), 'scores': tensor([0.8164, 0.8638, 0.9174]), 'objectness_scores': tensor([0.4893, 0.4855, 0.5462]), 'labels': tensor([2, 2, 2], dtype=torch.int32)}\n",
      "187236\n",
      "{'image_id': 187243, 'boxes': tensor([[ 20,   0,  63,  30],\n",
      "        [323, 346, 374, 484],\n",
      "        [ 52, 366, 305, 640],\n",
      "        [121,  39, 146,  51],\n",
      "        [363,   0, 438,  72],\n",
      "        [146, 132, 173, 164],\n",
      "        [114, 267, 284, 366],\n",
      "        [296,   0, 371,  60],\n",
      "        [ 55,  30,  94,  77],\n",
      "        [146, 132, 172, 184],\n",
      "        [  0,  25,  69,  57],\n",
      "        [ 65,   0,  87,  32],\n",
      "        [131,   0, 153,  45],\n",
      "        [192, 146, 263, 259]], dtype=torch.int32), 'scores': tensor([0.4075, 0.4242, 0.2690, 0.2871, 0.1626, 0.1973, 0.1729, 0.5909, 0.8582,\n",
      "        0.4260, 0.2598, 0.4006, 0.6343, 0.7606]), 'objectness_scores': tensor([0.4028, 0.2349, 0.2858, 0.2466, 0.2422, 0.4506, 0.2064, 0.2092, 0.2957,\n",
      "        0.3569, 0.2466, 0.2520, 0.2769, 0.4399]), 'labels': tensor([ 8, 11,  9, 11,  7, 11, 12,  7, 11, 11, 11,  7,  7, 10],\n",
      "       dtype=torch.int32)}\n",
      "187243\n",
      "{'image_id': 187513, 'boxes': tensor([[171, 186, 198, 211],\n",
      "        [307, 459, 390, 576],\n",
      "        [ 65, 264, 141, 279],\n",
      "        [245,  52, 314,  84],\n",
      "        [  0, 566,  75, 639],\n",
      "        [  0, 184,  42, 419],\n",
      "        [  0,  95,  36, 171],\n",
      "        [  1, 480, 135, 536],\n",
      "        [380, 168, 426, 646],\n",
      "        [153, 464, 179, 487],\n",
      "        [190,   0, 346,  40],\n",
      "        [  7, 474,  61, 506],\n",
      "        [  5, 517, 182, 640],\n",
      "        [  0, 233,  41, 415],\n",
      "        [377, 436, 393, 450],\n",
      "        [  0, 131,  37, 171]], dtype=torch.int32), 'scores': tensor([0.6214, 0.2901, 0.2216, 0.3192, 0.3386, 0.7675, 0.2912, 0.9572, 0.2904,\n",
      "        0.2688, 0.1777, 0.2485, 0.9719, 0.2911, 0.2646, 0.1527]), 'objectness_scores': tensor([0.3537, 0.3144, 0.3099, 0.2827, 0.2116, 0.3641, 0.3799, 0.5882, 0.2243,\n",
      "        0.2153, 0.2312, 0.6255, 0.3993, 0.2518, 0.2976, 0.2082]), 'labels': tensor([11,  7,  0, 11, 13, 11, 10, 15,  7, 16,  9, 15, 15, 11, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "187513\n",
      "{'image_id': 187585, 'boxes': tensor([[174, 148, 243, 228],\n",
      "        [154,   0, 388, 243],\n",
      "        [107,  15, 172,  92],\n",
      "        [ 65,  11, 214, 294],\n",
      "        [250, 273, 266, 293]], dtype=torch.int32), 'scores': tensor([0.3798, 0.6465, 0.6894, 0.7022, 0.4094]), 'objectness_scores': tensor([0.2212, 0.2016, 0.2307, 0.5682, 0.3673]), 'labels': tensor([11,  9,  9,  9, 11], dtype=torch.int32)}\n",
      "187585\n",
      "{'image_id': 187990, 'boxes': tensor([[331, 170, 373, 208],\n",
      "        [332, 176, 376, 222],\n",
      "        [425, 125, 450, 164]], dtype=torch.int32), 'scores': tensor([0.1869, 0.6762, 0.8362]), 'objectness_scores': tensor([0.2120, 0.4960, 0.2488]), 'labels': tensor([ 8, 11,  7], dtype=torch.int32)}\n",
      "187990\n",
      "{'image_id': 189436, 'boxes': tensor([[320, 238, 481, 393],\n",
      "        [ 79, 242, 323, 370]], dtype=torch.int32), 'scores': tensor([0.2328, 0.9514]), 'objectness_scores': tensor([0.2990, 0.5906]), 'labels': tensor([12,  7], dtype=torch.int32)}\n",
      "189436\n",
      "{'image_id': 189475, 'boxes': tensor([[354, 244, 402, 259],\n",
      "        [408, 221, 445, 290],\n",
      "        [323, 306, 457, 358],\n",
      "        [111, 164, 145, 186],\n",
      "        [ 68, 258, 102, 286],\n",
      "        [164, 251, 204, 365],\n",
      "        [ 56, 256, 104, 287],\n",
      "        [357, 243, 402, 302],\n",
      "        [454, 247, 498, 371],\n",
      "        [375, 198, 415, 272],\n",
      "        [199, 303, 336, 360]], dtype=torch.int32), 'scores': tensor([0.3578, 0.4468, 0.2764, 0.1646, 0.5698, 0.2183, 0.7696, 0.3995, 0.2823,\n",
      "        0.3590, 0.4195]), 'objectness_scores': tensor([0.2453, 0.3779, 0.3489, 0.3481, 0.2688, 0.4144, 0.2559, 0.3069, 0.3568,\n",
      "        0.4212, 0.2045]), 'labels': tensor([11, 10,  0,  2, 11, 10, 11, 10,  7,  6, 12], dtype=torch.int32)}\n",
      "189475\n",
      "{'image_id': 189752, 'boxes': tensor([[181,  13, 204,  66],\n",
      "        [239, 195, 436, 268],\n",
      "        [502,  62, 618, 224],\n",
      "        [ 83, 352, 497, 438],\n",
      "        [ 43,  62,  75, 117],\n",
      "        [  0, 273, 282, 480]], dtype=torch.int32), 'scores': tensor([0.2084, 0.9325, 0.5646, 0.8732, 0.2588, 0.4636]), 'objectness_scores': tensor([0.2084, 0.2209, 0.2726, 0.4135, 0.2303, 0.2025]), 'labels': tensor([ 7, 12, 10, 11, 10,  7], dtype=torch.int32)}\n",
      "189752\n",
      "{'image_id': 189820, 'boxes': tensor([[ 27, 110,  78, 123],\n",
      "        [367, 159, 438, 182],\n",
      "        [ 30, 165,  85, 267],\n",
      "        [  0, 317, 320, 425],\n",
      "        [ 89, 348, 278, 426],\n",
      "        [249, 186, 309, 216]], dtype=torch.int32), 'scores': tensor([0.2738, 0.5197, 0.3330, 0.9364, 0.9941, 0.9957]), 'objectness_scores': tensor([0.2142, 0.2041, 0.2597, 0.2083, 0.3071, 0.2295]), 'labels': tensor([11, 14,  8, 14, 14, 14], dtype=torch.int32)}\n",
      "189820\n",
      "{'image_id': 190140, 'boxes': tensor([[221, 159, 249, 167],\n",
      "        [384, 189, 413, 205],\n",
      "        [219, 141, 249, 163],\n",
      "        [356, 155, 432, 302]], dtype=torch.int32), 'scores': tensor([0.3205, 0.4773, 0.1460, 0.7974]), 'objectness_scores': tensor([0.3506, 0.3598, 0.3580, 0.5388]), 'labels': tensor([11, 11, 11,  8], dtype=torch.int32)}\n",
      "190140\n",
      "{'image_id': 190236, 'boxes': tensor([[ 79,  47, 133, 177],\n",
      "        [197, 133, 237, 156],\n",
      "        [ 62, 208, 102, 262],\n",
      "        [  9, 133, 310, 370],\n",
      "        [303, 116, 560, 307]], dtype=torch.int32), 'scores': tensor([0.6453, 0.9323, 0.2215, 0.2509, 0.4794]), 'objectness_scores': tensor([0.2660, 0.2152, 0.2232, 0.2024, 0.2453]), 'labels': tensor([14,  8,  9,  8, 14], dtype=torch.int32)}\n",
      "190236\n",
      "{'image_id': 190676, 'boxes': tensor([[  1,  60, 225, 149],\n",
      "        [  1, 111,  53, 149],\n",
      "        [ 29,  75, 143,  86],\n",
      "        [535,  92, 544,  98]], dtype=torch.int32), 'scores': tensor([0.3106, 0.2861, 0.2670, 0.1898]), 'objectness_scores': tensor([0.5427, 0.3163, 0.2546, 0.2420]), 'labels': tensor([ 6,  9,  0, 14], dtype=torch.int32)}\n",
      "190676\n",
      "{'image_id': 190753, 'boxes': tensor([[182, 317, 254, 422],\n",
      "        [246, 248, 269, 267],\n",
      "        [261, 253, 293, 272],\n",
      "        [226, 310, 253, 331]], dtype=torch.int32), 'scores': tensor([0.4146, 0.2852, 0.3370, 0.3326]), 'objectness_scores': tensor([0.2000, 0.2100, 0.2168, 0.2166]), 'labels': tensor([ 9, 11, 11, 14], dtype=torch.int32)}\n",
      "190753\n",
      "{'image_id': 190841, 'boxes': tensor([[339,  50, 372,  83],\n",
      "        [324, 222, 638, 286],\n",
      "        [346, 183, 446, 203],\n",
      "        [252, 111, 268, 137],\n",
      "        [590, 176, 598, 186],\n",
      "        [496, 172, 509, 188],\n",
      "        [594, 177, 602, 190],\n",
      "        [439, 174, 461, 189],\n",
      "        [202, 176, 237, 212],\n",
      "        [206, 177, 234, 200]], dtype=torch.int32), 'scores': tensor([0.3920, 0.6230, 0.3125, 0.1858, 0.2149, 0.3133, 0.1965, 0.2771, 0.1587,\n",
      "        0.1619]), 'objectness_scores': tensor([0.2716, 0.2874, 0.4591, 0.2066, 0.3126, 0.4522, 0.5882, 0.2079, 0.2179,\n",
      "        0.3396]), 'labels': tensor([ 8,  9, 11,  9, 14, 11, 14, 14,  7, 14], dtype=torch.int32)}\n",
      "190841\n",
      "{'image_id': 191580, 'boxes': tensor([[  0,   3, 477, 632],\n",
      "        [  2,   1, 442, 185],\n",
      "        [ 59, 153, 413, 498],\n",
      "        [386, 187, 451, 451],\n",
      "        [  0, 104, 475, 619]], dtype=torch.int32), 'scores': tensor([0.3755, 0.4629, 0.3960, 0.5266, 0.3690]), 'objectness_scores': tensor([0.4100, 0.2492, 0.3997, 0.6551, 0.2033]), 'labels': tensor([11,  7, 11,  7, 11], dtype=torch.int32)}\n",
      "191580\n",
      "{'image_id': 191845, 'boxes': tensor([[173,   0, 224,  21],\n",
      "        [296,  28, 345,  69],\n",
      "        [ 51,  83, 103, 123],\n",
      "        [215,  68, 278, 108],\n",
      "        [251, 155, 318, 201],\n",
      "        [471,   0, 509,  15],\n",
      "        [565,  31, 639,  87],\n",
      "        [209,  12, 248,  49],\n",
      "        [166,  43, 219,  77],\n",
      "        [436, 242, 547, 313],\n",
      "        [395, 253, 438, 309],\n",
      "        [ 84,  15, 131,  48],\n",
      "        [ 47, 175, 119, 223],\n",
      "        [106, 208, 178, 257],\n",
      "        [ 52, 139, 115, 179],\n",
      "        [430,   0, 477,  15],\n",
      "        [210, 133, 249, 187],\n",
      "        [ 23,  89,  64, 125],\n",
      "        [366, 136, 444, 199],\n",
      "        [259,  67, 326, 114],\n",
      "        [297, 260, 347, 322],\n",
      "        [  0, 132,  20, 162],\n",
      "        [394, 167, 482, 221],\n",
      "        [402,   9, 467,  41],\n",
      "        [199, 182, 268, 234]], dtype=torch.int32), 'scores': tensor([0.2374, 0.9643, 0.8579, 0.9947, 0.1714, 0.3464, 0.9980, 0.4040, 0.2588,\n",
      "        0.9996, 0.2381, 0.7216, 0.9966, 0.2466, 0.9385, 0.2668, 0.6572, 0.2488,\n",
      "        0.7739, 0.1831, 0.3605, 0.4147, 0.9954, 0.3473, 0.4097]), 'objectness_scores': tensor([0.2451, 0.3462, 0.3623, 0.3621, 0.3623, 0.2534, 0.3691, 0.3477, 0.3816,\n",
      "        0.3661, 0.3684, 0.3483, 0.3714, 0.3753, 0.3405, 0.2504, 0.3522, 0.3782,\n",
      "        0.3979, 0.3724, 0.3189, 0.2144, 0.3934, 0.3460, 0.3949]), 'labels': tensor([ 7,  6,  6,  6, 11, 11,  6,  9,  7,  6,  6,  6,  6,  8,  6, 11,  9,  0,\n",
      "         6, 11,  9,  9,  6,  6,  8], dtype=torch.int32)}\n",
      "191845\n",
      "{'image_id': 192904, 'boxes': tensor([[300, 246, 442, 350],\n",
      "        [ 86,  23, 611, 429],\n",
      "        [177, 161, 264, 245],\n",
      "        [278,  47, 378, 127],\n",
      "        [158, 177, 289, 273],\n",
      "        [300, 118, 395, 229],\n",
      "        [301, 227, 415, 320],\n",
      "        [157,  37, 578, 368]], dtype=torch.int32), 'scores': tensor([0.9780, 0.7867, 0.9986, 0.4272, 0.9883, 0.9496, 0.9916, 0.9567]), 'objectness_scores': tensor([0.2971, 0.2156, 0.3637, 0.2028, 0.2872, 0.3800, 0.3303, 0.2249]), 'labels': tensor([10, 15, 10, 12, 10, 10, 10, 10], dtype=torch.int32)}\n",
      "192904\n",
      "{'image_id': 192964, 'boxes': tensor([[103, 320, 173, 352],\n",
      "        [ 81, 332, 185, 385],\n",
      "        [134, 275, 198, 316]], dtype=torch.int32), 'scores': tensor([0.1732, 0.7697, 0.1999]), 'objectness_scores': tensor([0.3648, 0.6869, 0.3943]), 'labels': tensor([ 2,  9, 15], dtype=torch.int32)}\n",
      "192964\n",
      "{'image_id': 193162, 'boxes': tensor([[415,  97, 438, 113]], dtype=torch.int32), 'scores': tensor([0.1745]), 'objectness_scores': tensor([0.3127]), 'labels': tensor([4], dtype=torch.int32)}\n",
      "193162\n",
      "{'image_id': 193429, 'boxes': tensor([[249, 104, 292, 139],\n",
      "        [348, 268, 388, 292],\n",
      "        [  1,   8, 636, 430],\n",
      "        [384, 263, 421, 289],\n",
      "        [257, 276, 291, 302],\n",
      "        [251, 107, 292, 132]], dtype=torch.int32), 'scores': tensor([0.5978, 0.2556, 0.9945, 0.2555, 0.4952, 0.4976]), 'objectness_scores': tensor([0.3462, 0.2401, 0.2209, 0.2536, 0.2235, 0.3702]), 'labels': tensor([ 8,  8,  8,  8, 11,  8], dtype=torch.int32)}\n",
      "193429\n",
      "{'image_id': 193674, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "193674\n",
      "{'image_id': 194471, 'boxes': tensor([[121, 297, 182, 357],\n",
      "        [147, 163, 175, 181],\n",
      "        [216, 215, 231, 317],\n",
      "        [ 96, 229, 210, 331],\n",
      "        [125, 306, 254, 364]], dtype=torch.int32), 'scores': tensor([0.5354, 0.1888, 0.3353, 0.3271, 0.5139]), 'objectness_scores': tensor([0.3647, 0.2478, 0.2678, 0.2373, 0.6149]), 'labels': tensor([ 8,  8, 11, 14,  9], dtype=torch.int32)}\n",
      "194471\n",
      "{'image_id': 194724, 'boxes': tensor([[  5, 125, 634, 480],\n",
      "        [568, 221, 640, 285],\n",
      "        [512, 132, 609, 261],\n",
      "        [161, 238, 619, 481],\n",
      "        [  1, 242, 187, 407],\n",
      "        [  0, 190, 185, 412]], dtype=torch.int32), 'scores': tensor([0.3125, 0.6206, 0.9868, 0.3854, 0.7476, 0.8399]), 'objectness_scores': tensor([0.3170, 0.3647, 0.4089, 0.2407, 0.2093, 0.2084]), 'labels': tensor([12, 14, 10, 12, 12, 12], dtype=torch.int32)}\n",
      "194724\n",
      "{'image_id': 194832, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "194832\n",
      "{'image_id': 194875, 'boxes': tensor([[343, 288, 396, 328],\n",
      "        [434,  15, 471,  62],\n",
      "        [275,   1, 310,  62],\n",
      "        [357, 187, 368, 205],\n",
      "        [560, 188, 578, 206],\n",
      "        [ 43, 322, 110, 373],\n",
      "        [409, 195, 420, 211],\n",
      "        [416, 210, 430, 235],\n",
      "        [374, 166, 412, 206],\n",
      "        [117, 284, 156, 308]], dtype=torch.int32), 'scores': tensor([0.5316, 0.2567, 0.2303, 0.2244, 0.2120, 0.2943, 0.2720, 0.1688, 0.1462,\n",
      "        0.2373]), 'objectness_scores': tensor([0.2608, 0.3098, 0.2830, 0.3718, 0.2711, 0.2171, 0.4797, 0.2599, 0.2414,\n",
      "        0.2262]), 'labels': tensor([ 8,  6, 11, 11, 11,  7, 11, 11,  2,  8], dtype=torch.int32)}\n",
      "194875\n",
      "{'image_id': 194940, 'boxes': tensor([[400, 269, 432, 304],\n",
      "        [  0,   1, 495, 374],\n",
      "        [323, 243, 350, 273],\n",
      "        [212, 175, 246, 255],\n",
      "        [351, 271, 411, 314],\n",
      "        [313, 221, 431, 328],\n",
      "        [160, 144, 287, 269],\n",
      "        [329, 261, 415, 287],\n",
      "        [384, 270, 425, 281],\n",
      "        [258, 195, 289, 258],\n",
      "        [337, 271, 394, 323],\n",
      "        [357, 305, 387, 328],\n",
      "        [340, 250, 397, 262],\n",
      "        [159, 190, 180, 240]], dtype=torch.int32), 'scores': tensor([0.6841, 0.7886, 0.5741, 0.2913, 0.5894, 0.2250, 0.2469, 0.6285, 0.5713,\n",
      "        0.4968, 0.3581, 0.4714, 0.4184, 0.3745]), 'objectness_scores': tensor([0.3211, 0.3650, 0.3468, 0.2064, 0.3790, 0.2700, 0.2356, 0.4023, 0.2104,\n",
      "        0.3736, 0.4190, 0.2875, 0.3164, 0.2048]), 'labels': tensor([ 7, 10, 11, 14, 11, 11,  4, 11, 11, 11, 11, 11, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "194940\n",
      "{'image_id': 195165, 'boxes': tensor([[  0, 256,  22, 280],\n",
      "        [114,  75, 131,  92],\n",
      "        [395, 262, 436, 296],\n",
      "        [340,   0, 470, 241],\n",
      "        [353, 290, 498, 331],\n",
      "        [317, 416, 459, 478],\n",
      "        [486, 320, 508, 336],\n",
      "        [257, 275, 330, 327],\n",
      "        [437, 273, 477, 301],\n",
      "        [329, 317, 477, 349],\n",
      "        [510,  96, 594, 133],\n",
      "        [ 46, 339,  74, 372]], dtype=torch.int32), 'scores': tensor([0.6640, 0.3644, 0.2203, 0.3524, 0.3227, 0.2774, 0.1584, 0.2767, 0.3941,\n",
      "        0.5093, 0.2113, 0.1480]), 'objectness_scores': tensor([0.2546, 0.2157, 0.2984, 0.3355, 0.6032, 0.3440, 0.2020, 0.2968, 0.2610,\n",
      "        0.4447, 0.2098, 0.2080]), 'labels': tensor([11,  6, 10,  8,  9,  0, 11,  9,  9, 11,  7, 14], dtype=torch.int32)}\n",
      "195165\n",
      "{'image_id': 195754, 'boxes': tensor([[519, 119, 606, 221],\n",
      "        [189, 192, 343, 282],\n",
      "        [233, 246, 393, 345],\n",
      "        [518, 119, 604, 316],\n",
      "        [  5,  -2, 629, 430],\n",
      "        [490, 246, 598, 322],\n",
      "        [155, 232, 227, 303],\n",
      "        [362, 168, 434, 219]], dtype=torch.int32), 'scores': tensor([0.2568, 0.9972, 0.9605, 0.2999, 0.9590, 0.3090, 0.5199, 0.2581]), 'objectness_scores': tensor([0.2573, 0.4476, 0.4112, 0.3201, 0.2020, 0.2313, 0.2416, 0.2850]), 'labels': tensor([10, 13, 13, 13, 13, 10, 13,  8], dtype=torch.int32)}\n",
      "195754\n",
      "{'image_id': 195842, 'boxes': tensor([[231, 110, 293, 141],\n",
      "        [ 26, 114, 335, 379],\n",
      "        [367, 303, 458, 380]], dtype=torch.int32), 'scores': tensor([0.7584, 0.4758, 0.7277]), 'objectness_scores': tensor([0.2412, 0.2823, 0.2205]), 'labels': tensor([13, 13, 12], dtype=torch.int32)}\n",
      "195842\n",
      "{'image_id': 195918, 'boxes': tensor([[413,  63, 431, 112],\n",
      "        [236, 227, 286, 268],\n",
      "        [464, 212, 497, 258],\n",
      "        [554, 224, 584, 260],\n",
      "        [  1, 238, 636, 425],\n",
      "        [ 99, 298, 265, 337]], dtype=torch.int32), 'scores': tensor([0.4961, 0.6424, 0.3264, 0.4965, 0.8226, 0.9458]), 'objectness_scores': tensor([0.2472, 0.4361, 0.3699, 0.4188, 0.3825, 0.7775]), 'labels': tensor([11, 14, 11, 14, 14, 14], dtype=torch.int32)}\n",
      "195918\n",
      "{'image_id': 196843, 'boxes': tensor([[  0,  52, 630, 434],\n",
      "        [161, 211, 606, 320]], dtype=torch.int32), 'scores': tensor([0.9982, 0.9959]), 'objectness_scores': tensor([0.5232, 0.2180]), 'labels': tensor([1, 1], dtype=torch.int32)}\n",
      "196843\n",
      "{'image_id': 197004, 'boxes': tensor([[ 90, 239, 529, 405],\n",
      "        [  5,  38, 638, 428],\n",
      "        [  0,  92,  62, 211],\n",
      "        [143, 217, 459, 350],\n",
      "        [  0, 220,  88, 361],\n",
      "        [  0, 333, 306, 429]], dtype=torch.int32), 'scores': tensor([0.4555, 0.6314, 0.2095, 0.3853, 0.3422, 0.3636]), 'objectness_scores': tensor([0.2131, 0.3853, 0.2651, 0.2308, 0.2328, 0.2139]), 'labels': tensor([15,  4, 12,  4, 11, 11], dtype=torch.int32)}\n",
      "197004\n",
      "{'image_id': 197796, 'boxes': tensor([[115, 122, 151, 206],\n",
      "        [460, 142, 589, 297],\n",
      "        [ 84, 249, 372, 432],\n",
      "        [238,  89, 282, 165],\n",
      "        [ 37,   8, 127, 101],\n",
      "        [277,  59, 306, 167],\n",
      "        [  7,   1, 639, 485],\n",
      "        [206, 246, 253, 307],\n",
      "        [427,  55, 628, 465],\n",
      "        [ 76,  95, 123, 220],\n",
      "        [  8, 212,  44, 248]], dtype=torch.int32), 'scores': tensor([0.2659, 0.7826, 0.9991, 0.7538, 0.4384, 0.4050, 0.9586, 0.4337, 0.6151,\n",
      "        0.3813, 0.3036]), 'objectness_scores': tensor([0.2616, 0.3751, 0.4460, 0.3328, 0.3168, 0.2998, 0.2063, 0.4479, 0.3183,\n",
      "        0.2492, 0.2485]), 'labels': tensor([ 7,  7, 15, 10, 10,  7, 15,  9,  7,  8,  7], dtype=torch.int32)}\n",
      "197796\n",
      "{'image_id': 198489, 'boxes': tensor([[116, 289, 148, 521],\n",
      "        [105, 172, 261, 315],\n",
      "        [301,  29, 312,  41]], dtype=torch.int32), 'scores': tensor([0.3354, 0.3401, 0.2713]), 'objectness_scores': tensor([0.2144, 0.2265, 0.2503]), 'labels': tensor([ 7,  6, 11], dtype=torch.int32)}\n",
      "198489\n",
      "{'image_id': 198641, 'boxes': tensor([[309,  72, 336, 100],\n",
      "        [307,  72, 337, 117],\n",
      "        [  4, 287, 634, 477],\n",
      "        [172, 193, 491, 423]], dtype=torch.int32), 'scores': tensor([0.2818, 0.2821, 0.5806, 0.7520]), 'objectness_scores': tensor([0.3023, 0.2392, 0.3283, 0.5226]), 'labels': tensor([7, 7, 2, 2], dtype=torch.int32)}\n",
      "198641\n",
      "{'image_id': 198928, 'boxes': tensor([[126, 368, 207, 387],\n",
      "        [264, 232, 288, 279],\n",
      "        [297, 394, 325, 455],\n",
      "        [261, 238, 286, 398],\n",
      "        [282,   0, 349, 111],\n",
      "        [ 24, 354,  33, 399],\n",
      "        [262, 315, 285, 325],\n",
      "        [238, 331, 249, 407],\n",
      "        [137, 347, 147, 403],\n",
      "        [407, 311, 420, 381],\n",
      "        [274,   3, 368, 615],\n",
      "        [277, 321, 309, 358],\n",
      "        [295, 175, 349, 294],\n",
      "        [261, 201, 279, 223],\n",
      "        [ 83, 351,  91, 400],\n",
      "        [424, 341, 434, 399],\n",
      "        [205, 339, 214, 405],\n",
      "        [252, 288, 268, 409],\n",
      "        [  0, 322,  11, 383]], dtype=torch.int32), 'scores': tensor([0.4145, 0.6037, 0.4945, 0.2989, 0.8307, 0.2202, 0.4047, 0.2645, 0.6171,\n",
      "        0.3084, 0.2987, 0.6659, 0.6656, 0.5494, 0.2182, 0.3718, 0.2658, 0.2787,\n",
      "        0.4159]), 'objectness_scores': tensor([0.4225, 0.2096, 0.4182, 0.2539, 0.2230, 0.2062, 0.2456, 0.2593, 0.2546,\n",
      "        0.2172, 0.3262, 0.2065, 0.5087, 0.2539, 0.2780, 0.2767, 0.2702, 0.2784,\n",
      "        0.2040]), 'labels': tensor([ 7,  6,  8,  9,  6, 11, 14, 11,  1, 14,  1,  7,  8,  7, 11, 11, 11, 11,\n",
      "        11], dtype=torch.int32)}\n",
      "198928\n",
      "{'image_id': 199055, 'boxes': tensor([[157, 492, 347, 612],\n",
      "        [253, 235, 279, 265],\n",
      "        [232,  80, 293, 103]], dtype=torch.int32), 'scores': tensor([0.9697, 0.9965, 0.6384]), 'objectness_scores': tensor([0.6291, 0.3639, 0.2867]), 'labels': tensor([ 9,  5, 10], dtype=torch.int32)}\n",
      "199055\n",
      "{'image_id': 199771, 'boxes': tensor([[156,  70, 176,  89],\n",
      "        [306, 103, 339, 130],\n",
      "        [ 58,  61,  94,  84],\n",
      "        [395,   0, 428,  55],\n",
      "        [412,  67, 495, 122],\n",
      "        [310,  29, 393,  88],\n",
      "        [392, 337, 528, 405],\n",
      "        [365, 262, 439, 420],\n",
      "        [289, 292, 372, 422],\n",
      "        [ 44,  91,  86, 119]], dtype=torch.int32), 'scores': tensor([0.2344, 0.3593, 0.1731, 0.2974, 0.2277, 0.5858, 0.7270, 0.3583, 0.9263,\n",
      "        0.9044]), 'objectness_scores': tensor([0.2673, 0.2104, 0.2714, 0.2881, 0.2508, 0.2544, 0.2074, 0.3220, 0.2879,\n",
      "        0.2703]), 'labels': tensor([11,  7, 11,  8,  7,  7, 11, 16, 10, 10], dtype=torch.int32)}\n",
      "199771\n",
      "{'image_id': 200839, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "200839\n",
      "{'image_id': 201426, 'boxes': tensor([[493, 282, 584, 392],\n",
      "        [ 47, 305, 167, 455],\n",
      "        [186, 375, 430, 460],\n",
      "        [625, 123, 640, 143],\n",
      "        [ 34, 362, 649, 491]], dtype=torch.int32), 'scores': tensor([0.9611, 0.9895, 0.5473, 0.1964, 0.4697]), 'objectness_scores': tensor([0.3956, 0.4130, 0.2607, 0.2333, 0.3167]), 'labels': tensor([10, 10, 12, 11, 12], dtype=torch.int32)}\n",
      "201426\n",
      "{'image_id': 201646, 'boxes': tensor([[ 34, 135, 179, 188]], dtype=torch.int32), 'scores': tensor([0.2663]), 'objectness_scores': tensor([0.3328]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "201646\n",
      "{'image_id': 201775, 'boxes': tensor([[  4,   0, 499, 382],\n",
      "        [267, 160, 306, 233],\n",
      "        [ 31, 250,  65, 279],\n",
      "        [  0, 240, 145, 330],\n",
      "        [ 10, 133,  33, 178],\n",
      "        [390, 152, 436, 199],\n",
      "        [  0,   0,  72, 219]], dtype=torch.int32), 'scores': tensor([0.9070, 0.6398, 0.2776, 0.9627, 0.3332, 0.8472, 0.6141]), 'objectness_scores': tensor([0.2289, 0.3035, 0.5214, 0.7064, 0.3384, 0.2017, 0.6136]), 'labels': tensor([15, 15, 11, 15,  6, 15,  7], dtype=torch.int32)}\n",
      "201775\n",
      "{'image_id': 201934, 'boxes': tensor([[366, 181, 409, 249],\n",
      "        [209,  14, 251,  35],\n",
      "        [278,  60, 301,  84]], dtype=torch.int32), 'scores': tensor([0.2555, 0.6664, 0.1488]), 'objectness_scores': tensor([0.2150, 0.2905, 0.3189]), 'labels': tensor([14, 14,  0], dtype=torch.int32)}\n",
      "201934\n",
      "{'image_id': 202001, 'boxes': tensor([[321, 179, 330, 189],\n",
      "        [  4, 278, 498, 461]], dtype=torch.int32), 'scores': tensor([0.1886, 0.9958]), 'objectness_scores': tensor([0.5742, 0.4579]), 'labels': tensor([11,  7], dtype=torch.int32)}\n",
      "202001\n",
      "{'image_id': 202339, 'boxes': tensor([[194,  67, 464, 296],\n",
      "        [147, 107, 163, 174]], dtype=torch.int32), 'scores': tensor([0.9982, 0.5148]), 'objectness_scores': tensor([0.5107, 0.2791]), 'labels': tensor([ 1, 11], dtype=torch.int32)}\n",
      "202339\n",
      "{'image_id': 202445, 'boxes': tensor([[147, 272, 582, 535]], dtype=torch.int32), 'scores': tensor([0.9804]), 'objectness_scores': tensor([0.5217]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "202445\n",
      "{'image_id': 203294, 'boxes': tensor([[435, 148, 460, 224],\n",
      "        [ 71, 304,  86, 312],\n",
      "        [319, 153, 335, 209]], dtype=torch.int32), 'scores': tensor([0.2120, 0.3643, 0.3883]), 'objectness_scores': tensor([0.2839, 0.2215, 0.2647]), 'labels': tensor([ 8, 11,  3], dtype=torch.int32)}\n",
      "203294\n",
      "{'image_id': 203580, 'boxes': tensor([[ 85, 258, 147, 362],\n",
      "        [ 42, 257, 148, 363],\n",
      "        [157,   5, 172,  28],\n",
      "        [430, 273, 465, 316],\n",
      "        [319,  54, 574, 138],\n",
      "        [316,  55, 575, 273]], dtype=torch.int32), 'scores': tensor([0.4123, 0.4120, 0.2345, 0.2759, 0.9980, 0.9993]), 'objectness_scores': tensor([0.2224, 0.2625, 0.2197, 0.3397, 0.2172, 0.3975]), 'labels': tensor([8, 9, 7, 8, 6, 6], dtype=torch.int32)}\n",
      "203580\n",
      "{'image_id': 203629, 'boxes': tensor([[464, 193, 471, 199]], dtype=torch.int32), 'scores': tensor([0.1382]), 'objectness_scores': tensor([0.2498]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "203629\n",
      "{'image_id': 203639, 'boxes': tensor([[141,  36, 197, 108],\n",
      "        [144, 247, 286, 346],\n",
      "        [284, 310, 297, 321],\n",
      "        [199, 150, 243, 240],\n",
      "        [129, 227, 313, 407],\n",
      "        [171, 549, 208, 610],\n",
      "        [173, 239, 257, 273],\n",
      "        [145, 566, 194, 621],\n",
      "        [ 93, 127, 297, 315]], dtype=torch.int32), 'scores': tensor([0.4228, 0.9167, 0.2678, 0.9965, 0.4525, 0.1500, 0.3223, 0.2200, 0.6450]), 'objectness_scores': tensor([0.2923, 0.2567, 0.3332, 0.4949, 0.2305, 0.2613, 0.4857, 0.2628, 0.2167]), 'labels': tensor([ 7,  7,  7,  1,  7, 13, 11,  7,  7], dtype=torch.int32)}\n",
      "203639\n",
      "{'image_id': 204871, 'boxes': tensor([[451, 115, 506, 149],\n",
      "        [213,  99, 230, 121],\n",
      "        [ 43, 141,  67, 183],\n",
      "        [235,  60, 248,  92],\n",
      "        [209,  47, 244,  62],\n",
      "        [222,   9, 247,  39]], dtype=torch.int32), 'scores': tensor([0.4177, 0.3018, 0.2307, 0.6399, 0.5656, 0.4788]), 'objectness_scores': tensor([0.2619, 0.3524, 0.2189, 0.2566, 0.5942, 0.3678]), 'labels': tensor([ 1, 11, 14, 11, 14, 14], dtype=torch.int32)}\n",
      "204871\n",
      "{'image_id': 205401, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "205401\n",
      "{'image_id': 205514, 'boxes': tensor([[422, 196, 490, 237],\n",
      "        [  1, 284, 268, 387],\n",
      "        [345, 194, 436, 253],\n",
      "        [343, 194, 533, 310],\n",
      "        [356, 146, 388, 210],\n",
      "        [366, 205, 397, 228],\n",
      "        [327, 242, 362, 291],\n",
      "        [423, 200, 494, 240],\n",
      "        [ 46, 247, 144, 337],\n",
      "        [608, 239, 640, 267],\n",
      "        [433, 325, 641, 426],\n",
      "        [326, 256, 382, 316]], dtype=torch.int32), 'scores': tensor([0.4267, 0.1649, 0.9132, 0.9952, 0.2526, 0.2790, 0.3191, 0.9098, 0.4449,\n",
      "        0.2661, 0.6375, 0.4278]), 'objectness_scores': tensor([0.2416, 0.2419, 0.2653, 0.5158, 0.3448, 0.3912, 0.3302, 0.3143, 0.3618,\n",
      "        0.2008, 0.2327, 0.2199]), 'labels': tensor([13,  3, 13, 13,  7, 11,  1, 13,  6, 11, 15, 13], dtype=torch.int32)}\n",
      "205514\n",
      "{'image_id': 205834, 'boxes': tensor([[144,  17, 542, 412],\n",
      "        [  4,   0, 114, 155]], dtype=torch.int32), 'scores': tensor([0.9794, 0.2852]), 'objectness_scores': tensor([0.4552, 0.2001]), 'labels': tensor([3, 9], dtype=torch.int32)}\n",
      "205834\n",
      "{'image_id': 206025, 'boxes': tensor([[168, 373, 254, 639],\n",
      "        [  3, 321, 419, 635],\n",
      "        [128, 187, 296, 223]], dtype=torch.int32), 'scores': tensor([0.9977, 0.9998, 0.2047]), 'objectness_scores': tensor([0.5057, 0.2897, 0.2683]), 'labels': tensor([7, 7, 7], dtype=torch.int32)}\n",
      "206025\n",
      "{'image_id': 206135, 'boxes': tensor([[124,   0, 177, 192],\n",
      "        [ 17,   2, 296, 333],\n",
      "        [305, 276, 321, 333],\n",
      "        [173, 302, 232, 436]], dtype=torch.int32), 'scores': tensor([0.4731, 0.1709, 0.4622, 0.8362]), 'objectness_scores': tensor([0.2802, 0.2135, 0.2480, 0.6927]), 'labels': tensor([7, 3, 8, 4], dtype=torch.int32)}\n",
      "206135\n",
      "{'image_id': 206218, 'boxes': tensor([[211,  47, 387, 225],\n",
      "        [317, 186, 358, 241],\n",
      "        [264, 182, 364, 279],\n",
      "        [104,   0, 191,  76],\n",
      "        [191,   0, 236,  71],\n",
      "        [391, 232, 566, 274],\n",
      "        [  0,  16, 169, 262],\n",
      "        [209, 112, 330, 148]], dtype=torch.int32), 'scores': tensor([0.4296, 0.6838, 0.4332, 0.3304, 0.2790, 0.9965, 0.2357, 0.4627]), 'objectness_scores': tensor([0.2819, 0.2225, 0.2294, 0.2131, 0.3596, 0.2145, 0.3411, 0.2582]), 'labels': tensor([ 9, 14, 14,  8, 11, 14, 15, 11], dtype=torch.int32)}\n",
      "206218\n",
      "{'image_id': 206487, 'boxes': tensor([[489, 196, 523, 230],\n",
      "        [496, 305, 513, 316],\n",
      "        [ 39, 369,  98, 405],\n",
      "        [563, 340, 620, 368],\n",
      "        [521, 203, 549, 234],\n",
      "        [  0, 367,  98, 406],\n",
      "        [493, 318, 516, 331],\n",
      "        [  0, 369,  39, 403],\n",
      "        [610, 125, 639, 159],\n",
      "        [576, 294, 605, 331]], dtype=torch.int32), 'scores': tensor([0.2335, 0.2715, 0.2717, 0.2507, 0.6625, 0.7475, 0.6570, 0.5110, 0.3528,\n",
      "        0.3000]), 'objectness_scores': tensor([0.2330, 0.2018, 0.2771, 0.2149, 0.2580, 0.2085, 0.2087, 0.2334, 0.2921,\n",
      "        0.3222]), 'labels': tensor([12, 11,  7, 14,  9, 14, 14, 14,  9,  8], dtype=torch.int32)}\n",
      "206487\n",
      "{'image_id': 206579, 'boxes': tensor([[391, 294, 587, 401],\n",
      "        [291, 176, 639, 479],\n",
      "        [400, 218, 577, 396],\n",
      "        [402, 276, 578, 396]], dtype=torch.int32), 'scores': tensor([0.9869, 0.9987, 0.9987, 0.9973]), 'objectness_scores': tensor([0.2391, 0.3255, 0.3025, 0.5143]), 'labels': tensor([12, 12, 12, 12], dtype=torch.int32)}\n",
      "206579\n",
      "{'image_id': 207844, 'boxes': tensor([[371, 200, 437, 233],\n",
      "        [207, 194, 250, 221],\n",
      "        [  1, 169, 253, 331],\n",
      "        [  2, 260, 637, 478],\n",
      "        [239, 194, 361, 271],\n",
      "        [385, 150, 640, 249],\n",
      "        [180, 193, 252, 256],\n",
      "        [376, 150, 637, 313]], dtype=torch.int32), 'scores': tensor([0.3025, 0.2858, 0.9490, 0.4533, 0.9793, 0.7292, 0.8481, 0.9726]), 'objectness_scores': tensor([0.2097, 0.2304, 0.3509, 0.2150, 0.3141, 0.2242, 0.2369, 0.2826]), 'labels': tensor([8, 8, 6, 6, 6, 6, 6, 6], dtype=torch.int32)}\n",
      "207844\n",
      "{'image_id': 209142, 'boxes': tensor([[347, 357, 372, 380],\n",
      "        [304, 235, 325, 256],\n",
      "        [377,  28, 420,  40],\n",
      "        [ 97, 161, 120, 185],\n",
      "        [390, 226, 413, 250],\n",
      "        [360, 338, 387, 364],\n",
      "        [556, 296, 572, 319],\n",
      "        [455, 244, 529, 277],\n",
      "        [421, 133, 440, 153],\n",
      "        [ 82, 247, 103, 270],\n",
      "        [562, 212, 585, 243],\n",
      "        [130, 331, 151, 353],\n",
      "        [373,  10, 398,  32],\n",
      "        [425,  56, 446,  75],\n",
      "        [  1,   0,  62,  80],\n",
      "        [259, 245, 327, 290],\n",
      "        [ 72, 235,  95, 258],\n",
      "        [161, 214, 184, 238],\n",
      "        [100, 308, 118, 329],\n",
      "        [193, 172, 211, 190],\n",
      "        [195, 214, 219, 235],\n",
      "        [206, 105, 231, 123],\n",
      "        [ 61,   6, 590, 424],\n",
      "        [382, 269, 409, 295],\n",
      "        [269,  21, 288,  40],\n",
      "        [400,  24, 429,  39],\n",
      "        [537, 201, 559, 228],\n",
      "        [320, 367, 361, 409]], dtype=torch.int32), 'scores': tensor([0.2066, 0.1967, 0.3865, 0.2101, 0.2216, 0.1762, 0.2284, 0.5452, 0.4344,\n",
      "        0.2417, 0.3617, 0.2090, 0.3576, 0.2377, 0.1891, 0.7159, 0.2863, 0.1964,\n",
      "        0.1725, 0.1893, 0.2228, 0.5322, 0.2846, 0.4461, 0.2259, 0.2263, 0.3160,\n",
      "        0.3882]), 'objectness_scores': tensor([0.2153, 0.2305, 0.2236, 0.3169, 0.2085, 0.2071, 0.2290, 0.3020, 0.2201,\n",
      "        0.2881, 0.2358, 0.2722, 0.3399, 0.2008, 0.2202, 0.2040, 0.2618, 0.2503,\n",
      "        0.2049, 0.2325, 0.2809, 0.2466, 0.3838, 0.2228, 0.2372, 0.2947, 0.2340,\n",
      "        0.3094]), 'labels': tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11,  7,  7, 11, 11, 11, 11,  7], dtype=torch.int32)}\n",
      "209142\n",
      "{'image_id': 209530, 'boxes': tensor([[132,  82, 243, 106],\n",
      "        [398,   9, 451, 171]], dtype=torch.int32), 'scores': tensor([0.6281, 0.5897]), 'objectness_scores': tensor([0.2039, 0.2049]), 'labels': tensor([8, 8], dtype=torch.int32)}\n",
      "209530\n",
      "{'image_id': 209613, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "209613\n",
      "{'image_id': 209757, 'boxes': tensor([[ 72, 225,  86, 230],\n",
      "        [284,  44, 324,  93],\n",
      "        [167, 311, 315, 343],\n",
      "        [212, 219, 395, 265],\n",
      "        [393, 212, 403, 220],\n",
      "        [390, 195, 402, 215],\n",
      "        [ 67, 207,  87, 227]], dtype=torch.int32), 'scores': tensor([0.2338, 0.1443, 0.2529, 0.3667, 0.5934, 0.5133, 0.2564]), 'objectness_scores': tensor([0.2376, 0.3099, 0.5143, 0.2034, 0.2632, 0.2378, 0.2288]), 'labels': tensor([11,  2,  9,  4, 11, 11, 16], dtype=torch.int32)}\n",
      "209757\n",
      "{'image_id': 210030, 'boxes': tensor([[ 32,  71, 471, 310],\n",
      "        [  3,   3, 499, 401],\n",
      "        [166,  94, 324, 271]], dtype=torch.int32), 'scores': tensor([0.9719, 0.9998, 0.9996]), 'objectness_scores': tensor([0.5082, 0.5172, 0.2507]), 'labels': tensor([ 3, 12, 12], dtype=torch.int32)}\n",
      "210030\n",
      "{'image_id': 210032, 'boxes': tensor([[  1, 182, 536, 402]], dtype=torch.int32), 'scores': tensor([0.5031]), 'objectness_scores': tensor([0.2551]), 'labels': tensor([4], dtype=torch.int32)}\n",
      "210032\n",
      "{'image_id': 210099, 'boxes': tensor([[137,  76, 293, 453]], dtype=torch.int32), 'scores': tensor([0.7835]), 'objectness_scores': tensor([0.5336]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "210099\n",
      "{'image_id': 210273, 'boxes': tensor([[224, 134, 295, 220],\n",
      "        [339,  89, 387, 142],\n",
      "        [ 94, 188, 221, 318]], dtype=torch.int32), 'scores': tensor([0.9965, 0.9906, 0.9949]), 'objectness_scores': tensor([0.4860, 0.4611, 0.5356]), 'labels': tensor([1, 1, 1], dtype=torch.int32)}\n",
      "210273\n",
      "{'image_id': 210394, 'boxes': tensor([[ 40,  93,  73, 137]], dtype=torch.int32), 'scores': tensor([0.4836]), 'objectness_scores': tensor([0.2209]), 'labels': tensor([8], dtype=torch.int32)}\n",
      "210394\n",
      "{'image_id': 210520, 'boxes': tensor([[394, 378, 420, 543],\n",
      "        [233, 494, 270, 525],\n",
      "        [  0, 203, 125, 341],\n",
      "        [477, 346, 538, 436],\n",
      "        [211, 452, 229, 477],\n",
      "        [363,  94, 468, 223],\n",
      "        [265,  34, 332, 209],\n",
      "        [344, 138, 452, 259],\n",
      "        [501, 179, 517, 195],\n",
      "        [287, 364, 390, 413],\n",
      "        [ 90,   2, 244, 223],\n",
      "        [218, 347, 290, 448],\n",
      "        [543, 475, 610, 523],\n",
      "        [529, 330, 612, 394],\n",
      "        [268,   0, 365, 113],\n",
      "        [510, 392, 590, 479],\n",
      "        [ 76, 374, 186, 577],\n",
      "        [508, 239, 525, 258],\n",
      "        [  1,   0, 605, 603],\n",
      "        [576,  89, 605, 118],\n",
      "        [590, 355, 611, 433],\n",
      "        [473, 116, 494, 139],\n",
      "        [515,   0, 576,  46],\n",
      "        [163, 268, 233, 334],\n",
      "        [  0,  93,  54, 219],\n",
      "        [280, 457, 301, 480],\n",
      "        [264, 252, 314, 302],\n",
      "        [495, 107, 527, 140],\n",
      "        [197, 343, 400, 547],\n",
      "        [541,  94, 574, 120],\n",
      "        [423,   0, 488,  42],\n",
      "        [449, 292, 608, 594]], dtype=torch.int32), 'scores': tensor([0.5862, 0.1956, 0.9006, 0.3434, 0.2362, 0.5751, 0.7935, 0.7071, 0.3169,\n",
      "        0.2921, 0.4147, 0.4014, 0.3271, 0.7200, 0.9322, 0.4596, 0.6327, 0.1581,\n",
      "        0.2545, 0.2177, 0.2960, 0.2583, 0.3278, 0.7304, 0.5927, 0.2388, 0.6286,\n",
      "        0.2098, 0.2759, 0.2379, 0.5982, 0.4757]), 'objectness_scores': tensor([0.4635, 0.2263, 0.3515, 0.4199, 0.2615, 0.3767, 0.3178, 0.3144, 0.2063,\n",
      "        0.5616, 0.3208, 0.2214, 0.3933, 0.4195, 0.3666, 0.4699, 0.4603, 0.2227,\n",
      "        0.2550, 0.2085, 0.2004, 0.2563, 0.2830, 0.2845, 0.2200, 0.2213, 0.2088,\n",
      "        0.2029, 0.2879, 0.2005, 0.2716, 0.3342]), 'labels': tensor([11, 12, 10,  7, 11, 10, 10, 10, 11,  7, 10,  8,  7,  7, 10,  7,  8, 11,\n",
      "        11, 11, 11, 11, 15, 10,  8, 11, 10, 11, 11,  7, 10,  7],\n",
      "       dtype=torch.int32)}\n",
      "210520\n",
      "{'image_id': 210789, 'boxes': tensor([[194, 400, 218, 428],\n",
      "        [193, 249, 201, 262],\n",
      "        [ 29,  82, 309, 225],\n",
      "        [165, 398, 198, 421],\n",
      "        [126, 272, 194, 379],\n",
      "        [159, 423, 178, 442],\n",
      "        [133, 420, 153, 437]], dtype=torch.int32), 'scores': tensor([0.2620, 0.2509, 0.9960, 0.3562, 0.9990, 0.2563, 0.4724]), 'objectness_scores': tensor([0.2232, 0.3678, 0.5950, 0.2107, 0.3050, 0.2221, 0.2044]), 'labels': tensor([ 8, 11,  6, 11,  7,  4, 11], dtype=torch.int32)}\n",
      "210789\n",
      "{'image_id': 210855, 'boxes': tensor([[342, 367, 383, 411],\n",
      "        [333, 317, 385, 352],\n",
      "        [  2,   6, 136, 426],\n",
      "        [446, 184, 461, 206],\n",
      "        [528, 280, 578, 312],\n",
      "        [504, 351, 539, 389],\n",
      "        [349,  16, 614, 245],\n",
      "        [463, 259, 478, 283],\n",
      "        [493, 187, 522, 231],\n",
      "        [414, 262, 426, 267],\n",
      "        [415, 280, 504, 302],\n",
      "        [533, 273, 553, 285],\n",
      "        [368,  77, 402, 213],\n",
      "        [409, 262, 433, 275],\n",
      "        [574, 285, 601, 308],\n",
      "        [440, 261, 455, 279],\n",
      "        [504, 353, 593, 402]], dtype=torch.int32), 'scores': tensor([0.2520, 0.7828, 0.1879, 0.3963, 0.2769, 0.5392, 0.8325, 0.2835, 0.3200,\n",
      "        0.1747, 0.2550, 0.4004, 0.3927, 0.1645, 0.3465, 0.2885, 0.6388]), 'objectness_scores': tensor([0.3694, 0.3940, 0.2087, 0.2416, 0.3069, 0.2170, 0.5503, 0.5518, 0.3561,\n",
      "        0.2905, 0.6139, 0.2240, 0.2268, 0.2268, 0.2444, 0.2062, 0.3045]), 'labels': tensor([ 8, 13,  5, 11, 11, 13, 15,  9,  7, 11,  9, 11, 11,  9, 11,  9,  7],\n",
      "       dtype=torch.int32)}\n",
      "210855\n",
      "{'image_id': 211042, 'boxes': tensor([[ 12,  49, 214, 253],\n",
      "        [ 35,  85,  81, 109],\n",
      "        [164, 191, 280, 534],\n",
      "        [ 25,  47,  56,  95],\n",
      "        [  0, 168,  50, 244],\n",
      "        [256, 141, 285, 176],\n",
      "        [ 55, 344, 132, 491]], dtype=torch.int32), 'scores': tensor([0.9232, 0.3296, 0.8016, 0.1898, 0.7606, 0.1954, 0.2567]), 'objectness_scores': tensor([0.2583, 0.2241, 0.5014, 0.5327, 0.2081, 0.3012, 0.5293]), 'labels': tensor([15,  9,  2, 11, 13,  3,  7], dtype=torch.int32)}\n",
      "211042\n",
      "{'image_id': 211674, 'boxes': tensor([[209,  39, 535, 390],\n",
      "        [453, 238, 498, 247],\n",
      "        [ 57, 265,  76, 291]], dtype=torch.int32), 'scores': tensor([0.9994, 0.3149, 0.2807]), 'objectness_scores': tensor([0.5432, 0.2963, 0.2204]), 'labels': tensor([ 1, 11, 11], dtype=torch.int32)}\n",
      "211674\n",
      "{'image_id': 211825, 'boxes': tensor([[302, 207, 308, 237],\n",
      "        [  4, 260, 639, 480],\n",
      "        [321, 206, 327, 236],\n",
      "        [399, 243, 435, 267],\n",
      "        [237, 206, 371, 348],\n",
      "        [256, 225, 263, 259],\n",
      "        [445, 295, 529, 379],\n",
      "        [282, 204, 287, 236],\n",
      "        [265, 224, 271, 261],\n",
      "        [289, 239, 295, 268],\n",
      "        [  3, 290,  48, 310],\n",
      "        [240, 233, 369, 349],\n",
      "        [292, 207, 297, 237],\n",
      "        [312, 206, 318, 237],\n",
      "        [272, 207, 278, 238]], dtype=torch.int32), 'scores': tensor([0.2510, 0.9987, 0.2370, 0.4964, 0.9984, 0.2417, 0.3345, 0.3370, 0.1864,\n",
      "        0.1915, 0.2911, 0.9957, 0.3055, 0.2916, 0.2098]), 'objectness_scores': tensor([0.2276, 0.2080, 0.2160, 0.2153, 0.3668, 0.2163, 0.5257, 0.2283, 0.2043,\n",
      "        0.2102, 0.2823, 0.2828, 0.2345, 0.2098, 0.2486]), 'labels': tensor([11, 12, 11,  7, 12, 14, 10, 11, 11, 14, 11, 12, 11, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "211825\n",
      "{'image_id': 212573, 'boxes': tensor([[549, 133, 571, 153],\n",
      "        [483, 144, 492, 156],\n",
      "        [ 82,  72,  94,  90],\n",
      "        [163,  56, 172,  65],\n",
      "        [251,  10, 429,  69],\n",
      "        [341, 314, 378, 428],\n",
      "        [289, 321, 318, 429],\n",
      "        [144,  93, 151, 104],\n",
      "        [272, 200, 380, 307]], dtype=torch.int32), 'scores': tensor([0.2025, 0.1724, 0.2305, 0.2321, 0.9824, 0.2932, 0.4688, 0.2271, 0.3406]), 'objectness_scores': tensor([0.3174, 0.2634, 0.3083, 0.2582, 0.5065, 0.3405, 0.3293, 0.2655, 0.3988]), 'labels': tensor([14, 14, 14, 14,  6,  7,  7, 11,  9], dtype=torch.int32)}\n",
      "212573\n",
      "{'image_id': 212800, 'boxes': tensor([[ 51, 135, 120, 179],\n",
      "        [ 64, 130, 137, 177],\n",
      "        [188, 170, 276, 220],\n",
      "        [304, 151, 419, 237],\n",
      "        [186, 120, 251, 147],\n",
      "        [110, 129, 140, 148],\n",
      "        [186, 120, 250, 171],\n",
      "        [426, 149, 511, 220],\n",
      "        [110, 118, 224, 170],\n",
      "        [159, 152, 204, 172],\n",
      "        [340, 107, 455, 156],\n",
      "        [340, 123, 453, 162],\n",
      "        [109, 115, 224, 203],\n",
      "        [ 26, 132, 104, 179],\n",
      "        [257, 165, 357, 239],\n",
      "        [232, 115, 343, 174]], dtype=torch.int32), 'scores': tensor([0.4890, 0.9906, 0.9951, 0.9528, 0.3763, 0.2134, 0.9988, 0.9666, 0.9991,\n",
      "        0.8708, 0.3953, 0.4486, 0.9842, 0.8210, 0.9954, 0.9990]), 'objectness_scores': tensor([0.2926, 0.3856, 0.3305, 0.4188, 0.2715, 0.2175, 0.3928, 0.4254, 0.2020,\n",
      "        0.2364, 0.4520, 0.2113, 0.3978, 0.4174, 0.3485, 0.4680]), 'labels': tensor([11,  6,  6,  6, 11, 11,  6,  6,  6, 11,  6, 11,  6,  6,  6,  6],\n",
      "       dtype=torch.int32)}\n",
      "212800\n",
      "{'image_id': 213033, 'boxes': tensor([[305, 341, 319, 358],\n",
      "        [298, 342, 302, 350],\n",
      "        [ 22, 138, 340, 341]], dtype=torch.int32), 'scores': tensor([0.2814, 0.3226, 0.9935]), 'objectness_scores': tensor([0.2283, 0.3621, 0.5049]), 'labels': tensor([11, 11,  6], dtype=torch.int32)}\n",
      "213033\n",
      "{'image_id': 213445, 'boxes': tensor([[  1,   0, 103, 219],\n",
      "        [336,   1, 408, 122],\n",
      "        [108, 110, 306, 395],\n",
      "        [  2, 203, 404, 497],\n",
      "        [236,   0, 297,  99],\n",
      "        [211,   5, 407, 298],\n",
      "        [ 54, 347, 404, 499],\n",
      "        [339,  44, 406, 139]], dtype=torch.int32), 'scores': tensor([0.1707, 0.7989, 0.9795, 0.9400, 0.1848, 0.7497, 0.5845, 0.4276]), 'objectness_scores': tensor([0.2015, 0.2621, 0.5091, 0.2562, 0.2218, 0.5252, 0.4476, 0.3591]), 'labels': tensor([8, 7, 2, 2, 7, 2, 2, 7], dtype=torch.int32)}\n",
      "213445\n",
      "{'image_id': 213547, 'boxes': tensor([[328, 351, 349, 367],\n",
      "        [232, 267, 250, 292],\n",
      "        [249, 305, 300, 345],\n",
      "        [268, 305, 277, 329],\n",
      "        [185, 411, 193, 418],\n",
      "        [119, 141, 195, 244],\n",
      "        [ 44, 320,  61, 350],\n",
      "        [ 47,  49,  61,  85],\n",
      "        [ 35, 358,  47, 390],\n",
      "        [  1, 139, 197, 242],\n",
      "        [249, 325, 299, 345],\n",
      "        [259, 304, 268, 328],\n",
      "        [352, 104, 375, 129],\n",
      "        [232, 334, 316, 354],\n",
      "        [468,  55, 480,  96],\n",
      "        [282, 306, 292, 332]], dtype=torch.int32), 'scores': tensor([0.2034, 0.2784, 0.9645, 0.2503, 0.2136, 0.6458, 0.2539, 0.1397, 0.2272,\n",
      "        0.4233, 0.3336, 0.2115, 0.2873, 0.9601, 0.2646, 0.2895]), 'objectness_scores': tensor([0.2371, 0.3832, 0.4325, 0.2256, 0.3263, 0.2043, 0.2393, 0.2057, 0.2012,\n",
      "        0.2236, 0.2472, 0.2694, 0.2110, 0.2727, 0.2107, 0.2708]), 'labels': tensor([11, 11, 12, 11, 11, 12, 14, 14,  0,  9, 11, 11, 14,  7, 14, 11],\n",
      "       dtype=torch.int32)}\n",
      "213547\n",
      "{'image_id': 213605, 'boxes': tensor([[ 29, 366, 345, 567],\n",
      "        [428, 488, 473, 496],\n",
      "        [217,   1, 278, 260],\n",
      "        [ 61, 165, 115, 203],\n",
      "        [419, 513, 446, 526],\n",
      "        [285, 288, 345, 315],\n",
      "        [426, 497, 437, 506],\n",
      "        [  0, 491,  41, 560],\n",
      "        [463, 494, 479, 512],\n",
      "        [363, 492, 399, 512]], dtype=torch.int32), 'scores': tensor([0.9969, 0.2350, 0.3786, 0.2171, 0.5009, 0.1771, 0.1806, 0.2477, 0.2160,\n",
      "        0.4320]), 'objectness_scores': tensor([0.6079, 0.2117, 0.3236, 0.2252, 0.2255, 0.3214, 0.2307, 0.2938, 0.2702,\n",
      "        0.3199]), 'labels': tensor([ 1, 11,  6, 14, 14, 11,  0, 11,  8, 11], dtype=torch.int32)}\n",
      "213605\n",
      "{'image_id': 214224, 'boxes': tensor([[102, 204, 198, 379],\n",
      "        [114, 203, 198, 316],\n",
      "        [431, 316, 492, 374],\n",
      "        [425, 219, 496, 371]], dtype=torch.int32), 'scores': tensor([0.9529, 0.9816, 0.7277, 0.2959]), 'objectness_scores': tensor([0.4620, 0.2920, 0.2599, 0.2486]), 'labels': tensor([10, 10, 12,  7], dtype=torch.int32)}\n",
      "214224\n",
      "{'image_id': 214720, 'boxes': tensor([[173, 124, 375, 218],\n",
      "        [112, 321, 209, 389],\n",
      "        [ 69, 322, 140, 354],\n",
      "        [ 91,  82, 134, 149],\n",
      "        [ 35, 129, 373, 265],\n",
      "        [244, 195, 369, 285],\n",
      "        [  2, 402, 155, 471],\n",
      "        [ 96, 327, 226, 397]], dtype=torch.int32), 'scores': tensor([0.9436, 0.9985, 0.3532, 0.1650, 0.3792, 0.1919, 0.1750, 0.9959]), 'objectness_scores': tensor([0.4017, 0.4950, 0.2537, 0.2375, 0.2170, 0.2174, 0.2993, 0.2328]), 'labels': tensor([13, 12,  8, 14, 13, 14, 11, 12], dtype=torch.int32)}\n",
      "214720\n",
      "{'image_id': 215072, 'boxes': tensor([[245, 364, 285, 402],\n",
      "        [248,   0, 640, 321],\n",
      "        [255, 390, 374, 449],\n",
      "        [242,  -1, 635, 392]], dtype=torch.int32), 'scores': tensor([0.9871, 0.9392, 0.3413, 0.7811]), 'objectness_scores': tensor([0.3517, 0.2021, 0.2035, 0.3125]), 'labels': tensor([10,  6, 15,  6], dtype=torch.int32)}\n",
      "215072\n",
      "{'image_id': 215259, 'boxes': tensor([[222, 401, 239, 413],\n",
      "        [  0, 223, 122, 371],\n",
      "        [ 43, 223, 153, 387],\n",
      "        [149, 318, 197, 391],\n",
      "        [124, 412, 158, 443],\n",
      "        [148, 318, 258, 392],\n",
      "        [184, 223, 258, 431],\n",
      "        [179, 426, 221, 449],\n",
      "        [ 22, 363,  50, 395],\n",
      "        [238, 327, 335, 428],\n",
      "        [152, 283, 201, 333],\n",
      "        [  0, 268,  51, 300],\n",
      "        [270, 342, 327, 377]], dtype=torch.int32), 'scores': tensor([0.3150, 0.8393, 0.4928, 0.5765, 0.2060, 0.5835, 0.6212, 0.5651, 0.2650,\n",
      "        0.2698, 0.3767, 0.2233, 0.1886]), 'objectness_scores': tensor([0.4634, 0.4614, 0.2817, 0.2360, 0.3539, 0.3201, 0.2104, 0.4968, 0.3138,\n",
      "        0.2745, 0.2291, 0.2145, 0.2026]), 'labels': tensor([11, 13, 13,  7,  9, 13,  7, 11,  8, 13, 13, 11,  1], dtype=torch.int32)}\n",
      "215259\n",
      "{'image_id': 215723, 'boxes': tensor([[ 80,  52, 118,  84],\n",
      "        [307, 116, 429, 153],\n",
      "        [ 52,   0, 140,  51],\n",
      "        [367,   0, 499, 153]], dtype=torch.int32), 'scores': tensor([0.2701, 0.4024, 0.2507, 0.4763]), 'objectness_scores': tensor([0.2208, 0.2015, 0.2958, 0.3527]), 'labels': tensor([ 8, 14,  8,  7], dtype=torch.int32)}\n",
      "215723\n",
      "{'image_id': 215778, 'boxes': tensor([[  0, 162, 629, 426],\n",
      "        [528, 144, 637, 209],\n",
      "        [472, 139, 541, 199],\n",
      "        [561, 201, 615, 232]], dtype=torch.int32), 'scores': tensor([0.9242, 0.8439, 0.9775, 0.5677]), 'objectness_scores': tensor([0.2590, 0.4721, 0.2190, 0.2405]), 'labels': tensor([14, 14, 10,  7], dtype=torch.int32)}\n",
      "215778\n",
      "{'image_id': 216497, 'boxes': tensor([[  1, 306,  89, 348],\n",
      "        [ 57, 284,  91, 312],\n",
      "        [425, 113, 578, 174],\n",
      "        [545,  85, 638, 173],\n",
      "        [536, 235, 637, 272],\n",
      "        [  8, 270,  51, 311],\n",
      "        [ 50, 265,  76, 286],\n",
      "        [379, 248, 433, 257],\n",
      "        [ 45, 273,  80, 309],\n",
      "        [373, 221, 388, 253],\n",
      "        [  0, 262, 114, 440],\n",
      "        [ 58, 288,  95, 339],\n",
      "        [309, 246, 591, 454]], dtype=torch.int32), 'scores': tensor([0.2662, 0.5371, 0.1479, 0.2666, 0.7375, 0.4276, 0.2634, 0.1974, 0.4162,\n",
      "        0.8170, 0.6409, 0.7286, 0.2838]), 'objectness_scores': tensor([0.2529, 0.2074, 0.2153, 0.6037, 0.4839, 0.2755, 0.2324, 0.4657, 0.2878,\n",
      "        0.3951, 0.5098, 0.2219, 0.2502]), 'labels': tensor([13,  7,  7, 15, 14, 11,  2,  0,  7, 11, 13,  7, 10], dtype=torch.int32)}\n",
      "216497\n",
      "{'image_id': 217872, 'boxes': tensor([[285, 200, 299, 212],\n",
      "        [244, 185, 258, 195],\n",
      "        [169, 203, 187, 227]], dtype=torch.int32), 'scores': tensor([0.3472, 0.2008, 0.1677]), 'objectness_scores': tensor([0.5239, 0.4722, 0.2134]), 'labels': tensor([ 4, 11,  8], dtype=torch.int32)}\n",
      "217872\n",
      "{'image_id': 218091, 'boxes': tensor([[306, 144, 313, 151],\n",
      "        [347, 149, 381, 174],\n",
      "        [109, 230, 188, 316],\n",
      "        [  0, 169, 156, 281],\n",
      "        [423, 176, 478, 236],\n",
      "        [298, 103, 318, 139],\n",
      "        [322, 138, 361, 168],\n",
      "        [366, 197, 564, 359],\n",
      "        [434, 173, 451, 185],\n",
      "        [208, 261, 640, 433],\n",
      "        [ 66,  33, 187, 172],\n",
      "        [278, 159, 307, 171],\n",
      "        [449, 107, 478, 152],\n",
      "        [407, 148, 427, 177],\n",
      "        [373, 147, 412, 176],\n",
      "        [473, 198, 615, 359],\n",
      "        [430, 365, 509, 419],\n",
      "        [ 39, 174, 110, 231],\n",
      "        [ -1,   0, 628, 436]], dtype=torch.int32), 'scores': tensor([0.1578, 0.3721, 0.6342, 0.9970, 0.4647, 0.2164, 0.3269, 0.1842, 0.4350,\n",
      "        0.3728, 0.1811, 0.4044, 0.3684, 0.3872, 0.4027, 0.3145, 0.4002, 0.9962,\n",
      "        0.6065]), 'objectness_scores': tensor([0.2259, 0.2356, 0.4764, 0.4069, 0.4353, 0.2810, 0.2720, 0.2109, 0.4808,\n",
      "        0.3752, 0.3440, 0.3552, 0.2334, 0.2253, 0.2400, 0.2460, 0.2769, 0.2919,\n",
      "        0.2455]), 'labels': tensor([11, 11, 10, 13, 13, 11, 13, 13, 11,  7,  8, 11, 13,  7, 11, 14,  7, 13,\n",
      "        13], dtype=torch.int32)}\n",
      "218091\n",
      "{'image_id': 218439, 'boxes': tensor([[  3,  -4, 449, 334],\n",
      "        [371, 437, 445, 545]], dtype=torch.int32), 'scores': tensor([0.3859, 0.4168]), 'objectness_scores': tensor([0.2953, 0.2496]), 'labels': tensor([9, 7], dtype=torch.int32)}\n",
      "218439\n",
      "{'image_id': 220732, 'boxes': tensor([[262,  46, 276,  55],\n",
      "        [410, 165, 638, 262],\n",
      "        [343,  47, 355,  56],\n",
      "        [ 10, 240,  19, 265]], dtype=torch.int32), 'scores': tensor([0.2320, 0.9952, 0.2697, 0.2438]), 'objectness_scores': tensor([0.2751, 0.4260, 0.2687, 0.2947]), 'labels': tensor([14,  1, 14,  7], dtype=torch.int32)}\n",
      "220732\n",
      "{'image_id': 221693, 'boxes': tensor([[ 72,  10, 520, 428]], dtype=torch.int32), 'scores': tensor([0.3955]), 'objectness_scores': tensor([0.5147]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "221693\n",
      "{'image_id': 221708, 'boxes': tensor([[252,  90, 311, 119],\n",
      "        [303,  19, 368, 151],\n",
      "        [234, 286, 438, 440]], dtype=torch.int32), 'scores': tensor([0.2938, 0.4506, 0.5658]), 'objectness_scores': tensor([0.2969, 0.2426, 0.2015]), 'labels': tensor([7, 7, 2], dtype=torch.int32)}\n",
      "221708\n",
      "{'image_id': 222235, 'boxes': tensor([[126, 135, 425, 389]], dtype=torch.int32), 'scores': tensor([0.9886]), 'objectness_scores': tensor([0.6297]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "222235\n",
      "{'image_id': 222317, 'boxes': tensor([[225, 196, 450, 290],\n",
      "        [ 98,  90, 637, 478],\n",
      "        [ 45, 291, 109, 397],\n",
      "        [145, 237, 456, 423],\n",
      "        [165,  45, 189,  76]], dtype=torch.int32), 'scores': tensor([0.9047, 0.5737, 0.2036, 0.9070, 0.2481]), 'objectness_scores': tensor([0.4550, 0.5053, 0.2120, 0.2912, 0.2659]), 'labels': tensor([ 3, 13,  7, 13, 11], dtype=torch.int32)}\n",
      "222317\n",
      "{'image_id': 222735, 'boxes': tensor([[  2, 341, 471, 642],\n",
      "        [ 71, 144, 392, 375]], dtype=torch.int32), 'scores': tensor([0.9814, 0.7748]), 'objectness_scores': tensor([0.5286, 0.2322]), 'labels': tensor([14, 14], dtype=torch.int32)}\n",
      "222735\n",
      "{'image_id': 223090, 'boxes': tensor([[ 49,  97, 138, 482],\n",
      "        [  6,   0, 639, 479],\n",
      "        [199, 116, 602, 449],\n",
      "        [  8,   1, 290, 232],\n",
      "        [ 10,   3, 602, 453],\n",
      "        [  5,  89, 636, 477]], dtype=torch.int32), 'scores': tensor([0.5877, 0.3765, 0.5967, 0.4304, 0.3413, 0.5569]), 'objectness_scores': tensor([0.5082, 0.2737, 0.3828, 0.2674, 0.2095, 0.5216]), 'labels': tensor([12, 11,  7,  7, 11,  7], dtype=torch.int32)}\n",
      "223090\n",
      "{'image_id': 223188, 'boxes': tensor([[122, 158, 151, 188],\n",
      "        [225, 490, 298, 595],\n",
      "        [  3, 130, 131, 451],\n",
      "        [244, 485, 280, 516],\n",
      "        [  1, 133, 423, 639],\n",
      "        [ 78, 141,  83, 148],\n",
      "        [128, 177, 372, 484],\n",
      "        [213, 131, 273, 155]], dtype=torch.int32), 'scores': tensor([0.3674, 0.7249, 0.2394, 0.8632, 0.6457, 0.2296, 0.1975, 0.1503]), 'objectness_scores': tensor([0.5310, 0.2042, 0.2165, 0.3060, 0.2391, 0.3814, 0.2266, 0.2935]), 'labels': tensor([11,  9, 11,  7,  4, 11,  7, 10], dtype=torch.int32)}\n",
      "223188\n",
      "{'image_id': 223747, 'boxes': tensor([[ 83, 238, 206, 367],\n",
      "        [ 60,  83, 455, 369],\n",
      "        [ 79, 236, 308, 369]], dtype=torch.int32), 'scores': tensor([0.8817, 0.9965, 0.1591]), 'objectness_scores': tensor([0.2433, 0.2437, 0.3444]), 'labels': tensor([3, 5, 7], dtype=torch.int32)}\n",
      "223747\n",
      "{'image_id': 223789, 'boxes': tensor([[104, 119, 130, 163],\n",
      "        [ 78, 119,  99, 166],\n",
      "        [273,   7, 316,  84],\n",
      "        [260, 157, 301, 181],\n",
      "        [ 17,   1, 345, 265],\n",
      "        [241,   0, 320, 185],\n",
      "        [252, 134, 292, 165],\n",
      "        [260, 164, 301, 188],\n",
      "        [ 50, 127,  82, 175],\n",
      "        [ 85,  -2, 331, 198],\n",
      "        [122, 253, 182, 310],\n",
      "        [  0,   4, 347, 498],\n",
      "        [116, 110, 122, 120],\n",
      "        [ 51, 261, 147, 295]], dtype=torch.int32), 'scores': tensor([0.4031, 0.2741, 0.6639, 0.2694, 0.7007, 0.2011, 0.2098, 0.3955, 0.5283,\n",
      "        0.2043, 0.2936, 0.9656, 0.1853, 0.1432]), 'objectness_scores': tensor([0.5106, 0.2887, 0.4204, 0.2281, 0.2758, 0.2492, 0.2901, 0.2034, 0.4782,\n",
      "        0.4453, 0.5065, 0.2231, 0.2420, 0.4279]), 'labels': tensor([11,  9,  7, 11, 15,  7,  7,  7, 11, 15, 15, 15, 11,  7],\n",
      "       dtype=torch.int32)}\n",
      "223789\n",
      "{'image_id': 224807, 'boxes': tensor([[130, 247, 154, 279],\n",
      "        [227, 163, 241, 183],\n",
      "        [383, 133, 402, 158],\n",
      "        [ 95, 188, 160, 229],\n",
      "        [232,  85, 269,  96],\n",
      "        [261,  93, 287, 114],\n",
      "        [256, 245, 276, 274],\n",
      "        [344, 209, 361, 237],\n",
      "        [177, 173, 195, 202],\n",
      "        [337, 142, 352, 164],\n",
      "        [324, 251, 346, 281],\n",
      "        [123,  89, 162, 116],\n",
      "        [153, 185, 437, 422]], dtype=torch.int32), 'scores': tensor([0.2163, 0.2067, 0.5421, 0.5383, 0.3186, 0.5631, 0.2590, 0.2167, 0.2910,\n",
      "        0.2955, 0.4120, 0.3057, 0.2446]), 'objectness_scores': tensor([0.2602, 0.2430, 0.2606, 0.2554, 0.2104, 0.2273, 0.2593, 0.2477, 0.2952,\n",
      "        0.2335, 0.2616, 0.2007, 0.2503]), 'labels': tensor([11, 14, 11,  7, 11,  6,  7,  7, 10, 11, 10,  7, 12], dtype=torch.int32)}\n",
      "224807\n",
      "{'image_id': 225184, 'boxes': tensor([[  6, 175, 144, 250]], dtype=torch.int32), 'scores': tensor([0.2488]), 'objectness_scores': tensor([0.5179]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "225184\n",
      "{'image_id': 225670, 'boxes': tensor([[580, 181, 602, 204],\n",
      "        [252, 144, 399, 232],\n",
      "        [  4, 372, 638, 426],\n",
      "        [248, 330, 357, 350],\n",
      "        [391, 194, 413, 214],\n",
      "        [219, 201, 230, 222],\n",
      "        [  0, 172,  34, 242],\n",
      "        [ 70, 209,  78, 226]], dtype=torch.int32), 'scores': tensor([0.3263, 0.4809, 0.3280, 0.4477, 0.2757, 0.2977, 0.6338, 0.2130]), 'objectness_scores': tensor([0.5168, 0.5767, 0.2690, 0.2098, 0.5532, 0.5430, 0.3226, 0.4577]), 'labels': tensor([ 8,  3,  7, 14,  8, 14,  8,  0], dtype=torch.int32)}\n",
      "225670\n",
      "{'image_id': 225757, 'boxes': tensor([[428, 220, 470, 263],\n",
      "        [ 86, 234, 269, 300],\n",
      "        [ 29, 167,  63, 190],\n",
      "        [ 96, 175, 164, 237],\n",
      "        [  0, 195, 490, 365],\n",
      "        [265, 198, 288, 242],\n",
      "        [229, 197, 257, 240]], dtype=torch.int32), 'scores': tensor([0.3196, 0.9970, 0.3222, 0.7023, 0.9741, 0.8657, 0.4856]), 'objectness_scores': tensor([0.3115, 0.5085, 0.2187, 0.2014, 0.2994, 0.3448, 0.3043]), 'labels': tensor([12, 14, 11, 14, 14, 14, 14], dtype=torch.int32)}\n",
      "225757\n",
      "{'image_id': 226147, 'boxes': tensor([[121, 193, 210, 313],\n",
      "        [193,  47, 202,  60],\n",
      "        [222, 113, 448, 315],\n",
      "        [343, 335, 370, 358],\n",
      "        [290, 518, 335, 565],\n",
      "        [341, 100, 407, 184],\n",
      "        [  0,  11, 156, 416],\n",
      "        [266, 323, 297, 351],\n",
      "        [ 88, 371, 171, 480],\n",
      "        [316, 369, 347, 389],\n",
      "        [  1, 264, 479, 637],\n",
      "        [170, 497, 223, 562],\n",
      "        [170, 496, 224, 548],\n",
      "        [156, 321, 238, 375]], dtype=torch.int32), 'scores': tensor([0.7471, 0.2522, 0.5095, 0.3177, 0.3802, 0.9585, 0.3770, 0.5437, 0.9873,\n",
      "        0.6087, 0.7764, 0.3160, 0.3023, 0.2283]), 'objectness_scores': tensor([0.3206, 0.3243, 0.2419, 0.2397, 0.2745, 0.3046, 0.2051, 0.2728, 0.2698,\n",
      "        0.2135, 0.2398, 0.2130, 0.2215, 0.4000]), 'labels': tensor([ 7, 11,  7,  7, 12,  7, 10, 14, 10, 11, 12, 10, 12,  9],\n",
      "       dtype=torch.int32)}\n",
      "226147\n",
      "{'image_id': 226154, 'boxes': tensor([[212, 310, 276, 334],\n",
      "        [204, 106, 259, 155],\n",
      "        [143,  99, 525, 377],\n",
      "        [206, 199, 259, 222]], dtype=torch.int32), 'scores': tensor([0.2653, 0.3786, 0.6635, 0.1660]), 'objectness_scores': tensor([0.2795, 0.3563, 0.6544, 0.3198]), 'labels': tensor([7, 7, 7, 0], dtype=torch.int32)}\n",
      "226154\n",
      "{'image_id': 226171, 'boxes': tensor([[  3, 256, 637, 478],\n",
      "        [ 52, 285, 147, 398],\n",
      "        [208, 152, 232, 171]], dtype=torch.int32), 'scores': tensor([0.2299, 0.9951, 0.3124]), 'objectness_scores': tensor([0.3045, 0.3013, 0.2934]), 'labels': tensor([14, 10, 11], dtype=torch.int32)}\n",
      "226171\n",
      "{'image_id': 226802, 'boxes': tensor([[243, 175, 320, 205],\n",
      "        [240, 176, 277, 204],\n",
      "        [284, 177, 321, 202],\n",
      "        [432, 170, 468, 208],\n",
      "        [433, 130, 471, 156],\n",
      "        [362, 176, 372, 195],\n",
      "        [434, 172, 452, 208],\n",
      "        [328, 177, 363, 199],\n",
      "        [368, 167, 444, 218],\n",
      "        [462, 177, 476, 203]], dtype=torch.int32), 'scores': tensor([0.9957, 0.9971, 0.5040, 0.4684, 0.6421, 0.2344, 0.2604, 0.9960, 0.9994,\n",
      "        0.2675]), 'objectness_scores': tensor([0.4861, 0.2638, 0.2525, 0.4277, 0.2944, 0.3608, 0.2100, 0.5074, 0.4877,\n",
      "        0.2199]), 'labels': tensor([ 1,  1,  2, 11, 14, 14, 11,  1,  1, 11], dtype=torch.int32)}\n",
      "226802\n",
      "{'image_id': 226903, 'boxes': tensor([[ 56, 203, 102, 237],\n",
      "        [234, 198, 254, 218],\n",
      "        [201, 220, 243, 246],\n",
      "        [238, 215, 271, 244],\n",
      "        [192, 198, 335, 247],\n",
      "        [  4, 211, 637, 473],\n",
      "        [189, 215, 214, 239],\n",
      "        [201, 211, 257, 244],\n",
      "        [340, 249, 394, 314]], dtype=torch.int32), 'scores': tensor([0.4960, 0.1449, 0.3615, 0.4326, 0.7397, 0.4072, 0.1982, 0.7814, 0.5853]), 'objectness_scores': tensor([0.2198, 0.2067, 0.2444, 0.2208, 0.2133, 0.2356, 0.2164, 0.2132, 0.2082]), 'labels': tensor([11, 11,  7, 12, 12, 15, 11, 12, 11], dtype=torch.int32)}\n",
      "226903\n",
      "{'image_id': 226984, 'boxes': tensor([[486,  42, 509,  62],\n",
      "        [293,  52, 341, 104],\n",
      "        [362, 234, 397, 297],\n",
      "        [377,  11, 456,  61],\n",
      "        [240,  51, 289, 156],\n",
      "        [ 14, 315, 223, 426],\n",
      "        [291,  51, 388, 109],\n",
      "        [489,  59, 517, 118],\n",
      "        [239, 159, 263, 188],\n",
      "        [388,  58, 436, 159],\n",
      "        [ 84, 175, 153, 259],\n",
      "        [421, 304, 470, 365],\n",
      "        [288, 104, 391, 126],\n",
      "        [226,  28, 294,  50],\n",
      "        [438,  61, 482, 158],\n",
      "        [162, 168, 188, 193],\n",
      "        [449,  12, 515,  67],\n",
      "        [170,  49, 288, 158],\n",
      "        [301, 236, 331, 289],\n",
      "        [ 27, 222,  59, 302],\n",
      "        [235, 182, 281, 217],\n",
      "        [112,   0, 147, 158],\n",
      "        [199, 171, 238, 182],\n",
      "        [227, 351, 367, 427],\n",
      "        [221, 230, 294, 343],\n",
      "        [418, 362, 524, 425],\n",
      "        [  3,   0, 130, 160],\n",
      "        [286, 202, 403, 233],\n",
      "        [179,  48, 234, 156],\n",
      "        [506,   0, 542,  58],\n",
      "        [381,  58, 483, 160],\n",
      "        [400, 228, 476, 334]], dtype=torch.int32), 'scores': tensor([0.2054, 0.2393, 0.7211, 0.6052, 0.2792, 0.2245, 0.2487, 0.5028, 0.1736,\n",
      "        0.2159, 0.8766, 0.3697, 0.6231, 0.2267, 0.3787, 0.2988, 0.3144, 0.1638,\n",
      "        0.4381, 0.1614, 0.6764, 0.2395, 0.3073, 0.4929, 0.5498, 0.4002, 0.2262,\n",
      "        0.2882, 0.2188, 0.3675, 0.3089, 0.2668]), 'objectness_scores': tensor([0.2247, 0.2731, 0.2541, 0.5520, 0.2733, 0.2133, 0.2736, 0.2763, 0.2261,\n",
      "        0.2142, 0.3599, 0.4030, 0.5265, 0.5113, 0.2042, 0.3255, 0.2113, 0.2919,\n",
      "        0.3207, 0.2682, 0.4273, 0.2775, 0.3940, 0.2223, 0.3512, 0.3084, 0.3135,\n",
      "        0.3267, 0.2708, 0.3982, 0.3343, 0.3735]), 'labels': tensor([11,  8, 14,  7,  8,  7, 14,  7, 11, 15, 10, 13, 11, 11,  8, 14, 10, 11,\n",
      "         7,  3, 10,  7, 11,  7,  7,  9,  7, 14,  8,  7, 15,  7],\n",
      "       dtype=torch.int32)}\n",
      "226984\n",
      "{'image_id': 227044, 'boxes': tensor([[474,  36, 640, 120],\n",
      "        [506, 320, 560, 377],\n",
      "        [119,  43, 641, 428],\n",
      "        [115,   0, 174,  42],\n",
      "        [603, 351, 639, 424],\n",
      "        [  5,   0,  73,  43]], dtype=torch.int32), 'scores': tensor([0.4784, 0.5267, 0.9944, 0.8910, 0.2986, 0.7305]), 'objectness_scores': tensor([0.2174, 0.7679, 0.5668, 0.2077, 0.3511, 0.2135]), 'labels': tensor([ 7,  7,  0, 10, 11, 10], dtype=torch.int32)}\n",
      "227044\n",
      "{'image_id': 227985, 'boxes': tensor([[334, 212, 569, 359],\n",
      "        [286,   1, 415, 226],\n",
      "        [147, 298, 185, 335],\n",
      "        [337, 309, 437, 386],\n",
      "        [414, 320, 460, 346],\n",
      "        [285, 160, 311, 261],\n",
      "        [260, 161, 314, 355],\n",
      "        [349, 300, 495, 360],\n",
      "        [ 80, 293, 191, 338],\n",
      "        [ 81, 279, 274, 339],\n",
      "        [248, 162, 308, 321],\n",
      "        [ 31, 148,  94, 227],\n",
      "        [ 73, 284, 145, 315],\n",
      "        [548, 286, 594, 353],\n",
      "        [550, 245, 570, 307],\n",
      "        [543,  54, 641, 162],\n",
      "        [178, 297, 250, 390],\n",
      "        [352, 312, 494, 360],\n",
      "        [248, 263, 279, 320],\n",
      "        [474, 353, 550, 418],\n",
      "        [  2,   9, 628, 476],\n",
      "        [168,  83, 220, 106]], dtype=torch.int32), 'scores': tensor([0.2755, 0.3455, 0.2307, 0.2449, 0.2007, 0.5108, 0.2310, 0.9969, 0.3052,\n",
      "        0.6667, 0.2385, 0.7239, 0.3319, 0.4622, 0.3499, 0.9120, 0.4174, 0.2677,\n",
      "        0.3413, 0.3770, 0.2899, 0.2951]), 'objectness_scores': tensor([0.2312, 0.5090, 0.2818, 0.2203, 0.2715, 0.3046, 0.2932, 0.2636, 0.3142,\n",
      "        0.2340, 0.3309, 0.3322, 0.2751, 0.2719, 0.2198, 0.5978, 0.2992, 0.2984,\n",
      "        0.2323, 0.2225, 0.4967, 0.2088]), 'labels': tensor([ 4, 11, 11, 12, 11, 11, 11,  1,  7, 12,  7, 12, 11,  7, 11, 11, 12, 12,\n",
      "        11, 12, 12,  7], dtype=torch.int32)}\n",
      "227985\n",
      "{'image_id': 228214, 'boxes': tensor([[191, 327, 251, 377],\n",
      "        [338, 268, 428, 475],\n",
      "        [113,  26, 322, 179],\n",
      "        [191, 309, 211, 330],\n",
      "        [339, 264, 428, 386],\n",
      "        [  2, 200, 387, 640],\n",
      "        [150, 131, 272, 220]], dtype=torch.int32), 'scores': tensor([0.2080, 0.1776, 0.7311, 0.5437, 0.1698, 0.6254, 0.3964]), 'objectness_scores': tensor([0.4822, 0.3698, 0.4878, 0.2339, 0.2315, 0.2856, 0.3611]), 'labels': tensor([ 7,  7, 10, 11,  7,  7,  7], dtype=torch.int32)}\n",
      "228214\n",
      "{'image_id': 229311, 'boxes': tensor([[427, 197, 450, 217],\n",
      "        [350,   1, 385,  88],\n",
      "        [276,   0, 320,  80],\n",
      "        [128, 220, 299, 277],\n",
      "        [315, 285, 439, 358],\n",
      "        [115, 155, 141, 197],\n",
      "        [219, 246, 404, 323],\n",
      "        [ 92, 152, 118, 198],\n",
      "        [127, 153, 141, 169],\n",
      "        [ 13, 207,  50, 371],\n",
      "        [251, 160, 313, 247],\n",
      "        [364, 198, 398, 269],\n",
      "        [  0, 139,  13, 158]], dtype=torch.int32), 'scores': tensor([0.2388, 0.2301, 0.2325, 0.2145, 0.7504, 0.4129, 0.3698, 0.2953, 0.2056,\n",
      "        0.2402, 0.1546, 0.3460, 0.2220]), 'objectness_scores': tensor([0.2171, 0.2278, 0.2685, 0.4774, 0.4179, 0.2998, 0.4916, 0.3750, 0.3019,\n",
      "        0.2053, 0.4328, 0.3318, 0.2236]), 'labels': tensor([11, 11, 16,  7,  9, 11, 15, 11, 11,  7, 16,  8, 14], dtype=torch.int32)}\n",
      "229311\n",
      "{'image_id': 229358, 'boxes': tensor([[ 62,  10, 450, 272],\n",
      "        [302, 360, 552, 423],\n",
      "        [112, 146, 153, 178],\n",
      "        [130,  88, 141, 128],\n",
      "        [  0,   0, 128, 241],\n",
      "        [336, 147, 353, 172],\n",
      "        [451, 323, 481, 361],\n",
      "        [255,  17, 451, 247],\n",
      "        [422, 300, 440, 308],\n",
      "        [360, 321, 413, 389]], dtype=torch.int32), 'scores': tensor([0.3483, 0.2485, 0.3327, 0.3324, 0.5107, 0.6362, 0.2550, 0.9791, 0.3434,\n",
      "        0.3478]), 'objectness_scores': tensor([0.2549, 0.4603, 0.2903, 0.3886, 0.3764, 0.2393, 0.3224, 0.3126, 0.2044,\n",
      "        0.4216]), 'labels': tensor([ 7,  8,  9,  7, 15, 11, 11,  7, 11, 11], dtype=torch.int32)}\n",
      "229358\n",
      "{'image_id': 229553, 'boxes': tensor([[347,  56, 422, 106],\n",
      "        [418, 322, 499, 370],\n",
      "        [272, 339, 330, 382],\n",
      "        [162, 362, 547, 426],\n",
      "        [276, 134, 416, 308],\n",
      "        [ 53, 155, 131, 205],\n",
      "        [354, 142, 395, 174]], dtype=torch.int32), 'scores': tensor([0.2758, 0.7533, 0.8251, 0.3638, 0.9714, 0.3371, 0.5986]), 'objectness_scores': tensor([0.3771, 0.2358, 0.2630, 0.6409, 0.4351, 0.4691, 0.2485]), 'labels': tensor([ 8,  9,  9, 11,  2, 11,  7], dtype=torch.int32)}\n",
      "229553\n",
      "{'image_id': 229948, 'boxes': tensor([[266, 220, 288, 241],\n",
      "        [ 92, 175, 111, 191],\n",
      "        [222, 139, 234, 146],\n",
      "        [148, 164, 157, 175],\n",
      "        [  1,  90, 185, 212],\n",
      "        [112,  80, 241, 144],\n",
      "        [ 52, 181,  69, 192],\n",
      "        [  1,  91, 185, 164],\n",
      "        [225, 142, 237, 173],\n",
      "        [606, 169, 618, 181],\n",
      "        [113, 175, 135, 190]], dtype=torch.int32), 'scores': tensor([0.5219, 0.2011, 0.1526, 0.1689, 0.2149, 0.3434, 0.2487, 0.4209, 0.5880,\n",
      "        0.2090, 0.2674]), 'objectness_scores': tensor([0.2071, 0.2082, 0.2124, 0.2059, 0.3015, 0.2226, 0.4685, 0.2550, 0.2473,\n",
      "        0.2610, 0.4976]), 'labels': tensor([12,  3, 11, 11,  1,  8, 11,  8,  7, 11,  2], dtype=torch.int32)}\n",
      "229948\n",
      "{'image_id': 230983, 'boxes': tensor([[148, 294, 175, 321],\n",
      "        [160, 312, 231, 430],\n",
      "        [373, 110, 385, 125]], dtype=torch.int32), 'scores': tensor([0.4644, 0.7963, 0.1877]), 'objectness_scores': tensor([0.2018, 0.2044, 0.2411]), 'labels': tensor([11, 11, 11], dtype=torch.int32)}\n",
      "230983\n",
      "{'image_id': 230993, 'boxes': tensor([[370,  66, 620, 201],\n",
      "        [434, 190, 461, 229],\n",
      "        [ 52,  40, 387, 264],\n",
      "        [168, 276, 182, 296]], dtype=torch.int32), 'scores': tensor([0.9928, 0.5394, 0.9969, 0.2218]), 'objectness_scores': tensor([0.4949, 0.4277, 0.5308, 0.4091]), 'labels': tensor([ 6, 11,  6, 11], dtype=torch.int32)}\n",
      "230993\n",
      "{'image_id': 231097, 'boxes': tensor([[149,   0, 520,  37],\n",
      "        [404, 182, 454, 238],\n",
      "        [  4,  49, 639, 483],\n",
      "        [ 16, 108, 639, 349],\n",
      "        [218, 160, 262, 191]], dtype=torch.int32), 'scores': tensor([0.2676, 0.2216, 0.3674, 0.3726, 0.2729]), 'objectness_scores': tensor([0.3084, 0.2108, 0.3102, 0.3501, 0.2557]), 'labels': tensor([ 9,  2, 11, 11, 11], dtype=torch.int32)}\n",
      "231097\n",
      "{'image_id': 231527, 'boxes': tensor([[281, 317, 418, 412],\n",
      "        [161, 327, 282, 461],\n",
      "        [ 16, 269, 426, 582]], dtype=torch.int32), 'scores': tensor([0.5288, 0.3329, 0.4554]), 'objectness_scores': tensor([0.2977, 0.3207, 0.5001]), 'labels': tensor([ 7, 10, 10], dtype=torch.int32)}\n",
      "231527\n",
      "{'image_id': 231549, 'boxes': tensor([[  0, 414, 131, 479],\n",
      "        [306, 352, 455, 441],\n",
      "        [515, 405, 637, 478],\n",
      "        [309, 388, 352, 441],\n",
      "        [523, 423, 537, 441],\n",
      "        [520, 246, 570, 321],\n",
      "        [237, 399, 307, 457],\n",
      "        [288, 397, 333, 456],\n",
      "        [  3,  18, 636, 480],\n",
      "        [ 88, 411, 106, 439],\n",
      "        [ 65, 251, 123, 326],\n",
      "        [166, 354, 316, 442]], dtype=torch.int32), 'scores': tensor([0.3414, 0.7785, 0.3615, 0.3684, 0.2637, 0.1784, 0.7636, 0.9991, 0.4468,\n",
      "        0.2832, 0.2428, 0.9752]), 'objectness_scores': tensor([0.2273, 0.4083, 0.2126, 0.2540, 0.2424, 0.4387, 0.2262, 0.2176, 0.2367,\n",
      "        0.2794, 0.4546, 0.4230]), 'labels': tensor([14, 13, 14,  7, 11, 11, 13, 14,  5, 14,  7, 10], dtype=torch.int32)}\n",
      "231549\n",
      "{'image_id': 231580, 'boxes': tensor([[112, 233, 164, 269],\n",
      "        [165, 194, 176, 213],\n",
      "        [191, 362, 270, 477]], dtype=torch.int32), 'scores': tensor([0.3080, 0.1791, 0.2936]), 'objectness_scores': tensor([0.2145, 0.2641, 0.3033]), 'labels': tensor([ 9, 11,  3], dtype=torch.int32)}\n",
      "231580\n",
      "{'image_id': 231822, 'boxes': tensor([[383, 170, 401, 196],\n",
      "        [124, 256, 271, 327],\n",
      "        [  1,   2, 496, 363],\n",
      "        [ 89,  24, 162, 154],\n",
      "        [334, 200, 351, 306],\n",
      "        [192,   2, 261, 134],\n",
      "        [ 34, 148, 476, 357],\n",
      "        [ 69, 176, 295, 337]], dtype=torch.int32), 'scores': tensor([0.2192, 0.3997, 0.4322, 0.9086, 0.4295, 0.7960, 0.2060, 0.2736]), 'objectness_scores': tensor([0.2273, 0.2632, 0.2548, 0.3801, 0.2062, 0.3988, 0.4493, 0.2246]), 'labels': tensor([11, 12,  9, 10,  8, 10,  9, 12], dtype=torch.int32)}\n",
      "231822\n",
      "{'image_id': 231831, 'boxes': tensor([[  0, 169, 478, 632],\n",
      "        [ 37, 168, 477, 633]], dtype=torch.int32), 'scores': tensor([0.9293, 0.8938]), 'objectness_scores': tensor([0.2005, 0.4931]), 'labels': tensor([2, 2], dtype=torch.int32)}\n",
      "231831\n",
      "{'image_id': 231879, 'boxes': tensor([[414, 117, 553, 207],\n",
      "        [472, 132, 478, 168],\n",
      "        [526, 213, 638, 426],\n",
      "        [529, 193, 632, 235],\n",
      "        [226, 199, 258, 225],\n",
      "        [389, 184, 577, 213],\n",
      "        [417, 130, 538, 205]], dtype=torch.int32), 'scores': tensor([0.9735, 0.1581, 0.2471, 0.1698, 0.3017, 0.2937, 0.9528]), 'objectness_scores': tensor([0.3022, 0.4351, 0.2703, 0.2388, 0.3457, 0.2835, 0.3763]), 'labels': tensor([12,  0,  6, 11,  7, 11, 12], dtype=torch.int32)}\n",
      "231879\n",
      "{'image_id': 232088, 'boxes': tensor([[165, 370, 344, 480],\n",
      "        [270, 272, 489, 375],\n",
      "        [334, 266, 382, 323],\n",
      "        [128, 355, 508, 480],\n",
      "        [ 33, 244,  55, 270],\n",
      "        [ 58, 248, 209, 329],\n",
      "        [510, 243, 576, 305],\n",
      "        [356, 273, 404, 333],\n",
      "        [515, 404, 639, 479],\n",
      "        [  4,   3, 637, 491],\n",
      "        [338, 350, 468, 389],\n",
      "        [509, 121, 595, 256],\n",
      "        [161, 322, 318, 399],\n",
      "        [439, 115, 515, 210],\n",
      "        [  0, 230,  40, 277],\n",
      "        [302, 273, 487, 374],\n",
      "        [139, 272, 558, 477],\n",
      "        [333, 265, 409, 332]], dtype=torch.int32), 'scores': tensor([0.3973, 0.9828, 0.5875, 0.9670, 0.2305, 0.5922, 0.4397, 0.6904, 0.5995,\n",
      "        0.6456, 0.5165, 0.9282, 0.9949, 0.7504, 0.4398, 0.9455, 0.9989, 0.9654]), 'objectness_scores': tensor([0.2842, 0.2693, 0.2320, 0.3370, 0.2029, 0.3303, 0.5380, 0.2163, 0.2371,\n",
      "        0.2094, 0.2317, 0.2062, 0.3933, 0.2168, 0.2405, 0.2377, 0.3186, 0.2377]), 'labels': tensor([11, 13, 13, 13,  7,  1, 14,  7, 14, 14, 11,  7, 13,  7,  8, 13, 13, 13],\n",
      "       dtype=torch.int32)}\n",
      "232088\n",
      "{'image_id': 232563, 'boxes': tensor([[  0, 212, 126, 295],\n",
      "        [ -1,   1, 435, 259],\n",
      "        [187, 129, 278, 163]], dtype=torch.int32), 'scores': tensor([0.9960, 0.9321, 0.5597]), 'objectness_scores': tensor([0.3871, 0.4884, 0.3010]), 'labels': tensor([ 6,  6, 11], dtype=torch.int32)}\n",
      "232563\n",
      "{'image_id': 232649, 'boxes': tensor([[132, 202, 198, 242],\n",
      "        [ 67,  62,  77,  69],\n",
      "        [ 56, 207,  82, 252],\n",
      "        [  0, 227, 207, 381],\n",
      "        [ 12, 376, 165, 498],\n",
      "        [121, 320, 232, 448],\n",
      "        [  0,   0, 163, 144],\n",
      "        [249, 115, 284, 150],\n",
      "        [ 65,  32,  79,  52],\n",
      "        [ 20,  42,  76, 104],\n",
      "        [147, 231, 168, 244],\n",
      "        [ 99, 201, 139, 249],\n",
      "        [ 45,  43,  59,  61]], dtype=torch.int32), 'scores': tensor([0.1980, 0.1578, 0.6736, 0.9974, 0.5792, 0.2423, 0.2870, 0.2993, 0.3273,\n",
      "        0.1953, 0.3141, 0.5707, 0.3074]), 'objectness_scores': tensor([0.2408, 0.2233, 0.5251, 0.5818, 0.5398, 0.3802, 0.3336, 0.3530, 0.3597,\n",
      "        0.3124, 0.3845, 0.6052, 0.3455]), 'labels': tensor([ 7, 14, 10, 15, 13, 13,  7, 15,  6,  7, 11,  7, 11], dtype=torch.int32)}\n",
      "232649\n",
      "{'image_id': 233033, 'boxes': tensor([[167, 236, 179, 286],\n",
      "        [626, 299, 638, 334],\n",
      "        [134,  97, 466, 345],\n",
      "        [260, 338, 385, 418],\n",
      "        [133,  97, 468, 188]], dtype=torch.int32), 'scores': tensor([0.6443, 0.2774, 0.4720, 0.4702, 0.9994]), 'objectness_scores': tensor([0.2138, 0.2853, 0.4001, 0.2444, 0.2461]), 'labels': tensor([11,  7, 11,  6,  6], dtype=torch.int32)}\n",
      "233033\n",
      "{'image_id': 233567, 'boxes': tensor([[  2,   4, 476, 630]], dtype=torch.int32), 'scores': tensor([0.9980]), 'objectness_scores': tensor([0.2273]), 'labels': tensor([4], dtype=torch.int32)}\n",
      "233567\n",
      "{'image_id': 233727, 'boxes': tensor([[597, 202, 608, 211],\n",
      "        [ 82,  87, 453, 327],\n",
      "        [ 34,  93,  62, 270]], dtype=torch.int32), 'scores': tensor([0.1632, 0.9988, 0.2926]), 'objectness_scores': tensor([0.2049, 0.6110, 0.2126]), 'labels': tensor([11,  1,  9], dtype=torch.int32)}\n",
      "233727\n",
      "{'image_id': 233771, 'boxes': tensor([[193,   0, 294,  63],\n",
      "        [ 57, 325, 221, 462],\n",
      "        [479, 207, 522, 264],\n",
      "        [231, 319, 510, 418],\n",
      "        [330, 388, 514, 525]], dtype=torch.int32), 'scores': tensor([0.3611, 0.8868, 0.2961, 0.6986, 0.9708]), 'objectness_scores': tensor([0.2376, 0.2666, 0.2069, 0.2653, 0.3739]), 'labels': tensor([ 9,  1, 15,  1,  6], dtype=torch.int32)}\n",
      "233771\n",
      "{'image_id': 233825, 'boxes': tensor([[  0, 336,  95, 428],\n",
      "        [252, 421, 379, 479],\n",
      "        [  1, 352, 209, 478],\n",
      "        [139, 219, 174, 248],\n",
      "        [  0, 336,  94, 479],\n",
      "        [396, 349, 407, 364],\n",
      "        [462, 386, 508, 465],\n",
      "        [139, 219, 175, 359]], dtype=torch.int32), 'scores': tensor([0.9208, 0.3182, 0.4202, 0.5724, 0.8549, 0.1823, 0.3047, 0.3457]), 'objectness_scores': tensor([0.3073, 0.2234, 0.3197, 0.2048, 0.3076, 0.3602, 0.2604, 0.2126]), 'labels': tensor([10, 11, 10, 11,  7, 14, 11, 11], dtype=torch.int32)}\n",
      "233825\n",
      "{'image_id': 235241, 'boxes': tensor([[280, 195, 342, 230],\n",
      "        [ 45, 115, 171, 347],\n",
      "        [188, 163, 412, 423]], dtype=torch.int32), 'scores': tensor([0.2734, 0.2873, 0.4350]), 'objectness_scores': tensor([0.3182, 0.2118, 0.2062]), 'labels': tensor([7, 7, 9], dtype=torch.int32)}\n",
      "235241\n",
      "{'image_id': 235399, 'boxes': tensor([[ 94, 215, 110, 253],\n",
      "        [121, 343, 175, 369],\n",
      "        [180, 268, 190, 275],\n",
      "        [161, 227, 227, 318]], dtype=torch.int32), 'scores': tensor([0.4408, 0.3057, 0.1720, 0.7499]), 'objectness_scores': tensor([0.2199, 0.3056, 0.3118, 0.4732]), 'labels': tensor([11,  8, 11,  3], dtype=torch.int32)}\n",
      "235399\n",
      "{'image_id': 236166, 'boxes': tensor([[  3, 207, 424, 637],\n",
      "        [ 26, 101, 328, 287],\n",
      "        [ 11, 374, 283, 612],\n",
      "        [ 21,   1, 425, 285],\n",
      "        [ 11, 328, 351, 529]], dtype=torch.int32), 'scores': tensor([0.6438, 0.4474, 0.6245, 0.5990, 0.7645]), 'objectness_scores': tensor([0.2143, 0.2071, 0.2425, 0.4462, 0.4507]), 'labels': tensor([3, 7, 3, 7, 3], dtype=torch.int32)}\n",
      "236166\n",
      "{'image_id': 236592, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "236592\n",
      "{'image_id': 236721, 'boxes': tensor([[  2,  95, 600, 481],\n",
      "        [311, 441, 406, 478],\n",
      "        [343, 249, 446, 380],\n",
      "        [438, 281, 537, 384],\n",
      "        [255, 144, 405, 285],\n",
      "        [403, 190, 491, 282],\n",
      "        [230, 127, 274, 164],\n",
      "        [419, 442, 487, 478],\n",
      "        [477, 230, 526, 283],\n",
      "        [289,  87, 408, 166],\n",
      "        [101, 109, 579, 429]], dtype=torch.int32), 'scores': tensor([0.4169, 0.1659, 0.8188, 0.9156, 0.2850, 0.8390, 0.7678, 0.6234, 0.5828,\n",
      "        0.5554, 0.4840]), 'objectness_scores': tensor([0.2091, 0.2523, 0.2299, 0.3550, 0.2598, 0.2570, 0.2736, 0.2243, 0.2669,\n",
      "        0.2796, 0.2134]), 'labels': tensor([12, 11, 10, 10, 12, 10,  6,  7, 10,  8, 12], dtype=torch.int32)}\n",
      "236721\n",
      "{'image_id': 237316, 'boxes': tensor([[ 46, 258, 163, 345],\n",
      "        [ 74, 234, 101, 263],\n",
      "        [248, 152, 261, 168],\n",
      "        [251,   7, 271,  67],\n",
      "        [176, 235, 198, 255],\n",
      "        [118, 233, 129, 260],\n",
      "        [159, 242, 261, 425],\n",
      "        [160, 242, 262, 290]], dtype=torch.int32), 'scores': tensor([0.3429, 0.5868, 0.1450, 0.2588, 0.2335, 0.2705, 0.6108, 0.1835]), 'objectness_scores': tensor([0.2531, 0.6633, 0.2284, 0.2476, 0.4270, 0.2558, 0.2450, 0.5779]), 'labels': tensor([14, 10, 14, 11,  0,  0, 15,  0], dtype=torch.int32)}\n",
      "237316\n",
      "{'image_id': 237517, 'boxes': tensor([[319, 316, 398, 348],\n",
      "        [ 62, 478, 309, 543],\n",
      "        [  3,  81, 144, 310],\n",
      "        [155, 322, 292, 375],\n",
      "        [248, 521, 294, 555],\n",
      "        [256, 520, 363, 624],\n",
      "        [204, 259, 274, 312],\n",
      "        [313, 559, 362, 623],\n",
      "        [ 50, 485, 372, 638],\n",
      "        [259, 547, 303, 586],\n",
      "        [351, 414, 475, 471],\n",
      "        [332, 550, 368, 586],\n",
      "        [280, 521, 339, 561],\n",
      "        [  1, 311, 448, 641],\n",
      "        [290, 554, 320, 581],\n",
      "        [123, 521, 227, 616]], dtype=torch.int32), 'scores': tensor([0.1812, 0.5511, 0.1882, 0.7279, 0.2927, 0.6070, 0.3101, 0.8417, 0.8140,\n",
      "        0.2686, 0.3781, 0.4279, 0.6772, 0.3665, 0.5238, 0.3847]), 'objectness_scores': tensor([0.2476, 0.5144, 0.2090, 0.2754, 0.2274, 0.2499, 0.3844, 0.3117, 0.2530,\n",
      "        0.2648, 0.4324, 0.2292, 0.2723, 0.2388, 0.2197, 0.3513]), 'labels': tensor([ 7, 11, 16, 11, 12, 12, 10, 12, 11, 12, 12, 12, 12, 11,  2, 11],\n",
      "       dtype=torch.int32)}\n",
      "237517\n",
      "{'image_id': 238410, 'boxes': tensor([[ 48, 226,  77, 240],\n",
      "        [261, 124, 296, 185],\n",
      "        [555, 291, 576, 341],\n",
      "        [255, 329, 278, 353],\n",
      "        [355,   0, 406, 227],\n",
      "        [487, 312, 526, 372],\n",
      "        [193, 181, 213, 189],\n",
      "        [487, 313, 529, 400],\n",
      "        [416, 177, 460, 216],\n",
      "        [496, 396, 524, 421],\n",
      "        [141, 235, 160, 275],\n",
      "        [220, 167, 249, 206],\n",
      "        [123, 262, 143, 291],\n",
      "        [233, 327, 250, 338],\n",
      "        [361, 163, 407, 199],\n",
      "        [322, 188, 343, 200],\n",
      "        [214, 365, 246, 385],\n",
      "        [227, 325, 381, 478],\n",
      "        [214, 204, 227, 230],\n",
      "        [455, 282, 481, 342],\n",
      "        [313, 324, 329, 344],\n",
      "        [231, 273, 378, 477],\n",
      "        [356,   1, 406, 160],\n",
      "        [465, 198, 489, 210],\n",
      "        [ 74, 190, 131, 221],\n",
      "        [ 95, 357, 132, 415],\n",
      "        [547, 204, 617, 246],\n",
      "        [430, 241, 444, 261],\n",
      "        [505,  67, 593, 192],\n",
      "        [260, 275, 366, 335],\n",
      "        [524, 226, 539, 236],\n",
      "        [234, 322, 244, 332],\n",
      "        [212, 178, 235, 213],\n",
      "        [270, 188, 313, 239],\n",
      "        [209, 424, 232, 448]], dtype=torch.int32), 'scores': tensor([0.2106, 0.2039, 0.3827, 0.2236, 0.2284, 0.7091, 0.2525, 0.9997, 0.2125,\n",
      "        0.2969, 0.2317, 0.1459, 0.2793, 0.2842, 0.2169, 0.2323, 0.1880, 0.4567,\n",
      "        0.2031, 0.5961, 0.2154, 0.4014, 0.5180, 0.2918, 0.2146, 0.7267, 0.2615,\n",
      "        0.1458, 0.2938, 0.5002, 0.2265, 0.2063, 0.4156, 0.2328, 0.2668]), 'objectness_scores': tensor([0.3627, 0.2146, 0.3990, 0.3538, 0.6354, 0.4408, 0.3900, 0.2585, 0.3715,\n",
      "        0.5177, 0.2554, 0.3288, 0.3443, 0.3476, 0.3914, 0.3516, 0.3332, 0.3747,\n",
      "        0.3668, 0.4980, 0.2256, 0.2667, 0.2432, 0.3520, 0.5057, 0.4729, 0.4627,\n",
      "        0.2956, 0.2862, 0.3491, 0.2726, 0.2791, 0.2006, 0.3380, 0.2275]), 'labels': tensor([11, 11, 11,  9, 11, 10,  2, 12,  7,  7, 11, 11,  2, 11, 11, 11, 11, 10,\n",
      "        11, 10,  0,  8,  8, 11, 11, 10,  6,  1,  9, 10, 11, 11,  7,  7, 11],\n",
      "       dtype=torch.int32)}\n",
      "238410\n",
      "{'image_id': 239041, 'boxes': tensor([[ 60, 242,  85, 275],\n",
      "        [525, 283, 570, 329],\n",
      "        [196,   2, 478, 335],\n",
      "        [342,  77, 353,  96],\n",
      "        [  0,  52,  63, 225],\n",
      "        [592, 310, 608, 334],\n",
      "        [284,  76, 296,  95],\n",
      "        [115, 385, 188, 426],\n",
      "        [  0, 305,  86, 415],\n",
      "        [105, 403, 188, 427],\n",
      "        [323,  82, 378, 234],\n",
      "        [ 62, 187, 119, 247],\n",
      "        [155, 264, 172, 284],\n",
      "        [  0,   0,  39,  21],\n",
      "        [313, 298, 471, 337],\n",
      "        [ 33, 280,  57, 343],\n",
      "        [425, 299, 473, 339],\n",
      "        [  0, 287,  20, 329],\n",
      "        [  4, 303,  19, 329],\n",
      "        [549, 294, 563, 321],\n",
      "        [264,  82, 318, 213],\n",
      "        [120, 386, 181, 412]], dtype=torch.int32), 'scores': tensor([0.3147, 0.3405, 0.7540, 0.2271, 0.1891, 0.3218, 0.1831, 0.3559, 0.9478,\n",
      "        0.2292, 0.9901, 0.3449, 0.6661, 0.4774, 0.5827, 0.1549, 0.4308, 0.2754,\n",
      "        0.3238, 0.2577, 0.7411, 0.3140]), 'objectness_scores': tensor([0.3123, 0.2446, 0.3800, 0.2337, 0.4489, 0.2363, 0.2250, 0.3102, 0.4223,\n",
      "        0.2040, 0.2319, 0.4818, 0.2398, 0.2220, 0.5758, 0.5188, 0.3384, 0.3932,\n",
      "        0.2241, 0.2202, 0.2280, 0.2029]), 'labels': tensor([11, 14,  7, 11, 10, 11, 11, 13, 15, 11,  7, 10, 11, 11, 13,  9, 13, 11,\n",
      "         7,  8,  7, 11], dtype=torch.int32)}\n",
      "239041\n",
      "{'image_id': 239318, 'boxes': tensor([[ 71, 235, 324, 326],\n",
      "        [ 61, 323, 333, 454],\n",
      "        [  0, 190, 374, 497]], dtype=torch.int32), 'scores': tensor([0.7859, 0.9960, 0.9990]), 'objectness_scores': tensor([0.2615, 0.7061, 0.4069]), 'labels': tensor([14, 14, 14], dtype=torch.int32)}\n",
      "239318\n",
      "{'image_id': 239347, 'boxes': tensor([[182, 416, 520, 480],\n",
      "        [334, 240, 339, 245],\n",
      "        [359, 223, 370, 239],\n",
      "        [  5,   1, 637, 477],\n",
      "        [325,  62, 390,  99],\n",
      "        [218,  68, 285, 101],\n",
      "        [356, 222, 530, 286],\n",
      "        [237, 210, 270, 229],\n",
      "        [283, 177, 469, 229],\n",
      "        [189, 148, 273, 256]], dtype=torch.int32), 'scores': tensor([0.2029, 0.1876, 0.1759, 0.8633, 0.2882, 0.2404, 0.6111, 0.2176, 0.2261,\n",
      "        0.2698]), 'objectness_scores': tensor([0.2077, 0.2883, 0.4300, 0.2246, 0.2290, 0.2189, 0.2135, 0.3540, 0.2063,\n",
      "        0.2400]), 'labels': tensor([14, 10,  3, 13, 14, 11,  8, 10,  4,  7], dtype=torch.int32)}\n",
      "239347\n",
      "{'image_id': 239627, 'boxes': tensor([[528,  43, 592, 128],\n",
      "        [191,  25, 245,  62],\n",
      "        [331, 211, 396, 284],\n",
      "        [271,  26, 377, 190],\n",
      "        [  1,  72, 280, 400],\n",
      "        [195,  24, 378, 190],\n",
      "        [291,  61, 378, 191],\n",
      "        [296,  97, 604, 419]], dtype=torch.int32), 'scores': tensor([0.6982, 0.2020, 0.9062, 0.6307, 0.9954, 0.9913, 0.3582, 0.9895]), 'objectness_scores': tensor([0.3284, 0.2204, 0.2620, 0.2420, 0.3579, 0.3576, 0.2153, 0.3490]), 'labels': tensor([ 7,  7, 10, 11, 15, 15, 15, 15], dtype=torch.int32)}\n",
      "239627\n",
      "{'image_id': 240250, 'boxes': tensor([[136, 101, 193, 121],\n",
      "        [213, 355, 223, 363],\n",
      "        [284,  91, 386, 130],\n",
      "        [  0, 356, 606, 615],\n",
      "        [ 43, 364, 165, 431],\n",
      "        [  0, 439, 269, 614],\n",
      "        [238, 361, 422, 437],\n",
      "        [274, 161, 443, 369],\n",
      "        [279, 438, 610, 612],\n",
      "        [463, 343, 491, 380],\n",
      "        [134,  58, 160,  80],\n",
      "        [560, 305, 611, 447]], dtype=torch.int32), 'scores': tensor([0.3719, 0.2318, 0.2223, 0.5006, 0.2734, 0.3684, 0.4698, 0.3802, 0.5101,\n",
      "        0.1454, 0.4082, 0.2602]), 'objectness_scores': tensor([0.2232, 0.3217, 0.4449, 0.5169, 0.6317, 0.4789, 0.5468, 0.4066, 0.5085,\n",
      "        0.4065, 0.2433, 0.5306]), 'labels': tensor([11, 11, 14, 12,  7, 11, 12, 16, 12, 11, 11,  1], dtype=torch.int32)}\n",
      "240250\n",
      "{'image_id': 240940, 'boxes': tensor([[ 77,   0, 307, 336],\n",
      "        [301,   0, 357, 349],\n",
      "        [339, 246, 356, 277],\n",
      "        [115, 309, 205, 500],\n",
      "        [ 79, 145, 302, 337]], dtype=torch.int32), 'scores': tensor([0.4121, 0.2563, 0.4317, 0.5139, 0.7888]), 'objectness_scores': tensor([0.2243, 0.2379, 0.2304, 0.4698, 0.2653]), 'labels': tensor([9, 8, 6, 5, 2], dtype=torch.int32)}\n",
      "240940\n",
      "{'image_id': 241319, 'boxes': tensor([[206, 177, 302, 315],\n",
      "        [ 98,  63, 143, 139],\n",
      "        [ 79,   0, 108,  65],\n",
      "        [509, 214, 589, 305],\n",
      "        [351, 192, 424, 316],\n",
      "        [111, 223, 177, 317],\n",
      "        [105,  37, 144, 135],\n",
      "        [482, 285, 639, 321],\n",
      "        [ 96,  50, 144, 168],\n",
      "        [104,  85, 143, 132]], dtype=torch.int32), 'scores': tensor([0.5920, 0.3038, 0.1967, 0.4317, 0.5476, 0.5392, 0.1832, 0.4138, 0.2070,\n",
      "        0.2623]), 'objectness_scores': tensor([0.4127, 0.2332, 0.2949, 0.5217, 0.2042, 0.5561, 0.4104, 0.3894, 0.2639,\n",
      "        0.2818]), 'labels': tensor([15,  9,  3, 16, 15,  6, 10,  9,  9, 10], dtype=torch.int32)}\n",
      "241319\n",
      "{'image_id': 241602, 'boxes': tensor([[386,  79, 434, 127],\n",
      "        [302, 288, 329, 300],\n",
      "        [258, 292, 433, 312],\n",
      "        [213, 127, 259, 174],\n",
      "        [157, 227, 266, 338],\n",
      "        [ 89, 233, 100, 245],\n",
      "        [137,  73, 151, 125],\n",
      "        [506,  56, 576, 216],\n",
      "        [516, 102, 561, 209],\n",
      "        [197, 179, 222, 204],\n",
      "        [433, 246, 582, 421]], dtype=torch.int32), 'scores': tensor([0.6825, 0.1577, 0.4371, 0.4190, 0.5130, 0.2260, 0.3095, 0.5503, 0.7192,\n",
      "        0.4192, 0.3150]), 'objectness_scores': tensor([0.2020, 0.2409, 0.2539, 0.2119, 0.2099, 0.3128, 0.2187, 0.2563, 0.4598,\n",
      "        0.3404, 0.2696]), 'labels': tensor([ 7, 10, 11,  7, 15, 11, 11,  8,  8, 10,  9], dtype=torch.int32)}\n",
      "241602\n",
      "{'image_id': 241668, 'boxes': tensor([[290, 429, 355, 480],\n",
      "        [359, 500, 365, 513],\n",
      "        [  4, 347, 263, 641],\n",
      "        [172,   4, 249,  36],\n",
      "        [348, 510, 418, 595],\n",
      "        [  0, 360,  40, 388],\n",
      "        [157, 220, 214, 306],\n",
      "        [257, 281, 308, 606],\n",
      "        [266, 472, 373, 491],\n",
      "        [325, 365, 364, 422]], dtype=torch.int32), 'scores': tensor([0.6013, 0.3781, 0.4306, 0.1723, 0.2262, 0.6098, 0.1764, 0.2273, 0.4037,\n",
      "        0.2144]), 'objectness_scores': tensor([0.4969, 0.5129, 0.2639, 0.3382, 0.3039, 0.2147, 0.6616, 0.6119, 0.3617,\n",
      "        0.2258]), 'labels': tensor([12, 11, 12, 12, 13, 11, 10, 11, 11,  7], dtype=torch.int32)}\n",
      "241668\n",
      "{'image_id': 242060, 'boxes': tensor([[345, 226, 431, 320],\n",
      "        [418,  24, 550,  73],\n",
      "        [234,   0, 302, 109],\n",
      "        [528, 219, 614, 313],\n",
      "        [205,  49, 283, 185],\n",
      "        [135,  65, 643, 460],\n",
      "        [285,  15, 359, 143],\n",
      "        [252, 139, 638, 365],\n",
      "        [329, 147, 615, 341],\n",
      "        [  4,   1, 636, 459]], dtype=torch.int32), 'scores': tensor([0.9917, 0.5941, 0.9573, 0.9918, 0.9279, 0.9966, 0.1940, 0.3153, 0.9962,\n",
      "        0.2176]), 'objectness_scores': tensor([0.4465, 0.3330, 0.5122, 0.4635, 0.5075, 0.4234, 0.5274, 0.3295, 0.2257,\n",
      "        0.2033]), 'labels': tensor([12, 12, 10, 12, 10, 15, 11, 11, 14, 14], dtype=torch.int32)}\n",
      "242060\n",
      "{'image_id': 242934, 'boxes': tensor([[117, 168, 407, 227],\n",
      "        [355,  54, 371,  77],\n",
      "        [225,  98, 292, 133],\n",
      "        [413,  40, 428,  70],\n",
      "        [146, 101, 267, 183],\n",
      "        [ 59, 125,  93, 153],\n",
      "        [324,  87, 337, 106],\n",
      "        [164, 124, 195, 151],\n",
      "        [171, 122, 198, 144],\n",
      "        [275,  41, 324, 107],\n",
      "        [ 46,  46,  70, 149],\n",
      "        [218, 157, 352, 226],\n",
      "        [272, 104, 413, 197],\n",
      "        [178,  56, 200,  76],\n",
      "        [ 54, 207, 122, 227],\n",
      "        [368, 137, 394, 163],\n",
      "        [ 46,  56,  67, 150],\n",
      "        [356, 137, 380, 170],\n",
      "        [464,  61, 496, 140],\n",
      "        [330, 135, 360, 158],\n",
      "        [101, 131, 136, 157],\n",
      "        [156,  50, 175,  76],\n",
      "        [ 50, 131,  78, 160],\n",
      "        [148,  99, 409, 199],\n",
      "        [454, 131, 497, 227]], dtype=torch.int32), 'scores': tensor([0.3304, 0.4226, 0.4247, 0.4053, 0.9991, 0.2793, 0.1764, 0.8347, 0.8872,\n",
      "        0.6763, 0.3712, 0.3517, 0.9960, 0.2938, 0.1851, 0.8204, 0.2025, 0.5566,\n",
      "        0.4079, 0.3854, 0.1866, 0.4627, 0.3604, 0.9907, 0.1822]), 'objectness_scores': tensor([0.3684, 0.2055, 0.2421, 0.2249, 0.4555, 0.3355, 0.2037, 0.3771, 0.3482,\n",
      "        0.2338, 0.3092, 0.6132, 0.4900, 0.2431, 0.2471, 0.2292, 0.2040, 0.3186,\n",
      "        0.2934, 0.3150, 0.2014, 0.2306, 0.2469, 0.3420, 0.2567]), 'labels': tensor([14,  9, 13, 11, 13,  9, 11,  7,  7, 13, 10,  1, 13, 14, 14,  7,  8,  7,\n",
      "        16, 11, 11,  8, 11, 13, 14], dtype=torch.int32)}\n",
      "242934\n",
      "{'image_id': 242946, 'boxes': tensor([[  9, 346, 236, 461],\n",
      "        [ 39, 176, 224, 277],\n",
      "        [  1, 268, 106, 284],\n",
      "        [111, 289, 157, 339],\n",
      "        [ 44, 284, 102, 339],\n",
      "        [ 68, 288, 118, 340],\n",
      "        [ -3, 176, 624, 481]], dtype=torch.int32), 'scores': tensor([0.2443, 0.2796, 0.4102, 0.4452, 0.6730, 0.5450, 0.3062]), 'objectness_scores': tensor([0.2503, 0.2392, 0.2281, 0.2254, 0.2140, 0.2128, 0.2052]), 'labels': tensor([ 1,  7, 11, 12, 12, 12,  7], dtype=torch.int32)}\n",
      "242946\n",
      "{'image_id': 243344, 'boxes': tensor([[ 84, 274, 132, 349],\n",
      "        [179,  36, 475, 342],\n",
      "        [177, 165, 279, 350],\n",
      "        [ 30, 516,  81, 641],\n",
      "        [ 76, 441,  92, 459]], dtype=torch.int32), 'scores': tensor([0.2557, 0.1853, 0.9797, 0.4200, 0.3540]), 'objectness_scores': tensor([0.3460, 0.4170, 0.5716, 0.3549, 0.2931]), 'labels': tensor([ 8,  2,  2,  7, 11], dtype=torch.int32)}\n",
      "243344\n",
      "{'image_id': 243626, 'boxes': tensor([[202,  89, 266, 154],\n",
      "        [226,  75, 250, 113],\n",
      "        [  0,   0, 194, 291],\n",
      "        [ 68,  58, 209, 175],\n",
      "        [222,  58, 327, 167],\n",
      "        [253,  73, 330, 162],\n",
      "        [208, 115, 225, 132],\n",
      "        [203, 101, 324, 185],\n",
      "        [  3,   5, 382, 289],\n",
      "        [ 66,   0, 147,  54],\n",
      "        [ 54,  56, 300, 216],\n",
      "        [215,  73, 242, 116],\n",
      "        [ 22,  36, 372, 260],\n",
      "        [241,  92, 305, 181],\n",
      "        [242,  92, 261, 129],\n",
      "        [ 80, 166, 237, 238],\n",
      "        [260, 120, 314, 195],\n",
      "        [222,  61, 325, 167],\n",
      "        [202,  90, 226, 111],\n",
      "        [203, 101, 280, 167],\n",
      "        [201,  57, 330, 196]], dtype=torch.int32), 'scores': tensor([0.5758, 0.2303, 0.5560, 0.7023, 0.2173, 0.6390, 0.3148, 0.7141, 0.3269,\n",
      "        0.5784, 0.3667, 0.2346, 0.5920, 0.7217, 0.2647, 0.4592, 0.4028, 0.4684,\n",
      "        0.2014, 0.5934, 0.6739]), 'objectness_scores': tensor([0.2699, 0.2473, 0.2571, 0.2354, 0.4793, 0.3668, 0.2154, 0.4897, 0.2769,\n",
      "        0.5219, 0.4819, 0.3381, 0.4285, 0.3370, 0.2643, 0.4879, 0.3111, 0.2194,\n",
      "        0.2147, 0.2933, 0.4276]), 'labels': tensor([11, 11,  4,  4,  7, 11, 11, 11, 11, 12,  4, 11,  4, 11, 11, 12,  7, 11,\n",
      "         7, 11, 11], dtype=torch.int32)}\n",
      "243626\n",
      "{'image_id': 243867, 'boxes': tensor([[219, 250, 232, 275],\n",
      "        [547, 332, 565, 405],\n",
      "        [ 55, 100, 540, 302]], dtype=torch.int32), 'scores': tensor([0.2377, 0.5014, 0.9981]), 'objectness_scores': tensor([0.2379, 0.3415, 0.5982]), 'labels': tensor([ 8, 11,  1], dtype=torch.int32)}\n",
      "243867\n",
      "{'image_id': 243989, 'boxes': tensor([[108, 248, 176, 377],\n",
      "        [308, 268, 418, 402],\n",
      "        [ 30, 405,  83, 438],\n",
      "        [411, 400, 462, 438],\n",
      "        [220,  70, 308, 147],\n",
      "        [328, 192, 375, 224],\n",
      "        [  0, 301,  97, 372],\n",
      "        [482, 348, 499, 356],\n",
      "        [ 92, 390, 112, 399],\n",
      "        [204,  38, 253,  76],\n",
      "        [417, 406, 433, 418],\n",
      "        [ 12, 424,  44, 437],\n",
      "        [165, 159, 347, 405],\n",
      "        [219, 101, 272, 122],\n",
      "        [158, 203, 181, 215],\n",
      "        [332, 222, 371, 234],\n",
      "        [160, 175, 193, 205]], dtype=torch.int32), 'scores': tensor([0.6100, 0.3506, 0.2259, 0.2477, 0.1695, 0.3124, 0.6767, 0.4093, 0.5370,\n",
      "        0.4125, 0.2995, 0.2882, 0.9239, 0.1639, 0.2552, 0.4825, 0.3615]), 'objectness_scores': tensor([0.2314, 0.2226, 0.3417, 0.2341, 0.3146, 0.3080, 0.2283, 0.2967, 0.2680,\n",
      "        0.4973, 0.2662, 0.2494, 0.2233, 0.2491, 0.3160, 0.2928, 0.3052]), 'labels': tensor([ 7,  7,  4, 11,  7, 10,  7, 11, 11,  7, 11, 14,  9, 11, 11, 11,  7],\n",
      "       dtype=torch.int32)}\n",
      "243989\n",
      "{'image_id': 244496, 'boxes': tensor([[ 94, 399, 179, 418],\n",
      "        [ 94,  94, 175, 125],\n",
      "        [  7, 151, 265, 496],\n",
      "        [106, 182, 154, 426]], dtype=torch.int32), 'scores': tensor([0.2408, 0.3409, 0.9998, 0.9584]), 'objectness_scores': tensor([0.3768, 0.3834, 0.2510, 0.5486]), 'labels': tensor([7, 7, 7, 7], dtype=torch.int32)}\n",
      "244496\n",
      "{'image_id': 244750, 'boxes': tensor([[180, 147, 246, 170],\n",
      "        [  2, 357, 391, 493],\n",
      "        [125, 273, 171, 406],\n",
      "        [ 63, 290, 105, 363],\n",
      "        [311,  60, 392, 195],\n",
      "        [259, 280, 393, 433],\n",
      "        [  9, 313,  48, 404],\n",
      "        [173, 272, 219, 405],\n",
      "        [271, 190, 276, 195],\n",
      "        [311,  61, 392, 119],\n",
      "        [  0, 237,  74, 384],\n",
      "        [ 78, 223, 101, 295],\n",
      "        [225, 271, 271, 403]], dtype=torch.int32), 'scores': tensor([0.1836, 0.2868, 0.8284, 0.3087, 0.6399, 0.9673, 0.2721, 0.7988, 0.2806,\n",
      "        0.2323, 0.8022, 0.4347, 0.8204]), 'objectness_scores': tensor([0.2137, 0.2104, 0.4531, 0.2292, 0.2927, 0.4376, 0.4127, 0.4496, 0.3009,\n",
      "        0.2525, 0.3044, 0.3419, 0.4532]), 'labels': tensor([ 7, 15, 10,  7,  6, 10, 10, 10, 11, 14, 10,  7, 10], dtype=torch.int32)}\n",
      "244750\n",
      "{'image_id': 245026, 'boxes': tensor([[486, 124, 535, 164],\n",
      "        [ 98,   2, 285,  55],\n",
      "        [522, 342, 586, 421],\n",
      "        [422, 178, 638, 391],\n",
      "        [184, 269, 431, 404],\n",
      "        [419,  96, 491, 165],\n",
      "        [255,  89, 326, 110],\n",
      "        [529, 123, 584, 165],\n",
      "        [ 21, 330, 635, 421],\n",
      "        [463, 380, 639, 420],\n",
      "        [ 52, 303,  71, 323]], dtype=torch.int32), 'scores': tensor([0.1616, 0.2384, 0.9573, 0.4103, 0.9991, 0.9023, 0.2557, 0.3072, 0.9989,\n",
      "        0.2185, 0.2320]), 'objectness_scores': tensor([0.3336, 0.2877, 0.4585, 0.2824, 0.5486, 0.5062, 0.2395, 0.2418, 0.3032,\n",
      "        0.2251, 0.4517]), 'labels': tensor([ 7, 12, 10, 12, 12, 10,  7,  7, 12,  6, 11], dtype=torch.int32)}\n",
      "245026\n",
      "{'image_id': 245320, 'boxes': tensor([[408, 294, 420, 311],\n",
      "        [225, 268, 337, 318]], dtype=torch.int32), 'scores': tensor([0.2834, 0.2680]), 'objectness_scores': tensor([0.2725, 0.6092]), 'labels': tensor([14, 11], dtype=torch.int32)}\n",
      "245320\n",
      "{'image_id': 245576, 'boxes': tensor([[144,  64, 155,  81],\n",
      "        [ 75, 155, 108, 179],\n",
      "        [  0, 186, 632, 468],\n",
      "        [ 89,  69, 106, 122],\n",
      "        [576,  46, 637, 190],\n",
      "        [102,  60, 124, 119],\n",
      "        [ 77,   9, 128, 121],\n",
      "        [154,  63, 164,  81],\n",
      "        [194,  69, 278, 205],\n",
      "        [218,   3, 569, 397],\n",
      "        [125,  69, 135, 102],\n",
      "        [ 64, 104,  72, 121],\n",
      "        [ 77,  53, 101, 122],\n",
      "        [101, 112, 147, 181]], dtype=torch.int32), 'scores': tensor([0.1968, 0.3070, 0.6746, 0.4128, 0.1142, 0.6331, 0.5531, 0.3682, 0.3470,\n",
      "        0.5587, 0.1874, 0.2523, 0.3018, 0.2876]), 'objectness_scores': tensor([0.2193, 0.2057, 0.2489, 0.2312, 0.2163, 0.2186, 0.3304, 0.2408, 0.4284,\n",
      "        0.5283, 0.2851, 0.2269, 0.2987, 0.2666]), 'labels': tensor([11, 11, 14, 11, 11, 16,  8, 11, 15, 14, 11, 11,  7,  7],\n",
      "       dtype=torch.int32)}\n",
      "245576\n",
      "{'image_id': 245764, 'boxes': tensor([[446,   6, 575, 287],\n",
      "        [ 80, 384, 301, 479],\n",
      "        [395, 128, 414, 144],\n",
      "        [ 56,  52,  89, 104],\n",
      "        [ 58,  91, 113, 206],\n",
      "        [ 97,   1, 414, 198],\n",
      "        [191, 177, 492, 479],\n",
      "        [548,   0, 637, 105],\n",
      "        [ 59,  92, 476, 402]], dtype=torch.int32), 'scores': tensor([0.5476, 0.5786, 0.3228, 0.3024, 0.2074, 0.4716, 0.5302, 0.3111, 0.5797]), 'objectness_scores': tensor([0.2848, 0.2520, 0.2624, 0.3763, 0.2022, 0.2789, 0.4705, 0.2305, 0.5485]), 'labels': tensor([ 7,  7, 12, 11, 11,  2,  2,  7,  2], dtype=torch.int32)}\n",
      "245764\n",
      "{'image_id': 246308, 'boxes': tensor([[177,  74, 208, 123],\n",
      "        [ 57, 114, 132, 251],\n",
      "        [249, 222, 271, 269],\n",
      "        [ -1, 477, 443, 643],\n",
      "        [242,  75, 266, 122],\n",
      "        [145,  71, 172, 121],\n",
      "        [171, 223, 196, 250],\n",
      "        [ 66, 114,  98, 239],\n",
      "        [ 26, 113, 132, 253],\n",
      "        [351, 482, 392, 518],\n",
      "        [323, 194, 341, 252],\n",
      "        [ 25, 125,  63, 174],\n",
      "        [235, 205, 257, 241],\n",
      "        [ 21,  38, 438, 270],\n",
      "        [204, 200, 225, 251],\n",
      "        [112, 585, 303, 637],\n",
      "        [140, 195, 168, 251],\n",
      "        [144,  70, 268, 122],\n",
      "        [174, 196, 199, 250],\n",
      "        [403, 439, 431, 489],\n",
      "        [357, 337, 377, 381],\n",
      "        [ 25, 125,  71, 212],\n",
      "        [276,  34, 352, 122],\n",
      "        [209,  76, 238, 122],\n",
      "        [312, 192, 341, 253],\n",
      "        [393, 436, 454, 525],\n",
      "        [300,  51, 333, 124],\n",
      "        [235, 195, 258, 250],\n",
      "        [309, 191, 330, 252],\n",
      "        [ 53, 467,  88, 520],\n",
      "        [396, 373, 481, 520],\n",
      "        [374,  41, 407, 118],\n",
      "        [184, 232, 203, 252],\n",
      "        [203, 233, 214, 249],\n",
      "        [265, 186, 315, 252],\n",
      "        [252, 222, 271, 250],\n",
      "        [156, 230, 173, 252],\n",
      "        [ 64, 175,  93, 241],\n",
      "        [  0, 324,  23, 361],\n",
      "        [339,  37, 434, 122],\n",
      "        [ 39, 141,  69, 212],\n",
      "        [240, 508, 257, 518],\n",
      "        [102, 116, 130, 208],\n",
      "        [176, 196, 198, 236],\n",
      "        [ 81, 173, 116, 247],\n",
      "        [ 41, 121, 445, 272]], dtype=torch.int32), 'scores': tensor([0.3013, 0.1971, 0.3408, 0.9972, 0.2745, 0.2407, 0.9998, 0.5474, 0.3199,\n",
      "        0.6012, 0.4259, 0.7758, 0.3205, 0.3113, 0.4124, 0.9984, 0.1471, 0.6575,\n",
      "        0.2344, 0.2603, 0.2644, 0.3605, 0.3665, 0.1996, 0.3021, 0.3989, 0.4092,\n",
      "        0.3236, 0.9077, 0.6476, 0.2426, 0.4054, 0.3549, 0.1975, 0.2774, 0.4413,\n",
      "        0.4819, 0.3641, 0.4742, 0.5719, 0.2773, 0.3680, 0.3388, 0.4684, 0.8336,\n",
      "        0.5509]), 'objectness_scores': tensor([0.4850, 0.2106, 0.4165, 0.3690, 0.4578, 0.4915, 0.2725, 0.2694, 0.3585,\n",
      "        0.2398, 0.4219, 0.2076, 0.2093, 0.2655, 0.4522, 0.6208, 0.4801, 0.2068,\n",
      "        0.3465, 0.3123, 0.2016, 0.2811, 0.4101, 0.4895, 0.2244, 0.2233, 0.2558,\n",
      "        0.4390, 0.4117, 0.3590, 0.2490, 0.3025, 0.2813, 0.2949, 0.3831, 0.2730,\n",
      "        0.2085, 0.2410, 0.3258, 0.4113, 0.4021, 0.2220, 0.3193, 0.3840, 0.3950,\n",
      "        0.2087]), 'labels': tensor([ 7,  4, 11, 14,  8,  8,  5,  8,  9, 14,  8, 11, 11,  8, 11, 14, 10,  7,\n",
      "         8,  8,  8,  8, 16,  8,  8,  7,  7, 11,  2,  8,  7,  7,  8, 14,  3, 11,\n",
      "         7,  7, 11, 16,  8, 11, 11,  8, 10,  8], dtype=torch.int32)}\n",
      "246308\n",
      "{'image_id': 246436, 'boxes': tensor([[190, 448, 242, 462],\n",
      "        [271, 337, 419, 451],\n",
      "        [157, 408, 443, 523],\n",
      "        [230, 307, 314, 325],\n",
      "        [ 37, 118,  53, 171],\n",
      "        [406,  25, 479,  83],\n",
      "        [239, 403, 281, 463],\n",
      "        [245, 556, 432, 638],\n",
      "        [277, 382, 312, 423],\n",
      "        [240, 469, 455, 574],\n",
      "        [319, 284, 339, 322]], dtype=torch.int32), 'scores': tensor([0.2346, 0.6172, 0.5517, 0.4643, 0.3330, 0.2565, 0.9866, 0.6808, 0.2349,\n",
      "        0.5406, 0.2481]), 'objectness_scores': tensor([0.2051, 0.5252, 0.2251, 0.2730, 0.5317, 0.2035, 0.4322, 0.2493, 0.3674,\n",
      "        0.3429, 0.3130]), 'labels': tensor([11, 10, 12, 11, 11,  7, 10,  3,  7, 12, 11], dtype=torch.int32)}\n",
      "246436\n",
      "{'image_id': 246454, 'boxes': tensor([[  2, 232, 327, 620],\n",
      "        [  1, 279, 313, 639],\n",
      "        [291, 521, 366, 563],\n",
      "        [ 95, 279, 128, 302]], dtype=torch.int32), 'scores': tensor([0.9617, 0.9668, 0.3433, 0.1614]), 'objectness_scores': tensor([0.5114, 0.4681, 0.2925, 0.3124]), 'labels': tensor([ 3,  3, 11,  9], dtype=torch.int32)}\n",
      "246454\n",
      "{'image_id': 246968, 'boxes': tensor([[167, 126, 277, 151],\n",
      "        [563, 240, 573, 248],\n",
      "        [  0, 187,  54, 341],\n",
      "        [283,  77, 380, 159],\n",
      "        [336, 246, 377, 334],\n",
      "        [116,  70, 168, 190],\n",
      "        [ 67, 278,  93, 337],\n",
      "        [  5, 345,  78, 385],\n",
      "        [ 88, 355, 129, 386],\n",
      "        [146, 302, 169, 331],\n",
      "        [217, 242, 223, 258],\n",
      "        [219,  13, 474,  80],\n",
      "        [ 84, 265, 149, 344],\n",
      "        [ 71,   0, 139,  40],\n",
      "        [429, 269, 531, 341],\n",
      "        [381,  90, 452, 168],\n",
      "        [119, 270, 173, 316],\n",
      "        [169,  73, 276, 130],\n",
      "        [ 60,  51, 164, 195],\n",
      "        [225, 253, 266, 296]], dtype=torch.int32), 'scores': tensor([0.5968, 0.1977, 0.1227, 0.1751, 0.9336, 0.3952, 0.7186, 0.6873, 0.1920,\n",
      "        0.2766, 0.1605, 0.2692, 0.8870, 0.3945, 0.2493, 0.3712, 0.7972, 0.2815,\n",
      "        0.4027, 0.2457]), 'objectness_scores': tensor([0.5210, 0.2584, 0.2259, 0.2621, 0.2938, 0.2737, 0.2977, 0.5316, 0.2033,\n",
      "        0.2617, 0.2517, 0.2864, 0.4258, 0.2992, 0.2333, 0.2379, 0.2869, 0.3235,\n",
      "        0.2271, 0.2489]), 'labels': tensor([11, 11, 14,  7, 10,  7, 10, 14, 11, 11, 11,  7, 10,  6, 14,  7, 15, 13,\n",
      "         7,  7], dtype=torch.int32)}\n",
      "246968\n",
      "{'image_id': 248111, 'boxes': tensor([[328, 356, 366, 402],\n",
      "        [205, 263, 273, 280],\n",
      "        [333, 206, 390, 222],\n",
      "        [415, 244, 429, 272],\n",
      "        [381, 130, 398, 158],\n",
      "        [322,  72, 374, 102],\n",
      "        [245, 380, 269, 420],\n",
      "        [323, 257, 393, 283]], dtype=torch.int32), 'scores': tensor([0.9579, 0.4958, 0.2808, 0.9296, 0.5421, 0.3083, 0.2573, 0.3141]), 'objectness_scores': tensor([0.3053, 0.2560, 0.3258, 0.2372, 0.2077, 0.2041, 0.2278, 0.3867]), 'labels': tensor([10, 11, 11,  3, 11, 10, 10, 14], dtype=torch.int32)}\n",
      "248111\n",
      "{'image_id': 248284, 'boxes': tensor([[197, 119, 247, 215],\n",
      "        [176,  37, 199,  69],\n",
      "        [283,  81, 426, 129],\n",
      "        [283,  81, 426, 163]], dtype=torch.int32), 'scores': tensor([0.2421, 0.1877, 0.1586, 0.9465]), 'objectness_scores': tensor([0.3288, 0.2024, 0.2078, 0.5850]), 'labels': tensor([11, 11,  9,  6], dtype=torch.int32)}\n",
      "248284\n",
      "{'image_id': 248314, 'boxes': tensor([[406, 190, 427, 209],\n",
      "        [ 22,  -1, 579, 471],\n",
      "        [ 60, 301, 119, 362],\n",
      "        [372,  60, 423, 121]], dtype=torch.int32), 'scores': tensor([0.2994, 0.8340, 0.5441, 0.1258]), 'objectness_scores': tensor([0.2492, 0.2948, 0.2235, 0.2296]), 'labels': tensor([12, 14, 14, 11], dtype=torch.int32)}\n",
      "248314\n",
      "{'image_id': 249129, 'boxes': tensor([[186, 204, 380, 353],\n",
      "        [586,  88, 600, 128],\n",
      "        [265, 235, 294, 254],\n",
      "        [121,  75, 149, 106],\n",
      "        [190, 216, 224, 234],\n",
      "        [518,   0, 575, 137],\n",
      "        [247, 198, 291, 233],\n",
      "        [112,  57, 161, 109],\n",
      "        [320, 188, 342, 220],\n",
      "        [185,   0, 313, 210]], dtype=torch.int32), 'scores': tensor([0.3990, 0.1732, 0.2219, 0.1443, 0.2826, 0.3258, 0.1751, 0.3159, 0.1862,\n",
      "        0.3116]), 'objectness_scores': tensor([0.2905, 0.2134, 0.2360, 0.2242, 0.2529, 0.2112, 0.2200, 0.2739, 0.2099,\n",
      "        0.4922]), 'labels': tensor([ 8, 11, 11, 11, 11,  7, 11, 16,  8,  8], dtype=torch.int32)}\n",
      "249129\n",
      "{'image_id': 250127, 'boxes': tensor([[247, 259, 366, 456],\n",
      "        [142, 139, 408, 345],\n",
      "        [276, 550, 309, 601],\n",
      "        [310, 551, 340, 603]], dtype=torch.int32), 'scores': tensor([0.4636, 0.9980, 0.4759, 0.4073]), 'objectness_scores': tensor([0.3294, 0.3408, 0.2777, 0.2726]), 'labels': tensor([16,  6,  7,  7], dtype=torch.int32)}\n",
      "250127\n",
      "{'image_id': 250137, 'boxes': tensor([[ 34, 332,  49, 356],\n",
      "        [ 74, 307,  98, 352],\n",
      "        [  2,   2, 419, 374],\n",
      "        [192, 262, 270, 294],\n",
      "        [205, 298, 315, 493],\n",
      "        [391, 279, 439, 303]], dtype=torch.int32), 'scores': tensor([0.2371, 0.6524, 0.9840, 0.3183, 0.5946, 0.1315]), 'objectness_scores': tensor([0.3134, 0.2331, 0.3002, 0.2520, 0.2557, 0.3145]), 'labels': tensor([11, 11,  6, 16,  7, 11], dtype=torch.int32)}\n",
      "250137\n",
      "{'image_id': 250282, 'boxes': tensor([[449,  92, 461, 127],\n",
      "        [310, 126, 318, 139],\n",
      "        [415, 121, 424, 131],\n",
      "        [507, 246, 519, 267],\n",
      "        [140, 125, 151, 138],\n",
      "        [272,  80, 279,  89],\n",
      "        [ 60,  90,  67, 102],\n",
      "        [170, 169, 181, 183],\n",
      "        [234, 236, 244, 270],\n",
      "        [426, 312, 436, 329],\n",
      "        [390,  84, 398,  96],\n",
      "        [357, 310, 367, 334],\n",
      "        [ 88, 126,  95, 136],\n",
      "        [236, 179, 247, 190],\n",
      "        [557, 135, 565, 153],\n",
      "        [490, 127, 507, 135],\n",
      "        [515,  88, 521, 101],\n",
      "        [285, 309, 296, 330],\n",
      "        [497, 318, 508, 332],\n",
      "        [163,  77, 169,  90],\n",
      "        [304, 232, 318, 241],\n",
      "        [ 21, 362,  37, 381],\n",
      "        [448,  88, 456,  98],\n",
      "        [  4,  29, 632, 419],\n",
      "        [196, 122, 203, 134],\n",
      "        [156, 309, 165, 327],\n",
      "        [106,  82, 116, 112],\n",
      "        [330,  79, 336,  89],\n",
      "        [  4, 361,  22, 382],\n",
      "        [367, 121, 374, 130],\n",
      "        [369, 230, 382, 285]], dtype=torch.int32), 'scores': tensor([0.2460, 0.2527, 0.1695, 0.1691, 0.1490, 0.1469, 0.2682, 0.1603, 0.1744,\n",
      "        0.2553, 0.2107, 0.1420, 0.2580, 0.2084, 0.1719, 0.4784, 0.2398, 0.1717,\n",
      "        0.1556, 0.2100, 0.1514, 0.1899, 0.1456, 0.2786, 0.1483, 0.9989, 0.2112,\n",
      "        0.1159, 0.2028, 0.1358, 0.4129]), 'objectness_scores': tensor([0.4049, 0.3657, 0.2879, 0.2199, 0.2982, 0.3685, 0.2800, 0.2159, 0.3775,\n",
      "        0.4262, 0.3265, 0.3200, 0.2043, 0.2533, 0.4731, 0.2747, 0.3581, 0.3072,\n",
      "        0.4344, 0.4025, 0.3054, 0.2746, 0.2138, 0.2919, 0.3961, 0.4922, 0.4645,\n",
      "        0.3710, 0.2617, 0.3016, 0.4780]), 'labels': tensor([14,  0, 11, 14, 11, 14, 14,  0,  0, 14, 14, 14, 14, 14, 14,  7, 14, 11,\n",
      "         7, 14, 11, 11,  0, 11, 11,  1, 14,  6, 11, 11, 11], dtype=torch.int32)}\n",
      "250282\n",
      "{'image_id': 250619, 'boxes': tensor([[299, 311, 359, 346],\n",
      "        [533, 299, 548, 314],\n",
      "        [280, 311, 289, 330],\n",
      "        [  2, 137, 637, 478],\n",
      "        [493, 370, 533, 396],\n",
      "        [272, 291, 309, 312],\n",
      "        [201, 105, 487, 204],\n",
      "        [340, 328, 363, 349],\n",
      "        [284, 277, 312, 289],\n",
      "        [202, 105, 487, 346]], dtype=torch.int32), 'scores': tensor([0.2755, 0.4398, 0.2023, 0.9532, 0.7092, 0.2843, 0.7785, 0.5202, 0.2834,\n",
      "        0.9957]), 'objectness_scores': tensor([0.2705, 0.2385, 0.2411, 0.2741, 0.2830, 0.2336, 0.2038, 0.2421, 0.2131,\n",
      "        0.3630]), 'labels': tensor([ 8, 11, 11,  6, 10, 11,  6, 11, 11,  6], dtype=torch.int32)}\n",
      "250619\n",
      "{'image_id': 250766, 'boxes': tensor([[194, 258, 226, 288],\n",
      "        [290, 106, 390, 182],\n",
      "        [302, 306, 376, 359],\n",
      "        [252, 282, 335, 373],\n",
      "        [ 44,  12, 502, 410],\n",
      "        [381, 329, 426, 397],\n",
      "        [167, 253, 196, 292],\n",
      "        [293, 247, 323, 296],\n",
      "        [420, 296, 481, 347],\n",
      "        [186, 228, 226, 263],\n",
      "        [229, 250, 343, 409],\n",
      "        [443, 202, 488, 242],\n",
      "        [394, 242, 436, 303],\n",
      "        [304, 216, 378, 282],\n",
      "        [234, 106, 390, 196],\n",
      "        [261, 253, 303, 317],\n",
      "        [342, 274, 386, 316],\n",
      "        [355, 147, 395, 198],\n",
      "        [438, 369, 477, 410],\n",
      "        [397, 212, 422, 255],\n",
      "        [355, 199, 416, 249],\n",
      "        [385,  83, 426, 127],\n",
      "        [233, 143, 333, 195],\n",
      "        [404, 126, 450, 157],\n",
      "        [225,  62, 499, 409],\n",
      "        [481, 257, 498, 280],\n",
      "        [416,  62, 497, 150],\n",
      "        [384, 123, 418, 148],\n",
      "        [112, 184, 281, 388],\n",
      "        [256, 192, 378, 280],\n",
      "        [416, 149, 469, 203],\n",
      "        [289, 107, 338, 179],\n",
      "        [414, 211, 472, 268],\n",
      "        [421, 297, 493, 376]], dtype=torch.int32), 'scores': tensor([0.2761, 0.2000, 0.3155, 0.4213, 0.5311, 0.3953, 0.2530, 0.6998, 0.2684,\n",
      "        0.1482, 0.3560, 0.7568, 0.3398, 0.4397, 0.4933, 0.2872, 0.2374, 0.1753,\n",
      "        0.5072, 0.4823, 0.2970, 0.3021, 0.3631, 0.1837, 0.6985, 0.3071, 0.3532,\n",
      "        0.3251, 0.3541, 0.4376, 0.3798, 0.2963, 0.6697, 0.6492]), 'objectness_scores': tensor([0.3667, 0.4458, 0.4078, 0.4639, 0.3369, 0.3298, 0.3453, 0.2252, 0.2671,\n",
      "        0.3241, 0.2117, 0.4008, 0.3823, 0.2836, 0.3198, 0.3503, 0.4430, 0.2228,\n",
      "        0.2022, 0.2473, 0.2688, 0.5041, 0.4839, 0.3848, 0.3686, 0.2142, 0.2178,\n",
      "        0.4481, 0.4594, 0.5276, 0.3184, 0.2594, 0.2058, 0.3524]), 'labels': tensor([11, 11, 14, 11, 11, 11,  7, 11, 11, 11, 11, 10, 11, 12,  4, 11, 11, 11,\n",
      "         7, 16, 11, 11, 11, 11, 11,  7, 11, 11, 14, 11,  6, 11, 12, 12],\n",
      "       dtype=torch.int32)}\n",
      "250766\n",
      "{'image_id': 251572, 'boxes': tensor([[ -1,  93, 179, 425],\n",
      "        [246, 104, 387, 161],\n",
      "        [185, 122, 637, 427]], dtype=torch.int32), 'scores': tensor([0.6486, 0.2967, 0.9679]), 'objectness_scores': tensor([0.3237, 0.5584, 0.4527]), 'labels': tensor([3, 7, 3], dtype=torch.int32)}\n",
      "251572\n",
      "{'image_id': 251824, 'boxes': tensor([[418, 218, 427, 225],\n",
      "        [  2,   5, 496, 377],\n",
      "        [164,  64, 257, 252],\n",
      "        [188, 189, 256, 273],\n",
      "        [256, 236, 279, 253],\n",
      "        [  0,   9,  89, 202],\n",
      "        [387, 179, 498, 254],\n",
      "        [362, 164, 499, 302]], dtype=torch.int32), 'scores': tensor([0.1569, 0.6166, 0.8314, 0.4610, 0.2899, 0.4790, 0.4987, 0.1737]), 'objectness_scores': tensor([0.2598, 0.4868, 0.2286, 0.2443, 0.2094, 0.2518, 0.2722, 0.7250]), 'labels': tensor([ 3, 16, 16, 16, 11, 16, 11, 11], dtype=torch.int32)}\n",
      "251824\n",
      "{'image_id': 252219, 'boxes': tensor([[344, 227, 356, 246],\n",
      "        [208, 246, 316, 375]], dtype=torch.int32), 'scores': tensor([0.8165, 0.4058]), 'objectness_scores': tensor([0.2168, 0.3807]), 'labels': tensor([11, 13], dtype=torch.int32)}\n",
      "252219\n",
      "{'image_id': 252294, 'boxes': tensor([[117, 354, 148, 369],\n",
      "        [115, 365, 159, 388],\n",
      "        [ 65, 221, 206, 482],\n",
      "        [239, 460, 279, 491]], dtype=torch.int32), 'scores': tensor([0.3574, 0.4785, 0.9067, 0.3306]), 'objectness_scores': tensor([0.3064, 0.3455, 0.2657, 0.2087]), 'labels': tensor([11, 11,  7,  8], dtype=torch.int32)}\n",
      "252294\n",
      "{'image_id': 253386, 'boxes': tensor([[423, 256, 495, 329],\n",
      "        [144,  25, 459, 333],\n",
      "        [220, 122, 341, 280]], dtype=torch.int32), 'scores': tensor([0.2247, 0.9888, 0.9473]), 'objectness_scores': tensor([0.2122, 0.5525, 0.4488]), 'labels': tensor([5, 3, 3], dtype=torch.int32)}\n",
      "253386\n",
      "{'image_id': 253452, 'boxes': tensor([[  2,  26, 634, 426],\n",
      "        [428,   0, 591,  42],\n",
      "        [  2, 122, 436, 426],\n",
      "        [ 51,   0, 209,  37],\n",
      "        [449, 148, 641, 366],\n",
      "        [348,   0, 424,  41],\n",
      "        [ 20, 145, 391, 419],\n",
      "        [336,  35, 638, 201]], dtype=torch.int32), 'scores': tensor([0.2364, 0.3271, 0.5452, 0.1390, 0.9964, 0.2191, 0.5398, 0.3233]), 'objectness_scores': tensor([0.2799, 0.2278, 0.2719, 0.2314, 0.3961, 0.2143, 0.2408, 0.2714]), 'labels': tensor([12, 12, 11, 11, 10,  7, 11, 10], dtype=torch.int32)}\n",
      "253452\n",
      "{'image_id': 253742, 'boxes': tensor([[135,  82, 281, 176],\n",
      "        [588, 114, 627, 134],\n",
      "        [  0,  99,  40, 123],\n",
      "        [284,  95, 362, 172],\n",
      "        [ 81,  95, 179, 152],\n",
      "        [576, 126, 614, 147],\n",
      "        [331,   1, 615, 226],\n",
      "        [  1, 105, 101, 168],\n",
      "        [338,  66, 460, 109],\n",
      "        [316,  97, 407, 186],\n",
      "        [210, 140, 257, 176],\n",
      "        [520, 123, 600, 197]], dtype=torch.int32), 'scores': tensor([0.9792, 0.1858, 0.2818, 0.6861, 0.8123, 0.1674, 0.9953, 0.9612, 0.2402,\n",
      "        0.9008, 0.9820, 0.9926]), 'objectness_scores': tensor([0.2617, 0.2428, 0.2679, 0.2498, 0.3027, 0.3011, 0.2216, 0.3449, 0.2928,\n",
      "        0.2307, 0.2533, 0.2506]), 'labels': tensor([ 6,  8, 11,  6,  6,  8,  6,  6,  6,  6,  6,  6], dtype=torch.int32)}\n",
      "253742\n",
      "{'image_id': 253819, 'boxes': tensor([[290,  62, 330, 105]], dtype=torch.int32), 'scores': tensor([0.2687]), 'objectness_scores': tensor([0.2140]), 'labels': tensor([14], dtype=torch.int32)}\n",
      "253819\n",
      "{'image_id': 254814, 'boxes': tensor([[151,  45, 257,  98],\n",
      "        [213, 200, 229, 238],\n",
      "        [416,  97, 429, 127]], dtype=torch.int32), 'scores': tensor([0.9370, 0.3667, 0.4477]), 'objectness_scores': tensor([0.2178, 0.2590, 0.2384]), 'labels': tensor([ 1, 11, 14], dtype=torch.int32)}\n",
      "254814\n",
      "{'image_id': 255165, 'boxes': tensor([[510, 316, 639, 445],\n",
      "        [ 20, 334, 635, 479],\n",
      "        [217, 377, 364, 407],\n",
      "        [116, 339, 160, 377],\n",
      "        [426, 372, 457, 414],\n",
      "        [471, 453, 481, 479],\n",
      "        [198, 404, 366, 442]], dtype=torch.int32), 'scores': tensor([0.2668, 0.9891, 0.7747, 0.2102, 0.5941, 0.2676, 0.9937]), 'objectness_scores': tensor([0.2172, 0.2717, 0.4951, 0.2284, 0.2441, 0.2092, 0.4357]), 'labels': tensor([ 8, 14, 14, 14, 10, 11, 14], dtype=torch.int32)}\n",
      "255165\n",
      "{'image_id': 255401, 'boxes': tensor([[273, 190, 313, 275],\n",
      "        [213, 115, 233, 141],\n",
      "        [  8,   2,  65, 233],\n",
      "        [247, 117, 269, 143],\n",
      "        [190, 138, 285, 223],\n",
      "        [  0, 236,  90, 446],\n",
      "        [280, 105, 315, 122],\n",
      "        [335,  69, 368, 104]], dtype=torch.int32), 'scores': tensor([0.5666, 0.2759, 0.7663, 0.3622, 0.9323, 0.3124, 0.2591, 0.4167]), 'objectness_scores': tensor([0.4528, 0.3802, 0.4100, 0.3338, 0.3438, 0.4122, 0.2707, 0.2119]), 'labels': tensor([ 7, 10, 15, 11, 15,  7, 11,  7], dtype=torch.int32)}\n",
      "255401\n",
      "{'image_id': 255483, 'boxes': tensor([[331, 141, 393, 190],\n",
      "        [135,  64, 156,  83],\n",
      "        [254, 205, 266, 242],\n",
      "        [254, 192, 294, 312],\n",
      "        [168, 261, 316, 298],\n",
      "        [273, 274, 290, 315],\n",
      "        [254, 191, 272, 242]], dtype=torch.int32), 'scores': tensor([0.2350, 0.7877, 0.2186, 0.2975, 0.5454, 0.2130, 0.1704]), 'objectness_scores': tensor([0.2162, 0.2897, 0.2352, 0.2347, 0.4896, 0.2615, 0.3936]), 'labels': tensor([ 7, 11, 11,  2, 16,  3,  7], dtype=torch.int32)}\n",
      "255483\n",
      "{'image_id': 255536, 'boxes': tensor([[180, 117, 377, 306],\n",
      "        [183, 117, 376, 182]], dtype=torch.int32), 'scores': tensor([0.8227, 0.8783]), 'objectness_scores': tensor([0.5086, 0.2390]), 'labels': tensor([6, 6], dtype=torch.int32)}\n",
      "255536\n",
      "{'image_id': 255664, 'boxes': tensor([[ 93,  45, 322, 336]], dtype=torch.int32), 'scores': tensor([0.9884]), 'objectness_scores': tensor([0.5479]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "255664\n",
      "{'image_id': 255749, 'boxes': tensor([[108, 112, 461, 321],\n",
      "        [245, 170, 265, 184]], dtype=torch.int32), 'scores': tensor([0.9930, 0.3415]), 'objectness_scores': tensor([0.6277, 0.2211]), 'labels': tensor([ 1, 11], dtype=torch.int32)}\n",
      "255749\n",
      "{'image_id': 256407, 'boxes': tensor([[264, 193, 321, 246],\n",
      "        [167, 197, 205, 246],\n",
      "        [119, 236, 168, 283],\n",
      "        [108, 291, 151, 331],\n",
      "        [289, 388, 327, 428],\n",
      "        [221, 180, 258, 223],\n",
      "        [309, 232, 360, 280],\n",
      "        [215, 180, 263, 224],\n",
      "        [279, 193, 315, 235],\n",
      "        [333, 283, 377, 327],\n",
      "        [168, 391, 206, 432],\n",
      "        [320, 230, 359, 268],\n",
      "        [101, 183, 381, 455],\n",
      "        [101, 285, 161, 342],\n",
      "        [156, 379, 220, 441],\n",
      "        [122, 235, 164, 277],\n",
      "        [  2,   4, 477, 635],\n",
      "        [317, 230, 359, 274],\n",
      "        [157, 195, 216, 250],\n",
      "        [329, 344, 366, 380],\n",
      "        [123, 347, 163, 388]], dtype=torch.int32), 'scores': tensor([0.9947, 0.6698, 0.4283, 0.9909, 0.7259, 0.7529, 0.9642, 0.9547, 0.9876,\n",
      "        0.3681, 0.1428, 0.8816, 0.6944, 0.9949, 0.9752, 0.9884, 0.2782, 0.9273,\n",
      "        0.9453, 0.8166, 0.9824]), 'objectness_scores': tensor([0.3856, 0.4503, 0.3432, 0.3880, 0.4284, 0.4877, 0.3403, 0.2042, 0.4830,\n",
      "        0.4723, 0.4238, 0.2537, 0.3485, 0.3946, 0.3424, 0.4576, 0.2594, 0.4401,\n",
      "        0.3555, 0.2879, 0.4302]), 'labels': tensor([10, 10, 11, 10, 10, 10, 10, 10, 10, 10, 14, 10, 10, 10, 10, 10,  9, 10,\n",
      "        10, 10, 10], dtype=torch.int32)}\n",
      "256407\n",
      "{'image_id': 256518, 'boxes': tensor([[  7,  60, 637, 427],\n",
      "        [256, 235, 413, 331],\n",
      "        [ 40, 137, 640, 424],\n",
      "        [302,  16, 386,  70],\n",
      "        [ 88, 142, 425, 162],\n",
      "        [440, 216, 573, 365],\n",
      "        [  5,   2, 637, 431],\n",
      "        [378,  11, 439,  45],\n",
      "        [183,   0, 277, 117],\n",
      "        [286, 170, 425, 276],\n",
      "        [136, 233, 412, 353],\n",
      "        [222, 115, 422, 126],\n",
      "        [ 57, 123, 484, 397],\n",
      "        [483, 273, 559, 341],\n",
      "        [512, 176, 591, 246],\n",
      "        [428,  47, 558, 212]], dtype=torch.int32), 'scores': tensor([0.6076, 0.2633, 0.4103, 0.7862, 0.1821, 0.3291, 0.6641, 0.3555, 0.9937,\n",
      "        0.6237, 0.4606, 0.5049, 0.3562, 0.3085, 0.3812, 0.9926]), 'objectness_scores': tensor([0.3834, 0.2064, 0.2133, 0.2651, 0.2650, 0.3833, 0.2105, 0.2590, 0.4121,\n",
      "        0.2481, 0.3031, 0.3219, 0.2512, 0.2414, 0.2259, 0.3407]), 'labels': tensor([10,  4, 10, 12, 14, 11, 10, 12, 10, 12,  7, 11, 11, 12, 10, 10],\n",
      "       dtype=torch.int32)}\n",
      "256518\n",
      "{'image_id': 256868, 'boxes': tensor([[214, 181, 245, 202],\n",
      "        [284, 245, 310, 273],\n",
      "        [ 11, 190,  23, 196]], dtype=torch.int32), 'scores': tensor([0.3862, 0.4303, 0.1828]), 'objectness_scores': tensor([0.2390, 0.3287, 0.2413]), 'labels': tensor([11,  4, 14], dtype=torch.int32)}\n",
      "256868\n",
      "{'image_id': 256916, 'boxes': tensor([[  3,   1, 630, 477]], dtype=torch.int32), 'scores': tensor([0.6702]), 'objectness_scores': tensor([0.2414]), 'labels': tensor([12], dtype=torch.int32)}\n",
      "256916\n",
      "{'image_id': 256941, 'boxes': tensor([[148, 270, 253, 322],\n",
      "        [137, 237, 268, 279],\n",
      "        [150, 273, 194, 322],\n",
      "        [ 17,   1, 332, 109],\n",
      "        [ 17,   2, 333, 192],\n",
      "        [ 13,   3, 332, 291]], dtype=torch.int32), 'scores': tensor([0.2516, 0.1916, 0.2259, 0.9983, 0.9992, 0.9985]), 'objectness_scores': tensor([0.4053, 0.2031, 0.2301, 0.2745, 0.2934, 0.2889]), 'labels': tensor([11, 11, 14,  6,  6,  6], dtype=torch.int32)}\n",
      "256941\n",
      "{'image_id': 257084, 'boxes': tensor([[417, 159, 495, 200],\n",
      "        [209, 155, 384, 216],\n",
      "        [308,  51, 323,  66],\n",
      "        [152, 114, 231, 153],\n",
      "        [ 95, 157, 109, 177],\n",
      "        [417, 157, 465, 180]], dtype=torch.int32), 'scores': tensor([0.5416, 0.9920, 0.1449, 0.5473, 0.2896, 0.1783]), 'objectness_scores': tensor([0.4260, 0.4502, 0.2477, 0.2530, 0.2374, 0.2145]), 'labels': tensor([ 1,  9, 11,  7, 14, 11], dtype=torch.int32)}\n",
      "257084\n",
      "{'image_id': 257896, 'boxes': tensor([[210, 599, 228, 620],\n",
      "        [214, 321, 257, 380],\n",
      "        [154, 241, 478, 637],\n",
      "        [126,  22, 357, 184]], dtype=torch.int32), 'scores': tensor([0.2101, 0.2555, 0.9860, 0.2395]), 'objectness_scores': tensor([0.2046, 0.5994, 0.2679, 0.4184]), 'labels': tensor([11,  7,  7,  7], dtype=torch.int32)}\n",
      "257896\n",
      "{'image_id': 258388, 'boxes': tensor([[345, 213, 369, 296],\n",
      "        [436, 153, 444, 158],\n",
      "        [448, 342, 492, 359],\n",
      "        [146, 288, 188, 310],\n",
      "        [148, 295, 226, 332],\n",
      "        [348, 104, 433, 163],\n",
      "        [190, 285, 239, 302]], dtype=torch.int32), 'scores': tensor([0.2964, 0.1597, 0.4716, 0.4080, 0.3384, 0.4246, 0.4776]), 'objectness_scores': tensor([0.2936, 0.2365, 0.2104, 0.2344, 0.6609, 0.2862, 0.2009]), 'labels': tensor([11, 11, 11, 11, 13, 11, 11], dtype=torch.int32)}\n",
      "258388\n",
      "{'image_id': 258541, 'boxes': tensor([[ 18, 105, 259, 358],\n",
      "        [104, 143, 151, 373]], dtype=torch.int32), 'scores': tensor([0.9972, 0.9971]), 'objectness_scores': tensor([0.2421, 0.6233]), 'labels': tensor([7, 7], dtype=torch.int32)}\n",
      "258541\n",
      "{'image_id': 258911, 'boxes': tensor([[ 12, 197, 239, 246],\n",
      "        [379, 147, 452, 206],\n",
      "        [157, 142, 400, 205],\n",
      "        [549, 102, 621, 150],\n",
      "        [  6, 152, 406, 296],\n",
      "        [  8, 180, 282, 259],\n",
      "        [124, 166, 337, 202],\n",
      "        [222, 155, 372, 197],\n",
      "        [495, 267, 550, 287],\n",
      "        [376, 146, 414, 174],\n",
      "        [358, 196, 484, 302],\n",
      "        [ 13, 200, 110, 232],\n",
      "        [222, 188, 427, 424],\n",
      "        [ 91, 145, 333, 192],\n",
      "        [ 70, 144, 375, 215],\n",
      "        [247, 162, 474, 422],\n",
      "        [572, 165, 593, 190],\n",
      "        [340, 198, 479, 412],\n",
      "        [ 91, 167, 299, 201],\n",
      "        [324, 149, 400, 220],\n",
      "        [109, 191, 285, 234],\n",
      "        [ 68, 178, 214, 214],\n",
      "        [372, 147, 451, 220],\n",
      "        [326, 147, 451, 231],\n",
      "        [107, 169, 218, 195],\n",
      "        [579, 407, 619, 426],\n",
      "        [241, 189, 415, 306],\n",
      "        [136, 141, 435, 223],\n",
      "        [237, 189, 468, 307]], dtype=torch.int32), 'scores': tensor([0.3477, 0.5021, 0.4455, 0.1755, 0.9881, 0.1833, 0.4792, 0.5968, 0.4592,\n",
      "        0.5287, 0.9967, 0.2051, 0.9915, 0.2674, 0.6472, 0.9946, 0.2304, 0.9934,\n",
      "        0.1746, 0.8271, 0.2757, 0.2512, 0.7568, 0.9645, 0.1860, 0.3177, 0.9980,\n",
      "        0.6505, 0.9970]), 'objectness_scores': tensor([0.2626, 0.2662, 0.2612, 0.4859, 0.2543, 0.2775, 0.2456, 0.2269, 0.4051,\n",
      "        0.2275, 0.3932, 0.2212, 0.2965, 0.2165, 0.3100, 0.2362, 0.6111, 0.2556,\n",
      "        0.3208, 0.3541, 0.2569, 0.4144, 0.3890, 0.4125, 0.2545, 0.2511, 0.3325,\n",
      "        0.2175, 0.3126]), 'labels': tensor([11,  3,  5, 11,  4, 13, 11, 13, 11,  3,  4, 11,  4, 11,  4,  4,  3,  4,\n",
      "        11,  3,  7,  3,  4,  4,  3,  2,  4,  3,  4], dtype=torch.int32)}\n",
      "258911\n",
      "{'image_id': 259571, 'boxes': tensor([[238,  64, 252,  73],\n",
      "        [228,  56, 238,  64],\n",
      "        [237,  56, 247,  64],\n",
      "        [267,  56, 280,  66],\n",
      "        [302, 100, 313, 106],\n",
      "        [392,  67, 405,  82],\n",
      "        [262,  61, 274,  68],\n",
      "        [379,  72, 392,  83],\n",
      "        [277,  79, 288,  87],\n",
      "        [352,  97, 365, 106],\n",
      "        [229,  57, 239,  64],\n",
      "        [421,  78, 432,  89],\n",
      "        [435,  77, 452,  91]], dtype=torch.int32), 'scores': tensor([0.2398, 0.2028, 0.1505, 0.1815, 0.2809, 0.2289, 0.1410, 0.1992, 0.1533,\n",
      "        0.1571, 0.1757, 0.1621, 0.2641]), 'objectness_scores': tensor([0.3184, 0.3276, 0.2835, 0.3245, 0.2642, 0.3266, 0.3294, 0.3491, 0.3260,\n",
      "        0.2866, 0.2831, 0.3375, 0.2974]), 'labels': tensor([14, 14, 11, 11, 11, 14,  1,  6, 11,  0, 14, 14, 11], dtype=torch.int32)}\n",
      "259571\n",
      "{'image_id': 259690, 'boxes': tensor([[515, 165, 527, 175],\n",
      "        [490, 171, 499, 177],\n",
      "        [360, 166, 472, 217],\n",
      "        [306, 263, 408, 465],\n",
      "        [154, 204, 333, 409]], dtype=torch.int32), 'scores': tensor([0.3386, 0.1256, 0.4045, 0.5218, 0.3368]), 'objectness_scores': tensor([0.2109, 0.2037, 0.3401, 0.2760, 0.4829]), 'labels': tensor([11,  4, 11,  9,  9], dtype=torch.int32)}\n",
      "259690\n",
      "{'image_id': 260105, 'boxes': tensor([[236,  63, 356, 133],\n",
      "        [ 58, 127, 257, 355],\n",
      "        [276,   0, 368,  56],\n",
      "        [182,  90, 234, 141],\n",
      "        [283, 100, 383, 150],\n",
      "        [259, 157, 515, 377],\n",
      "        [205, 101, 259, 148],\n",
      "        [  4,   3, 634, 486],\n",
      "        [182,  89, 209, 140],\n",
      "        [184,  93, 279, 163],\n",
      "        [250, 131, 578, 381],\n",
      "        [  1,   0, 146,  32],\n",
      "        [410,   1, 472,  65],\n",
      "        [230, 128, 283, 163],\n",
      "        [  3,  62, 625, 479],\n",
      "        [  0, 137,  90, 316],\n",
      "        [230,   0, 422,  71]], dtype=torch.int32), 'scores': tensor([0.5985, 0.2170, 0.7745, 0.2901, 0.3451, 0.5843, 0.3763, 0.4804, 0.1871,\n",
      "        0.3097, 0.4917, 0.4451, 0.4639, 0.2197, 0.5316, 0.4165, 0.5461]), 'objectness_scores': tensor([0.4593, 0.3708, 0.2778, 0.2375, 0.5062, 0.3514, 0.2486, 0.3079, 0.3191,\n",
      "        0.4291, 0.2428, 0.2566, 0.2248, 0.2874, 0.3262, 0.3837, 0.2353]), 'labels': tensor([12,  7, 10, 11, 11, 12, 11, 12,  8, 11, 12, 12, 11,  7, 12, 12, 10],\n",
      "       dtype=torch.int32)}\n",
      "260105\n",
      "{'image_id': 260261, 'boxes': tensor([[207, 158, 302, 215],\n",
      "        [258,  43, 409, 172],\n",
      "        [135, 371, 165, 401],\n",
      "        [119, 398, 150, 427],\n",
      "        [ 69, 314,  99, 339],\n",
      "        [118, 342, 141, 372],\n",
      "        [ 65, 357,  86, 384],\n",
      "        [ 80, 331, 114, 360],\n",
      "        [ 58, 410,  91, 432],\n",
      "        [131, 321, 150, 337],\n",
      "        [  0, 256,  17, 290],\n",
      "        [134, 306, 149, 319],\n",
      "        [ 98, 347, 134, 376],\n",
      "        [  9, 343,  27, 393],\n",
      "        [ 26, 351,  54, 383],\n",
      "        [111, 293, 141, 315],\n",
      "        [170, 314, 205, 342],\n",
      "        [ 97, 310, 118, 326],\n",
      "        [184, 390, 221, 421]], dtype=torch.int32), 'scores': tensor([0.4387, 0.2353, 0.2462, 0.2811, 0.3472, 0.2162, 0.2078, 0.2753, 0.2295,\n",
      "        0.4119, 0.2142, 0.2214, 0.8142, 0.1938, 0.2814, 0.1921, 0.2769, 0.3421,\n",
      "        0.2628]), 'objectness_scores': tensor([0.2084, 0.2547, 0.3769, 0.3935, 0.3238, 0.3031, 0.2767, 0.3551, 0.3600,\n",
      "        0.3005, 0.2884, 0.2520, 0.3532, 0.2178, 0.3611, 0.3441, 0.3999, 0.2964,\n",
      "        0.4057]), 'labels': tensor([ 7,  4, 11, 11, 11, 11, 11, 11, 11, 11,  4, 11, 14, 11, 11,  9, 11, 11,\n",
      "        12], dtype=torch.int32)}\n",
      "260261\n",
      "{'image_id': 260470, 'boxes': tensor([[428, 152, 453, 175],\n",
      "        [506, 126, 532, 143],\n",
      "        [411, 163, 444, 189],\n",
      "        [458, 138, 487, 155],\n",
      "        [516, 115, 543, 132],\n",
      "        [260, 185, 271, 196],\n",
      "        [262, 151, 286, 174],\n",
      "        [444, 151, 489, 190],\n",
      "        [344, 138, 370, 161],\n",
      "        [367, 202, 421, 236],\n",
      "        [180, 214, 198, 228],\n",
      "        [444, 126, 469, 142],\n",
      "        [ -2,  15, 585, 436],\n",
      "        [ 42, 228, 280, 428],\n",
      "        [377, 161, 409, 188],\n",
      "        [365, 122, 389, 143],\n",
      "        [411, 163, 448, 193],\n",
      "        [399, 148, 424, 167],\n",
      "        [287, 213, 339, 252],\n",
      "        [473, 114, 499, 129],\n",
      "        [  0, 248,  66, 316],\n",
      "        [328, 200, 374, 228],\n",
      "        [420, 206, 480, 243],\n",
      "        [424, 111, 554, 179],\n",
      "        [384, 131, 405, 156],\n",
      "        [280, 138, 303, 158],\n",
      "        [210, 175, 220, 183],\n",
      "        [134, 153, 310, 226],\n",
      "        [341, 121, 368, 138],\n",
      "        [280, 158, 307, 185],\n",
      "        [474, 146, 497, 174],\n",
      "        [510, 151, 542, 175],\n",
      "        [444, 161, 481, 194],\n",
      "        [431, 135, 461, 154],\n",
      "        [ 44, 259, 187, 427],\n",
      "        [473, 126, 501, 147],\n",
      "        [113,  26, 141,  46],\n",
      "        [311, 141, 334, 165],\n",
      "        [426, 145, 496, 188],\n",
      "        [422, 207, 454, 239],\n",
      "        [254, 237, 300, 281],\n",
      "        [381, 180, 419, 209],\n",
      "        [348, 119, 386, 140],\n",
      "        [378,  98, 493, 128],\n",
      "        [327, 179, 489, 272],\n",
      "        [415, 182, 456, 213],\n",
      "        [445, 145, 466, 165],\n",
      "        [380, 179, 418, 209],\n",
      "        [153, 238, 277, 415],\n",
      "        [468, 148, 495, 178],\n",
      "        [ 54, 218,  74, 230],\n",
      "        [457, 187, 498, 222],\n",
      "        [497, 129, 530, 155],\n",
      "        [419, 142, 437, 162],\n",
      "        [455, 124, 478, 139],\n",
      "        [240, 155, 266, 176],\n",
      "        [231, 158, 258, 176],\n",
      "        [318, 130, 341, 157],\n",
      "        [  1, 201, 240, 281],\n",
      "        [117, 216, 137, 228],\n",
      "        [492, 115, 518, 132],\n",
      "        [379, 158, 412, 185],\n",
      "        [347, 179, 386, 208],\n",
      "        [211, 187, 222, 196],\n",
      "        [514,  72, 542, 110],\n",
      "        [264, 148, 288, 167],\n",
      "        [491, 150, 510, 173],\n",
      "        [295, 154, 320, 178],\n",
      "        [531, 128, 557, 152],\n",
      "        [222, 171, 231, 179],\n",
      "        [321, 162, 353, 191],\n",
      "        [366, 142, 392, 166]], dtype=torch.int32), 'scores': tensor([0.2398, 0.3749, 0.2830, 0.3793, 0.2853, 0.2801, 0.3593, 0.5321, 0.4622,\n",
      "        0.8138, 0.2154, 0.2738, 0.9989, 0.9992, 0.5696, 0.1979, 0.8142, 0.2739,\n",
      "        0.8353, 0.2824, 0.9988, 0.5461, 0.6885, 0.4785, 0.2987, 0.9604, 0.1558,\n",
      "        0.9651, 0.2924, 0.6362, 0.2618, 0.2647, 0.7090, 0.1686, 0.9990, 0.1893,\n",
      "        0.5805, 0.6994, 0.2936, 0.2938, 0.4346, 0.5036, 0.2923, 0.1876, 0.9332,\n",
      "        0.7934, 0.1761, 0.6240, 0.9990, 0.4163, 0.2716, 0.9161, 0.3731, 0.1660,\n",
      "        0.2059, 0.2064, 0.2152, 0.4952, 0.9658, 0.2618, 0.2690, 0.2404, 0.4236,\n",
      "        0.1493, 0.2216, 0.2047, 0.2453, 0.3733, 0.3687, 0.1721, 0.9915, 0.4535]), 'objectness_scores': tensor([0.2076, 0.2528, 0.2151, 0.2769, 0.3297, 0.2121, 0.2334, 0.2070, 0.3363,\n",
      "        0.4256, 0.2481, 0.2871, 0.2246, 0.4272, 0.3131, 0.2720, 0.3448, 0.2025,\n",
      "        0.3032, 0.2865, 0.3643, 0.4260, 0.4180, 0.2105, 0.2802, 0.3640, 0.2004,\n",
      "        0.2587, 0.2169, 0.3673, 0.2625, 0.4283, 0.3232, 0.3104, 0.2603, 0.3432,\n",
      "        0.2198, 0.3934, 0.2104, 0.2086, 0.4249, 0.2067, 0.3372, 0.2365, 0.2121,\n",
      "        0.4284, 0.2559, 0.4509, 0.2361, 0.2055, 0.2426, 0.4329, 0.3559, 0.2747,\n",
      "        0.2620, 0.3405, 0.2729, 0.2323, 0.3638, 0.2341, 0.2733, 0.2061, 0.4138,\n",
      "        0.2086, 0.2061, 0.3134, 0.3964, 0.3569, 0.4098, 0.2005, 0.3868, 0.3981]), 'labels': tensor([12, 11, 12, 11, 14,  6, 10, 12, 12, 12, 11, 11, 12, 12, 12,  7, 10, 11,\n",
      "        12, 14, 12, 12, 12, 12, 14, 12,  0, 12, 12, 12, 11, 11, 12, 11, 12, 11,\n",
      "         7, 12,  7, 11, 12, 12, 14,  9, 12, 12, 14, 12, 12, 12, 12, 12, 12,  4,\n",
      "        14, 12, 11, 12, 12, 11, 11, 14, 10,  6, 11, 11, 14, 12, 12, 10, 12, 12],\n",
      "       dtype=torch.int32)}\n",
      "260470\n",
      "{'image_id': 260925, 'boxes': tensor([[ 66, 245, 600, 420]], dtype=torch.int32), 'scores': tensor([0.7958]), 'objectness_scores': tensor([0.5004]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "260925\n",
      "{'image_id': 261116, 'boxes': tensor([[  4,   0, 494, 264],\n",
      "        [  0, 268, 114, 375],\n",
      "        [434, 135, 463, 165],\n",
      "        [  0, 103,  83, 228],\n",
      "        [129, 226, 170, 283],\n",
      "        [463, 128, 487, 157],\n",
      "        [ 46, 227,  81, 275]], dtype=torch.int32), 'scores': tensor([0.4629, 0.4494, 0.2686, 0.9856, 0.1583, 0.1826, 0.1627]), 'objectness_scores': tensor([0.2492, 0.2932, 0.2265, 0.2522, 0.3567, 0.2084, 0.2092]), 'labels': tensor([12,  7, 11, 12, 11, 11, 11], dtype=torch.int32)}\n",
      "261116\n",
      "{'image_id': 261161, 'boxes': tensor([[404, 215, 423, 423],\n",
      "        [317,  32, 617, 426]], dtype=torch.int32), 'scores': tensor([0.9610, 0.9521]), 'objectness_scores': tensor([0.2163, 0.5223]), 'labels': tensor([7, 3], dtype=torch.int32)}\n",
      "261161\n",
      "{'image_id': 261706, 'boxes': tensor([[ 24,   0, 351, 196],\n",
      "        [101,  87, 370, 626]], dtype=torch.int32), 'scores': tensor([0.7539, 0.8744]), 'objectness_scores': tensor([0.5259, 0.5533]), 'labels': tensor([2, 2], dtype=torch.int32)}\n",
      "261706\n",
      "{'image_id': 261982, 'boxes': tensor([[154, 212, 355, 444],\n",
      "        [ 90, 198, 207, 273],\n",
      "        [187, 165, 251, 219],\n",
      "        [258, 327, 383, 400],\n",
      "        [ 91,   1, 340, 349]], dtype=torch.int32), 'scores': tensor([0.1824, 0.4387, 0.3630, 0.5810, 0.8697]), 'objectness_scores': tensor([0.5856, 0.2510, 0.2048, 0.2536, 0.2624]), 'labels': tensor([ 4,  8, 16,  9,  9], dtype=torch.int32)}\n",
      "261982\n",
      "{'image_id': 262048, 'boxes': tensor([[355, 423, 395, 455],\n",
      "        [239, 398, 312, 479],\n",
      "        [ 50, 186, 100, 216],\n",
      "        [ 55, 197, 101, 212],\n",
      "        [ 22, 365, 587, 586],\n",
      "        [240, 426, 254, 450],\n",
      "        [561, 316, 577, 337],\n",
      "        [120, 315, 153, 345],\n",
      "        [541, 271, 550, 281],\n",
      "        [ 57, 292, 102, 341],\n",
      "        [ 70, 140, 509, 384],\n",
      "        [518, 385, 587, 401],\n",
      "        [ 53, 455, 276, 542],\n",
      "        [463, 470, 537, 521],\n",
      "        [ 70, 139, 508, 404]], dtype=torch.int32), 'scores': tensor([0.2189, 0.8736, 0.2577, 0.1820, 0.2384, 0.3054, 0.3248, 0.3390, 0.2347,\n",
      "        0.2300, 0.9989, 0.7780, 0.1996, 0.1680, 0.9952]), 'objectness_scores': tensor([0.2781, 0.3051, 0.2924, 0.2365, 0.2801, 0.4903, 0.3056, 0.2669, 0.2143,\n",
      "        0.2071, 0.2643, 0.2349, 0.2699, 0.2237, 0.3417]), 'labels': tensor([ 7,  5, 11, 11,  6, 11, 11,  7, 11,  9,  6, 11,  2, 11,  4],\n",
      "       dtype=torch.int32)}\n",
      "262048\n",
      "{'image_id': 262440, 'boxes': tensor([[259, 338, 357, 466],\n",
      "        [ 55, 343, 210, 449],\n",
      "        [ 12,   3, 396, 633],\n",
      "        [180,  81, 245, 127],\n",
      "        [305, 330, 313, 336],\n",
      "        [315, 320, 332, 340],\n",
      "        [342, 266, 400, 470],\n",
      "        [ 50, 341,  72, 356],\n",
      "        [312, 219, 363, 301],\n",
      "        [ 55, 343, 207, 392],\n",
      "        [328, 117, 400, 263],\n",
      "        [ 25, 377, 102, 526],\n",
      "        [287, 336, 345, 350],\n",
      "        [ 28, 405,  45, 529]], dtype=torch.int32), 'scores': tensor([0.4558, 0.9719, 0.4283, 0.9152, 0.2034, 0.2618, 0.5780, 0.2601, 0.1734,\n",
      "        0.5521, 0.9993, 0.1897, 0.2157, 0.5339]), 'objectness_scores': tensor([0.4470, 0.2587, 0.2412, 0.4205, 0.2081, 0.5053, 0.2458, 0.3620, 0.5408,\n",
      "        0.5326, 0.2577, 0.3086, 0.5895, 0.3169]), 'labels': tensor([15, 15, 11,  8, 14, 11,  8, 14,  7, 15,  6, 15, 14, 11],\n",
      "       dtype=torch.int32)}\n",
      "262440\n",
      "{'image_id': 262682, 'boxes': tensor([[ 76, 285, 106, 321],\n",
      "        [183, 216, 264, 308],\n",
      "        [289, 386, 314, 413],\n",
      "        [126, 378, 169, 467],\n",
      "        [207, 414, 239, 533],\n",
      "        [266, 219, 280, 267],\n",
      "        [133, 225, 183, 305],\n",
      "        [111, 348, 141, 368],\n",
      "        [163, 311, 179, 343],\n",
      "        [ 84, 288, 117, 336],\n",
      "        [  2, 179, 131, 283],\n",
      "        [ 70,   2, 109, 149],\n",
      "        [281, 466, 360, 639],\n",
      "        [ 38, 385, 120, 417],\n",
      "        [231, 345, 252, 377],\n",
      "        [275, 406, 347, 439],\n",
      "        [251, 351, 264, 380],\n",
      "        [239, 427, 284, 579],\n",
      "        [180, 322, 202, 363],\n",
      "        [ 39, 364, 118, 392],\n",
      "        [128, 332, 144, 340],\n",
      "        [ 52, 287,  88, 342],\n",
      "        [148, 310, 165, 339],\n",
      "        [176, 380, 206, 489],\n",
      "        [232, 385, 305, 415],\n",
      "        [328, 422, 377, 448],\n",
      "        [218, 381, 416, 486]], dtype=torch.int32), 'scores': tensor([0.7307, 0.1814, 0.4113, 0.2072, 0.2957, 0.2786, 0.3224, 0.1849, 0.3108,\n",
      "        0.1995, 0.4944, 0.1863, 0.2204, 0.3350, 0.2676, 0.2133, 0.3448, 0.2941,\n",
      "        0.2246, 0.3934, 0.2825, 0.2162, 0.2579, 0.4478, 0.5596, 0.5281, 0.9988]), 'objectness_scores': tensor([0.2139, 0.3134, 0.3844, 0.3205, 0.2230, 0.2316, 0.3079, 0.2867, 0.3376,\n",
      "        0.2571, 0.7349, 0.2334, 0.2499, 0.2034, 0.5046, 0.4085, 0.2094, 0.2062,\n",
      "        0.5243, 0.4923, 0.2256, 0.4448, 0.2336, 0.3043, 0.4305, 0.2414, 0.2439]), 'labels': tensor([15, 12, 15,  7, 11, 11,  7,  8, 11, 10, 11, 14,  7,  9, 11, 10, 11, 11,\n",
      "        11,  9, 14, 15,  3,  7,  9, 12, 15], dtype=torch.int32)}\n",
      "262682\n",
      "{'image_id': 262895, 'boxes': tensor([[  1, 136, 332, 497],\n",
      "        [162, 295, 270, 498]], dtype=torch.int32), 'scores': tensor([0.9737, 0.9992]), 'objectness_scores': tensor([0.2601, 0.5989]), 'labels': tensor([7, 7], dtype=torch.int32)}\n",
      "262895\n",
      "{'image_id': 262938, 'boxes': tensor([[463,  80, 640, 281]], dtype=torch.int32), 'scores': tensor([0.4303]), 'objectness_scores': tensor([0.3202]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "262938\n",
      "{'image_id': 263068, 'boxes': tensor([[190, 129, 225, 212],\n",
      "        [201,  43, 231,  64]], dtype=torch.int32), 'scores': tensor([0.3292, 0.2094]), 'objectness_scores': tensor([0.6883, 0.3099]), 'labels': tensor([ 7, 11], dtype=torch.int32)}\n",
      "263068\n",
      "{'image_id': 263463, 'boxes': tensor([[306, 112, 385, 179],\n",
      "        [292, 169, 363, 248],\n",
      "        [221, 113, 383, 251],\n",
      "        [217, 163, 283, 225],\n",
      "        [219, 164, 356, 250]], dtype=torch.int32), 'scores': tensor([0.7626, 0.6218, 0.9667, 0.9286, 0.7921]), 'objectness_scores': tensor([0.2064, 0.2024, 0.5388, 0.3045, 0.2205]), 'labels': tensor([3, 3, 3, 3, 3], dtype=torch.int32)}\n",
      "263463\n",
      "{'image_id': 263969, 'boxes': tensor([[146, 487, 162, 508],\n",
      "        [411, 202, 450, 296],\n",
      "        [276, 313, 410, 606],\n",
      "        [ 87, 535, 223, 595],\n",
      "        [312, 187, 637, 625],\n",
      "        [ 75,  84, 107, 117],\n",
      "        [ 87, 461, 200, 555],\n",
      "        [252, 416, 256, 423],\n",
      "        [163, 440, 242, 473],\n",
      "        [ 71, 455, 231, 606],\n",
      "        [115, 134, 146, 162],\n",
      "        [141, 455, 154, 474],\n",
      "        [130, 456, 147, 475],\n",
      "        [ 33,  47,  64,  74],\n",
      "        [346, 144, 372, 163],\n",
      "        [129, 486, 152, 509]], dtype=torch.int32), 'scores': tensor([0.2743, 0.8819, 0.9187, 0.4133, 0.6409, 0.3066, 0.9731, 0.3665, 0.7220,\n",
      "        0.9793, 0.2290, 0.2268, 0.4279, 0.5740, 0.3503, 0.3450]), 'objectness_scores': tensor([0.3072, 0.2024, 0.2179, 0.2084, 0.2303, 0.6205, 0.2415, 0.2243, 0.3673,\n",
      "        0.4469, 0.6330, 0.2747, 0.3088, 0.5731, 0.2320, 0.3366]), 'labels': tensor([11,  7,  7, 12,  7, 10, 12,  2, 11, 12, 11, 11, 11, 12, 12, 11],\n",
      "       dtype=torch.int32)}\n",
      "263969\n",
      "{'image_id': 264441, 'boxes': tensor([[ 14, 192, 374, 418]], dtype=torch.int32), 'scores': tensor([0.9563]), 'objectness_scores': tensor([0.4557]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "264441\n",
      "{'image_id': 265108, 'boxes': tensor([[173, 262, 260, 364],\n",
      "        [197, 423, 222, 606]], dtype=torch.int32), 'scores': tensor([0.5890, 0.4066]), 'objectness_scores': tensor([0.7246, 0.4892]), 'labels': tensor([ 6, 11], dtype=torch.int32)}\n",
      "265108\n",
      "{'image_id': 265518, 'boxes': tensor([[ 88,  64, 205, 172],\n",
      "        [265, 200, 443, 360],\n",
      "        [ 54,  46, 213, 189],\n",
      "        [172, 112, 533, 468]], dtype=torch.int32), 'scores': tensor([0.9728, 0.3333, 0.9955, 0.3776]), 'objectness_scores': tensor([0.2949, 0.2632, 0.4467, 0.3872]), 'labels': tensor([10, 11, 10, 13], dtype=torch.int32)}\n",
      "265518\n",
      "{'image_id': 266768, 'boxes': tensor([[169, 352, 388, 580],\n",
      "        [185, 387, 229, 404],\n",
      "        [315, 373, 336, 397],\n",
      "        [363, 544, 416, 578],\n",
      "        [203, 509, 258, 528],\n",
      "        [198, 306, 208, 312],\n",
      "        [216, 329, 226, 345],\n",
      "        [420, 396, 427, 408],\n",
      "        [199, 359, 219, 386],\n",
      "        [292, 505, 354, 530],\n",
      "        [150, 549, 208, 570],\n",
      "        [316, 254, 368, 278]], dtype=torch.int32), 'scores': tensor([0.6222, 0.2855, 0.3679, 0.2180, 0.2726, 0.2646, 0.4352, 0.3907, 0.4135,\n",
      "        0.2414, 0.1199, 0.3563]), 'objectness_scores': tensor([0.2649, 0.2914, 0.3930, 0.3539, 0.3613, 0.2020, 0.2377, 0.2864, 0.3456,\n",
      "        0.3847, 0.3930, 0.2974]), 'labels': tensor([10,  8,  7,  9, 11, 11,  7, 11, 11, 11, 14, 16], dtype=torch.int32)}\n",
      "266768\n",
      "{'image_id': 266981, 'boxes': tensor([[390, 573, 410, 584],\n",
      "        [131,  63, 320, 128],\n",
      "        [ -1,  33, 368, 334],\n",
      "        [343, 549, 357, 560]], dtype=torch.int32), 'scores': tensor([0.2791, 0.1831, 0.9989, 0.1961]), 'objectness_scores': tensor([0.2145, 0.2055, 0.2461, 0.2059]), 'labels': tensor([11,  7,  5, 14], dtype=torch.int32)}\n",
      "266981\n",
      "{'image_id': 267169, 'boxes': tensor([[282,   2, 357,  56]], dtype=torch.int32), 'scores': tensor([0.3683]), 'objectness_scores': tensor([0.2486]), 'labels': tensor([5], dtype=torch.int32)}\n",
      "267169\n",
      "{'image_id': 267191, 'boxes': tensor([[233, 322, 640, 480],\n",
      "        [ 27,  39, 633, 477],\n",
      "        [337, 418, 357, 479],\n",
      "        [  1, 294, 352, 480],\n",
      "        [  1, 288, 237, 480],\n",
      "        [433, 361, 643, 480],\n",
      "        [222, 335, 357, 480],\n",
      "        [539,  56, 601,  98]], dtype=torch.int32), 'scores': tensor([0.8796, 0.9994, 0.4931, 0.9982, 0.9980, 0.9906, 0.9990, 0.4113]), 'objectness_scores': tensor([0.2371, 0.4832, 0.2310, 0.3472, 0.5453, 0.3260, 0.5632, 0.2407]), 'labels': tensor([5, 5, 9, 5, 5, 5, 5, 8], dtype=torch.int32)}\n",
      "267191\n",
      "{'image_id': 267300, 'boxes': tensor([[ 70,   0, 201, 126],\n",
      "        [187,  48, 471, 365],\n",
      "        [124, 284, 185, 309],\n",
      "        [  9,  30, 633, 348],\n",
      "        [219,  27, 640, 335],\n",
      "        [ 22,  48, 481, 361],\n",
      "        [350, 335, 366, 346],\n",
      "        [  0,   0,  79, 121],\n",
      "        [272,  54, 357, 115]], dtype=torch.int32), 'scores': tensor([0.4764, 0.7937, 0.4123, 0.8510, 0.2382, 0.9175, 0.3407, 0.3617, 0.5479]), 'objectness_scores': tensor([0.3109, 0.2444, 0.2319, 0.2922, 0.3338, 0.2072, 0.2024, 0.3769, 0.2358]), 'labels': tensor([10,  3, 11,  3,  0,  3, 11,  7,  3], dtype=torch.int32)}\n",
      "267300\n",
      "{'image_id': 267537, 'boxes': tensor([[ 92,  73, 285, 180],\n",
      "        [113,   0, 164,  14],\n",
      "        [110, 142, 294, 319],\n",
      "        [544,   0, 593,  30],\n",
      "        [260,  64, 442, 191],\n",
      "        [265,  64, 441, 142],\n",
      "        [  9,   0,  57,  15]], dtype=torch.int32), 'scores': tensor([0.3857, 0.6636, 0.3396, 0.4962, 0.9489, 0.1910, 0.3145]), 'objectness_scores': tensor([0.4571, 0.3089, 0.2085, 0.3441, 0.3827, 0.4257, 0.2945]), 'labels': tensor([ 8, 11, 13,  7,  6,  8, 11], dtype=torch.int32)}\n",
      "267537\n",
      "{'image_id': 267670, 'boxes': tensor([[  6,  39,  21,  60],\n",
      "        [363, 131, 406, 206],\n",
      "        [157,   7, 195,  31],\n",
      "        [ 31, 538, 267, 599],\n",
      "        [ 33, 202,  65, 218],\n",
      "        [  0,   2, 134, 231],\n",
      "        [382, 279, 448, 305],\n",
      "        [116, 237, 349, 304],\n",
      "        [357,  87, 410, 142],\n",
      "        [164, 182, 183, 213],\n",
      "        [ 58, 142,  74, 158],\n",
      "        [207,   0, 337, 176],\n",
      "        [240, 205, 270, 245],\n",
      "        [353,   6, 448, 593],\n",
      "        [ 22,  30, 115, 180]], dtype=torch.int32), 'scores': tensor([0.1637, 0.2649, 0.1938, 0.1859, 0.4207, 0.6907, 0.3263, 0.8373, 0.3878,\n",
      "        0.3304, 0.3602, 0.4953, 0.4959, 0.2659, 0.3712]), 'objectness_scores': tensor([0.2200, 0.4304, 0.2765, 0.4664, 0.4054, 0.5286, 0.2787, 0.6497, 0.2856,\n",
      "        0.4861, 0.2255, 0.5884, 0.6284, 0.2626, 0.3071]), 'labels': tensor([11, 11, 11, 12, 11, 15,  9, 15, 16, 11, 14, 15, 16, 15, 10],\n",
      "       dtype=torch.int32)}\n",
      "267670\n",
      "{'image_id': 267903, 'boxes': tensor([[ 79, 108, 323, 178],\n",
      "        [194, 181, 215, 240],\n",
      "        [243, 211, 280, 248],\n",
      "        [210, 215, 236, 291]], dtype=torch.int32), 'scores': tensor([0.3481, 0.7521, 0.3396, 0.1671]), 'objectness_scores': tensor([0.3246, 0.2126, 0.3135, 0.3578]), 'labels': tensor([13,  7,  3,  7], dtype=torch.int32)}\n",
      "267903\n",
      "{'image_id': 268378, 'boxes': tensor([[321, 238, 340, 255],\n",
      "        [348, 232, 367, 294],\n",
      "        [454, 275, 467, 296],\n",
      "        [313, 275, 338, 323],\n",
      "        [199, 226, 440, 359],\n",
      "        [365, 259, 388, 301],\n",
      "        [316, 214, 334, 232],\n",
      "        [391, 224, 400, 239],\n",
      "        [315, 193, 334, 212],\n",
      "        [347, 189, 353, 241],\n",
      "        [331, 213, 347, 228],\n",
      "        [304, 175, 309, 213],\n",
      "        [266, 217, 286, 254],\n",
      "        [304, 238, 322, 256],\n",
      "        [306, 213, 321, 228]], dtype=torch.int32), 'scores': tensor([0.1912, 0.4654, 0.2742, 0.3729, 0.5430, 0.7635, 0.5213, 0.1507, 0.6890,\n",
      "        0.9992, 0.1853, 0.1829, 0.4830, 0.6370, 0.3642]), 'objectness_scores': tensor([0.2192, 0.2288, 0.3648, 0.2281, 0.2136, 0.2089, 0.2343, 0.3640, 0.2070,\n",
      "        0.3169, 0.2118, 0.3907, 0.2084, 0.2313, 0.2353]), 'labels': tensor([11, 11,  8, 11, 12, 10, 11, 14, 12,  6,  2, 11, 10, 12,  2],\n",
      "       dtype=torch.int32)}\n",
      "268378\n",
      "{'image_id': 268831, 'boxes': tensor([[147,  19, 189,  33],\n",
      "        [144, 151, 234, 181],\n",
      "        [127,  84, 236, 181],\n",
      "        [158, 171, 181, 180],\n",
      "        [129, 138, 235, 181]], dtype=torch.int32), 'scores': tensor([0.1476, 0.3975, 0.9822, 0.5274, 0.5823]), 'objectness_scores': tensor([0.2145, 0.4429, 0.3036, 0.5117, 0.3402]), 'labels': tensor([11, 14, 15,  0,  7], dtype=torch.int32)}\n",
      "268831\n",
      "{'image_id': 269314, 'boxes': tensor([[291, 172, 371, 272],\n",
      "        [  0,  -1, 613, 478]], dtype=torch.int32), 'scores': tensor([0.9945, 0.2767]), 'objectness_scores': tensor([0.4568, 0.2302]), 'labels': tensor([2, 5], dtype=torch.int32)}\n",
      "269314\n",
      "{'image_id': 269632, 'boxes': tensor([[100,  54, 491, 363]], dtype=torch.int32), 'scores': tensor([0.9856]), 'objectness_scores': tensor([0.6167]), 'labels': tensor([0], dtype=torch.int32)}\n",
      "269632\n",
      "{'image_id': 270677, 'boxes': tensor([[207, 228, 426, 545]], dtype=torch.int32), 'scores': tensor([0.5242]), 'objectness_scores': tensor([0.3228]), 'labels': tensor([9], dtype=torch.int32)}\n",
      "270677\n",
      "{'image_id': 271116, 'boxes': tensor([[502, 239, 541, 320],\n",
      "        [440, 236, 480, 248],\n",
      "        [250, 104, 318, 132],\n",
      "        [309, 189, 316, 209],\n",
      "        [329, 200, 351, 243],\n",
      "        [388, 198, 402, 212],\n",
      "        [337, 230, 365, 251],\n",
      "        [147, 126, 202, 364],\n",
      "        [462, 183, 550, 333],\n",
      "        [423, 200, 447, 239],\n",
      "        [369, 196, 379, 215],\n",
      "        [254, 242, 298, 251],\n",
      "        [331, 247, 376, 255],\n",
      "        [241, 196, 253, 217],\n",
      "        [308, 199, 322, 223],\n",
      "        [285, 212, 299, 222],\n",
      "        [424, 350, 448, 390],\n",
      "        [463, 200, 476, 232],\n",
      "        [261, 196, 276, 224],\n",
      "        [242, 223, 478, 413],\n",
      "        [243, 223, 477, 308],\n",
      "        [412, 191, 421, 216],\n",
      "        [471, 201, 487, 238],\n",
      "        [115,  46, 191,  84]], dtype=torch.int32), 'scores': tensor([0.8394, 0.3254, 0.4367, 0.1493, 0.9087, 0.1771, 0.4136, 0.9954, 0.9959,\n",
      "        0.3849, 0.2007, 0.3408, 0.4040, 0.1989, 0.1470, 0.6922, 0.3503, 0.2316,\n",
      "        0.2253, 0.6964, 0.4369, 0.1347, 0.2275, 0.4204]), 'objectness_scores': tensor([0.2226, 0.2003, 0.2968, 0.3788, 0.3948, 0.2546, 0.3718, 0.4109, 0.4583,\n",
      "        0.3633, 0.2657, 0.2066, 0.2241, 0.2199, 0.2934, 0.2777, 0.4631, 0.2644,\n",
      "        0.3368, 0.2032, 0.3095, 0.4057, 0.2832, 0.2651]), 'labels': tensor([ 7, 11, 11,  3, 10, 11, 14,  7,  7, 10, 11, 11, 11, 14, 14,  8, 11, 11,\n",
      "        14,  7, 10,  3, 11, 14], dtype=torch.int32)}\n",
      "271116\n",
      "{'image_id': 271728, 'boxes': tensor([[  0,  89, 327, 423],\n",
      "        [125,  60, 146, 130],\n",
      "        [391,   9, 423,  32],\n",
      "        [123,   0, 156, 124],\n",
      "        [462,   0, 488,  39],\n",
      "        [174,  97, 210, 141],\n",
      "        [112, 208, 261, 298],\n",
      "        [525, 116, 639, 245],\n",
      "        [126,  51, 169, 130],\n",
      "        [155,   0, 497, 245]], dtype=torch.int32), 'scores': tensor([0.7826, 0.4407, 0.2974, 0.4412, 0.2417, 0.3026, 0.9852, 0.3310, 0.4160,\n",
      "        0.5597]), 'objectness_scores': tensor([0.4597, 0.3305, 0.2036, 0.2576, 0.2252, 0.3385, 0.5204, 0.2527, 0.2571,\n",
      "        0.2413]), 'labels': tensor([13, 11,  8, 11,  8,  8,  2,  7, 11, 13], dtype=torch.int32)}\n",
      "271728\n",
      "{'image_id': 271997, 'boxes': tensor([[146, 588, 303, 640],\n",
      "        [ 52,   0, 445, 258]], dtype=torch.int32), 'scores': tensor([0.3208, 0.5162]), 'objectness_scores': tensor([0.2252, 0.3768]), 'labels': tensor([7, 7], dtype=torch.int32)}\n",
      "271997\n",
      "{'image_id': 272049, 'boxes': tensor([[ -1,  36, 199, 112],\n",
      "        [ 33,  43,  92,  80],\n",
      "        [ 91,  44, 162,  95]], dtype=torch.int32), 'scores': tensor([0.9739, 0.3842, 0.8143]), 'objectness_scores': tensor([0.4561, 0.2384, 0.2469]), 'labels': tensor([0, 0, 0], dtype=torch.int32)}\n",
      "272049\n",
      "{'image_id': 272136, 'boxes': tensor([[513,  22, 535,  35],\n",
      "        [ 32,  45,  50,  59],\n",
      "        [ 74,   9, 642, 425],\n",
      "        [248,  55, 263,  71]], dtype=torch.int32), 'scores': tensor([0.4870, 0.3327, 0.8246, 0.2729]), 'objectness_scores': tensor([0.2125, 0.2727, 0.5045, 0.2501]), 'labels': tensor([11, 11,  0, 11], dtype=torch.int32)}\n",
      "272136\n",
      "{'image_id': 272566, 'boxes': tensor([[ 28, 230, 209, 316],\n",
      "        [ 79, 336, 284, 423],\n",
      "        [ 62, 309, 299, 450],\n",
      "        [504, 303, 638, 381],\n",
      "        [474, 102, 608, 168],\n",
      "        [363, 195, 409, 267],\n",
      "        [ 30, 313,  66, 334],\n",
      "        [335, 357, 514, 405],\n",
      "        [  0, 314,  40, 341],\n",
      "        [502,  76, 638, 339]], dtype=torch.int32), 'scores': tensor([0.2330, 0.3260, 0.3245, 0.5099, 0.3196, 0.6212, 0.2708, 0.1841, 0.3333,\n",
      "        0.2782]), 'objectness_scores': tensor([0.3741, 0.2504, 0.2719, 0.2371, 0.3285, 0.2258, 0.2868, 0.2936, 0.3032,\n",
      "        0.2394]), 'labels': tensor([12,  7, 12, 12, 13, 10,  3, 12,  9,  7], dtype=torch.int32)}\n",
      "272566\n",
      "{'image_id': 273232, 'boxes': tensor([[236, 202, 287, 261],\n",
      "        [358, 277, 461, 362]], dtype=torch.int32), 'scores': tensor([0.2416, 0.8593]), 'objectness_scores': tensor([0.2072, 0.4983]), 'labels': tensor([8, 4], dtype=torch.int32)}\n",
      "273232\n",
      "{'image_id': 273420, 'boxes': tensor([[307, 286, 314, 298],\n",
      "        [142, 244, 169, 296],\n",
      "        [174, 287, 191, 311]], dtype=torch.int32), 'scores': tensor([0.2971, 0.5166, 0.1594]), 'objectness_scores': tensor([0.2037, 0.2882, 0.2359]), 'labels': tensor([11,  7,  2], dtype=torch.int32)}\n",
      "273420\n",
      "{'image_id': 273642, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "273642\n",
      "{'image_id': 273711, 'boxes': tensor([[181, 418, 225, 441],\n",
      "        [267, 436, 307, 452],\n",
      "        [242, 400, 284, 435],\n",
      "        [ 81, 237, 124, 260],\n",
      "        [549,  62, 597,  87],\n",
      "        [ 89, 227, 132, 251],\n",
      "        [201, 392, 244, 428],\n",
      "        [280, 419, 313, 444],\n",
      "        [ 79, 195, 163, 258],\n",
      "        [296, 132, 323, 156],\n",
      "        [492, 312, 522, 341],\n",
      "        [ 81, 195, 163, 232],\n",
      "        [ 65, 208, 185, 273],\n",
      "        [226, 430, 268, 449],\n",
      "        [249, 222, 278, 258],\n",
      "        [ 57,  74, 557, 477],\n",
      "        [111, 225, 164, 239],\n",
      "        [344,  38, 453, 175]], dtype=torch.int32), 'scores': tensor([0.3079, 0.4023, 0.3632, 0.2969, 0.5401, 0.2083, 0.4307, 0.4187, 0.4515,\n",
      "        0.3713, 0.1737, 0.2390, 0.4173, 0.4072, 0.2016, 0.9414, 0.2812, 0.4948]), 'objectness_scores': tensor([0.2323, 0.2285, 0.2671, 0.2321, 0.2078, 0.2271, 0.2736, 0.2317, 0.2313,\n",
      "        0.2047, 0.2031, 0.3073, 0.2434, 0.2342, 0.3046, 0.3070, 0.2328, 0.3733]), 'labels': tensor([12, 11, 12,  9, 12, 11, 12, 11, 12, 11, 11, 11, 11, 11, 11, 12, 11, 12],\n",
      "       dtype=torch.int32)}\n",
      "273711\n",
      "{'image_id': 274219, 'boxes': tensor([[175, 326, 258, 369]], dtype=torch.int32), 'scores': tensor([0.5199]), 'objectness_scores': tensor([0.7098]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "274219\n",
      "{'image_id': 274272, 'boxes': tensor([[211, 189, 250, 228],\n",
      "        [266, 141, 307, 195],\n",
      "        [135, 185, 209, 250],\n",
      "        [392, 141, 433, 194],\n",
      "        [564, 190, 607, 220]], dtype=torch.int32), 'scores': tensor([0.3317, 0.1913, 0.5215, 0.2173, 0.4121]), 'objectness_scores': tensor([0.2129, 0.2696, 0.2713, 0.2736, 0.2373]), 'labels': tensor([14,  9,  1,  7,  8], dtype=torch.int32)}\n",
      "274272\n",
      "{'image_id': 275198, 'boxes': tensor([[394, 229, 415, 249],\n",
      "        [137, 146, 330, 285],\n",
      "        [344, 229, 394, 249],\n",
      "        [600, 316, 625, 330],\n",
      "        [465, 272, 525, 305],\n",
      "        [161, 358, 275, 425],\n",
      "        [178, 292, 264, 324],\n",
      "        [322,  47, 541, 230],\n",
      "        [ 84, 254, 458, 479],\n",
      "        [443, 264, 470, 331],\n",
      "        [ 92,  98, 107, 115],\n",
      "        [101, 333, 142, 373],\n",
      "        [230, 380, 244, 424],\n",
      "        [ 91, 446, 119, 476],\n",
      "        [311, 333, 333, 375],\n",
      "        [278, 345, 303, 387],\n",
      "        [173, 329, 208, 366],\n",
      "        [197, 314, 221, 351]], dtype=torch.int32), 'scores': tensor([0.5457, 0.9957, 0.3516, 0.8576, 0.4335, 0.7043, 0.2792, 0.9983, 0.6114,\n",
      "        0.5993, 0.9140, 0.6850, 0.2482, 0.3183, 0.9168, 0.4452, 0.5008, 0.7928]), 'objectness_scores': tensor([0.2239, 0.3889, 0.2311, 0.3502, 0.2124, 0.2143, 0.2018, 0.4225, 0.3196,\n",
      "        0.3400, 0.2070, 0.2335, 0.3194, 0.2518, 0.2251, 0.2488, 0.2123, 0.2360]), 'labels': tensor([10,  6, 11, 11, 12, 12, 12,  6, 12, 10, 11, 11, 11, 11,  3, 10, 14, 10],\n",
      "       dtype=torch.int32)}\n",
      "275198\n",
      "{'image_id': 275749, 'boxes': tensor([[233, 287, 249, 311],\n",
      "        [292, 228, 308, 265],\n",
      "        [237, 328, 263, 364]], dtype=torch.int32), 'scores': tensor([0.1305, 0.3426, 0.9779]), 'objectness_scores': tensor([0.2073, 0.2224, 0.2421]), 'labels': tensor([11, 11, 10], dtype=torch.int32)}\n",
      "275749\n",
      "{'image_id': 276024, 'boxes': tensor([[488, 253, 540, 280]], dtype=torch.int32), 'scores': tensor([0.4611]), 'objectness_scores': tensor([0.2322]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "276024\n",
      "{'image_id': 276055, 'boxes': tensor([[224,  47, 300,  80],\n",
      "        [213, 167, 382, 374],\n",
      "        [331,  45, 498, 360],\n",
      "        [312, 157, 365, 251]], dtype=torch.int32), 'scores': tensor([0.2296, 0.4388, 0.7597, 0.8690]), 'objectness_scores': tensor([0.3100, 0.4532, 0.2096, 0.3951]), 'labels': tensor([ 7, 10, 10, 10], dtype=torch.int32)}\n",
      "276055\n",
      "{'image_id': 276285, 'boxes': tensor([[209, 129, 402, 220],\n",
      "        [216, 420, 266, 462],\n",
      "        [258, 429, 306, 463],\n",
      "        [ 69,   0, 301, 145],\n",
      "        [318,  51, 384, 141],\n",
      "        [  0,  80,  74, 204],\n",
      "        [377, 334, 427, 425],\n",
      "        [102, 434, 426, 625],\n",
      "        [ 37, 201, 348, 356],\n",
      "        [250, 484, 304, 534],\n",
      "        [  0, 309,  88, 434],\n",
      "        [  0, 112, 427, 637],\n",
      "        [149, 457, 210, 508],\n",
      "        [128, 353, 427, 554],\n",
      "        [190, 483, 249, 532],\n",
      "        [294, 466, 350, 506],\n",
      "        [243, 458, 283, 483],\n",
      "        [333, 434, 380, 474],\n",
      "        [283, 418, 333, 451],\n",
      "        [192, 431, 238, 482]], dtype=torch.int32), 'scores': tensor([0.2889, 0.2629, 0.2147, 0.3101, 0.1871, 0.9407, 0.2652, 0.5284, 0.2661,\n",
      "        0.2905, 0.4316, 0.2881, 0.2291, 0.5831, 0.2437, 0.2842, 0.2994, 0.4973,\n",
      "        0.2686, 0.2853]), 'objectness_scores': tensor([0.2546, 0.3368, 0.3072, 0.2435, 0.2690, 0.3493, 0.2116, 0.2365, 0.2231,\n",
      "        0.2479, 0.2188, 0.2401, 0.2822, 0.3618, 0.2853, 0.2712, 0.2066, 0.2854,\n",
      "        0.3137, 0.2693]), 'labels': tensor([12, 12,  7,  9,  9, 10, 11, 11, 11, 12, 10,  7, 12, 11, 11, 12,  2, 12,\n",
      "        12,  3], dtype=torch.int32)}\n",
      "276285\n",
      "{'image_id': 276434, 'boxes': tensor([[  0, 192, 632, 425],\n",
      "        [  1,  90, 145, 216],\n",
      "        [201, 126, 216, 141],\n",
      "        [210, 274, 228, 288],\n",
      "        [ 42,  99,  62, 120],\n",
      "        [274, 264, 296, 280],\n",
      "        [178, 144, 193, 160],\n",
      "        [ 25, 111,  46, 132],\n",
      "        [474,   3, 639, 331],\n",
      "        [211, 301, 234, 322],\n",
      "        [249, 286, 266, 302],\n",
      "        [130, 244, 365, 402],\n",
      "        [239, 259, 257, 276],\n",
      "        [224, 283, 242, 302],\n",
      "        [219, 124, 234, 135],\n",
      "        [162, 145, 181, 165],\n",
      "        [201, 138, 217, 153],\n",
      "        [136, 110, 305, 238],\n",
      "        [189, 127, 205, 144],\n",
      "        [215, 131, 232, 148],\n",
      "        [168, 154, 184, 168],\n",
      "        [263, 275, 281, 291],\n",
      "        [225, 306, 246, 325],\n",
      "        [176, 131, 194, 145],\n",
      "        [127, 109, 362, 403],\n",
      "        [220, 262, 241, 282],\n",
      "        [241, 274, 265, 292],\n",
      "        [ 58, 109,  80, 130],\n",
      "        [302, 258, 339, 287],\n",
      "        [207, 284, 228, 303],\n",
      "        [318, 202, 386, 254]], dtype=torch.int32), 'scores': tensor([0.9993, 0.9993, 0.2565, 0.1719, 0.2845, 0.3467, 0.2777, 0.3283, 0.9122,\n",
      "        0.3234, 0.3072, 0.9989, 0.3270, 0.2993, 0.2102, 0.3857, 0.2103, 0.9991,\n",
      "        0.1751, 0.2527, 0.1768, 0.2680, 0.2660, 0.3110, 0.9995, 0.3218, 0.2910,\n",
      "        0.2597, 0.2432, 0.1345, 0.8165]), 'objectness_scores': tensor([0.2907, 0.4738, 0.2228, 0.2185, 0.2175, 0.2792, 0.2342, 0.2180, 0.2328,\n",
      "        0.2883, 0.2113, 0.4041, 0.2240, 0.2398, 0.2026, 0.2674, 0.2328, 0.4404,\n",
      "        0.2303, 0.2632, 0.2210, 0.2254, 0.2405, 0.2381, 0.2325, 0.2353, 0.2398,\n",
      "        0.2107, 0.2100, 0.2392, 0.2810]), 'labels': tensor([12, 12, 11, 11, 11, 11, 11, 11,  7, 11, 11, 12, 11, 11, 11, 11, 11, 12,\n",
      "        11, 11, 11, 11, 11, 11, 12, 11, 11, 11, 11,  0, 11], dtype=torch.int32)}\n",
      "276434\n",
      "{'image_id': 277020, 'boxes': tensor([[184, 156, 346, 357],\n",
      "        [421, 155, 458, 179],\n",
      "        [385, 248, 414, 286],\n",
      "        [281, 186, 302, 275],\n",
      "        [424, 206, 438, 237],\n",
      "        [226, 272, 452, 336],\n",
      "        [187, 200, 231, 223],\n",
      "        [ 17,   7, 137, 102],\n",
      "        [432, 240, 450, 288]], dtype=torch.int32), 'scores': tensor([0.9626, 0.4414, 0.8250, 0.5942, 0.3215, 0.4273, 0.1997, 0.3052, 0.7291]), 'objectness_scores': tensor([0.2028, 0.2940, 0.4516, 0.4774, 0.4500, 0.2617, 0.2289, 0.3466, 0.2069]), 'labels': tensor([ 7,  7, 10,  7, 11, 11, 12,  7, 11], dtype=torch.int32)}\n",
      "277020\n",
      "{'image_id': 277051, 'boxes': tensor([[  2, 276, 630, 426],\n",
      "        [  1, 328, 388, 426],\n",
      "        [  8, 340, 507, 426],\n",
      "        [396, 120, 642, 382],\n",
      "        [  0, 383,  55, 413]], dtype=torch.int32), 'scores': tensor([0.4354, 0.3255, 0.4178, 0.2470, 0.2691]), 'objectness_scores': tensor([0.2488, 0.2557, 0.5840, 0.2615, 0.2193]), 'labels': tensor([11, 11, 11,  7, 12], dtype=torch.int32)}\n",
      "277051\n",
      "{'image_id': 277197, 'boxes': tensor([[121, 279, 225, 324],\n",
      "        [385, 262, 464, 349],\n",
      "        [540,  52, 599, 222],\n",
      "        [128, 177, 178, 233],\n",
      "        [298, 242, 347, 283],\n",
      "        [506, 247, 543, 266],\n",
      "        [ 87, 251, 247, 318],\n",
      "        [415, 182, 427, 198],\n",
      "        [329, 231, 342, 244],\n",
      "        [521, 260, 570, 311],\n",
      "        [ 48, 281,  93, 315],\n",
      "        [493, 283, 528, 312],\n",
      "        [240, 278, 313, 318],\n",
      "        [177, 336, 378, 418],\n",
      "        [414, 202, 431, 218],\n",
      "        [325, 172, 346, 234],\n",
      "        [415, 222, 426, 239],\n",
      "        [ 90, 253, 129, 283],\n",
      "        [565, 246, 598, 318],\n",
      "        [  0, 254,  36, 317],\n",
      "        [ -2, 350, 541, 416],\n",
      "        [464, 261, 514, 308],\n",
      "        [426, 244, 598, 415],\n",
      "        [160, 252, 191, 267],\n",
      "        [  0, 316,  40, 354],\n",
      "        [493, 260, 531, 307],\n",
      "        [199, 251, 228, 279],\n",
      "        [421, 203, 472, 262],\n",
      "        [514, 245, 573, 311]], dtype=torch.int32), 'scores': tensor([0.8161, 0.9860, 0.2482, 0.2285, 0.9961, 0.2583, 0.9596, 0.1935, 0.4010,\n",
      "        0.4397, 0.5261, 0.2158, 0.2021, 0.5905, 0.2077, 0.4447, 0.1644, 0.3843,\n",
      "        0.3899, 0.2897, 0.4430, 0.2770, 0.9984, 0.9755, 0.1747, 0.4378, 0.1182,\n",
      "        0.9365, 0.8937]), 'objectness_scores': tensor([0.3589, 0.3103, 0.2172, 0.2792, 0.2263, 0.2006, 0.5529, 0.2221, 0.2249,\n",
      "        0.2341, 0.4118, 0.3829, 0.3819, 0.4595, 0.2333, 0.2243, 0.2498, 0.2483,\n",
      "        0.2098, 0.2815, 0.3556, 0.3422, 0.4702, 0.2839, 0.2330, 0.2192, 0.3016,\n",
      "        0.3551, 0.2920]), 'labels': tensor([13, 13, 10,  4,  1,  0, 13, 11, 14, 13, 13,  7, 14, 10, 14,  8,  1, 11,\n",
      "        11,  7,  7,  7, 13,  0, 12,  7,  2,  6, 13], dtype=torch.int32)}\n",
      "277197\n",
      "{'image_id': 277584, 'boxes': tensor([[256, 145, 405, 275],\n",
      "        [256, 145, 406, 375]], dtype=torch.int32), 'scores': tensor([0.2094, 0.9808]), 'objectness_scores': tensor([0.2377, 0.4945]), 'labels': tensor([7, 2], dtype=torch.int32)}\n",
      "277584\n",
      "{'image_id': 278463, 'boxes': tensor([[409, 213, 444, 294],\n",
      "        [467, 172, 546, 279],\n",
      "        [124, 238, 226, 338],\n",
      "        [ 66, 146, 191, 255],\n",
      "        [371, 217, 402, 294],\n",
      "        [  0, 189, 631, 478],\n",
      "        [ -2, 288, 628, 478]], dtype=torch.int32), 'scores': tensor([0.8607, 0.2759, 0.7654, 0.3621, 0.4050, 0.7108, 0.9776]), 'objectness_scores': tensor([0.3177, 0.2000, 0.3580, 0.2042, 0.3183, 0.2463, 0.2583]), 'labels': tensor([ 8, 11,  2, 10, 11, 14, 14], dtype=torch.int32)}\n",
      "278463\n",
      "{'image_id': 278705, 'boxes': tensor([[339, 308, 438, 337],\n",
      "        [102, 277, 191, 301],\n",
      "        [407, 219, 419, 227],\n",
      "        [108, 115, 132, 135],\n",
      "        [115, 128, 163, 193],\n",
      "        [441,  50, 473,  67],\n",
      "        [274, 170, 302, 196]], dtype=torch.int32), 'scores': tensor([0.5190, 0.2933, 0.1983, 0.3077, 0.5478, 0.4596, 0.3049]), 'objectness_scores': tensor([0.5267, 0.5642, 0.2688, 0.2008, 0.2512, 0.2379, 0.2332]), 'labels': tensor([ 9,  9, 11,  7,  7, 14, 11], dtype=torch.int32)}\n",
      "278705\n",
      "{'image_id': 278848, 'boxes': tensor([[102, 272, 277, 330],\n",
      "        [280, 291, 418, 339],\n",
      "        [149, 272, 232, 287],\n",
      "        [174, 601, 218, 615],\n",
      "        [234, 457, 291, 555],\n",
      "        [219, 595, 240, 606],\n",
      "        [290,  49, 299,  82],\n",
      "        [113, 381, 150, 413],\n",
      "        [330, 603, 351, 629],\n",
      "        [103, 271, 277, 425],\n",
      "        [250, 333, 416, 439],\n",
      "        [ 46, 312, 109, 478],\n",
      "        [ 80,  79, 149, 301],\n",
      "        [ 49, 331,  82, 472]], dtype=torch.int32), 'scores': tensor([0.7083, 0.1779, 0.3570, 0.2419, 0.1329, 0.2336, 0.3304, 0.1648, 0.2857,\n",
      "        0.9972, 0.2995, 0.4104, 0.4547, 0.3846]), 'objectness_scores': tensor([0.5962, 0.6091, 0.3021, 0.2792, 0.6036, 0.2178, 0.6101, 0.2162, 0.2021,\n",
      "        0.2209, 0.6143, 0.2327, 0.2627, 0.2027]), 'labels': tensor([ 6,  9, 11, 11,  7, 11, 11, 11, 11,  6, 11,  7,  8, 14],\n",
      "       dtype=torch.int32)}\n",
      "278848\n",
      "{'image_id': 279145, 'boxes': tensor([[398,  59, 473, 164],\n",
      "        [100, 326, 205, 468],\n",
      "        [322, 318, 514, 481],\n",
      "        [  8, 156, 172, 413]], dtype=torch.int32), 'scores': tensor([0.2896, 0.9691, 0.2473, 0.3495]), 'objectness_scores': tensor([0.2492, 0.5698, 0.2697, 0.2405]), 'labels': tensor([10,  2, 10,  2], dtype=torch.int32)}\n",
      "279145\n",
      "{'image_id': 279278, 'boxes': tensor([[601,  34, 627,  81],\n",
      "        [529,   0, 589,  63],\n",
      "        [171,  72, 219,  85],\n",
      "        [506, 158, 575, 240],\n",
      "        [292,  15, 304,  23],\n",
      "        [453, 285, 480, 312],\n",
      "        [125, 169, 210, 192],\n",
      "        [261, 227, 297, 248],\n",
      "        [154, 170, 181, 183],\n",
      "        [308, 174, 343, 190],\n",
      "        [140, 183, 168, 200],\n",
      "        [227, 258, 290, 290],\n",
      "        [191, 254, 225, 277],\n",
      "        [374, 289, 405, 320]], dtype=torch.int32), 'scores': tensor([0.2613, 0.9729, 0.3416, 0.9818, 0.1661, 0.1933, 0.5078, 0.2609, 0.3322,\n",
      "        0.4036, 0.2662, 0.5855, 0.2101, 0.4882]), 'objectness_scores': tensor([0.2130, 0.4602, 0.5512, 0.5524, 0.2111, 0.3872, 0.4425, 0.2418, 0.2685,\n",
      "        0.2031, 0.2585, 0.2891, 0.2783, 0.3864]), 'labels': tensor([11, 10, 11,  3,  3,  7,  9, 11, 11, 16, 11,  9, 11,  9],\n",
      "       dtype=torch.int32)}\n",
      "279278\n",
      "{'image_id': 279730, 'boxes': tensor([[ 48, 167, 179, 333],\n",
      "        [353,   7, 470, 199],\n",
      "        [357,   9, 472, 149],\n",
      "        [198, 129, 386, 250],\n",
      "        [112, 120, 135, 183],\n",
      "        [404,  33, 473, 156],\n",
      "        [358,   7, 424, 139]], dtype=torch.int32), 'scores': tensor([0.5003, 0.7271, 0.5496, 0.3738, 0.4439, 0.1957, 0.2965]), 'objectness_scores': tensor([0.5067, 0.2429, 0.2837, 0.2230, 0.2988, 0.3116, 0.3220]), 'labels': tensor([ 9, 10, 10,  3, 11, 10, 10], dtype=torch.int32)}\n",
      "279730\n",
      "{'image_id': 279927, 'boxes': tensor([[154, 203, 207, 225],\n",
      "        [210, 212, 273, 245],\n",
      "        [ 33, 188,  93, 214],\n",
      "        [134, 205, 156, 217],\n",
      "        [ 97, 202, 118, 218],\n",
      "        [138, 216, 162, 236],\n",
      "        [ 33, 185,  93, 249]], dtype=torch.int32), 'scores': tensor([0.3384, 0.9799, 0.2852, 0.1730, 0.2429, 0.2479, 0.9884]), 'objectness_scores': tensor([0.4383, 0.5186, 0.2026, 0.2680, 0.3021, 0.2582, 0.4219]), 'labels': tensor([ 8,  6, 11, 11,  8, 11,  6], dtype=torch.int32)}\n",
      "279927\n",
      "{'image_id': 280710, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "280710\n",
      "{'image_id': 281693, 'boxes': tensor([[555, 251, 639, 341],\n",
      "        [ 11, 123,  36, 213],\n",
      "        [467, 200, 564, 240],\n",
      "        [  2,  58, 631, 335],\n",
      "        [580, 135, 638, 206],\n",
      "        [ 61,  59, 204, 240],\n",
      "        [ 74, 272, 151, 314],\n",
      "        [  1, 137,  67, 218],\n",
      "        [  1, 285,  28, 302],\n",
      "        [453, 137, 631, 331],\n",
      "        [169,  77, 200, 186]], dtype=torch.int32), 'scores': tensor([0.9687, 0.4333, 0.3669, 0.9746, 0.3083, 0.7116, 0.2830, 0.5119, 0.9910,\n",
      "        0.8850, 0.4031]), 'objectness_scores': tensor([0.3721, 0.2669, 0.2096, 0.4971, 0.3899, 0.2344, 0.2285, 0.4468, 0.2011,\n",
      "        0.2639, 0.3086]), 'labels': tensor([ 0, 11, 14,  0,  8,  0,  2,  7, 10,  0, 11], dtype=torch.int32)}\n",
      "281693\n",
      "{'image_id': 281754, 'boxes': tensor([[ 96, 496, 140, 599],\n",
      "        [129, 134, 163, 212],\n",
      "        [ 54, 296,  78, 305],\n",
      "        [193, 564, 244, 623],\n",
      "        [ 88, 107, 195, 226],\n",
      "        [ 25,   4, 413, 251],\n",
      "        [ 68, 331,  75, 334],\n",
      "        [  0,   0, 246, 118],\n",
      "        [200, 393, 292, 520],\n",
      "        [ 76, 221, 212, 312],\n",
      "        [235, 570, 276, 622],\n",
      "        [ 52, 329,  59, 337]], dtype=torch.int32), 'scores': tensor([0.3158, 0.3848, 0.2440, 0.3235, 0.5393, 0.9938, 0.1654, 0.8655, 0.5065,\n",
      "        0.3418, 0.2119, 0.1672]), 'objectness_scores': tensor([0.2012, 0.5997, 0.4411, 0.5109, 0.3153, 0.5324, 0.3228, 0.2094, 0.2522,\n",
      "        0.2921, 0.5164, 0.5010]), 'labels': tensor([ 7,  7, 11,  9,  7,  6, 10,  6,  7, 11,  9, 14], dtype=torch.int32)}\n",
      "281754\n",
      "{'image_id': 281759, 'boxes': tensor([[  0, 303,  33, 328],\n",
      "        [382, 178, 457, 328],\n",
      "        [ 53,  73, 208, 207],\n",
      "        [195,  80, 321, 206],\n",
      "        [137, 389, 158, 402],\n",
      "        [240, 389, 268, 405],\n",
      "        [104, 233, 176, 275],\n",
      "        [235, 169, 256, 188],\n",
      "        [107, 387, 129, 400],\n",
      "        [441, 403, 462, 419],\n",
      "        [478, 406, 499, 419],\n",
      "        [126, 180, 134, 194],\n",
      "        [408, 401, 441, 415],\n",
      "        [208, 387, 233, 401],\n",
      "        [348, 402, 370, 415],\n",
      "        [509, 408, 530, 422],\n",
      "        [217, 173, 282, 299],\n",
      "        [ 70, 228, 107, 269]], dtype=torch.int32), 'scores': tensor([0.2748, 0.6911, 0.9915, 0.9821, 0.2571, 0.2299, 0.4612, 0.6525, 0.6120,\n",
      "        0.3155, 0.2865, 0.1791, 0.5777, 0.5221, 0.3097, 0.6266, 0.5431, 0.1764]), 'objectness_scores': tensor([0.2271, 0.3279, 0.4493, 0.4316, 0.2812, 0.2716, 0.2120, 0.3340, 0.3123,\n",
      "        0.2613, 0.2487, 0.2247, 0.2728, 0.2993, 0.2133, 0.2546, 0.3691, 0.2331]), 'labels': tensor([ 7,  7,  6,  6, 11, 11,  7,  7, 11, 14, 11, 14, 11, 11, 11, 11,  7, 10],\n",
      "       dtype=torch.int32)}\n",
      "281759\n",
      "{'image_id': 281929, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "281929\n",
      "{'image_id': 283412, 'boxes': tensor([[  5,  97, 637, 426],\n",
      "        [  0, 281, 134, 427],\n",
      "        [  2,   3, 436, 417],\n",
      "        [ 13,   0, 440, 129]], dtype=torch.int32), 'scores': tensor([0.9548, 0.9960, 0.8182, 0.4406]), 'objectness_scores': tensor([0.3438, 0.4903, 0.4902, 0.2183]), 'labels': tensor([ 3, 10,  3,  3], dtype=torch.int32)}\n",
      "283412\n",
      "{'image_id': 284445, 'boxes': tensor([[229, 153, 292, 266],\n",
      "        [164, 339, 296, 501],\n",
      "        [246, 160, 298, 266],\n",
      "        [150, 278, 164, 310],\n",
      "        [184, 176, 229, 245],\n",
      "        [428, 273, 441, 299],\n",
      "        [ 99, 332, 126, 346],\n",
      "        [171, 288, 181, 310]], dtype=torch.int32), 'scores': tensor([0.2646, 0.2899, 0.1975, 0.4256, 0.3439, 0.6188, 0.3744, 0.2318]), 'objectness_scores': tensor([0.3972, 0.2130, 0.3296, 0.3055, 0.2311, 0.2669, 0.2699, 0.2754]), 'labels': tensor([ 7,  6,  9, 11, 14,  8,  1,  7], dtype=torch.int32)}\n",
      "284445\n",
      "{'image_id': 284623, 'boxes': tensor([[ 32,   3, 467, 414],\n",
      "        [546, 245, 636, 369],\n",
      "        [441, 159, 532, 370]], dtype=torch.int32), 'scores': tensor([0.9840, 0.3475, 0.3895]), 'objectness_scores': tensor([0.5207, 0.3214, 0.3742]), 'labels': tensor([ 2, 15, 16], dtype=torch.int32)}\n",
      "284623\n",
      "{'image_id': 284725, 'boxes': tensor([[168, 333, 201, 348],\n",
      "        [ 70, 146, 486, 307]], dtype=torch.int32), 'scores': tensor([0.5786, 0.9985]), 'objectness_scores': tensor([0.2472, 0.5622]), 'labels': tensor([11,  1], dtype=torch.int32)}\n",
      "284725\n",
      "{'image_id': 284764, 'boxes': tensor([[486, 275, 508, 308],\n",
      "        [251, 247, 310, 317]], dtype=torch.int32), 'scores': tensor([0.3946, 0.2250]), 'objectness_scores': tensor([0.6095, 0.4481]), 'labels': tensor([11, 10], dtype=torch.int32)}\n",
      "284764\n",
      "{'image_id': 285047, 'boxes': tensor([[189, 560, 279, 601],\n",
      "        [336, 474, 404, 518],\n",
      "        [  4, 243, 424, 606],\n",
      "        [205, 243, 315, 286],\n",
      "        [196, 541, 259, 588]], dtype=torch.int32), 'scores': tensor([0.6721, 0.5020, 0.2529, 0.2110, 0.8873]), 'objectness_scores': tensor([0.3281, 0.4686, 0.2576, 0.3440, 0.3471]), 'labels': tensor([10, 11, 10, 10, 10], dtype=torch.int32)}\n",
      "285047\n",
      "{'image_id': 286422, 'boxes': tensor([[345,   2, 359, 297],\n",
      "        [ 77, 273, 105, 313],\n",
      "        [377, 256, 393, 267],\n",
      "        [405, 285, 441, 305]], dtype=torch.int32), 'scores': tensor([0.7328, 0.3718, 0.2489, 0.3613]), 'objectness_scores': tensor([0.2031, 0.5808, 0.2110, 0.2208]), 'labels': tensor([11,  7, 11, 11], dtype=torch.int32)}\n",
      "286422\n",
      "{'image_id': 286503, 'boxes': tensor([[282, 175, 525, 377]], dtype=torch.int32), 'scores': tensor([0.9990]), 'objectness_scores': tensor([0.5618]), 'labels': tensor([5], dtype=torch.int32)}\n",
      "286503\n",
      "{'image_id': 286553, 'boxes': tensor([[  7, 349, 415, 479],\n",
      "        [250, 328, 280, 387]], dtype=torch.int32), 'scores': tensor([0.4905, 0.9266]), 'objectness_scores': tensor([0.2081, 0.2437]), 'labels': tensor([12, 10], dtype=torch.int32)}\n",
      "286553\n",
      "{'image_id': 286908, 'boxes': tensor([[341,  53, 394, 101],\n",
      "        [ 74,  26,  99,  66],\n",
      "        [  5, 420, 317, 635],\n",
      "        [104, 591, 117, 614],\n",
      "        [119, 429, 304, 519],\n",
      "        [  7, 443, 122, 570],\n",
      "        [323,   5, 387,  57],\n",
      "        [420, 515, 511, 601],\n",
      "        [521,  64, 632, 212],\n",
      "        [341,  38, 630, 263],\n",
      "        [212, 217, 275, 254],\n",
      "        [148, 430, 194, 457],\n",
      "        [534,  75, 594,  99],\n",
      "        [  5,   3, 317, 212],\n",
      "        [325, 372, 393, 447],\n",
      "        [442, 325, 634, 522],\n",
      "        [ 79, 607,  97, 628],\n",
      "        [ 25, 321, 145, 421],\n",
      "        [124,   4, 319, 102],\n",
      "        [409,  46, 542, 178],\n",
      "        [535,  74, 632, 149],\n",
      "        [109, 620, 254, 633],\n",
      "        [155,   7, 304,  55],\n",
      "        [ 85,  28, 117,  65],\n",
      "        [225, 263, 295, 307],\n",
      "        [110, 572, 153, 622],\n",
      "        [ 68, 218, 201, 295],\n",
      "        [390, 146, 428, 214],\n",
      "        [  6,  86,  82, 212],\n",
      "        [224, 524, 317, 634],\n",
      "        [ 50, 216, 309, 319],\n",
      "        [126, 114, 194, 180],\n",
      "        [224, 322, 313, 406],\n",
      "        [142,  53, 177,  91],\n",
      "        [278,  40, 317,  86]], dtype=torch.int32), 'scores': tensor([0.5335, 0.5815, 0.7210, 0.3008, 0.4110, 0.3280, 0.2031, 0.2537, 0.2962,\n",
      "        0.2326, 0.2880, 0.2775, 0.2797, 0.7033, 0.8244, 0.2877, 0.3362, 0.5365,\n",
      "        0.5362, 0.2290, 0.2288, 0.6505, 0.8191, 0.5216, 0.2791, 0.2333, 0.8109,\n",
      "        0.1992, 0.3174, 0.4894, 0.6546, 0.2616, 0.5327, 0.4035, 0.6512]), 'objectness_scores': tensor([0.5188, 0.5541, 0.2047, 0.2261, 0.3518, 0.3180, 0.2640, 0.2687, 0.2961,\n",
      "        0.2643, 0.2190, 0.2313, 0.2104, 0.2017, 0.2418, 0.3383, 0.2521, 0.3231,\n",
      "        0.3364, 0.2358, 0.2112, 0.5000, 0.4219, 0.4034, 0.2529, 0.2616, 0.3023,\n",
      "        0.2096, 0.3801, 0.2630, 0.2111, 0.2330, 0.2630, 0.2434, 0.4667]), 'labels': tensor([12, 11, 11, 11, 11, 12, 10, 11, 11,  7, 12,  3, 11, 11, 12, 12, 11, 12,\n",
      "        11, 11, 11, 11, 12, 11, 11, 12, 12, 16, 12, 12, 12,  3, 10, 12, 12],\n",
      "       dtype=torch.int32)}\n",
      "286908\n",
      "{'image_id': 287347, 'boxes': tensor([[  0, 238,  36, 295],\n",
      "        [259, 378, 431, 467],\n",
      "        [345, 175, 360, 194],\n",
      "        [299, 258, 310, 276],\n",
      "        [175, 487, 282, 640]], dtype=torch.int32), 'scores': tensor([0.3316, 0.4573, 0.3487, 0.3515, 0.5897]), 'objectness_scores': tensor([0.2017, 0.3963, 0.2557, 0.2921, 0.2931]), 'labels': tensor([ 7, 11, 11, 10,  1], dtype=torch.int32)}\n",
      "287347\n",
      "{'image_id': 287527, 'boxes': tensor([[487, 451, 628, 632],\n",
      "        [202, 260, 636, 634]], dtype=torch.int32), 'scores': tensor([0.5169, 0.9532]), 'objectness_scores': tensor([0.5462, 0.2344]), 'labels': tensor([7, 7], dtype=torch.int32)}\n",
      "287527\n",
      "{'image_id': 287649, 'boxes': tensor([[  2,   0, 632, 437],\n",
      "        [133,   2, 630, 404],\n",
      "        [382,  65, 489,  91]], dtype=torch.int32), 'scores': tensor([0.9495, 0.9805, 0.3940]), 'objectness_scores': tensor([0.2577, 0.4542, 0.3054]), 'labels': tensor([ 2,  2, 11], dtype=torch.int32)}\n",
      "287649\n",
      "{'image_id': 287667, 'boxes': tensor([[200, 100, 321, 216],\n",
      "        [  3,   3, 636, 482],\n",
      "        [126,   6, 546, 177],\n",
      "        [231,  25, 319, 105],\n",
      "        [311,  88, 427, 203],\n",
      "        [596, 259, 639, 346]], dtype=torch.int32), 'scores': tensor([0.6312, 0.2734, 0.7512, 0.9083, 0.4764, 0.2933]), 'objectness_scores': tensor([0.5808, 0.3505, 0.6139, 0.5508, 0.5763, 0.4229]), 'labels': tensor([12, 12, 11, 11, 12, 12], dtype=torch.int32)}\n",
      "287667\n",
      "{'image_id': 287714, 'boxes': tensor([[  2, 300, 288, 481],\n",
      "        [350,   0, 387, 122],\n",
      "        [340, 377, 367, 411],\n",
      "        [410, 286, 434, 324],\n",
      "        [372, 303, 386, 314],\n",
      "        [518, 282, 546, 333],\n",
      "        [411,   0, 638, 210],\n",
      "        [389, 289, 410, 301],\n",
      "        [380, 282, 398, 292],\n",
      "        [418, 210, 441, 263],\n",
      "        [367, 324, 422, 365],\n",
      "        [422, 332, 581, 401],\n",
      "        [380,   3, 638, 275],\n",
      "        [614, 349, 639, 365],\n",
      "        [619,  11, 636,  57],\n",
      "        [353, 396, 368, 433],\n",
      "        [367, 186, 384, 217],\n",
      "        [341, 203, 371, 243],\n",
      "        [340, 378, 367, 434],\n",
      "        [354, 301, 401, 333],\n",
      "        [495, 282, 545, 333],\n",
      "        [172,   6, 263,  49],\n",
      "        [  2, 288, 139, 320],\n",
      "        [332, 276, 392, 306]], dtype=torch.int32), 'scores': tensor([0.9812, 0.1636, 0.1926, 0.1594, 0.3040, 0.2974, 0.2761, 0.2751, 0.1907,\n",
      "        0.2785, 0.5068, 0.6381, 0.4360, 0.5436, 0.7033, 0.2226, 0.2463, 0.6020,\n",
      "        0.3039, 0.7461, 0.9908, 0.2135, 0.6476, 0.2496]), 'objectness_scores': tensor([0.6307, 0.2144, 0.2269, 0.4569, 0.3469, 0.2120, 0.4132, 0.2881, 0.2808,\n",
      "        0.2326, 0.2875, 0.6187, 0.2363, 0.2060, 0.2256, 0.2179, 0.3977, 0.3582,\n",
      "        0.3286, 0.2040, 0.4336, 0.4663, 0.3794, 0.3142]), 'labels': tensor([15, 11, 11,  9, 11, 11,  7, 11, 11,  8,  4, 15, 15, 11, 11, 11,  7,  7,\n",
      "         8, 12, 15,  7, 11, 12], dtype=torch.int32)}\n",
      "287714\n",
      "{'image_id': 288042, 'boxes': tensor([[416, 313, 464, 452],\n",
      "        [531, 160, 630, 218],\n",
      "        [335, 140, 355, 241]], dtype=torch.int32), 'scores': tensor([0.6707, 0.9952, 0.2546]), 'objectness_scores': tensor([0.2675, 0.4682, 0.2043]), 'labels': tensor([ 8,  6, 14], dtype=torch.int32)}\n",
      "288042\n",
      "{'image_id': 288685, 'boxes': tensor([[109,  79, 136,  97],\n",
      "        [181, 104, 196, 109],\n",
      "        [112, 113, 122, 142],\n",
      "        [456, 110, 471, 115],\n",
      "        [444, 179, 462, 186],\n",
      "        [ 30, 114,  47, 119],\n",
      "        [  0, 176, 633, 312],\n",
      "        [395, 132, 417, 146],\n",
      "        [291, 108, 302, 116],\n",
      "        [ 83, 103, 102, 117],\n",
      "        [440, 151, 461, 165],\n",
      "        [232, 126, 247, 132],\n",
      "        [263, 146, 277, 151],\n",
      "        [326,  87, 359, 104],\n",
      "        [396, 107, 412, 113],\n",
      "        [492, 147, 512, 160]], dtype=torch.int32), 'scores': tensor([0.3836, 0.2092, 0.2251, 0.2240, 0.2534, 0.2548, 0.6358, 0.2250, 0.2082,\n",
      "        0.1880, 0.3555, 0.1680, 0.1933, 0.2130, 0.2138, 0.3166]), 'objectness_scores': tensor([0.2275, 0.2304, 0.4592, 0.2022, 0.2286, 0.2015, 0.2663, 0.2182, 0.4525,\n",
      "        0.2502, 0.2475, 0.2556, 0.2032, 0.2574, 0.2069, 0.2245]), 'labels': tensor([11, 10, 14, 10, 14, 10,  4,  8, 14, 11, 11, 10, 10,  7, 10, 11],\n",
      "       dtype=torch.int32)}\n",
      "288685\n",
      "{'image_id': 288862, 'boxes': tensor([[112, 133, 246, 189],\n",
      "        [165, 341, 207, 388],\n",
      "        [141, 155, 173, 186],\n",
      "        [250, 237, 300, 286],\n",
      "        [286, 177, 313, 206],\n",
      "        [217, 195, 254, 234],\n",
      "        [407, 332, 427, 349]], dtype=torch.int32), 'scores': tensor([0.7654, 0.2706, 0.7693, 0.2557, 0.5595, 0.4248, 0.2067]), 'objectness_scores': tensor([0.5497, 0.2821, 0.2220, 0.2215, 0.2019, 0.2330, 0.2279]), 'labels': tensor([ 9,  3, 11,  9, 11, 11,  8], dtype=torch.int32)}\n",
      "288862\n",
      "{'image_id': 289222, 'boxes': tensor([[156, 197, 371, 401],\n",
      "        [191, 101, 279, 198],\n",
      "        [287, 220, 340, 270],\n",
      "        [259, 193, 372, 399],\n",
      "        [154, 295, 260, 400],\n",
      "        [421,  85, 560, 395]], dtype=torch.int32), 'scores': tensor([0.2242, 0.3120, 0.4167, 0.3095, 0.2226, 0.3601]), 'objectness_scores': tensor([0.2146, 0.2453, 0.2182, 0.4900, 0.3793, 0.5311]), 'labels': tensor([ 5, 11, 10, 11, 10,  7], dtype=torch.int32)}\n",
      "289222\n",
      "{'image_id': 289229, 'boxes': tensor([[ 55, 454,  91, 500],\n",
      "        [ 49, 120, 341, 498],\n",
      "        [159, 227, 258, 300],\n",
      "        [145, 355, 155, 367],\n",
      "        [159, 164, 190, 235],\n",
      "        [206, 260, 264, 331]], dtype=torch.int32), 'scores': tensor([0.3450, 0.6140, 0.7499, 0.1814, 0.9901, 0.3697]), 'objectness_scores': tensor([0.3573, 0.3892, 0.4484, 0.2128, 0.5438, 0.3479]), 'labels': tensor([11,  7, 16, 14,  7, 16], dtype=torch.int32)}\n",
      "289229\n",
      "{'image_id': 289343, 'boxes': tensor([[244, 402, 260, 413],\n",
      "        [472, 394, 514, 423],\n",
      "        [123,  72, 154, 107],\n",
      "        [173, 155, 204, 177],\n",
      "        [456, 200, 471, 214],\n",
      "        [235, 265, 243, 271],\n",
      "        [125, 175, 177, 183],\n",
      "        [226, 236, 249, 255]], dtype=torch.int32), 'scores': tensor([0.1819, 0.5953, 0.1736, 0.3219, 0.1745, 0.2234, 0.3302, 0.3333]), 'objectness_scores': tensor([0.2274, 0.5420, 0.2543, 0.5572, 0.2306, 0.4147, 0.2216, 0.4712]), 'labels': tensor([11,  3, 11, 11, 11, 14, 14, 11], dtype=torch.int32)}\n",
      "289343\n",
      "{'image_id': 289393, 'boxes': tensor([[  0,   2, 357, 349],\n",
      "        [437, 262, 556, 385]], dtype=torch.int32), 'scores': tensor([0.6998, 0.3538]), 'objectness_scores': tensor([0.2096, 0.2223]), 'labels': tensor([4, 4], dtype=torch.int32)}\n",
      "289393\n",
      "{'image_id': 289741, 'boxes': tensor([[ 15, 257, 106, 320],\n",
      "        [380, 268, 528, 397],\n",
      "        [364,  70, 403, 104],\n",
      "        [245, 327, 424, 477],\n",
      "        [254, 261, 351, 342]], dtype=torch.int32), 'scores': tensor([0.2395, 0.2579, 0.9718, 0.9269, 0.8778]), 'objectness_scores': tensor([0.2954, 0.2656, 0.2341, 0.2822, 0.2831]), 'labels': tensor([14,  8,  0,  6,  6], dtype=torch.int32)}\n",
      "289741\n",
      "{'image_id': 289938, 'boxes': tensor([[  3, 116, 209, 188],\n",
      "        [311, 102, 636, 185],\n",
      "        [438, 231, 451, 252],\n",
      "        [  2, 116, 208, 271]], dtype=torch.int32), 'scores': tensor([0.9947, 0.2000, 0.2366, 0.8263]), 'objectness_scores': tensor([0.4137, 0.2951, 0.3965, 0.2073]), 'labels': tensor([ 6, 10, 11,  6], dtype=torch.int32)}\n",
      "289938\n",
      "{'image_id': 290179, 'boxes': tensor([[218, 192, 244, 314],\n",
      "        [  5, 181, 638, 414]], dtype=torch.int32), 'scores': tensor([0.1703, 0.6235]), 'objectness_scores': tensor([0.3157, 0.2073]), 'labels': tensor([1, 1], dtype=torch.int32)}\n",
      "290179\n",
      "{'image_id': 290768, 'boxes': tensor([[  0, 209, 414, 607],\n",
      "        [198,  94, 223, 140],\n",
      "        [ 83, 193, 144, 264],\n",
      "        [159, 193, 226, 266],\n",
      "        [186, 137, 218, 194],\n",
      "        [421, 251, 610, 369],\n",
      "        [140, 205, 323, 250],\n",
      "        [212,  99, 235, 141],\n",
      "        [330, 312, 363, 425],\n",
      "        [ 81,   0, 297,  36],\n",
      "        [128, 115, 187, 211],\n",
      "        [153, 190, 203, 253],\n",
      "        [219, 277, 291, 375],\n",
      "        [298, 182, 322, 218]], dtype=torch.int32), 'scores': tensor([0.4412, 0.5322, 0.4135, 0.6183, 0.5326, 0.3017, 0.1347, 0.4805, 0.2373,\n",
      "        0.2112, 0.5612, 0.4535, 0.1820, 0.3440]), 'objectness_scores': tensor([0.2086, 0.3160, 0.4565, 0.3988, 0.2451, 0.7127, 0.2573, 0.3299, 0.2726,\n",
      "        0.3624, 0.3642, 0.3942, 0.2008, 0.2856]), 'labels': tensor([15,  7,  7, 10, 11, 14, 16,  7, 11, 11,  7,  6, 14,  7],\n",
      "       dtype=torch.int32)}\n",
      "290768\n",
      "{'image_id': 290771, 'boxes': tensor([[586, 227, 611, 249],\n",
      "        [  1, 380, 101, 477],\n",
      "        [325, 252, 565, 399],\n",
      "        [191, 328, 320, 423],\n",
      "        [317, 290, 445, 394],\n",
      "        [416, 322, 512, 354],\n",
      "        [165, 386, 190, 407],\n",
      "        [439, 332, 568, 394],\n",
      "        [ 94, 370, 317, 467],\n",
      "        [339, 216, 345, 239],\n",
      "        [130, 389, 168, 405],\n",
      "        [240, 347, 253, 379],\n",
      "        [322, 253, 369, 302],\n",
      "        [580, 242, 639, 301],\n",
      "        [411, 372, 583, 480],\n",
      "        [104, 404, 335, 477]], dtype=torch.int32), 'scores': tensor([0.4116, 0.6766, 0.7886, 0.6541, 0.2866, 0.6863, 0.3236, 0.5559, 0.6911,\n",
      "        0.2563, 0.4510, 0.2237, 0.1633, 0.6471, 0.5353, 0.5335]), 'objectness_scores': tensor([0.2272, 0.2175, 0.5071, 0.3982, 0.2526, 0.3340, 0.2081, 0.2366, 0.2900,\n",
      "        0.2299, 0.2133, 0.2578, 0.3861, 0.2111, 0.2377, 0.2488]), 'labels': tensor([14, 14, 13,  9,  9,  7,  9, 13, 13, 11,  9, 14, 13, 13,  7, 13],\n",
      "       dtype=torch.int32)}\n",
      "290771\n",
      "{'image_id': 290843, 'boxes': tensor([[ 21, 248, 237, 502],\n",
      "        [  0,   0, 180,  72]], dtype=torch.int32), 'scores': tensor([0.9583, 0.3317]), 'objectness_scores': tensor([0.4999, 0.2095]), 'labels': tensor([ 2, 14], dtype=torch.int32)}\n",
      "290843\n",
      "{'image_id': 291490, 'boxes': tensor([[116,  73, 360, 317]], dtype=torch.int32), 'scores': tensor([0.9902]), 'objectness_scores': tensor([0.5203]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "291490\n",
      "{'image_id': 291551, 'boxes': tensor([[358, 447, 376, 464],\n",
      "        [126, 446, 150, 476],\n",
      "        [201, 297, 338, 423],\n",
      "        [193, 506, 236, 559],\n",
      "        [254, 530, 270, 547]], dtype=torch.int32), 'scores': tensor([0.1780, 0.1333, 0.6445, 0.7005, 0.2131]), 'objectness_scores': tensor([0.2161, 0.2492, 0.2282, 0.2077, 0.2181]), 'labels': tensor([11,  7,  9,  9, 11], dtype=torch.int32)}\n",
      "291551\n",
      "{'image_id': 292005, 'boxes': tensor([[122, 500, 308, 639],\n",
      "        [395, 546, 456, 623],\n",
      "        [  1, 150, 133, 645],\n",
      "        [394, 545, 456, 580],\n",
      "        [ 99, 186, 329, 638],\n",
      "        [  1, 135, 317, 159],\n",
      "        [313, 530, 406, 608]], dtype=torch.int32), 'scores': tensor([0.9887, 0.9358, 0.8295, 0.8282, 0.7601, 0.6035, 0.2607]), 'objectness_scores': tensor([0.5922, 0.4049, 0.4923, 0.2088, 0.2619, 0.2749, 0.4438]), 'labels': tensor([15, 10,  7, 10, 15, 11, 13], dtype=torch.int32)}\n",
      "292005\n",
      "{'image_id': 292024, 'boxes': tensor([[472, 471, 608, 595],\n",
      "        [315, 238, 437, 351],\n",
      "        [  0, 348, 533, 613],\n",
      "        [236, 135, 432, 219],\n",
      "        [539, 471, 612, 612],\n",
      "        [ -1, 420, 600, 609],\n",
      "        [  0, 566,  42, 588],\n",
      "        [469, 487, 557, 597]], dtype=torch.int32), 'scores': tensor([0.3692, 0.3118, 0.3583, 0.2651, 0.3310, 0.6372, 0.8253, 0.3273]), 'objectness_scores': tensor([0.2803, 0.2405, 0.4768, 0.5852, 0.4126, 0.2580, 0.2074, 0.2557]), 'labels': tensor([11,  7, 11,  7,  7, 12, 11, 11], dtype=torch.int32)}\n",
      "292024\n",
      "{'image_id': 292060, 'boxes': tensor([[232, 358, 247, 389],\n",
      "        [129, 344, 142, 365],\n",
      "        [316, 343, 336, 366],\n",
      "        [175, 389, 277, 408],\n",
      "        [173, 385, 348, 412],\n",
      "        [268,  95, 341, 175],\n",
      "        [223,  85, 261, 131],\n",
      "        [170, 405, 359, 582],\n",
      "        [247, 386, 347, 403],\n",
      "        [263, 369, 270, 389],\n",
      "        [330, 101, 370, 177],\n",
      "        [262, 170, 329, 273],\n",
      "        [167, 348, 186, 369],\n",
      "        [373,  89, 425, 178],\n",
      "        [271, 272, 295, 298],\n",
      "        [ 59,   1, 349, 109],\n",
      "        [  1,  37, 179, 215],\n",
      "        [356, 408, 403, 561],\n",
      "        [208, 272, 233, 299],\n",
      "        [152,  71, 261, 133],\n",
      "        [299, 272, 322, 298],\n",
      "        [289, 272, 323, 323],\n",
      "        [171, 415, 290, 581],\n",
      "        [290, 407, 356, 558],\n",
      "        [325, 175, 364, 313],\n",
      "        [  1, 394, 170, 445],\n",
      "        [ 92, 344, 104, 354],\n",
      "        [180, 161, 259, 271],\n",
      "        [179, 271, 203, 299],\n",
      "        [152,  84, 194, 131],\n",
      "        [192,  73, 232, 119],\n",
      "        [ 77, 395, 156, 418],\n",
      "        [365, 172, 415, 317]], dtype=torch.int32), 'scores': tensor([0.8479, 0.6211, 0.3819, 0.2299, 0.4325, 0.4074, 0.3357, 0.2114, 0.4087,\n",
      "        0.2352, 0.3523, 0.3220, 0.2286, 0.3616, 0.3932, 0.7899, 0.4420, 0.2389,\n",
      "        0.2926, 0.2650, 0.2342, 0.2412, 0.3028, 0.3042, 0.2883, 0.2494, 0.4485,\n",
      "        0.4129, 0.2197, 0.4230, 0.4752, 0.2255, 0.2631]), 'objectness_scores': tensor([0.3023, 0.5042, 0.2516, 0.3095, 0.2239, 0.2058, 0.2459, 0.2790, 0.2571,\n",
      "        0.2658, 0.2240, 0.2308, 0.3242, 0.2368, 0.4341, 0.7812, 0.3516, 0.4287,\n",
      "        0.4524, 0.2430, 0.4409, 0.3064, 0.2826, 0.3509, 0.2688, 0.2577, 0.2387,\n",
      "        0.2393, 0.4513, 0.2585, 0.2792, 0.2100, 0.2631]), 'labels': tensor([ 2, 14, 11, 11, 11,  7,  7, 12, 11, 11, 14,  7, 11, 14,  7,  8, 11,  7,\n",
      "         9,  7,  9,  9, 12,  7, 14,  9, 14, 14, 14,  7, 10,  8, 16],\n",
      "       dtype=torch.int32)}\n",
      "292060\n",
      "{'image_id': 292082, 'boxes': tensor([[298, 526, 314, 534],\n",
      "        [195, 329, 236, 384],\n",
      "        [325,  14, 624, 337],\n",
      "        [ 83, 244, 261, 324],\n",
      "        [191, 328, 243, 428]], dtype=torch.int32), 'scores': tensor([0.1960, 0.3382, 0.6358, 0.8215, 0.9252]), 'objectness_scores': tensor([0.5088, 0.2939, 0.2194, 0.2041, 0.5520]), 'labels': tensor([0, 7, 7, 7, 7], dtype=torch.int32)}\n",
      "292082\n",
      "{'image_id': 292155, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "292155\n",
      "{'image_id': 292415, 'boxes': tensor([[196, 200, 222, 261],\n",
      "        [198, 195, 221, 241],\n",
      "        [195, 193, 219, 218],\n",
      "        [  3, 146, 329, 499]], dtype=torch.int32), 'scores': tensor([0.2732, 0.2103, 0.3958, 0.9459]), 'objectness_scores': tensor([0.3055, 0.2162, 0.2804, 0.3604]), 'labels': tensor([11, 11,  4,  9], dtype=torch.int32)}\n",
      "292415\n",
      "{'image_id': 293300, 'boxes': tensor([[ 13, 360,  92, 390],\n",
      "        [ -9, 239, 619, 427],\n",
      "        [119, 148, 259, 273],\n",
      "        [119,  80, 430, 301]], dtype=torch.int32), 'scores': tensor([0.2849, 0.9900, 0.9993, 0.9977]), 'objectness_scores': tensor([0.2131, 0.2028, 0.2133, 0.6005]), 'labels': tensor([11,  5,  5,  5], dtype=torch.int32)}\n",
      "293300\n",
      "{'image_id': 293324, 'boxes': tensor([[372, 226, 427, 281],\n",
      "        [ 89, 234, 157, 286],\n",
      "        [340, 225, 567, 329],\n",
      "        [ 91, 236, 262, 297],\n",
      "        [193, 244, 202, 277],\n",
      "        [ 98, 228, 557, 329],\n",
      "        [ 17, 276, 141, 328],\n",
      "        [ 31, 276,  63, 303],\n",
      "        [178, 242, 411, 326],\n",
      "        [234, 272, 246, 282],\n",
      "        [524, 305, 560, 324],\n",
      "        [ 85, 238, 363, 326],\n",
      "        [ 81, 240, 261, 327],\n",
      "        [190, 272, 206, 292]], dtype=torch.int32), 'scores': tensor([0.9294, 0.9294, 0.9630, 0.8867, 0.3159, 0.9646, 0.8961, 0.7429, 0.4134,\n",
      "        0.2234, 0.2470, 0.9755, 0.9598, 0.6930]), 'objectness_scores': tensor([0.2937, 0.3861, 0.4401, 0.2256, 0.2030, 0.4564, 0.3616, 0.4566, 0.2928,\n",
      "        0.3927, 0.2533, 0.4511, 0.3771, 0.3028]), 'labels': tensor([ 0,  0,  0, 13,  0,  0,  1,  0, 11, 14, 11,  0,  0,  0],\n",
      "       dtype=torch.int32)}\n",
      "293324\n",
      "{'image_id': 293390, 'boxes': tensor([[384, 163, 539, 399],\n",
      "        [391,  19, 418,  90],\n",
      "        [ 10, 185,  59, 307],\n",
      "        [333,  51, 368,  87],\n",
      "        [282,  47, 300,  84],\n",
      "        [ 53, 233, 193, 318],\n",
      "        [193,  83, 385, 137],\n",
      "        [ 85,   1, 141,  99],\n",
      "        [182, 169, 388, 226],\n",
      "        [ 33, 161, 542, 414],\n",
      "        [521,   0, 639, 480],\n",
      "        [179, 166, 390, 394],\n",
      "        [394, 166, 536, 223],\n",
      "        [ 37, 171, 181, 227],\n",
      "        [ 34, 170, 202, 411],\n",
      "        [ 70,   0, 158, 106],\n",
      "        [212,  54, 249,  88]], dtype=torch.int32), 'scores': tensor([0.3099, 0.3448, 0.6611, 0.2907, 0.3960, 0.2200, 0.2263, 0.5879, 0.5844,\n",
      "        0.3776, 0.3632, 0.2543, 0.3496, 0.7600, 0.1987, 0.6889, 0.2572]), 'objectness_scores': tensor([0.2996, 0.4675, 0.2081, 0.2141, 0.3851, 0.2687, 0.5479, 0.4187, 0.2740,\n",
      "        0.3040, 0.2023, 0.2922, 0.3185, 0.3006, 0.2922, 0.2841, 0.2229]), 'labels': tensor([ 7, 10,  7, 11, 11, 13, 11,  7, 14, 13,  7,  8, 14, 14,  8,  7, 11],\n",
      "       dtype=torch.int32)}\n",
      "293390\n",
      "{'image_id': 293625, 'boxes': tensor([[401, 311, 519, 401],\n",
      "        [247, 254, 388, 448],\n",
      "        [123, 100, 229, 127],\n",
      "        [362, 172, 393, 288],\n",
      "        [322, 201, 379, 216],\n",
      "        [376, 308, 422, 382],\n",
      "        [534,  61, 633, 239],\n",
      "        [365, 172, 394, 220]], dtype=torch.int32), 'scores': tensor([0.1755, 0.2097, 0.1830, 0.2572, 0.2658, 0.2584, 0.3006, 0.1552]), 'objectness_scores': tensor([0.2360, 0.2092, 0.3960, 0.2693, 0.3692, 0.2807, 0.2369, 0.2162]), 'labels': tensor([ 8,  7, 10,  7, 11,  7, 11,  7], dtype=torch.int32)}\n",
      "293625\n",
      "{'image_id': 293794, 'boxes': tensor([[304,  19, 320,  38],\n",
      "        [134, 379, 204, 455],\n",
      "        [358,   0, 383,  30],\n",
      "        [329,  16, 344,  36],\n",
      "        [346,  27, 362,  39]], dtype=torch.int32), 'scores': tensor([0.1842, 0.1720, 0.2453, 0.1888, 0.2050]), 'objectness_scores': tensor([0.2657, 0.2258, 0.3571, 0.2499, 0.2244]), 'labels': tensor([14, 11, 11, 11, 14], dtype=torch.int32)}\n",
      "293794\n",
      "{'image_id': 293804, 'boxes': tensor([[179,   0, 310, 161],\n",
      "        [  0, 185, 206, 332],\n",
      "        [176, 159, 311, 239],\n",
      "        [118, 201, 192, 257],\n",
      "        [260, 188, 498, 333],\n",
      "        [ 51, 129, 155, 178],\n",
      "        [ 84,  59, 125, 152],\n",
      "        [ 77, 197, 160, 254]], dtype=torch.int32), 'scores': tensor([0.2061, 0.9967, 0.5967, 0.7348, 0.9887, 0.1658, 0.2526, 0.4768]), 'objectness_scores': tensor([0.2469, 0.4533, 0.2093, 0.3210, 0.3788, 0.2107, 0.3078, 0.2884]), 'labels': tensor([13, 13, 13, 13, 13,  0, 11, 13], dtype=torch.int32)}\n",
      "293804\n",
      "{'image_id': 293858, 'boxes': tensor([[ 52, 216, 117, 276],\n",
      "        [322,  82, 404, 209],\n",
      "        [ 61, 190, 126, 253],\n",
      "        [270, 168, 315, 223],\n",
      "        [116, 209, 142, 236],\n",
      "        [140,   1, 259, 130],\n",
      "        [ 37, 185, 466, 444],\n",
      "        [436,  20, 479,  43],\n",
      "        [ 60, 131, 495, 449]], dtype=torch.int32), 'scores': tensor([0.5290, 0.3746, 0.2832, 0.2903, 0.6349, 0.3164, 0.5598, 0.2049, 0.3155]), 'objectness_scores': tensor([0.5897, 0.4098, 0.6804, 0.6001, 0.2052, 0.2135, 0.3046, 0.2816, 0.2585]), 'labels': tensor([11, 16, 11, 12, 11,  7, 12, 11, 12], dtype=torch.int32)}\n",
      "293858\n",
      "{'image_id': 294783, 'boxes': tensor([[349, 229, 371, 245],\n",
      "        [325, 228, 341, 245],\n",
      "        [278, 251, 300, 274],\n",
      "        [517, 138, 639, 357],\n",
      "        [375,  89, 395, 132],\n",
      "        [374,  14, 394, 132],\n",
      "        [338, 227, 357, 243],\n",
      "        [386, 178, 399, 199],\n",
      "        [203, 318, 250, 356],\n",
      "        [235, 307, 293, 369],\n",
      "        [479, 197, 509, 217],\n",
      "        [ 98, 218, 120, 298],\n",
      "        [204, 296, 252, 337],\n",
      "        [215,  77, 319, 140],\n",
      "        [191, 102, 203, 165]], dtype=torch.int32), 'scores': tensor([0.4053, 0.3991, 0.1583, 0.2795, 0.3684, 0.4283, 0.3231, 0.6402, 0.8834,\n",
      "        0.5921, 0.4284, 0.3573, 0.7318, 0.3573, 0.4432]), 'objectness_scores': tensor([0.2363, 0.2418, 0.2747, 0.2358, 0.2274, 0.2817, 0.2225, 0.2115, 0.3703,\n",
      "        0.3668, 0.2123, 0.4030, 0.4226, 0.4261, 0.2420]), 'labels': tensor([11, 11, 11,  7,  7, 11, 11, 11,  7,  7, 14,  7,  7,  6, 11],\n",
      "       dtype=torch.int32)}\n",
      "294783\n",
      "{'image_id': 294831, 'boxes': tensor([[ 89,  83, 558, 363],\n",
      "        [302,  18, 638, 147],\n",
      "        [466,  45, 489,  79]], dtype=torch.int32), 'scores': tensor([0.3614, 0.2588, 0.2261]), 'objectness_scores': tensor([0.3756, 0.2672, 0.2501]), 'labels': tensor([11, 14, 11], dtype=torch.int32)}\n",
      "294831\n",
      "{'image_id': 295138, 'boxes': tensor([[168, 328, 388, 371],\n",
      "        [305, 304, 353, 338],\n",
      "        [259, 223, 316, 325],\n",
      "        [151, 311, 162, 323],\n",
      "        [157, 227, 170, 237],\n",
      "        [289,  22, 330,  52],\n",
      "        [166, 310, 211, 344]], dtype=torch.int32), 'scores': tensor([0.9601, 0.1621, 0.2767, 0.2017, 0.1646, 0.2481, 0.2162]), 'objectness_scores': tensor([0.5361, 0.3907, 0.2031, 0.2567, 0.2105, 0.5219, 0.3810]), 'labels': tensor([ 7, 11, 11, 14,  2,  4, 16], dtype=torch.int32)}\n",
      "295138\n",
      "{'image_id': 295478, 'boxes': tensor([[306, 585, 346, 614],\n",
      "        [155, 316, 178, 333],\n",
      "        [107, 354, 166, 509],\n",
      "        [228,  74, 286,  96],\n",
      "        [232,  91, 340, 348],\n",
      "        [198, 300, 346, 610],\n",
      "        [ 49, 492, 134, 575],\n",
      "        [227,  88, 234,  98],\n",
      "        [229, 123, 270, 174]], dtype=torch.int32), 'scores': tensor([0.1835, 0.2134, 0.4236, 0.1933, 0.2766, 0.4641, 0.9752, 0.2432, 0.2548]), 'objectness_scores': tensor([0.2857, 0.5066, 0.2187, 0.4417, 0.2005, 0.2274, 0.4871, 0.3933, 0.5769]), 'labels': tensor([ 7, 11,  9,  3,  7,  7,  3, 11,  7], dtype=torch.int32)}\n",
      "295478\n",
      "{'image_id': 296222, 'boxes': tensor([[132, 222, 155, 235],\n",
      "        [456, 163, 502, 230],\n",
      "        [  1,   0, 118, 209],\n",
      "        [268,  38, 360,  93],\n",
      "        [293, 415, 422, 474],\n",
      "        [451, 415, 494, 445],\n",
      "        [130, 148, 492, 475],\n",
      "        [225, 418, 246, 456]], dtype=torch.int32), 'scores': tensor([0.2711, 0.5304, 0.7413, 0.4997, 0.3582, 0.2572, 0.2608, 0.7358]), 'objectness_scores': tensor([0.2306, 0.3977, 0.2187, 0.3317, 0.2611, 0.3541, 0.2084, 0.3097]), 'labels': tensor([11,  0,  7,  7, 11, 11, 12, 11], dtype=torch.int32)}\n",
      "296222\n",
      "{'image_id': 296224, 'boxes': tensor([[275, 139, 336, 310],\n",
      "        [ 55,  30, 569, 471],\n",
      "        [355, 222, 425, 255]], dtype=torch.int32), 'scores': tensor([0.2970, 0.9988, 0.2361]), 'objectness_scores': tensor([0.2573, 0.5060, 0.2214]), 'labels': tensor([7, 1, 0], dtype=torch.int32)}\n",
      "296224\n",
      "{'image_id': 296657, 'boxes': tensor([[179, 212, 214, 217],\n",
      "        [ 82, 228, 111, 261],\n",
      "        [280, 121, 299, 181],\n",
      "        [198, 302, 220, 338],\n",
      "        [258, 169, 290, 181],\n",
      "        [377, 156, 405, 183],\n",
      "        [366, 193, 399, 199],\n",
      "        [304, 300, 316, 320],\n",
      "        [152, 242, 167, 264],\n",
      "        [478, 301, 499, 318],\n",
      "        [205, 159, 219, 171],\n",
      "        [ 84, 228, 111, 252],\n",
      "        [309, 230, 325, 236],\n",
      "        [391, 236, 403, 257],\n",
      "        [190, 141, 199, 150],\n",
      "        [568, 308, 592, 327],\n",
      "        [287, 301, 314, 334],\n",
      "        [491, 186, 536, 198],\n",
      "        [498, 138, 526, 182]], dtype=torch.int32), 'scores': tensor([0.2319, 0.1674, 0.3584, 0.6004, 0.2950, 0.1966, 0.2315, 0.2130, 0.2164,\n",
      "        0.1965, 0.2942, 0.4679, 0.2623, 0.2441, 0.1451, 0.2200, 0.2727, 0.2382,\n",
      "        0.9984]), 'objectness_scores': tensor([0.3856, 0.2252, 0.4549, 0.2776, 0.3810, 0.3559, 0.3225, 0.2550, 0.2395,\n",
      "        0.2484, 0.2419, 0.2147, 0.3774, 0.2843, 0.3603, 0.2164, 0.2547, 0.3388,\n",
      "        0.4240]), 'labels': tensor([11,  2,  7,  7,  0, 11,  0, 11, 11, 11, 11, 11, 11, 11, 11,  9,  7,  0,\n",
      "         7], dtype=torch.int32)}\n",
      "296657\n",
      "{'image_id': 297084, 'boxes': tensor([[  1, 228,  97, 603],\n",
      "        [238,   1, 268,  35],\n",
      "        [334, 429, 362, 456],\n",
      "        [  3, 117,  65, 173],\n",
      "        [497, 398, 611, 613],\n",
      "        [497, 272, 611, 613],\n",
      "        [  0, 350,  95, 606],\n",
      "        [  0,   0,  60, 145],\n",
      "        [174,   0, 232,  38],\n",
      "        [141, 103, 178, 128],\n",
      "        [ 84,   3, 117,  40],\n",
      "        [216, 389, 464, 515],\n",
      "        [118,   0, 168,  38],\n",
      "        [145, 380, 231, 557],\n",
      "        [272, 179, 370, 295]], dtype=torch.int32), 'scores': tensor([0.9261, 0.4356, 0.3169, 0.1239, 0.7133, 0.7768, 0.9072, 0.3369, 0.1831,\n",
      "        0.2398, 0.4053, 0.5533, 0.3874, 0.2863, 0.3119]), 'objectness_scores': tensor([0.2405, 0.2246, 0.2799, 0.5429, 0.2250, 0.2568, 0.2897, 0.2862, 0.2432,\n",
      "        0.2494, 0.2336, 0.3129, 0.2375, 0.4530, 0.5263]), 'labels': tensor([10,  7,  7, 10, 10, 15, 10,  7,  7, 13,  2, 11,  7, 10,  4],\n",
      "       dtype=torch.int32)}\n",
      "297084\n",
      "{'image_id': 297085, 'boxes': tensor([[  0, 183, 126, 343],\n",
      "        [109, 291, 167, 343],\n",
      "        [340,  32, 389, 121],\n",
      "        [162, 163, 319, 282],\n",
      "        [302, 123, 325, 145]], dtype=torch.int32), 'scores': tensor([0.3454, 0.4998, 0.3876, 0.3398, 0.1533]), 'objectness_scores': tensor([0.2442, 0.2037, 0.3680, 0.2516, 0.2110]), 'labels': tensor([ 1,  7,  7,  8, 11], dtype=torch.int32)}\n",
      "297085\n",
      "{'image_id': 297562, 'boxes': tensor([[143, 191, 306, 291],\n",
      "        [268, 110, 363, 216],\n",
      "        [355, 211, 387, 231],\n",
      "        [328, 218, 356, 232],\n",
      "        [ 50,  41, 145, 233]], dtype=torch.int32), 'scores': tensor([0.5760, 0.3019, 0.2240, 0.3228, 0.4333]), 'objectness_scores': tensor([0.2359, 0.2639, 0.2845, 0.4612, 0.2641]), 'labels': tensor([11,  7, 14, 11, 10], dtype=torch.int32)}\n",
      "297562\n",
      "{'image_id': 297578, 'boxes': tensor([[245, 143, 249, 150],\n",
      "        [240,  76, 269, 196],\n",
      "        [151,  47, 328, 280]], dtype=torch.int32), 'scores': tensor([0.2193, 0.1340, 0.9027]), 'objectness_scores': tensor([0.2498, 0.5350, 0.2856]), 'labels': tensor([11, 11,  7], dtype=torch.int32)}\n",
      "297578\n",
      "{'image_id': 297830, 'boxes': tensor([[159,  45, 435, 569]], dtype=torch.int32), 'scores': tensor([0.9842]), 'objectness_scores': tensor([0.4262]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "297830\n",
      "{'image_id': 298396, 'boxes': tensor([[593,  72, 626, 123],\n",
      "        [142,  45, 171, 109],\n",
      "        [422, 218, 443, 257],\n",
      "        [586, 246, 629, 317],\n",
      "        [588, 170, 625, 239],\n",
      "        [483, 180, 526, 234],\n",
      "        [466,   3, 567, 151],\n",
      "        [ 84, 273, 202, 296],\n",
      "        [ 72, 223, 104, 284],\n",
      "        [406,  24, 470, 149],\n",
      "        [ 39, 289, 152, 313],\n",
      "        [239, 319, 617, 480],\n",
      "        [606, 234, 637, 283],\n",
      "        [231, 191, 277, 251],\n",
      "        [589, 124, 628, 185],\n",
      "        [  0, 276,  68, 319],\n",
      "        [424, 177, 438, 205]], dtype=torch.int32), 'scores': tensor([0.3545, 0.2085, 0.4099, 0.1544, 0.2010, 0.9211, 0.1789, 0.3781, 0.2666,\n",
      "        0.3753, 0.2581, 0.8413, 0.1456, 0.2566, 0.7343, 0.2019, 0.2601]), 'objectness_scores': tensor([0.2566, 0.2948, 0.3880, 0.2787, 0.2358, 0.2844, 0.2267, 0.3019, 0.3626,\n",
      "        0.2158, 0.2770, 0.2948, 0.2854, 0.4698, 0.2982, 0.2003, 0.2562]), 'labels': tensor([15, 11, 11,  9, 11,  7,  2, 11,  7,  7, 11, 12, 11, 10, 15, 13, 11],\n",
      "       dtype=torch.int32)}\n",
      "298396\n",
      "{'image_id': 298697, 'boxes': tensor([[170, 227, 185, 249]], dtype=torch.int32), 'scores': tensor([0.3148]), 'objectness_scores': tensor([0.6125]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "298697\n",
      "{'image_id': 300039, 'boxes': tensor([[130, 269, 164, 298],\n",
      "        [201,   0, 300, 130],\n",
      "        [  2,  24, 495, 374],\n",
      "        [ 87,  92, 435, 333],\n",
      "        [225, 169, 268, 227]], dtype=torch.int32), 'scores': tensor([0.2068, 0.6277, 0.3455, 0.2883, 0.8576]), 'objectness_scores': tensor([0.2178, 0.4411, 0.2733, 0.4122, 0.3839]), 'labels': tensor([10, 10, 10, 10, 10], dtype=torch.int32)}\n",
      "300039\n",
      "{'image_id': 300276, 'boxes': tensor([[337, 278, 358, 295],\n",
      "        [403, 321, 427, 344],\n",
      "        [371, 260, 458, 304],\n",
      "        [405, 306, 426, 326],\n",
      "        [406, 283, 425, 302],\n",
      "        [391, 266, 410, 281],\n",
      "        [429, 300, 450, 314],\n",
      "        [530, 337, 561, 359],\n",
      "        [421, 260, 436, 273],\n",
      "        [432, 262, 448, 278],\n",
      "        [440, 313, 460, 333],\n",
      "        [333, 266, 350, 281],\n",
      "        [375, 302, 504, 349],\n",
      "        [312, 268, 330, 282],\n",
      "        [302, 277, 322, 293],\n",
      "        [360, 260, 380, 276],\n",
      "        [441, 307, 460, 325],\n",
      "        [411, 273, 427, 286],\n",
      "        [373, 262, 475, 307],\n",
      "        [308, 262, 392, 302],\n",
      "        [430, 324, 456, 347],\n",
      "        [414, 267, 431, 281],\n",
      "        [457, 322, 482, 349],\n",
      "        [  0,  70,  69, 121],\n",
      "        [336, 261, 355, 275],\n",
      "        [318, 258, 334, 271],\n",
      "        [390, 278, 406, 292],\n",
      "        [397, 260, 412, 272],\n",
      "        [389, 304, 411, 322],\n",
      "        [460, 311, 479, 326],\n",
      "        [427, 227, 441, 234],\n",
      "        [319, 258, 384, 296],\n",
      "        [223, 222, 236, 232],\n",
      "        [358, 303, 526, 355],\n",
      "        [384, 304, 403, 324],\n",
      "        [368, 256, 384, 270],\n",
      "        [482, 316, 502, 335],\n",
      "        [481, 324, 503, 351],\n",
      "        [421, 269, 436, 282],\n",
      "        [390, 280, 410, 300],\n",
      "        [312, 268, 329, 284],\n",
      "        [333, 266, 351, 281],\n",
      "        [448, 268, 464, 283],\n",
      "        [415, 260, 431, 273],\n",
      "        [347, 267, 366, 284],\n",
      "        [396, 266, 413, 279],\n",
      "        [476, 302, 498, 321],\n",
      "        [397, 305, 414, 323],\n",
      "        [426, 309, 446, 329],\n",
      "        [478, 310, 496, 327],\n",
      "        [378, 317, 400, 342],\n",
      "        [343,  40, 406,  91],\n",
      "        [444, 283, 465, 303],\n",
      "        [358, 276, 379, 294],\n",
      "        [360, 103, 389, 135],\n",
      "        [423, 283, 444, 303],\n",
      "        [367, 264, 387, 280],\n",
      "        [450, 262, 466, 278],\n",
      "        [431, 272, 448, 287],\n",
      "        [251, 303, 345, 350]], dtype=torch.int32), 'scores': tensor([0.2123, 0.1561, 0.8697, 0.1566, 0.1771, 0.1756, 0.2445, 0.8272, 0.4258,\n",
      "        0.3047, 0.1626, 0.3141, 0.7898, 0.3755, 0.1577, 0.1849, 0.1782, 0.2903,\n",
      "        0.1983, 0.9285, 0.1819, 0.3666, 0.2948, 0.2376, 0.1925, 0.1470, 0.2751,\n",
      "        0.1391, 0.2064, 0.2579, 0.3499, 0.8909, 0.3132, 0.7979, 0.2052, 0.1911,\n",
      "        0.2500, 0.4580, 0.3112, 0.1541, 0.2011, 0.1809, 0.1873, 0.9296, 0.1691,\n",
      "        0.1938, 0.1776, 0.2511, 0.1956, 0.1919, 0.5697, 0.1958, 0.1646, 0.1675,\n",
      "        0.3874, 0.4055, 0.1983, 0.2379, 0.2056, 0.8134]), 'objectness_scores': tensor([0.2573, 0.3173, 0.2514, 0.2860, 0.2909, 0.2560, 0.2750, 0.2320, 0.2467,\n",
      "        0.2080, 0.2955, 0.2605, 0.3119, 0.2700, 0.2514, 0.2610, 0.2681, 0.2583,\n",
      "        0.2020, 0.2138, 0.3209, 0.2342, 0.3203, 0.2700, 0.2157, 0.2596, 0.2227,\n",
      "        0.2156, 0.2552, 0.2770, 0.2162, 0.3355, 0.2718, 0.2109, 0.2893, 0.2489,\n",
      "        0.2867, 0.3340, 0.2054, 0.2772, 0.2249, 0.2655, 0.2460, 0.2061, 0.2693,\n",
      "        0.2403, 0.2907, 0.2599, 0.2866, 0.2243, 0.3151, 0.2282, 0.2787, 0.2443,\n",
      "        0.2815, 0.2773, 0.2398, 0.2563, 0.2822, 0.4063]), 'labels': tensor([14,  3, 12,  8, 11, 11,  8, 10,  2, 16,  8, 14, 12, 14, 10,  9,  4, 11,\n",
      "         7, 12,  8, 11,  8,  7, 14, 14, 11, 14, 14,  8, 11, 12, 11, 12,  4,  8,\n",
      "        12, 12, 11, 11,  8, 14, 11,  3, 11, 11,  8, 14, 14, 14, 10,  4,  8, 11,\n",
      "         7, 12,  8, 11, 11, 12], dtype=torch.int32)}\n",
      "300276\n",
      "{'image_id': 301061, 'boxes': tensor([[ 35, 398, 194, 421],\n",
      "        [132, 150, 455, 637],\n",
      "        [ 47, 562,  76, 601],\n",
      "        [ 42, 399,  63, 517],\n",
      "        [128, 151, 436, 407],\n",
      "        [ 43, 396,  57, 404]], dtype=torch.int32), 'scores': tensor([0.6813, 0.7788, 0.1705, 0.4350, 0.5984, 0.2268]), 'objectness_scores': tensor([0.2211, 0.2404, 0.3254, 0.3115, 0.2118, 0.2930]), 'labels': tensor([11,  4,  9, 11,  5, 11], dtype=torch.int32)}\n",
      "301061\n",
      "{'image_id': 301421, 'boxes': tensor([[513, 144, 584, 240],\n",
      "        [ 35, 169, 595, 426],\n",
      "        [309, 164, 374, 211],\n",
      "        [251, 135, 293, 198],\n",
      "        [135, 237, 251, 297],\n",
      "        [468, 170, 522, 261],\n",
      "        [406, 158, 457, 238],\n",
      "        [348, 223, 381, 283],\n",
      "        [489, 144, 588, 281]], dtype=torch.int32), 'scores': tensor([0.2407, 0.4044, 0.1894, 0.3617, 0.9981, 0.6818, 0.4177, 0.3673, 0.2857]), 'objectness_scores': tensor([0.3375, 0.3293, 0.3764, 0.4048, 0.4123, 0.3814, 0.4902, 0.2289, 0.2152]), 'labels': tensor([11, 14, 15,  8, 14, 14,  8,  7, 14], dtype=torch.int32)}\n",
      "301421\n",
      "{'image_id': 301718, 'boxes': tensor([[189, 537, 230, 590],\n",
      "        [ 81, 460, 390, 572],\n",
      "        [322, 571, 378, 640],\n",
      "        [121, 443, 482, 642],\n",
      "        [ 76, 498, 308, 575],\n",
      "        [278, 493, 398, 589],\n",
      "        [ 22, 274, 157, 305],\n",
      "        [ 17, 243,  23, 252],\n",
      "        [220, 302, 402, 353],\n",
      "        [261, 241, 390, 281],\n",
      "        [212, 569, 268, 625],\n",
      "        [236, 547, 288, 599],\n",
      "        [  2, 278, 478, 640],\n",
      "        [277, 305, 396, 327],\n",
      "        [272, 576, 329, 640],\n",
      "        [108, 317, 128, 333],\n",
      "        [297, 395, 481, 418],\n",
      "        [ 76, 445, 398, 575],\n",
      "        [220, 446, 398, 513],\n",
      "        [352, 476, 457, 545]], dtype=torch.int32), 'scores': tensor([0.1822, 0.3726, 0.7519, 0.4073, 0.3306, 0.3060, 0.3968, 0.2340, 0.3218,\n",
      "        0.3362, 0.6155, 0.6049, 0.5011, 0.2240, 0.2111, 0.3101, 0.8200, 0.5931,\n",
      "        0.3540, 0.7973]), 'objectness_scores': tensor([0.2218, 0.2964, 0.2645, 0.2603, 0.2480, 0.2629, 0.2555, 0.3343, 0.2162,\n",
      "        0.2304, 0.2392, 0.2244, 0.2913, 0.2770, 0.2837, 0.2045, 0.4415, 0.5743,\n",
      "        0.2374, 0.2547]), 'labels': tensor([ 4, 11, 12,  7,  4, 12,  8, 11, 10, 11, 12, 12,  7,  9, 12, 11, 11,  7,\n",
      "        12, 12], dtype=torch.int32)}\n",
      "301718\n",
      "{'image_id': 301867, 'boxes': tensor([[296, 109, 335, 124],\n",
      "        [382, 171, 488, 379],\n",
      "        [214,  43, 441, 213],\n",
      "        [145, 268, 266, 394],\n",
      "        [228, 129, 245, 140],\n",
      "        [271, 261, 300, 280],\n",
      "        [238, 292, 259, 319],\n",
      "        [149, 173, 254, 279],\n",
      "        [363, 228, 374, 244],\n",
      "        [265, 145, 370, 350],\n",
      "        [188, 129, 210, 145],\n",
      "        [371, 135, 414, 151]], dtype=torch.int32), 'scores': tensor([0.2595, 0.4173, 0.9934, 0.1431, 0.3250, 0.2508, 0.9890, 0.4535, 0.2797,\n",
      "        0.4973, 0.3511, 0.3808]), 'objectness_scores': tensor([0.2962, 0.3003, 0.4949, 0.2317, 0.2762, 0.5963, 0.4356, 0.2074, 0.3072,\n",
      "        0.3299, 0.3637, 0.3483]), 'labels': tensor([14,  7,  6,  4, 11,  7,  8,  6, 11,  7,  7, 11], dtype=torch.int32)}\n",
      "301867\n",
      "{'image_id': 302030, 'boxes': tensor([[369,  84, 615, 191],\n",
      "        [334, 138, 380, 143],\n",
      "        [534,  36, 560,  94],\n",
      "        [144, 162, 294, 235],\n",
      "        [620,  89, 639, 114],\n",
      "        [  2, 130, 396, 357],\n",
      "        [259,   0, 331,  72],\n",
      "        [420,  92, 557, 128],\n",
      "        [407,  80, 450, 103],\n",
      "        [286, 114, 328, 143],\n",
      "        [303,  47, 323,  72],\n",
      "        [390, 100, 423, 118],\n",
      "        [560,  86, 602, 113]], dtype=torch.int32), 'scores': tensor([0.9492, 0.1891, 0.2978, 0.4714, 0.3316, 0.9523, 0.2067, 0.9904, 0.1844,\n",
      "        0.2988, 0.2129, 0.3480, 0.2249]), 'objectness_scores': tensor([0.2350, 0.3394, 0.5453, 0.2010, 0.4980, 0.2465, 0.2422, 0.6233, 0.3524,\n",
      "        0.2196, 0.2342, 0.2121, 0.2550]), 'labels': tensor([14, 11,  8, 14, 11, 14, 10, 14,  8,  9,  8,  9, 14], dtype=torch.int32)}\n",
      "302030\n",
      "{'image_id': 302536, 'boxes': tensor([[  0, 172, 133, 295],\n",
      "        [111, 178, 116, 183],\n",
      "        [107, 183, 113, 188],\n",
      "        [382,   0, 498,  96],\n",
      "        [101, 175, 105, 179],\n",
      "        [116, 172, 121, 177],\n",
      "        [462, 176, 487, 227],\n",
      "        [233,  71, 287,  95],\n",
      "        [ 66, 193,  73, 199],\n",
      "        [ 84, 178,  89, 183],\n",
      "        [224, 212, 335, 345],\n",
      "        [364, 169, 393, 207],\n",
      "        [369, 305, 384, 329],\n",
      "        [350, 160, 370, 203],\n",
      "        [350, 159, 370, 194],\n",
      "        [243, 181, 248, 210],\n",
      "        [217,  32, 283,  73],\n",
      "        [ 21, 344,  69, 373]], dtype=torch.int32), 'scores': tensor([0.4618, 0.2945, 0.2172, 0.2921, 0.2363, 0.4247, 0.2976, 0.2775, 0.9995,\n",
      "        0.2989, 0.9702, 0.4089, 0.2992, 0.4498, 0.6660, 0.4480, 0.7162, 0.2782]), 'objectness_scores': tensor([0.3294, 0.5174, 0.4927, 0.3800, 0.4553, 0.4806, 0.2038, 0.2629, 0.3346,\n",
      "        0.3787, 0.4801, 0.2231, 0.2672, 0.2671, 0.2516, 0.3826, 0.3249, 0.2418]), 'labels': tensor([ 9, 11, 11,  7, 11, 11, 11, 16,  5, 11, 13, 12, 11, 11, 11, 11,  7,  9],\n",
      "       dtype=torch.int32)}\n",
      "302536\n",
      "{'image_id': 302760, 'boxes': tensor([[380, 242, 501, 304],\n",
      "        [168, 195, 321, 266],\n",
      "        [264, 130, 326, 203],\n",
      "        [426, 293, 498, 337],\n",
      "        [214, 110, 239, 190],\n",
      "        [162,   0, 262,  91],\n",
      "        [ 77, 235, 317, 376],\n",
      "        [269,  70, 293,  90],\n",
      "        [392, 101, 415, 120],\n",
      "        [428,   9, 498, 140],\n",
      "        [449, 262, 472, 283],\n",
      "        [  0, 191,  94, 376],\n",
      "        [  1,   1, 496, 376],\n",
      "        [160,   0, 495, 144]], dtype=torch.int32), 'scores': tensor([0.3257, 0.7331, 0.9794, 0.6822, 0.5673, 0.1077, 0.9861, 0.2320, 0.1754,\n",
      "        0.2057, 0.2351, 0.1978, 0.9985, 0.9094]), 'objectness_scores': tensor([0.4960, 0.6263, 0.5730, 0.2020, 0.5785, 0.2038, 0.2231, 0.6630, 0.4088,\n",
      "        0.4605, 0.4333, 0.2837, 0.2033, 0.4741]), 'labels': tensor([15, 10, 15, 10,  8, 11, 15, 11, 14,  8,  8,  7, 15, 15],\n",
      "       dtype=torch.int32)}\n",
      "302760\n",
      "{'image_id': 303305, 'boxes': tensor([[ 16,  57, 598, 357]], dtype=torch.int32), 'scores': tensor([0.9989]), 'objectness_scores': tensor([0.5679]), 'labels': tensor([1], dtype=torch.int32)}\n",
      "303305\n",
      "{'image_id': 303818, 'boxes': tensor([[204, 124, 210, 147],\n",
      "        [ 53, 227,  74, 240],\n",
      "        [328,  59, 481, 315],\n",
      "        [190,  95, 203, 145],\n",
      "        [151, 116, 160, 147]], dtype=torch.int32), 'scores': tensor([0.1847, 0.2022, 0.9968, 0.2422, 0.2413]), 'objectness_scores': tensor([0.2133, 0.2724, 0.4179, 0.2413, 0.2215]), 'labels': tensor([ 0, 11,  1, 14, 14], dtype=torch.int32)}\n",
      "303818\n",
      "{'image_id': 304180, 'boxes': tensor([[550,   0, 575,  28],\n",
      "        [280, 257, 335, 400],\n",
      "        [618, 385, 639, 406],\n",
      "        [554,  95, 586, 139],\n",
      "        [553,  39, 576,  82],\n",
      "        [564, 220, 639, 267],\n",
      "        [593, 401, 627, 417],\n",
      "        [554,   0, 576,  13],\n",
      "        [532,   0, 552,  28],\n",
      "        [551, 402, 618, 418],\n",
      "        [621,  33, 640,  79],\n",
      "        [617,   0, 636,  26],\n",
      "        [578,   0, 599,  27],\n",
      "        [535,  60, 558,  84],\n",
      "        [331, 143, 395, 276],\n",
      "        [289, 243, 299, 250],\n",
      "        [574,  54, 599,  82]], dtype=torch.int32), 'scores': tensor([0.1946, 0.3139, 0.2904, 0.2872, 0.1966, 0.2263, 0.2597, 0.2007, 0.1856,\n",
      "        0.4084, 0.5002, 0.2760, 0.1977, 0.1628, 0.2307, 0.1806, 0.2705]), 'objectness_scores': tensor([0.2350, 0.5666, 0.2774, 0.3653, 0.3463, 0.2340, 0.2556, 0.2057, 0.3343,\n",
      "        0.3232, 0.2233, 0.2049, 0.3313, 0.2974, 0.3061, 0.3075, 0.3315]), 'labels': tensor([14, 11, 11, 10, 11, 10, 11, 11,  7, 11, 14, 11, 11, 11, 13, 10, 10],\n",
      "       dtype=torch.int32)}\n",
      "304180\n",
      "{'image_id': 304404, 'boxes': tensor([[ 33, 166,  56, 202],\n",
      "        [  0, 255,  76, 312],\n",
      "        [243, 167, 252, 175],\n",
      "        [369, 171, 388, 175],\n",
      "        [ 19,  52,  36,  62],\n",
      "        [173, 198, 201, 216],\n",
      "        [491, 160, 502, 168],\n",
      "        [611, 167, 628, 171],\n",
      "        [183, 173, 196, 182],\n",
      "        [266,  92, 305, 122],\n",
      "        [538, 158, 551, 166],\n",
      "        [409, 169, 428, 172],\n",
      "        [411, 121, 423, 129],\n",
      "        [  9, 167,  55, 206],\n",
      "        [371, 123, 384, 131],\n",
      "        [572, 121, 585, 130],\n",
      "        [283, 201, 311, 212],\n",
      "        [239, 118, 308, 178],\n",
      "        [616, 128, 628, 135],\n",
      "        [ 96, 213, 129, 244],\n",
      "        [375, 156, 390, 165],\n",
      "        [228, 107, 252, 125],\n",
      "        [573, 170, 589, 175],\n",
      "        [ 83, 182,  96, 190]], dtype=torch.int32), 'scores': tensor([0.2413, 0.2081, 0.1371, 0.2960, 0.3418, 0.3610, 0.1636, 0.2061, 0.2277,\n",
      "        0.5629, 0.1753, 0.1667, 0.1705, 0.2108, 0.1530, 0.2314, 0.2107, 0.2182,\n",
      "        0.2272, 0.2393, 0.2206, 0.2831, 0.2453, 0.8622]), 'objectness_scores': tensor([0.2135, 0.2310, 0.2158, 0.3380, 0.2352, 0.2237, 0.2828, 0.2692, 0.2343,\n",
      "        0.2580, 0.2818, 0.2883, 0.2577, 0.3209, 0.2693, 0.2814, 0.2998, 0.5375,\n",
      "        0.2720, 0.5151, 0.2232, 0.2134, 0.2546, 0.2160]), 'labels': tensor([11,  4, 11, 11,  6,  7, 14, 10, 14,  8, 14, 11, 14, 11, 11,  7, 11,  4,\n",
      "        11, 11, 11, 11, 11, 10], dtype=torch.int32)}\n",
      "304404\n",
      "{'image_id': 304984, 'boxes': tensor([[ 65, 117, 382, 259],\n",
      "        [283,   0, 386, 123],\n",
      "        [  1, 135, 382, 289],\n",
      "        [222, 188, 359, 250],\n",
      "        [  2, 134, 148, 289],\n",
      "        [156, 152, 255, 197]], dtype=torch.int32), 'scores': tensor([0.8507, 0.9095, 0.8352, 0.3560, 0.6145, 0.2467]), 'objectness_scores': tensor([0.4535, 0.6117, 0.2341, 0.3405, 0.5171, 0.3320]), 'labels': tensor([12, 10, 12, 11, 12, 12], dtype=torch.int32)}\n",
      "304984\n",
      "{'image_id': 305609, 'boxes': tensor([[ 13, 322, 609, 587],\n",
      "        [490, 163, 597, 251],\n",
      "        [464, 162, 612, 262],\n",
      "        [  3, 135, 606, 610],\n",
      "        [257, 208, 479, 324],\n",
      "        [  0, 400, 209, 566],\n",
      "        [ 17, 357, 197, 468],\n",
      "        [  0, 247, 116, 411],\n",
      "        [215, 337, 612, 558],\n",
      "        [ 28, 142, 274, 253],\n",
      "        [296, 133, 484, 213]], dtype=torch.int32), 'scores': tensor([0.5700, 0.5263, 0.4199, 0.3887, 0.3102, 0.5573, 0.5114, 0.4113, 0.8510,\n",
      "        0.4765, 0.3172]), 'objectness_scores': tensor([0.2940, 0.2473, 0.4478, 0.4619, 0.4674, 0.4846, 0.3181, 0.2759, 0.4777,\n",
      "        0.4904, 0.5235]), 'labels': tensor([12, 12, 12, 12, 12, 12, 12, 12, 12, 10, 12], dtype=torch.int32)}\n",
      "305609\n",
      "{'image_id': 306136, 'boxes': tensor([[114, 318, 413, 609],\n",
      "        [  0, 371,  41, 392]], dtype=torch.int32), 'scores': tensor([0.9992, 0.3112]), 'objectness_scores': tensor([0.4744, 0.2079]), 'labels': tensor([ 1, 11], dtype=torch.int32)}\n",
      "306136\n",
      "{'image_id': 306437, 'boxes': tensor([[200, 393, 248, 432]], dtype=torch.int32), 'scores': tensor([0.3543]), 'objectness_scores': tensor([0.6415]), 'labels': tensor([9], dtype=torch.int32)}\n",
      "306437\n",
      "{'image_id': 306733, 'boxes': tensor([[406, 221, 491, 327],\n",
      "        [129, 172, 248, 188],\n",
      "        [161,  79, 221, 145],\n",
      "        [280,  58, 340, 312],\n",
      "        [159, 173, 229, 305],\n",
      "        [204, 357, 276, 398],\n",
      "        [544, 336, 574, 358],\n",
      "        [546, 266, 571, 303],\n",
      "        [ 71, 247,  87, 261],\n",
      "        [179, 173, 213, 212],\n",
      "        [ 94,  12, 506, 369],\n",
      "        [288,  29, 501, 328],\n",
      "        [197, 394, 358, 425],\n",
      "        [  1, 296, 106, 423],\n",
      "        [ 97, 331, 218, 369]], dtype=torch.int32), 'scores': tensor([0.3121, 0.3309, 0.2652, 0.9073, 0.5280, 0.9756, 0.6777, 0.2814, 0.2324,\n",
      "        0.3611, 0.9142, 0.1948, 0.3353, 0.3854, 0.6381]), 'objectness_scores': tensor([0.2765, 0.2446, 0.2685, 0.3123, 0.4335, 0.4724, 0.4125, 0.2343, 0.3025,\n",
      "        0.2361, 0.2689, 0.2838, 0.3248, 0.2205, 0.4256]), 'labels': tensor([ 7, 11,  5,  6,  7, 15, 11, 11, 14,  7, 15,  7, 14, 12, 14],\n",
      "       dtype=torch.int32)}\n",
      "306733\n",
      "{'image_id': 307145, 'boxes': tensor([[161,  79, 200, 105],\n",
      "        [ 41,  88,  61, 149],\n",
      "        [216,   0, 248,  39],\n",
      "        [208,  56, 226,  73],\n",
      "        [232,  75, 253,  99],\n",
      "        [ 51,  86, 344, 286],\n",
      "        [  0,  79,  85, 159],\n",
      "        [216,   0, 276,  41],\n",
      "        [189,   0, 216,  33],\n",
      "        [192,  61, 209,  76],\n",
      "        [103, 112, 189, 241],\n",
      "        [167,  92, 237, 112],\n",
      "        [207,  78, 232,  97],\n",
      "        [253,  67, 349, 100],\n",
      "        [200,  73, 234,  99],\n",
      "        [275,   0, 384,  74],\n",
      "        [185, 111, 344, 287],\n",
      "        [ 50,  90, 259, 246],\n",
      "        [192,  58, 227,  93],\n",
      "        [285, 141, 330, 182],\n",
      "        [ 54, 100, 111, 196],\n",
      "        [  0,   0,  72,  51],\n",
      "        [325,  87, 360, 178],\n",
      "        [352,  91, 395, 189],\n",
      "        [  0,  87,  59, 156],\n",
      "        [ 43,  81,  86, 149],\n",
      "        [176,  95, 255, 117]], dtype=torch.int32), 'scores': tensor([0.2510, 0.2390, 0.2522, 0.3506, 0.2306, 0.9966, 0.4069, 0.1892, 0.2298,\n",
      "        0.2481, 0.3631, 0.2635, 0.3294, 0.3092, 0.1987, 0.2914, 0.5583, 0.9866,\n",
      "        0.3282, 0.2324, 0.5577, 0.1783, 0.3696, 0.2259, 0.5861, 0.2536, 0.2384]), 'objectness_scores': tensor([0.5602, 0.2880, 0.2422, 0.2984, 0.3674, 0.2783, 0.2919, 0.2860, 0.2682,\n",
      "        0.2992, 0.2760, 0.2091, 0.2461, 0.5357, 0.3703, 0.2076, 0.3526, 0.2744,\n",
      "        0.2169, 0.2630, 0.3411, 0.2786, 0.2851, 0.2986, 0.4460, 0.2450, 0.2379]), 'labels': tensor([11,  7,  8, 11, 11, 15, 13, 11, 11, 11, 15, 13, 11,  1, 13, 13, 15, 15,\n",
      "        13, 11,  7, 13, 13, 11, 13,  7, 11], dtype=torch.int32)}\n",
      "307145\n",
      "{'image_id': 307172, 'boxes': tensor([[ 75, 255, 571, 417],\n",
      "        [278,  44, 303,  67],\n",
      "        [  0,  75, 580, 424],\n",
      "        [304,  29, 354,  75],\n",
      "        [280,  43, 292,  54],\n",
      "        [  1,  65, 190, 155]], dtype=torch.int32), 'scores': tensor([0.8377, 0.6224, 0.6702, 0.3095, 0.1975, 0.3084]), 'objectness_scores': tensor([0.4831, 0.6471, 0.4725, 0.4146, 0.2117, 0.5007]), 'labels': tensor([12, 16, 12, 11, 11, 16], dtype=torch.int32)}\n",
      "307172\n",
      "{'image_id': 308165, 'boxes': tensor([[196, 385, 252, 494],\n",
      "        [337, 326, 367, 350],\n",
      "        [167, 348, 272, 386],\n",
      "        [120, 339, 142, 365],\n",
      "        [104, 337, 121, 365]], dtype=torch.int32), 'scores': tensor([0.3504, 0.3747, 0.4339, 0.2974, 0.2448]), 'objectness_scores': tensor([0.7714, 0.2115, 0.6648, 0.2015, 0.2001]), 'labels': tensor([ 7,  7,  9,  7, 14], dtype=torch.int32)}\n",
      "308165\n",
      "{'image_id': 308394, 'boxes': tensor([[114, 234, 157, 324]], dtype=torch.int32), 'scores': tensor([0.2796]), 'objectness_scores': tensor([0.2457]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "308394\n",
      "{'image_id': 308466, 'boxes': tensor([[328, 336, 351, 355],\n",
      "        [  0, 163, 139, 361],\n",
      "        [317,  95, 347, 120],\n",
      "        [291, 342, 626, 481],\n",
      "        [  0,  68, 137, 127],\n",
      "        [252, 102, 633, 158],\n",
      "        [ 98, 428, 137, 463],\n",
      "        [ 37, 397, 236, 480]], dtype=torch.int32), 'scores': tensor([0.6886, 0.5661, 0.6367, 0.5161, 0.3163, 0.2845, 0.2462, 0.9847]), 'objectness_scores': tensor([0.3406, 0.4942, 0.2288, 0.6014, 0.2397, 0.2106, 0.4105, 0.2932]), 'labels': tensor([11, 14, 16, 14,  7, 16, 11, 15], dtype=torch.int32)}\n",
      "308466\n",
      "{'image_id': 308799, 'boxes': tensor([[ 68, 109, 187, 170],\n",
      "        [182, 271, 261, 297],\n",
      "        [ 79, 269, 180, 296],\n",
      "        [259, 326, 327, 381],\n",
      "        [ 78, 248, 192, 266],\n",
      "        [263,  57, 334, 151],\n",
      "        [ 60,  76,  78, 144],\n",
      "        [ 78, 324, 183, 370],\n",
      "        [185,  68, 264, 208],\n",
      "        [ 76,  72, 185, 113],\n",
      "        [ 77, 269, 181, 328],\n",
      "        [181, 270, 263, 373],\n",
      "        [ 76, 268, 183, 371]], dtype=torch.int32), 'scores': tensor([0.4252, 0.3417, 0.4109, 0.3310, 0.4174, 0.2388, 0.3801, 0.3234, 0.1662,\n",
      "        0.2278, 0.3126, 0.2119, 0.2707]), 'objectness_scores': tensor([0.6805, 0.2586, 0.2207, 0.3686, 0.5402, 0.4132, 0.2523, 0.2947, 0.4277,\n",
      "        0.4482, 0.3218, 0.4122, 0.4193]), 'labels': tensor([11, 14, 11, 14, 11,  8, 11, 14, 11, 13, 13, 12, 13], dtype=torch.int32)}\n",
      "308799\n",
      "{'image_id': 309391, 'boxes': tensor([[556, 166, 565, 185],\n",
      "        [ 98,   0, 127,  45],\n",
      "        [ 49,   3,  81,  41],\n",
      "        [187,  60, 221,  96],\n",
      "        [234,  69, 248,  93],\n",
      "        [299,  67, 307,  95],\n",
      "        [323, 138, 328, 149],\n",
      "        [209, 149, 219, 178],\n",
      "        [597, 184, 609, 220],\n",
      "        [268,  70, 279,  93],\n",
      "        [624, 213, 638, 255],\n",
      "        [115, 163, 126, 193],\n",
      "        [ 91, 198, 104, 214],\n",
      "        [ 75, 120, 105, 166],\n",
      "        [127, 126, 179, 168],\n",
      "        [109, 141, 136, 152],\n",
      "        [551, 120, 557, 135],\n",
      "        [252, 144, 269, 151],\n",
      "        [  4, 140,  19, 185],\n",
      "        [564, 194, 572, 218],\n",
      "        [261, 257, 282, 264],\n",
      "        [321,  64, 353,  94],\n",
      "        [ 75, 213, 102, 240],\n",
      "        [307,  94, 312, 107],\n",
      "        [344, 114, 349, 130],\n",
      "        [311, 157, 319, 165],\n",
      "        [249,  60, 270, 100],\n",
      "        [477,  12, 491,  42],\n",
      "        [252,  65, 265,  99],\n",
      "        [279,  85, 295, 104],\n",
      "        [570, 165, 583, 197],\n",
      "        [542,   1, 583,  39],\n",
      "        [453,  79, 463,  91]], dtype=torch.int32), 'scores': tensor([0.1595, 0.3707, 0.2140, 0.3283, 0.9940, 0.1640, 0.1660, 0.1706, 0.2574,\n",
      "        0.2997, 0.2688, 0.1568, 0.3790, 0.3578, 0.1656, 0.4624, 0.1914, 0.3178,\n",
      "        0.4960, 0.1388, 0.1487, 0.3528, 0.2756, 0.1938, 0.1477, 0.1753, 0.9939,\n",
      "        0.1836, 0.1833, 0.2221, 0.1556, 0.1842, 0.2445]), 'objectness_scores': tensor([0.2333, 0.4219, 0.3501, 0.3380, 0.2180, 0.3691, 0.2609, 0.3951, 0.4519,\n",
      "        0.2368, 0.5004, 0.4518, 0.2494, 0.2418, 0.2425, 0.2489, 0.3234, 0.2193,\n",
      "        0.4370, 0.3784, 0.2188, 0.2948, 0.2099, 0.2267, 0.3006, 0.2080, 0.4853,\n",
      "        0.4340, 0.2052, 0.2408, 0.2077, 0.2295, 0.2215]), 'labels': tensor([11,  9,  9, 12,  5, 14, 14, 14, 14, 14, 14, 14, 11,  8, 12, 11, 11, 14,\n",
      "         8, 11, 11, 14, 11, 14, 14, 14,  5,  9, 14, 14, 11, 11, 14],\n",
      "       dtype=torch.int32)}\n",
      "309391\n",
      "{'image_id': 309484, 'boxes': tensor([[ 29, 173,  65, 190],\n",
      "        [394, 140, 520, 265]], dtype=torch.int32), 'scores': tensor([0.8386, 0.2319]), 'objectness_scores': tensor([0.6470, 0.4311]), 'labels': tensor([11,  7], dtype=torch.int32)}\n",
      "309484\n",
      "{'image_id': 309655, 'boxes': tensor([[278, 200, 321, 232],\n",
      "        [137, 231, 143, 236],\n",
      "        [362, 225, 369, 231],\n",
      "        [226, 237, 231, 242],\n",
      "        [253, 220, 262, 226],\n",
      "        [ 58, 244,  64, 249],\n",
      "        [397, 224, 405, 232],\n",
      "        [252, 347, 278, 376],\n",
      "        [ 25, 215,  37, 225],\n",
      "        [345, 375, 376, 481],\n",
      "        [343, 236, 348, 240],\n",
      "        [241, 374, 269, 479],\n",
      "        [279, 218, 319, 240],\n",
      "        [241, 218, 249, 224],\n",
      "        [  9, 210,  22, 219],\n",
      "        [335, 343, 359, 377],\n",
      "        [ 93, 239, 100, 245],\n",
      "        [ 77, 221,  85, 228]], dtype=torch.int32), 'scores': tensor([0.9366, 0.2825, 0.2909, 0.1477, 0.1920, 0.2094, 0.2176, 0.2805, 0.1818,\n",
      "        0.5637, 0.1753, 0.1656, 0.9995, 0.2670, 0.2100, 0.1989, 0.1899, 0.2035]), 'objectness_scores': tensor([0.3053, 0.2480, 0.2942, 0.2379, 0.2502, 0.2337, 0.2876, 0.2879, 0.2645,\n",
      "        0.2239, 0.2377, 0.2059, 0.4671, 0.3262, 0.2392, 0.2844, 0.2085, 0.2372]), 'labels': tensor([ 8,  0, 11, 11,  0,  8, 11,  0, 11, 11, 11,  7, 14,  0, 11,  7, 11, 14],\n",
      "       dtype=torch.int32)}\n",
      "309655\n",
      "{'image_id': 309938, 'boxes': tensor([[  2,   1, 183, 241],\n",
      "        [552, 133, 638, 201],\n",
      "        [239,   0, 495,  65],\n",
      "        [ 96, 103, 435, 334]], dtype=torch.int32), 'scores': tensor([0.3715, 0.4378, 0.2820, 0.9411]), 'objectness_scores': tensor([0.2188, 0.2752, 0.2325, 0.4284]), 'labels': tensor([16, 16,  7,  3], dtype=torch.int32)}\n",
      "309938\n",
      "{'image_id': 309964, 'boxes': tensor([[467, 247, 540, 320],\n",
      "        [428, 311, 536, 420],\n",
      "        [151,  90, 202, 128],\n",
      "        [155, 122, 200, 137],\n",
      "        [182, 247, 198, 273]], dtype=torch.int32), 'scores': tensor([0.7822, 0.8943, 0.1806, 0.1752, 0.5070]), 'objectness_scores': tensor([0.2484, 0.5175, 0.2122, 0.2131, 0.5053]), 'labels': tensor([ 6, 10,  7,  8, 11], dtype=torch.int32)}\n",
      "309964\n",
      "{'image_id': 310862, 'boxes': tensor([[432, 235, 460, 266],\n",
      "        [508, 249, 531, 276],\n",
      "        [190, 336, 307, 579],\n",
      "        [540, 429, 565, 469],\n",
      "        [563, 258, 585, 284],\n",
      "        [  7, 248, 570, 612]], dtype=torch.int32), 'scores': tensor([0.4266, 0.2435, 0.9959, 0.2608, 0.4670, 0.9995]), 'objectness_scores': tensor([0.4059, 0.2910, 0.6501, 0.3358, 0.2975, 0.2089]), 'labels': tensor([ 7, 11,  7, 11, 11,  7], dtype=torch.int32)}\n",
      "310862\n",
      "{'image_id': 310980, 'boxes': tensor([[ -1, 347, 392, 427]], dtype=torch.int32), 'scores': tensor([0.7327]), 'objectness_scores': tensor([0.4216]), 'labels': tensor([14], dtype=torch.int32)}\n",
      "310980\n",
      "{'image_id': 311180, 'boxes': tensor([[ 98, 312, 481, 480],\n",
      "        [236, 363, 247, 373]], dtype=torch.int32), 'scores': tensor([0.9983, 0.1512]), 'objectness_scores': tensor([0.7503, 0.2326]), 'labels': tensor([16, 11], dtype=torch.int32)}\n",
      "311180\n",
      "{'image_id': 311190, 'boxes': tensor([[ 16,  62, 331, 285],\n",
      "        [ 17,  69, 330, 497]], dtype=torch.int32), 'scores': tensor([0.9393, 0.9588]), 'objectness_scores': tensor([0.3913, 0.4810]), 'labels': tensor([3, 3], dtype=torch.int32)}\n",
      "311190\n",
      "{'image_id': 311303, 'boxes': tensor([[ -1,  91, 364, 291],\n",
      "        [  4,  56, 634, 427],\n",
      "        [353,  54, 616, 403],\n",
      "        [210,  95, 355, 248],\n",
      "        [ 68, 186, 108, 219],\n",
      "        [106, 200, 179, 265],\n",
      "        [  0, 328, 258, 426]], dtype=torch.int32), 'scores': tensor([0.6502, 0.9368, 0.9801, 0.3078, 0.2908, 0.8506, 0.2674]), 'objectness_scores': tensor([0.2311, 0.3242, 0.4338, 0.3222, 0.2539, 0.2500, 0.2153]), 'labels': tensor([12, 10, 10,  4, 12, 12, 11], dtype=torch.int32)}\n",
      "311303\n",
      "{'image_id': 311392, 'boxes': tensor([[  1,  75, 545, 428]], dtype=torch.int32), 'scores': tensor([0.9984]), 'objectness_scores': tensor([0.5804]), 'labels': tensor([4], dtype=torch.int32)}\n",
      "311392\n",
      "{'image_id': 312213, 'boxes': tensor([[306,   7, 638, 479],\n",
      "        [  0, 249, 331, 330]], dtype=torch.int32), 'scores': tensor([0.9777, 0.9987]), 'objectness_scores': tensor([0.4818, 0.3165]), 'labels': tensor([ 2, 14], dtype=torch.int32)}\n",
      "312213\n",
      "{'image_id': 312237, 'boxes': tensor([[427, 206, 450, 215],\n",
      "        [412, 190, 418, 194]], dtype=torch.int32), 'scores': tensor([0.2333, 0.1738]), 'objectness_scores': tensor([0.2754, 0.3103]), 'labels': tensor([11, 10], dtype=torch.int32)}\n",
      "312237\n",
      "{'image_id': 312421, 'boxes': tensor([[517, 115, 549, 138],\n",
      "        [ 69, 206, 104, 239],\n",
      "        [ 88,  -1, 478, 148]], dtype=torch.int32), 'scores': tensor([0.1888, 0.1620, 0.2739]), 'objectness_scores': tensor([0.2307, 0.2474, 0.4659]), 'labels': tensor([ 0, 11, 10], dtype=torch.int32)}\n",
      "312421\n",
      "{'image_id': 313034, 'boxes': tensor([[403,   0, 481,  55],\n",
      "        [ 53, 356, 238, 479],\n",
      "        [583, 232, 590, 242]], dtype=torch.int32), 'scores': tensor([0.6842, 0.2756, 0.2942]), 'objectness_scores': tensor([0.2091, 0.2189, 0.2135]), 'labels': tensor([16,  7, 11], dtype=torch.int32)}\n",
      "313034\n",
      "{'image_id': 313182, 'boxes': tensor([[175, 251, 180, 262],\n",
      "        [146, 255, 154, 270],\n",
      "        [  2, 279,  24, 294],\n",
      "        [170, 251, 176, 263],\n",
      "        [166, 251, 172, 264]], dtype=torch.int32), 'scores': tensor([0.2505, 0.1784, 0.1990, 0.1687, 0.6272]), 'objectness_scores': tensor([0.6208, 0.7735, 0.4079, 0.4389, 0.5914]), 'labels': tensor([14, 14,  7, 14, 10], dtype=torch.int32)}\n",
      "313182\n",
      "{'image_id': 313454, 'boxes': tensor([[324, 277, 342, 313],\n",
      "        [ 88, 147, 110, 227],\n",
      "        [392, 273, 464, 313],\n",
      "        [149, 215, 263, 336],\n",
      "        [225, 302, 541, 387],\n",
      "        [339, 261, 381, 306],\n",
      "        [165, 252, 250, 290],\n",
      "        [404, 263, 426, 279],\n",
      "        [112, 135, 150, 201]], dtype=torch.int32), 'scores': tensor([0.1937, 0.4521, 0.2599, 0.5051, 0.5457, 0.4722, 0.9718, 0.6080, 0.5447]), 'objectness_scores': tensor([0.4384, 0.3980, 0.2603, 0.2326, 0.2784, 0.6906, 0.2039, 0.4057, 0.5191]), 'labels': tensor([ 7, 11, 12,  6,  7,  7, 13, 11,  7], dtype=torch.int32)}\n",
      "313454\n",
      "{'image_id': 313588, 'boxes': tensor([[ 42,  88,  56, 328],\n",
      "        [339, 193, 479, 291],\n",
      "        [160,  83, 173, 289],\n",
      "        [ 45,  94,  55, 128],\n",
      "        [430, 553, 457, 574],\n",
      "        [163,  90, 169, 127]], dtype=torch.int32), 'scores': tensor([0.5756, 0.9900, 0.2147, 0.3853, 0.3216, 0.1482]), 'objectness_scores': tensor([0.2476, 0.5027, 0.2392, 0.4899, 0.2329, 0.4594]), 'labels': tensor([11,  6, 11,  7,  8,  0], dtype=torch.int32)}\n",
      "313588\n",
      "{'image_id': 314034, 'boxes': tensor([[491, 220, 569, 274],\n",
      "        [610, 194, 640, 223],\n",
      "        [135, 215, 224, 265],\n",
      "        [316, 219, 388, 276],\n",
      "        [143, 198, 212, 231],\n",
      "        [265, 185, 288, 195],\n",
      "        [307, 212, 347, 272],\n",
      "        [310, 212, 342, 235],\n",
      "        [313, 221, 366, 275],\n",
      "        [276, 218, 317, 277],\n",
      "        [262, 193, 307, 219],\n",
      "        [  2, 191,  52, 216],\n",
      "        [  2, 281, 636, 471],\n",
      "        [242, 212, 278, 277],\n",
      "        [220, 204, 280, 241],\n",
      "        [351, 220, 412, 278]], dtype=torch.int32), 'scores': tensor([0.9971, 0.2213, 0.9990, 0.9953, 0.5495, 0.2250, 0.9818, 0.8925, 0.9778,\n",
      "        0.9434, 0.9655, 0.2185, 0.3266, 0.9988, 0.9961, 0.9991]), 'objectness_scores': tensor([0.6517, 0.3356, 0.6522, 0.5156, 0.5920, 0.2061, 0.3406, 0.2582, 0.2404,\n",
      "        0.5257, 0.5202, 0.6241, 0.2231, 0.5514, 0.5643, 0.5424]), 'labels': tensor([ 4,  4,  4,  4,  4, 11,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4],\n",
      "       dtype=torch.int32)}\n",
      "314034\n",
      "{'image_id': 315187, 'boxes': tensor([[226, 311, 234, 323],\n",
      "        [366, 290, 373, 300],\n",
      "        [ 24, 298,  53, 308],\n",
      "        [249, 122, 355, 301],\n",
      "        [  9, 243,  41, 353],\n",
      "        [ 81, 207, 173, 366],\n",
      "        [ 24, 312,  55, 327],\n",
      "        [300, 285, 558, 408],\n",
      "        [433, 239, 554, 282],\n",
      "        [159, 311, 164, 324],\n",
      "        [236, 207, 263, 354]], dtype=torch.int32), 'scores': tensor([0.2084, 0.1549, 0.4132, 0.2949, 0.2345, 0.1567, 0.2008, 0.9969, 0.3509,\n",
      "        0.2307, 0.1431]), 'objectness_scores': tensor([0.2422, 0.3465, 0.2193, 0.2656, 0.2326, 0.2777, 0.2177, 0.6081, 0.2141,\n",
      "        0.4003, 0.2782]), 'labels': tensor([14, 14, 14,  7,  9,  7, 14,  1,  1, 11,  7], dtype=torch.int32)}\n",
      "315187\n",
      "{'image_id': 315450, 'boxes': tensor([[134, 187, 146, 207],\n",
      "        [418, 119, 639, 308],\n",
      "        [ 10,  88,  25, 109],\n",
      "        [ 39, 141,  48, 161],\n",
      "        [ 21, 177,  26, 189],\n",
      "        [165, 110, 405, 304],\n",
      "        [330, 171, 365, 224],\n",
      "        [115, 135, 124, 154],\n",
      "        [ 66, 146,  72, 158],\n",
      "        [ 49, 136,  60, 148],\n",
      "        [372, 172, 403, 223],\n",
      "        [ 75, 175,  82, 190],\n",
      "        [135,  85, 148, 116],\n",
      "        [ 90, 192, 115, 208],\n",
      "        [ 10, 169,  32, 175]], dtype=torch.int32), 'scores': tensor([0.1981, 0.9989, 0.2242, 0.1786, 0.2772, 0.9990, 0.1857, 0.2224, 0.2064,\n",
      "        0.3835, 0.2191, 0.1855, 0.2585, 0.7195, 0.2064]), 'objectness_scores': tensor([0.2544, 0.5106, 0.2521, 0.5122, 0.3351, 0.5964, 0.2505, 0.4885, 0.2918,\n",
      "        0.2240, 0.3157, 0.4746, 0.3675, 0.3336, 0.3288]), 'labels': tensor([14,  1, 11, 14, 14,  1,  8, 14, 14, 14, 11, 14, 11, 14,  0],\n",
      "       dtype=torch.int32)}\n",
      "315450\n",
      "{'image_id': 316015, 'boxes': tensor([[ 71,  37, 122, 190],\n",
      "        [304, 164, 459, 367],\n",
      "        [ 32, 174,  87, 268],\n",
      "        [105, 196, 147, 240],\n",
      "        [125, 235, 320, 313],\n",
      "        [330, 143, 397, 228],\n",
      "        [365, 143, 395, 212],\n",
      "        [330, 190, 368, 229],\n",
      "        [  1, 214, 495, 387]], dtype=torch.int32), 'scores': tensor([0.6331, 0.9557, 0.6527, 0.4833, 0.5850, 0.3569, 0.3219, 0.2777, 0.5833]), 'objectness_scores': tensor([0.3800, 0.5359, 0.2030, 0.2781, 0.7339, 0.2047, 0.2577, 0.2796, 0.4702]), 'labels': tensor([16,  2, 14, 10, 14, 10,  7, 10,  2], dtype=torch.int32)}\n",
      "316015\n",
      "{'image_id': 316666, 'boxes': tensor([[481, 383, 638, 448],\n",
      "        [  0, 107,  45, 158],\n",
      "        [352, 196, 443, 289],\n",
      "        [234, 165, 438, 349],\n",
      "        [113,  14, 163,  52],\n",
      "        [370, 124, 435, 190],\n",
      "        [230, 169, 371, 347],\n",
      "        [392, 265, 421, 309],\n",
      "        [110, 260, 136, 295],\n",
      "        [417, 262, 441, 299],\n",
      "        [576,  92, 612, 164],\n",
      "        [ 96, 174, 197, 281],\n",
      "        [262, 263, 286, 302]], dtype=torch.int32), 'scores': tensor([0.3588, 0.4057, 0.7163, 0.4167, 0.2192, 0.3848, 0.5026, 0.7170, 0.2754,\n",
      "        0.3129, 0.3568, 0.5104, 0.3095]), 'objectness_scores': tensor([0.2064, 0.2012, 0.2381, 0.2735, 0.3315, 0.2429, 0.2171, 0.2881, 0.2082,\n",
      "        0.2465, 0.2475, 0.2929, 0.2312]), 'labels': tensor([10, 11, 10, 10,  7,  7,  7, 10, 10, 11, 11, 10, 11], dtype=torch.int32)}\n",
      "316666\n",
      "{'image_id': 318114, 'boxes': tensor([[120, 102, 379, 290],\n",
      "        [ 10,  82, 384, 308],\n",
      "        [ 13,   9, 137, 207],\n",
      "        [ 25,  42, 135, 198]], dtype=torch.int32), 'scores': tensor([0.9920, 0.9778, 0.9752, 0.9721]), 'objectness_scores': tensor([0.4824, 0.7012, 0.5695, 0.3703]), 'labels': tensor([12, 12, 10, 10], dtype=torch.int32)}\n",
      "318114\n",
      "{'image_id': 318238, 'boxes': tensor([[  0,   0, 134, 109],\n",
      "        [117,  86, 294, 257],\n",
      "        [298,  94, 478, 255],\n",
      "        [259, 105, 356, 210],\n",
      "        [193, 100, 356, 243]], dtype=torch.int32), 'scores': tensor([0.1615, 0.8109, 0.4078, 0.4843, 0.9225]), 'objectness_scores': tensor([0.2485, 0.3259, 0.2488, 0.2578, 0.2723]), 'labels': tensor([4, 3, 3, 2, 3], dtype=torch.int32)}\n",
      "318238\n",
      "{'image_id': 319100, 'boxes': tensor([[214, 309, 221, 313],\n",
      "        [305, 227, 319, 251],\n",
      "        [ 66,   0, 236,  51],\n",
      "        [430, 104, 479, 183],\n",
      "        [305, 227, 321, 252],\n",
      "        [384,  41, 404,  64],\n",
      "        [ -3, 120, 461, 332],\n",
      "        [224, 215, 234, 240],\n",
      "        [205, 260, 225, 271],\n",
      "        [399, 222, 422, 236],\n",
      "        [413, 263, 418, 267],\n",
      "        [  2, 289, 150, 332],\n",
      "        [  0, 211,  46, 305],\n",
      "        [416, 194, 497, 327],\n",
      "        [361, 120, 437, 230]], dtype=torch.int32), 'scores': tensor([0.2436, 0.1536, 0.3830, 0.2941, 0.2086, 0.3745, 0.3014, 0.9678, 0.3805,\n",
      "        0.4453, 0.1493, 0.9825, 0.4920, 0.6288, 0.4433]), 'objectness_scores': tensor([0.2916, 0.2263, 0.2000, 0.2504, 0.2546, 0.2370, 0.4280, 0.2827, 0.3293,\n",
      "        0.3717, 0.3173, 0.2052, 0.2192, 0.2026, 0.3377]), 'labels': tensor([11, 11, 13, 13, 11,  7,  7,  3, 11, 11,  4, 13,  7, 13,  7],\n",
      "       dtype=torch.int32)}\n",
      "319100\n",
      "{'image_id': 319369, 'boxes': tensor([[ 25, 102,  73, 272],\n",
      "        [297, 306, 333, 326],\n",
      "        [137, 266, 204, 335],\n",
      "        [ 53, 166, 303, 334],\n",
      "        [  1,  99,  30, 108],\n",
      "        [351, 141, 393, 156],\n",
      "        [216, 287, 232, 294],\n",
      "        [ 97, 133, 282, 164],\n",
      "        [529, 285, 537, 292],\n",
      "        [ 22, 126,  34, 151],\n",
      "        [380, 107, 513, 145]], dtype=torch.int32), 'scores': tensor([0.2790, 0.5429, 0.2557, 0.2137, 0.7201, 0.2304, 0.1932, 0.2699, 0.2732,\n",
      "        0.2693, 0.4188]), 'objectness_scores': tensor([0.2178, 0.2217, 0.2556, 0.2252, 0.3596, 0.2041, 0.2584, 0.2580, 0.4115,\n",
      "        0.2252, 0.2554]), 'labels': tensor([ 9,  6,  7, 11, 14, 14, 11,  7, 14, 14,  8], dtype=torch.int32)}\n",
      "319369\n",
      "{'image_id': 319534, 'boxes': tensor([[156, 142, 169, 150]], dtype=torch.int32), 'scores': tensor([0.3412]), 'objectness_scores': tensor([0.2235]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "319534\n",
      "{'image_id': 319607, 'boxes': tensor([[340, 272, 382, 328],\n",
      "        [225, 592, 267, 638],\n",
      "        [221, 149, 317, 312],\n",
      "        [303, 397, 325, 420],\n",
      "        [296, 290, 313, 309],\n",
      "        [146,  30, 232, 313],\n",
      "        [156, 244, 220, 307]], dtype=torch.int32), 'scores': tensor([0.3586, 0.2331, 0.1898, 0.3705, 0.2371, 0.3691, 0.1990]), 'objectness_scores': tensor([0.2074, 0.2019, 0.4024, 0.2198, 0.2521, 0.5319, 0.2400]), 'labels': tensor([ 7,  9,  7, 14, 11,  7,  8], dtype=torch.int32)}\n",
      "319607\n",
      "{'image_id': 319935, 'boxes': tensor([[397, 236, 638, 397],\n",
      "        [513, 254, 620, 345],\n",
      "        [ 69, 288, 102, 300],\n",
      "        [ 83,  66, 159, 100],\n",
      "        [502, 238, 567, 299],\n",
      "        [104, 229, 256, 376],\n",
      "        [167, 133, 208, 149]], dtype=torch.int32), 'scores': tensor([0.9970, 0.9414, 0.2923, 0.7615, 0.9685, 0.9775, 0.4464]), 'objectness_scores': tensor([0.3154, 0.2122, 0.2032, 0.3228, 0.2008, 0.3435, 0.6547]), 'labels': tensor([13, 13, 14, 10, 13, 13, 11], dtype=torch.int32)}\n",
      "319935\n",
      "{'image_id': 320232, 'boxes': tensor([[138, 395, 148, 410],\n",
      "        [347, 407, 365, 453],\n",
      "        [221, 376, 255, 432],\n",
      "        [234,  97, 355, 219],\n",
      "        [138, 302, 146, 317],\n",
      "        [234,  97, 358, 272],\n",
      "        [134, 302, 146, 317],\n",
      "        [109, 292, 115, 331],\n",
      "        [334, 411, 357, 459],\n",
      "        [240, 207, 353, 270],\n",
      "        [352, 406, 369, 450],\n",
      "        [ 21, 245, 162, 310],\n",
      "        [210, 283, 223, 292],\n",
      "        [ 79, 363,  84, 370]], dtype=torch.int32), 'scores': tensor([0.2585, 0.2266, 0.3015, 0.4255, 0.1547, 0.4121, 0.3384, 0.2128, 0.6372,\n",
      "        0.4147, 0.4680, 0.4054, 0.2985, 0.2076]), 'objectness_scores': tensor([0.2006, 0.6389, 0.2125, 0.2500, 0.3629, 0.3050, 0.2432, 0.2714, 0.7351,\n",
      "        0.2445, 0.6319, 0.2113, 0.2849, 0.2004]), 'labels': tensor([11,  7, 14,  1,  4,  8, 14, 11,  7,  1,  7,  7,  7, 14],\n",
      "       dtype=torch.int32)}\n",
      "320232\n",
      "{'image_id': 320554, 'boxes': tensor([[222, 194, 344, 292]], dtype=torch.int32), 'scores': tensor([0.9825]), 'objectness_scores': tensor([0.5309]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "320554\n",
      "{'image_id': 320664, 'boxes': tensor([[  0,   1, 211, 269],\n",
      "        [398, 142, 642, 193],\n",
      "        [ 11,   2, 644, 482],\n",
      "        [ 78, 199, 204, 324],\n",
      "        [347, 187, 508, 389],\n",
      "        [ 27,  64, 549, 480],\n",
      "        [215, 215, 308, 480]], dtype=torch.int32), 'scores': tensor([0.5543, 0.6061, 0.3479, 0.9078, 0.2138, 0.3931, 0.3794]), 'objectness_scores': tensor([0.2515, 0.4615, 0.2826, 0.2412, 0.3409, 0.3355, 0.4407]), 'labels': tensor([11,  8, 11, 12, 12, 11, 11], dtype=torch.int32)}\n",
      "320664\n",
      "{'image_id': 320743, 'boxes': tensor([[523,  68, 636, 220],\n",
      "        [324,  21, 339,  28],\n",
      "        [161,  38, 283, 147],\n",
      "        [135,  18, 172,  65],\n",
      "        [156,  53, 186,  69],\n",
      "        [618, 144, 638, 315],\n",
      "        [528,  32, 549,  43],\n",
      "        [152, 186, 171, 206],\n",
      "        [445,  55, 484,  74],\n",
      "        [106,  12, 129,  24],\n",
      "        [271, 127, 538, 347],\n",
      "        [315,  28, 336,  42],\n",
      "        [ 52,  74, 117, 193],\n",
      "        [ 60,  65, 252, 194],\n",
      "        [344,  55, 384,  77],\n",
      "        [288,  52, 364,  90],\n",
      "        [ 73,  21, 170,  77],\n",
      "        [  0,  68,  73, 211],\n",
      "        [303,  66, 466, 168],\n",
      "        [113, 132, 293, 336],\n",
      "        [268,  51, 353, 149],\n",
      "        [174,  13, 187,  21],\n",
      "        [ 71,  39, 110,  77],\n",
      "        [  0,  65,  70, 309]], dtype=torch.int32), 'scores': tensor([0.9819, 0.1515, 0.9755, 0.2534, 0.2750, 0.3218, 0.2364, 0.6076, 0.5165,\n",
      "        0.2896, 0.9994, 0.1409, 0.5394, 0.7673, 0.2526, 0.1443, 0.2455, 0.5684,\n",
      "        0.4856, 0.9995, 0.9991, 0.1902, 0.1218, 0.9841]), 'objectness_scores': tensor([0.5519, 0.2377, 0.5877, 0.3598, 0.2307, 0.3026, 0.2344, 0.2798, 0.2366,\n",
      "        0.2575, 0.6618, 0.2328, 0.3635, 0.6391, 0.2555, 0.3478, 0.4918, 0.4134,\n",
      "        0.6766, 0.6542, 0.3111, 0.2531, 0.3441, 0.3173]), 'labels': tensor([ 5, 11,  5,  4, 12, 11, 11,  9, 12, 12,  5,  8,  4,  5, 11,  2,  4,  5,\n",
      "         4,  5,  5, 11,  9,  5], dtype=torch.int32)}\n",
      "320743\n",
      "{'image_id': 321214, 'boxes': tensor([[269, 222, 541, 480],\n",
      "        [168, 460, 190, 479],\n",
      "        [  9, 402, 638, 479]], dtype=torch.int32), 'scores': tensor([0.9992, 0.4491, 0.9558]), 'objectness_scores': tensor([0.2302, 0.2708, 0.2280]), 'labels': tensor([12, 11, 12], dtype=torch.int32)}\n",
      "321214\n",
      "{'image_id': 322429, 'boxes': tensor([[ 20, 195,  70, 231],\n",
      "        [201,  68, 306, 147],\n",
      "        [ 75, 179, 136, 230],\n",
      "        [346, 520, 436, 620],\n",
      "        [ 14,   0,  40,  33],\n",
      "        [227, 164, 266, 227],\n",
      "        [304,  69, 359, 145],\n",
      "        [125, 183, 170, 228],\n",
      "        [ 88, 507, 177, 597],\n",
      "        [112, 547, 225, 609],\n",
      "        [329, 186, 371, 225],\n",
      "        [141, 344, 194, 431],\n",
      "        [ 14, 336, 148, 440]], dtype=torch.int32), 'scores': tensor([0.3086, 0.9148, 0.9153, 0.9677, 0.2447, 0.3656, 0.2604, 0.1939, 0.9843,\n",
      "        0.4714, 0.3934, 0.6523, 0.9683]), 'objectness_scores': tensor([0.2988, 0.3173, 0.3050, 0.3478, 0.2062, 0.2242, 0.2180, 0.3021, 0.3518,\n",
      "        0.3131, 0.2899, 0.2384, 0.3540]), 'labels': tensor([16, 10, 10, 10, 11,  7, 16, 10, 10,  9,  2, 10, 10], dtype=torch.int32)}\n",
      "322429\n",
      "{'image_id': 322574, 'boxes': tensor([[ 84, 173, 593, 474],\n",
      "        [  4, 145, 638, 477],\n",
      "        [ 87, 307, 582, 479]], dtype=torch.int32), 'scores': tensor([0.2825, 0.3424, 0.9995]), 'objectness_scores': tensor([0.3038, 0.2720, 0.4015]), 'labels': tensor([12, 11, 14], dtype=torch.int32)}\n",
      "322574\n",
      "{'image_id': 322610, 'boxes': tensor([[472,  10, 490,  23],\n",
      "        [143, 449, 163, 468],\n",
      "        [327, 104, 432, 132],\n",
      "        [ 33, 268,  45, 277],\n",
      "        [491, 138, 512, 156],\n",
      "        [  8, 274,  28, 280],\n",
      "        [132, 107, 206, 167],\n",
      "        [324, 108, 344, 122],\n",
      "        [191,  78, 241, 103],\n",
      "        [  5, 204,  39, 244],\n",
      "        [130, 162, 211, 298],\n",
      "        [204,   2, 223,  15],\n",
      "        [317, 248, 427, 346],\n",
      "        [ 16, 124,  40, 146],\n",
      "        [544, 135, 640, 253],\n",
      "        [325,  63, 437,  92],\n",
      "        [322, 126, 538, 276],\n",
      "        [169, 439, 196, 461],\n",
      "        [543, 136, 640, 200]], dtype=torch.int32), 'scores': tensor([0.2720, 0.3119, 0.2532, 0.5010, 0.1616, 0.3244, 0.3137, 0.1711, 0.3459,\n",
      "        0.5313, 0.4998, 0.1958, 0.2103, 0.4924, 0.8171, 0.1611, 0.9981, 0.3068,\n",
      "        0.2697]), 'objectness_scores': tensor([0.2336, 0.2466, 0.2432, 0.2065, 0.3029, 0.3114, 0.3099, 0.2606, 0.2050,\n",
      "        0.2301, 0.2618, 0.2713, 0.2334, 0.3420, 0.2437, 0.2144, 0.4568, 0.2480,\n",
      "        0.3095]), 'labels': tensor([11, 11, 14, 15,  7, 11,  3, 11, 14,  7,  7, 11, 11,  7,  6, 11,  6, 11,\n",
      "         6], dtype=torch.int32)}\n",
      "322610\n",
      "{'image_id': 322895, 'boxes': tensor([[123, 236, 174, 311],\n",
      "        [182, 265, 227, 305],\n",
      "        [295, 278, 504, 375],\n",
      "        [116, 214, 283, 253],\n",
      "        [201, 261, 237, 303],\n",
      "        [379, 310, 531, 481],\n",
      "        [489, 315, 635, 371],\n",
      "        [381, 302, 639, 482],\n",
      "        [110, 238, 311, 455],\n",
      "        [111, 221, 213, 247]], dtype=torch.int32), 'scores': tensor([0.8740, 0.4311, 0.9294, 0.9613, 0.2316, 0.9533, 0.9427, 0.9936, 0.9969,\n",
      "        0.2024]), 'objectness_scores': tensor([0.2326, 0.2052, 0.5347, 0.3473, 0.2079, 0.2202, 0.2573, 0.4399, 0.4906,\n",
      "        0.2952]), 'labels': tensor([13,  7, 13, 13, 11, 13, 13, 13, 13, 11], dtype=torch.int32)}\n",
      "322895\n",
      "{'image_id': 322959, 'boxes': tensor([[382, 244, 582, 595],\n",
      "        [290, 322, 440, 520],\n",
      "        [452, 357, 561, 467],\n",
      "        [274, 148, 396, 260],\n",
      "        [ 22,  99, 589, 571]], dtype=torch.int32), 'scores': tensor([0.7087, 0.2532, 0.7328, 0.6296, 0.8470]), 'objectness_scores': tensor([0.3315, 0.3367, 0.3648, 0.2377, 0.3572]), 'labels': tensor([11, 11, 12, 12, 12], dtype=torch.int32)}\n",
      "322959\n",
      "{'image_id': 323151, 'boxes': tensor([[  2,  20, 481, 633],\n",
      "        [112,  90, 292, 168],\n",
      "        [379,  13, 478, 282],\n",
      "        [ -1, 246, 469, 602]], dtype=torch.int32), 'scores': tensor([0.3130, 0.2826, 0.4899, 0.3380]), 'objectness_scores': tensor([0.2690, 0.3354, 0.3967, 0.3079]), 'labels': tensor([11, 12, 10, 11], dtype=torch.int32)}\n",
      "323151\n",
      "{'image_id': 323751, 'boxes': tensor([[187, 252, 213, 281]], dtype=torch.int32), 'scores': tensor([0.2681]), 'objectness_scores': tensor([0.2061]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "323751\n",
      "{'image_id': 324158, 'boxes': tensor([[196, 183, 220, 236],\n",
      "        [215, 101, 232, 119],\n",
      "        [223, 246, 253, 262]], dtype=torch.int32), 'scores': tensor([0.4601, 0.2353, 0.9321]), 'objectness_scores': tensor([0.4463, 0.2805, 0.5587]), 'labels': tensor([3, 8, 8], dtype=torch.int32)}\n",
      "324158\n",
      "{'image_id': 324258, 'boxes': tensor([[623, 305, 639, 332],\n",
      "        [ -2, 256, 323, 452],\n",
      "        [103, 367, 217, 480],\n",
      "        [477, 109, 515, 144],\n",
      "        [481, 254, 641, 401]], dtype=torch.int32), 'scores': tensor([0.2554, 0.1964, 0.2429, 0.4875, 0.7891]), 'objectness_scores': tensor([0.2024, 0.4471, 0.2280, 0.2107, 0.4082]), 'labels': tensor([11, 12, 14,  7, 13], dtype=torch.int32)}\n",
      "324258\n",
      "{'image_id': 324715, 'boxes': tensor([[337,   0, 478, 116],\n",
      "        [422, 237, 428, 243],\n",
      "        [  3,   0, 498, 333],\n",
      "        [389, 123, 452, 195],\n",
      "        [405, 132, 434, 165],\n",
      "        [347, 190, 478, 300],\n",
      "        [394, 131, 449, 193]], dtype=torch.int32), 'scores': tensor([0.8609, 0.3034, 0.4811, 0.6231, 0.2812, 0.9691, 0.2177]), 'objectness_scores': tensor([0.2370, 0.2223, 0.2855, 0.2881, 0.4187, 0.7514, 0.2917]), 'labels': tensor([ 7, 12, 16,  7,  9, 16, 11], dtype=torch.int32)}\n",
      "324715\n",
      "{'image_id': 324927, 'boxes': tensor([[  0,   8, 375, 639],\n",
      "        [145, 427, 207, 501],\n",
      "        [305,   1, 445, 419]], dtype=torch.int32), 'scores': tensor([0.4808, 0.2729, 0.3921]), 'objectness_scores': tensor([0.4071, 0.2101, 0.5902]), 'labels': tensor([11, 12, 10], dtype=torch.int32)}\n",
      "324927\n",
      "{'image_id': 325031, 'boxes': tensor([[  1,  55, 626, 604],\n",
      "        [  3, 445, 633, 606],\n",
      "        [ 80,  63, 563, 544],\n",
      "        [ 97, 147, 546, 546]], dtype=torch.int32), 'scores': tensor([0.9956, 0.3199, 0.9942, 0.9920]), 'objectness_scores': tensor([0.2727, 0.2575, 0.5367, 0.2368]), 'labels': tensor([5, 8, 5, 5], dtype=torch.int32)}\n",
      "325031\n",
      "{'image_id': 325483, 'boxes': tensor([[256, 221, 279, 241],\n",
      "        [  0, 302, 165, 479],\n",
      "        [177, 177, 345, 324],\n",
      "        [452, 267, 642, 417]], dtype=torch.int32), 'scores': tensor([0.2953, 0.2789, 0.4327, 0.2666]), 'objectness_scores': tensor([0.2967, 0.3478, 0.2198, 0.3435]), 'labels': tensor([11, 13,  7, 13], dtype=torch.int32)}\n",
      "325483\n",
      "{'image_id': 325838, 'boxes': tensor([[539, 246, 593, 290],\n",
      "        [ 67, 345, 228, 453],\n",
      "        [266, 202, 639, 479],\n",
      "        [296, 262, 387, 321],\n",
      "        [  6, 197, 639, 478],\n",
      "        [ -1,  -2, 139, 153],\n",
      "        [103, 327, 208, 402],\n",
      "        [394, 287, 532, 398]], dtype=torch.int32), 'scores': tensor([0.3926, 0.6044, 0.8888, 0.9947, 0.9004, 0.3588, 0.9858, 0.6709]), 'objectness_scores': tensor([0.2119, 0.2169, 0.3279, 0.3688, 0.2746, 0.3212, 0.2039, 0.2744]), 'labels': tensor([16, 14, 14, 14, 14,  6, 14, 14], dtype=torch.int32)}\n",
      "325838\n",
      "{'image_id': 326082, 'boxes': tensor([[ 23, 208, 138, 307],\n",
      "        [150, 264, 293, 352],\n",
      "        [  0, 265, 272, 427],\n",
      "        [221, 237, 233, 254],\n",
      "        [450, 241, 626, 423],\n",
      "        [116, 284, 369, 402]], dtype=torch.int32), 'scores': tensor([0.9986, 0.2803, 0.9787, 0.1944, 0.4457, 0.8761]), 'objectness_scores': tensor([0.3269, 0.3751, 0.4045, 0.2146, 0.2586, 0.2019]), 'labels': tensor([13, 15, 13, 14, 12, 13], dtype=torch.int32)}\n",
      "326082\n",
      "{'image_id': 326128, 'boxes': tensor([[274, 206, 317, 232],\n",
      "        [275, 184, 317, 223],\n",
      "        [111, 500, 232, 590],\n",
      "        [271, 385, 325, 467],\n",
      "        [248, 359, 277, 424],\n",
      "        [278, 521, 309, 549],\n",
      "        [304, 537, 349, 591]], dtype=torch.int32), 'scores': tensor([0.7352, 0.9681, 0.9952, 0.3492, 0.2588, 0.3419, 0.9442]), 'objectness_scores': tensor([0.4506, 0.2238, 0.2001, 0.3160, 0.2332, 0.2362, 0.2643]), 'labels': tensor([ 8,  8,  8, 11,  8,  2,  8], dtype=torch.int32)}\n",
      "326128\n",
      "{'image_id': 326248, 'boxes': tensor([[284,  53, 303,  64],\n",
      "        [  0, 244, 149, 329],\n",
      "        [210,  60, 245,  81],\n",
      "        [426, 175, 456, 194],\n",
      "        [174,   3, 188,   9],\n",
      "        [ 27, 183,  60, 198],\n",
      "        [ 52, 262,  59, 270],\n",
      "        [346,  10, 354,  21],\n",
      "        [157,  13, 254,  47],\n",
      "        [428,  88, 443,  94],\n",
      "        [127, 274, 171, 326],\n",
      "        [471, 225, 543, 276],\n",
      "        [307, 242, 491, 330],\n",
      "        [219,  66, 250,  85],\n",
      "        [ 27, 250, 198, 425],\n",
      "        [169, 129, 242, 322]], dtype=torch.int32), 'scores': tensor([0.2415, 0.1554, 0.1991, 0.2513, 0.2790, 0.2838, 0.2826, 0.2373, 0.2240,\n",
      "        0.2701, 0.5074, 0.6209, 0.1436, 0.2191, 0.5001, 0.4203]), 'objectness_scores': tensor([0.2323, 0.3016, 0.2935, 0.3030, 0.2583, 0.3379, 0.2429, 0.2688, 0.2118,\n",
      "        0.2236, 0.2076, 0.2163, 0.2815, 0.2407, 0.2351, 0.3371]), 'labels': tensor([ 6, 11, 11,  7, 11, 11, 11, 14,  7, 11,  7,  8, 10, 11,  7,  9],\n",
      "       dtype=torch.int32)}\n",
      "326248\n",
      "{'image_id': 327306, 'boxes': tensor([[ 94, 222, 528, 329],\n",
      "        [  0, 103, 259, 273],\n",
      "        [ 36, 132, 112, 163],\n",
      "        [  3,   3, 639, 401],\n",
      "        [ 34, 121, 160, 180],\n",
      "        [128,  95, 184, 132]], dtype=torch.int32), 'scores': tensor([0.4353, 0.9713, 0.2707, 0.9193, 0.4173, 0.2002]), 'objectness_scores': tensor([0.2342, 0.2611, 0.2724, 0.2033, 0.5508, 0.2981]), 'labels': tensor([16,  9,  8,  9,  9,  7], dtype=torch.int32)}\n",
      "327306\n",
      "{'image_id': 327592, 'boxes': tensor([[ 98, 149, 113, 169],\n",
      "        [194, 210, 399, 255],\n",
      "        [213,  93, 344, 161],\n",
      "        [388, 272, 455, 331],\n",
      "        [232, 190, 371, 238]], dtype=torch.int32), 'scores': tensor([0.9429, 0.6067, 0.2209, 0.3039, 0.9748]), 'objectness_scores': tensor([0.6308, 0.5218, 0.4812, 0.5546, 0.5524]), 'labels': tensor([11, 11,  7, 10, 12], dtype=torch.int32)}\n",
      "327592\n",
      "{'image_id': 327701, 'boxes': tensor([[ 29, 375,  87, 428],\n",
      "        [ 68, 295, 122, 399],\n",
      "        [609,  40, 641, 296],\n",
      "        [359, 347, 375, 357],\n",
      "        [381, 156, 399, 176],\n",
      "        [552, 270, 559, 282],\n",
      "        [329, 345, 444, 427],\n",
      "        [535,  89, 581, 287],\n",
      "        [ 38,  90,  89, 281],\n",
      "        [363, 264, 379, 284]], dtype=torch.int32), 'scores': tensor([0.4202, 0.5944, 0.3402, 0.1864, 0.1404, 0.1919, 0.4625, 0.2246, 0.4213,\n",
      "        0.2314]), 'objectness_scores': tensor([0.3076, 0.2292, 0.2208, 0.4447, 0.6194, 0.2468, 0.2559, 0.2439, 0.2611,\n",
      "        0.2763]), 'labels': tensor([10,  9, 11, 11,  9, 11,  7, 11,  7, 11], dtype=torch.int32)}\n",
      "327701\n",
      "{'image_id': 327769, 'boxes': tensor([[260,   2, 316,  88],\n",
      "        [ 35, 178, 574, 423],\n",
      "        [  3,  64, 597, 365],\n",
      "        [  2,   3, 618, 424],\n",
      "        [149,  91, 481, 259],\n",
      "        [306,   0, 363,  69],\n",
      "        [111,  15, 169, 141],\n",
      "        [203, 117, 454, 254],\n",
      "        [ 80, 327, 204, 423],\n",
      "        [170,  37, 291, 122]], dtype=torch.int32), 'scores': tensor([0.3623, 0.9144, 0.9345, 0.2180, 0.6042, 0.1672, 0.4235, 0.9546, 0.2987,\n",
      "        0.8120]), 'objectness_scores': tensor([0.4275, 0.2525, 0.3243, 0.2280, 0.5690, 0.4317, 0.5404, 0.4866, 0.6760,\n",
      "        0.4987]), 'labels': tensor([10, 15, 15, 11,  2,  7, 10,  2, 10, 15], dtype=torch.int32)}\n",
      "327769\n",
      "{'image_id': 327780, 'boxes': tensor([[  0,  33, 321, 217],\n",
      "        [  5,   3, 574, 479],\n",
      "        [297, 146, 507, 464],\n",
      "        [ -1,  36, 336, 469]], dtype=torch.int32), 'scores': tensor([0.9992, 0.9997, 0.9994, 0.9999]), 'objectness_scores': tensor([0.2708, 0.4885, 0.3785, 0.4076]), 'labels': tensor([12, 12, 12, 12], dtype=torch.int32)}\n",
      "327780\n",
      "{'image_id': 329219, 'boxes': tensor([[  1, 147, 281, 369],\n",
      "        [249, 126, 302, 139],\n",
      "        [310, 168, 380, 302],\n",
      "        [ 10,  68,  51, 119],\n",
      "        [ 12,   0,  22,  40],\n",
      "        [ 68,  90,  90, 108],\n",
      "        [329,  53, 377, 111],\n",
      "        [  7,  68,  53, 146],\n",
      "        [315, 126, 332, 155],\n",
      "        [160, 128, 178, 146],\n",
      "        [330,  79, 346,  97],\n",
      "        [297, 253, 358, 361],\n",
      "        [349,  71, 364,  92],\n",
      "        [370, 149, 475, 355],\n",
      "        [343,  56, 357,  74],\n",
      "        [100,  66, 128,  97]], dtype=torch.int32), 'scores': tensor([0.5886, 0.2087, 0.3175, 0.9582, 0.3946, 0.2614, 0.2974, 0.3247, 0.4067,\n",
      "        0.2465, 0.2793, 0.9770, 0.2743, 0.2816, 0.1795, 0.2092]), 'objectness_scores': tensor([0.2066, 0.3136, 0.2684, 0.3078, 0.2933, 0.3505, 0.2179, 0.4697, 0.2029,\n",
      "        0.2391, 0.2109, 0.4629, 0.2009, 0.2218, 0.2058, 0.2769]), 'labels': tensor([15, 11,  2, 10, 11, 11,  8, 11, 11, 11,  2,  3, 11,  7, 11,  6],\n",
      "       dtype=torch.int32)}\n",
      "329219\n",
      "{'image_id': 329319, 'boxes': tensor([[ 78, 289, 394, 508]], dtype=torch.int32), 'scores': tensor([0.9475]), 'objectness_scores': tensor([0.5305]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "329319\n",
      "{'image_id': 329455, 'boxes': tensor([[ 56, 151, 568, 455],\n",
      "        [159, 392, 274, 479],\n",
      "        [ 54, 379, 166, 480],\n",
      "        [109, 356, 222, 416],\n",
      "        [411,  68, 454, 138]], dtype=torch.int32), 'scores': tensor([0.3052, 0.9672, 0.9741, 0.5503, 0.9131]), 'objectness_scores': tensor([0.3369, 0.2097, 0.2240, 0.2059, 0.2422]), 'labels': tensor([12, 10, 10, 15, 10], dtype=torch.int32)}\n",
      "329455\n",
      "{'image_id': 329542, 'boxes': tensor([[122, 251, 261, 390],\n",
      "        [101, 127, 227, 260],\n",
      "        [  0,  29, 104, 166],\n",
      "        [418, 189, 547, 381],\n",
      "        [275, 227, 402, 361]], dtype=torch.int32), 'scores': tensor([0.6643, 0.9239, 0.9906, 0.3054, 0.9870]), 'objectness_scores': tensor([0.5840, 0.5883, 0.6054, 0.4139, 0.5817]), 'labels': tensor([14, 12, 12, 12, 12], dtype=torch.int32)}\n",
      "329542\n",
      "{'image_id': 329614, 'boxes': tensor([[258, 139, 263, 146],\n",
      "        [411, 165, 420, 185]], dtype=torch.int32), 'scores': tensor([0.1839, 0.1660]), 'objectness_scores': tensor([0.2552, 0.2883]), 'labels': tensor([14, 11], dtype=torch.int32)}\n",
      "329614\n",
      "{'image_id': 331352, 'boxes': tensor([[ 57,  60, 301, 162],\n",
      "        [ 63, 164, 101, 187],\n",
      "        [259, 396, 322, 445],\n",
      "        [170,  38, 184,  98],\n",
      "        [311, 164, 339, 210],\n",
      "        [ 56, 407, 293, 499],\n",
      "        [ 30, 410,  59, 443]], dtype=torch.int32), 'scores': tensor([0.9966, 0.3312, 0.2741, 0.4130, 0.5504, 0.4337, 0.3110]), 'objectness_scores': tensor([0.3780, 0.2939, 0.3736, 0.6022, 0.2471, 0.3374, 0.2149]), 'labels': tensor([15,  7,  7, 11, 11, 12,  7], dtype=torch.int32)}\n",
      "331352\n",
      "{'image_id': 331817, 'boxes': tensor([[422, 180, 552, 480],\n",
      "        [ 79, 261, 290, 377],\n",
      "        [  2, 148, 634, 479],\n",
      "        [295, 355, 415, 433]], dtype=torch.int32), 'scores': tensor([0.9483, 0.9657, 0.8592, 0.5199]), 'objectness_scores': tensor([0.2908, 0.2010, 0.3103, 0.2657]), 'labels': tensor([10, 12, 12, 12], dtype=torch.int32)}\n",
      "331817\n",
      "{'image_id': 332318, 'boxes': tensor([[ 63, 390,  82, 398],\n",
      "        [200, 371, 210, 383],\n",
      "        [  0, 392,  18, 403],\n",
      "        [233, 376, 239, 381],\n",
      "        [227, 387, 236, 394],\n",
      "        [230, 380, 244, 392],\n",
      "        [ 90, 388, 103, 395],\n",
      "        [220, 379, 230, 385],\n",
      "        [  0, 394,   9, 403],\n",
      "        [106, 386, 122, 395],\n",
      "        [332, 379, 338, 383],\n",
      "        [248, 371, 266, 385],\n",
      "        [158, 380, 167, 386],\n",
      "        [260, 381, 269, 393],\n",
      "        [  0,  15, 633, 331],\n",
      "        [120, 394, 134, 401],\n",
      "        [219, 378, 240, 388],\n",
      "        [178, 368, 190, 376],\n",
      "        [293, 377, 302, 383],\n",
      "        [122, 382, 131, 385],\n",
      "        [159, 380, 175, 387],\n",
      "        [211, 386, 224, 394]], dtype=torch.int32), 'scores': tensor([0.3287, 0.2015, 0.2522, 0.1816, 0.1691, 0.2313, 0.1528, 0.1184, 0.1914,\n",
      "        0.2433, 0.2107, 0.2865, 0.1832, 0.1996, 0.3629, 0.1942, 0.1824, 0.2802,\n",
      "        0.3024, 0.2133, 0.1724, 0.1417]), 'objectness_scores': tensor([0.6124, 0.6256, 0.2628, 0.3242, 0.4593, 0.5442, 0.6101, 0.4570, 0.4106,\n",
      "        0.6264, 0.4098, 0.6206, 0.2276, 0.6228, 0.2281, 0.5754, 0.2306, 0.6061,\n",
      "        0.5000, 0.4815, 0.5596, 0.5573]), 'labels': tensor([11,  4, 11, 11, 14, 11,  4, 14, 11, 11, 11,  4, 11, 11,  8, 11,  4, 11,\n",
      "        11, 10, 11, 11], dtype=torch.int32)}\n",
      "332318\n",
      "{'image_id': 333402, 'boxes': tensor([[513, 170, 524, 189],\n",
      "        [105,  47, 525, 366]], dtype=torch.int32), 'scores': tensor([0.1847, 0.9996]), 'objectness_scores': tensor([0.3501, 0.5175]), 'labels': tensor([11,  1], dtype=torch.int32)}\n",
      "333402\n",
      "{'image_id': 333745, 'boxes': tensor([[ 52, 294, 196, 408],\n",
      "        [132, 482, 183, 505],\n",
      "        [313, 356, 425, 638],\n",
      "        [ 35, 249, 100, 446],\n",
      "        [  0,  56,  93, 140],\n",
      "        [ 92, 480, 123, 502],\n",
      "        [ 10,  30,  96,  69],\n",
      "        [ 27,  88, 281, 221],\n",
      "        [ 73, 186, 168, 313]], dtype=torch.int32), 'scores': tensor([0.2820, 0.3380, 0.1967, 0.9960, 0.2111, 0.2638, 0.5328, 0.9860, 0.5983]), 'objectness_scores': tensor([0.2642, 0.2707, 0.2306, 0.2044, 0.2809, 0.2735, 0.2284, 0.3965, 0.3296]), 'labels': tensor([ 9, 11,  3,  5,  8, 11,  7,  6,  7], dtype=torch.int32)}\n",
      "333745\n",
      "{'image_id': 333772, 'boxes': tensor([[ 11,  76, 492, 372],\n",
      "        [ 69, 126, 446, 352],\n",
      "        [227,  97, 349, 149],\n",
      "        [287, 273, 372, 320],\n",
      "        [ 52,   9,  75,  33],\n",
      "        [254, 258, 410, 362],\n",
      "        [ 92, 120, 148, 177]], dtype=torch.int32), 'scores': tensor([0.5904, 0.6080, 0.3789, 0.3489, 0.4561, 0.6050, 0.9403]), 'objectness_scores': tensor([0.4265, 0.5281, 0.2093, 0.2383, 0.2352, 0.2091, 0.4249]), 'labels': tensor([ 2,  2, 11,  6, 11,  2, 10], dtype=torch.int32)}\n",
      "333772\n",
      "{'image_id': 334371, 'boxes': tensor([[ 99, 185, 116, 225],\n",
      "        [237, 191, 253, 227],\n",
      "        [416, 203, 538, 291],\n",
      "        [415, 203, 512, 292],\n",
      "        [505, 216, 546, 291],\n",
      "        [141, 160, 154, 196],\n",
      "        [236, 185, 412, 293]], dtype=torch.int32), 'scores': tensor([0.4654, 0.2537, 0.9985, 0.9971, 0.9286, 0.2467, 0.9971]), 'objectness_scores': tensor([0.5098, 0.4093, 0.4554, 0.2652, 0.3022, 0.4780, 0.4604]), 'labels': tensor([11, 11,  1,  1,  1, 11,  1], dtype=torch.int32)}\n",
      "334371\n",
      "{'image_id': 334417, 'boxes': tensor([[322, 347, 366, 405],\n",
      "        [ 90, 307, 595, 421]], dtype=torch.int32), 'scores': tensor([0.8761, 0.9990]), 'objectness_scores': tensor([0.5928, 0.2667]), 'labels': tensor([7, 7], dtype=torch.int32)}\n",
      "334417\n",
      "{'image_id': 334483, 'boxes': tensor([[325, 402, 482, 484],\n",
      "        [350, 524, 457, 575],\n",
      "        [191, 494, 275, 540],\n",
      "        [397, 522, 442, 569],\n",
      "        [244, 369, 317, 394],\n",
      "        [100, 345, 414, 652],\n",
      "        [432, 340, 479, 399],\n",
      "        [ 37, 180,  75, 238],\n",
      "        [326, 332, 471, 464],\n",
      "        [288,  78, 327, 113],\n",
      "        [118, 447, 246, 508],\n",
      "        [193, 582, 330, 643],\n",
      "        [247, 369, 281, 389],\n",
      "        [322, 117, 385, 137],\n",
      "        [194, 384, 262, 420],\n",
      "        [193, 499, 227, 538],\n",
      "        [186, 496, 313, 561],\n",
      "        [361, 341, 410, 383],\n",
      "        [332, 368, 471, 460],\n",
      "        [247, 162, 363, 338],\n",
      "        [367, 568, 485, 639],\n",
      "        [272, 118, 312, 134]], dtype=torch.int32), 'scores': tensor([0.9993, 0.3012, 0.7654, 0.8863, 0.3153, 0.9905, 0.5138, 0.5641, 0.9994,\n",
      "        0.1435, 0.4251, 0.9724, 0.3922, 0.2245, 0.6874, 0.2345, 0.8764, 0.9542,\n",
      "        0.9981, 0.7159, 0.8633, 0.2163]), 'objectness_scores': tensor([0.2461, 0.4197, 0.2675, 0.2046, 0.4335, 0.3069, 0.4776, 0.2901, 0.3536,\n",
      "        0.2391, 0.2295, 0.3303, 0.2008, 0.2542, 0.3029, 0.2831, 0.4444, 0.4577,\n",
      "        0.3889, 0.2340, 0.3885, 0.2454]), 'labels': tensor([12, 12, 12, 12,  8, 12, 10,  7, 12,  6, 11, 12, 11,  9,  8, 12, 12, 12,\n",
      "        12,  7, 12, 11], dtype=torch.int32)}\n",
      "334483\n",
      "{'image_id': 334555, 'boxes': tensor([[118, 163, 124, 169],\n",
      "        [202, 123, 532, 370],\n",
      "        [373,  34, 466, 123]], dtype=torch.int32), 'scores': tensor([0.2028, 0.9990, 0.1748]), 'objectness_scores': tensor([0.2105, 0.6114, 0.2052]), 'labels': tensor([11,  4,  6], dtype=torch.int32)}\n",
      "334555\n",
      "{'image_id': 335658, 'boxes': tensor([[  0, 101, 325, 278],\n",
      "        [  3,   0, 626, 476]], dtype=torch.int32), 'scores': tensor([0.9996, 0.9975]), 'objectness_scores': tensor([0.8022, 0.6256]), 'labels': tensor([14, 14], dtype=torch.int32)}\n",
      "335658\n",
      "{'image_id': 335954, 'boxes': tensor([[300, 330, 397, 373],\n",
      "        [  0,   3, 607, 608],\n",
      "        [ 95, 409, 124, 435],\n",
      "        [332, 331, 393, 369],\n",
      "        [298, 185, 573, 480],\n",
      "        [103, 233, 238, 370],\n",
      "        [421, 421, 453, 455],\n",
      "        [318, 238, 400, 338],\n",
      "        [300, 336, 342, 369],\n",
      "        [ 58, 259,  91, 286],\n",
      "        [ 13, 152, 253, 446],\n",
      "        [169, 475, 387, 612],\n",
      "        [ 72, 316, 174, 415],\n",
      "        [374, 313, 422, 344],\n",
      "        [363, 207, 481, 305],\n",
      "        [ 17, 344,  36, 375],\n",
      "        [317, 375, 432, 480],\n",
      "        [224, 532, 370, 612],\n",
      "        [398, 297, 486, 366],\n",
      "        [145, 468, 297, 610],\n",
      "        [ 47, 392,  77, 412]], dtype=torch.int32), 'scores': tensor([0.1951, 0.6415, 0.2013, 0.1537, 0.6235, 0.5816, 0.2136, 0.2977, 0.2477,\n",
      "        0.2217, 0.7442, 0.9799, 0.6476, 0.1405, 0.3559, 0.1950, 0.3410, 0.9651,\n",
      "        0.2143, 0.4599, 0.1843]), 'objectness_scores': tensor([0.2927, 0.2178, 0.3028, 0.2580, 0.2159, 0.6624, 0.3435, 0.6801, 0.2639,\n",
      "        0.3103, 0.2069, 0.2407, 0.6519, 0.3430, 0.6800, 0.2368, 0.2495, 0.2316,\n",
      "        0.2287, 0.3734, 0.3097]), 'labels': tensor([ 2, 12,  7, 11, 12, 12,  4, 12,  7, 11, 12, 11, 12, 11, 12, 11, 10, 11,\n",
      "         9, 11, 11], dtype=torch.int32)}\n",
      "335954\n",
      "{'image_id': 336053, 'boxes': tensor([[  1, 266, 107, 336],\n",
      "        [240,  66, 265, 155],\n",
      "        [ 82, 194, 173, 295],\n",
      "        [394, 229, 499, 408],\n",
      "        [257, 383, 544, 479],\n",
      "        [ 65, 194, 232, 265],\n",
      "        [ 16, 184, 637, 472],\n",
      "        [  2, 397, 150, 480],\n",
      "        [242, 133, 297, 225]], dtype=torch.int32), 'scores': tensor([0.3212, 0.7478, 0.9697, 0.2065, 0.4678, 0.5071, 0.3502, 0.3942, 0.7918]), 'objectness_scores': tensor([0.2113, 0.3043, 0.2258, 0.3632, 0.2164, 0.2057, 0.2237, 0.2042, 0.2684]), 'labels': tensor([ 7, 11, 10, 11, 10, 10,  8,  7, 10], dtype=torch.int32)}\n",
      "336053\n",
      "{'image_id': 336209, 'boxes': tensor([[555, 349, 597, 402],\n",
      "        [338, 269, 402, 292],\n",
      "        [191, 280, 381, 378]], dtype=torch.int32), 'scores': tensor([0.1759, 0.2682, 0.9566]), 'objectness_scores': tensor([0.2283, 0.3040, 0.2356]), 'labels': tensor([14,  7,  9], dtype=torch.int32)}\n",
      "336209\n",
      "{'image_id': 336232, 'boxes': tensor([[477, 166, 512, 180],\n",
      "        [314,  59, 397, 166],\n",
      "        [122, 132, 163, 165],\n",
      "        [434, 179, 451, 194],\n",
      "        [582,  76, 594,  87]], dtype=torch.int32), 'scores': tensor([0.4817, 0.9957, 0.1228, 0.1461, 0.1494]), 'objectness_scores': tensor([0.2530, 0.4068, 0.2403, 0.2305, 0.2210]), 'labels': tensor([11,  1,  9, 14, 14], dtype=torch.int32)}\n",
      "336232\n",
      "{'image_id': 336356, 'boxes': tensor([[102, 156, 136, 211],\n",
      "        [  1, 325, 422, 643],\n",
      "        [122, 341, 313, 387],\n",
      "        [350, 438, 381, 595],\n",
      "        [220, 163, 252, 194],\n",
      "        [ 55, 280, 129, 406],\n",
      "        [ 55, 331, 417, 417],\n",
      "        [375, 318, 415, 372],\n",
      "        [299, 316, 382, 453]], dtype=torch.int32), 'scores': tensor([0.4672, 0.3012, 0.3489, 0.4374, 0.5556, 0.9384, 0.5208, 0.2048, 0.3196]), 'objectness_scores': tensor([0.2634, 0.2839, 0.2110, 0.5230, 0.4108, 0.4040, 0.2132, 0.2150, 0.4084]), 'labels': tensor([14, 11, 12,  7,  7, 10, 11, 11, 11], dtype=torch.int32)}\n",
      "336356\n",
      "{'image_id': 336628, 'boxes': tensor([[290, 173, 308, 209],\n",
      "        [148, 126, 228, 274],\n",
      "        [ 23, 467,  80, 523],\n",
      "        [136,  62, 226, 116],\n",
      "        [291, 172, 318, 268]], dtype=torch.int32), 'scores': tensor([0.4373, 0.9579, 0.2157, 0.2657, 0.2307]), 'objectness_scores': tensor([0.2096, 0.2045, 0.2014, 0.2621, 0.2651]), 'labels': tensor([11,  7,  9, 15,  7], dtype=torch.int32)}\n",
      "336628\n",
      "{'image_id': 336658, 'boxes': tensor([[ 96,  73, 121, 104],\n",
      "        [302, 366, 321, 410],\n",
      "        [399, 253, 476, 278]], dtype=torch.int32), 'scores': tensor([0.3326, 0.2293, 0.9900]), 'objectness_scores': tensor([0.3950, 0.2013, 0.5070]), 'labels': tensor([11, 11,  1], dtype=torch.int32)}\n",
      "336658\n",
      "{'image_id': 337498, 'boxes': tensor([[235, 326, 268, 362],\n",
      "        [  0,   3,  69, 200],\n",
      "        [  2,   2, 637, 478],\n",
      "        [ 31, 149, 640, 478],\n",
      "        [320,   0, 438,  74],\n",
      "        [ 69,  24, 207,  74]], dtype=torch.int32), 'scores': tensor([0.2279, 0.2548, 0.9120, 0.8348, 0.6974, 0.2660]), 'objectness_scores': tensor([0.2301, 0.4126, 0.4085, 0.4623, 0.3874, 0.2796]), 'labels': tensor([11, 11, 12, 12, 10, 11], dtype=torch.int32)}\n",
      "337498\n",
      "{'image_id': 338428, 'boxes': tensor([[186,  64, 237, 170],\n",
      "        [132, 232, 175, 286]], dtype=torch.int32), 'scores': tensor([0.3690, 0.3016]), 'objectness_scores': tensor([0.2018, 0.4723]), 'labels': tensor([11,  9], dtype=torch.int32)}\n",
      "338428\n",
      "{'image_id': 338624, 'boxes': tensor([[160, 153, 205, 233],\n",
      "        [ 83,  25,  93,  47]], dtype=torch.int32), 'scores': tensor([0.7923, 0.1677]), 'objectness_scores': tensor([0.4528, 0.2532]), 'labels': tensor([3, 8], dtype=torch.int32)}\n",
      "338624\n",
      "{'image_id': 338625, 'boxes': tensor([[141,  78, 512, 326],\n",
      "        [176,  14, 190,  25]], dtype=torch.int32), 'scores': tensor([0.9991, 0.1938]), 'objectness_scores': tensor([0.4606, 0.2361]), 'labels': tensor([ 1, 11], dtype=torch.int32)}\n",
      "338625\n",
      "{'image_id': 338901, 'boxes': tensor([[ 78, 157, 366, 337],\n",
      "        [258, 189, 641, 478],\n",
      "        [ 86,   1, 641, 479],\n",
      "        [260, 190, 638, 397],\n",
      "        [213,  79, 388, 141],\n",
      "        [280, 146, 477, 294],\n",
      "        [  0, 366, 156, 478]], dtype=torch.int32), 'scores': tensor([0.6043, 0.7464, 0.5291, 0.8018, 0.1885, 0.9760, 0.2244]), 'objectness_scores': tensor([0.2131, 0.2127, 0.4990, 0.2174, 0.2493, 0.4937, 0.3325]), 'labels': tensor([13, 13,  3,  3,  9,  3, 11], dtype=torch.int32)}\n",
      "338901\n",
      "{'image_id': 338905, 'boxes': tensor([[319, 186, 371, 218],\n",
      "        [258, 305, 293, 327],\n",
      "        [249, 218, 262, 238],\n",
      "        [228, 261, 246, 295],\n",
      "        [211, 211, 225, 239],\n",
      "        [188, 241, 227, 258],\n",
      "        [  0,   4, 145,  87],\n",
      "        [263, 297, 286, 329],\n",
      "        [169, 196, 321, 359],\n",
      "        [236, 196, 266, 206],\n",
      "        [226, 195, 236, 214],\n",
      "        [238, 145, 253, 177],\n",
      "        [235, 267, 252, 301],\n",
      "        [203, 161, 219, 167],\n",
      "        [112,   1, 479, 175],\n",
      "        [262, 242, 279, 251],\n",
      "        [236, 204, 250, 210],\n",
      "        [265, 266, 309, 287],\n",
      "        [129,   0, 477, 109],\n",
      "        [290, 187, 309, 207],\n",
      "        [232, 201, 268, 212],\n",
      "        [246, 218, 284, 229],\n",
      "        [164, 272, 229, 297],\n",
      "        [250, 237, 299, 254],\n",
      "        [170, 314, 256, 352],\n",
      "        [296, 291, 312, 320],\n",
      "        [296, 237, 305, 249],\n",
      "        [252, 256, 268, 276],\n",
      "        [234, 185, 243, 199],\n",
      "        [249, 244, 300, 259],\n",
      "        [174,  88, 359, 173],\n",
      "        [389, 308, 404, 326],\n",
      "        [352, 172, 408, 203],\n",
      "        [153, 184, 167, 191],\n",
      "        [395, 258, 414, 272],\n",
      "        [288, 275, 309, 290],\n",
      "        [164, 183, 177, 200],\n",
      "        [222, 223, 233, 246]], dtype=torch.int32), 'scores': tensor([0.2052, 0.2838, 0.2177, 0.1905, 0.2725, 0.2467, 0.2776, 0.2142, 0.7736,\n",
      "        0.2387, 0.2429, 0.1471, 0.2288, 0.1962, 0.4505, 0.2011, 0.2053, 0.3407,\n",
      "        0.3968, 0.2627, 0.1737, 0.9744, 0.6068, 0.5222, 0.4730, 0.1889, 0.3241,\n",
      "        0.2377, 0.2856, 0.4312, 0.5647, 0.2832, 0.1879, 0.2456, 0.2161, 0.7513,\n",
      "        0.1585, 0.1840]), 'objectness_scores': tensor([0.3993, 0.3117, 0.2679, 0.3340, 0.2718, 0.4369, 0.2060, 0.3477, 0.3812,\n",
      "        0.3231, 0.2902, 0.2113, 0.2525, 0.4119, 0.3150, 0.2433, 0.2123, 0.4289,\n",
      "        0.2963, 0.3773, 0.4403, 0.3691, 0.4337, 0.4059, 0.4342, 0.3085, 0.3634,\n",
      "        0.2137, 0.2062, 0.2030, 0.2086, 0.4645, 0.3708, 0.2124, 0.2519, 0.2148,\n",
      "        0.2104, 0.2165]), 'labels': tensor([ 8, 10, 11, 11, 11, 11,  7, 11,  7, 11, 11, 11, 11, 11,  6, 11, 11, 11,\n",
      "         6, 11, 11, 14, 11, 11, 10,  0, 11, 11,  0, 11,  6, 11,  2, 11, 11, 12,\n",
      "        11, 14], dtype=torch.int32)}\n",
      "338905\n",
      "{'image_id': 339823, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "339823\n",
      "{'image_id': 340175, 'boxes': tensor([[518, 101, 548, 184],\n",
      "        [433,   0, 537,  75],\n",
      "        [  0,  43, 141, 299],\n",
      "        [331, 231, 553, 298],\n",
      "        [167, 105, 203, 136],\n",
      "        [ 66,   0,  96,  64],\n",
      "        [  2,   0,  36,  48],\n",
      "        [424, 175, 610, 250],\n",
      "        [ 46, 202, 240, 336],\n",
      "        [143, 190, 250, 252],\n",
      "        [ 35,  20,  66,  56],\n",
      "        [315, 177, 424, 219],\n",
      "        [264, 145, 273, 160],\n",
      "        [475, 113, 505, 137],\n",
      "        [219, 272, 235, 283],\n",
      "        [174,   0, 276,  76]], dtype=torch.int32), 'scores': tensor([0.5190, 0.5348, 0.7565, 0.6256, 0.1858, 0.3419, 0.9416, 0.9997, 0.3646,\n",
      "        0.5068, 0.1533, 0.4545, 0.3075, 0.2105, 0.2358, 0.4056]), 'objectness_scores': tensor([0.3448, 0.3315, 0.2209, 0.3370, 0.2565, 0.2119, 0.2245, 0.5368, 0.3179,\n",
      "        0.2757, 0.2199, 0.6506, 0.2154, 0.2079, 0.3289, 0.3175]), 'labels': tensor([11,  6, 13,  8, 14,  8,  8, 13, 13,  9,  3, 14, 14,  3, 11,  6],\n",
      "       dtype=torch.int32)}\n",
      "340175\n",
      "{'image_id': 340894, 'boxes': tensor([[459, 329, 636, 390],\n",
      "        [ 83, 227, 276, 308],\n",
      "        [548, 255, 587, 317],\n",
      "        [ 94, 336, 456, 480],\n",
      "        [  2, 245, 635, 479]], dtype=torch.int32), 'scores': tensor([0.2918, 0.9978, 0.9831, 0.9989, 0.9982]), 'objectness_scores': tensor([0.2116, 0.2177, 0.2435, 0.4856, 0.2422]), 'labels': tensor([11, 14, 10, 14, 14], dtype=torch.int32)}\n",
      "340894\n",
      "{'image_id': 341058, 'boxes': tensor([[129,  37, 210, 147],\n",
      "        [ 26, 378,  42, 383],\n",
      "        [177, 101, 313, 240],\n",
      "        [ 17,  72,  61, 145],\n",
      "        [  0,  10, 200, 490],\n",
      "        [ 28, 366,  42, 373],\n",
      "        [ 48,   0, 159,  83]], dtype=torch.int32), 'scores': tensor([0.6224, 0.3743, 0.6320, 0.5781, 0.4053, 0.3879, 0.3011]), 'objectness_scores': tensor([0.2743, 0.2425, 0.3394, 0.2675, 0.2333, 0.2460, 0.2253]), 'labels': tensor([11, 14,  5,  8,  6, 14, 10], dtype=torch.int32)}\n",
      "341058\n",
      "{'image_id': 341719, 'boxes': tensor([[  0,  74, 634, 480]], dtype=torch.int32), 'scores': tensor([0.9972]), 'objectness_scores': tensor([0.2254]), 'labels': tensor([8], dtype=torch.int32)}\n",
      "341719\n",
      "{'image_id': 343076, 'boxes': tensor([[197, 505, 401, 591],\n",
      "        [  1,  16, 454, 637]], dtype=torch.int32), 'scores': tensor([0.7587, 0.7885]), 'objectness_scores': tensor([0.3509, 0.4913]), 'labels': tensor([7, 2], dtype=torch.int32)}\n",
      "343076\n",
      "{'image_id': 343466, 'boxes': tensor([[160,  24, 200, 107],\n",
      "        [177, 161, 251, 241],\n",
      "        [183,  19, 201,  70],\n",
      "        [148, 140, 222, 169],\n",
      "        [144, 159, 152, 199],\n",
      "        [179, 165, 194, 238],\n",
      "        [241,   0, 277, 113],\n",
      "        [159,  35, 172, 107],\n",
      "        [170,  19, 201,  71],\n",
      "        [169,  27, 184,  73],\n",
      "        [241, 146, 269, 167],\n",
      "        [202, 160, 299, 187],\n",
      "        [217,   0, 279, 113],\n",
      "        [236, 131, 241, 143],\n",
      "        [200,   4, 241, 110],\n",
      "        [200,  11, 218, 110],\n",
      "        [216,   1, 243, 111],\n",
      "        [275,   0, 321, 117]], dtype=torch.int32), 'scores': tensor([0.1986, 0.7152, 0.1922, 0.2619, 0.2998, 0.4008, 0.2251, 0.2141, 0.1908,\n",
      "        0.2862, 0.1629, 0.8157, 0.1799, 0.2826, 0.1806, 0.2119, 0.2382, 0.5045]), 'objectness_scores': tensor([0.4144, 0.2070, 0.2569, 0.4661, 0.3326, 0.4402, 0.2666, 0.3400, 0.4242,\n",
      "        0.2193, 0.6792, 0.5583, 0.3424, 0.4059, 0.2496, 0.3470, 0.2691, 0.2283]), 'labels': tensor([14, 15,  0, 14, 11, 11, 11, 11, 11, 11, 11, 11,  8,  0, 11, 11,  0, 11],\n",
      "       dtype=torch.int32)}\n",
      "343466\n",
      "{'image_id': 343937, 'boxes': tensor([[  2,   0, 637, 425],\n",
      "        [285,  70, 382, 219],\n",
      "        [340, 184, 370, 236],\n",
      "        [273,  23, 322,  64],\n",
      "        [272,  46, 321,  64]], dtype=torch.int32), 'scores': tensor([0.9890, 0.9050, 0.3863, 0.2726, 0.2881]), 'objectness_scores': tensor([0.2524, 0.2396, 0.3963, 0.3368, 0.2385]), 'labels': tensor([ 8,  8,  8,  7, 11], dtype=torch.int32)}\n",
      "343937\n",
      "{'image_id': 344029, 'boxes': tensor([[ 39, 214,  93, 251],\n",
      "        [105, 224, 165, 248],\n",
      "        [582, 201, 612, 267],\n",
      "        [505, 230, 556, 300],\n",
      "        [ 94, 113, 576, 399],\n",
      "        [545, 199, 631, 272]], dtype=torch.int32), 'scores': tensor([0.9985, 0.2711, 0.2997, 0.2244, 0.9989, 0.9737]), 'objectness_scores': tensor([0.4259, 0.2606, 0.2495, 0.2259, 0.5160, 0.2866]), 'labels': tensor([ 1, 11,  8,  1,  1,  1], dtype=torch.int32)}\n",
      "344029\n",
      "{'image_id': 344100, 'boxes': tensor([[207,   1, 397, 207],\n",
      "        [325, 183, 597, 329],\n",
      "        [454,   0, 563,  39],\n",
      "        [206,   3, 326, 200],\n",
      "        [ 97, 154, 169, 245],\n",
      "        [549,  28, 640, 201],\n",
      "        [230,   0, 329, 113],\n",
      "        [393, 244, 466, 298],\n",
      "        [ 85, 132, 169, 246],\n",
      "        [  0,   1, 634, 429],\n",
      "        [304,  67, 394, 171],\n",
      "        [208,  96, 312, 200],\n",
      "        [297, 130, 411, 226]], dtype=torch.int32), 'scores': tensor([0.2831, 0.8964, 0.2747, 0.2075, 0.9705, 0.8745, 0.2042, 0.3569, 0.9928,\n",
      "        0.9709, 0.2557, 0.2042, 0.2567]), 'objectness_scores': tensor([0.5230, 0.3708, 0.2084, 0.2485, 0.2180, 0.4687, 0.2092, 0.2229, 0.4426,\n",
      "        0.3652, 0.2832, 0.2389, 0.3300]), 'labels': tensor([ 2, 12, 14,  3, 10, 10,  7, 11, 10, 12, 14,  3, 14], dtype=torch.int32)}\n",
      "344100\n",
      "{'image_id': 344268, 'boxes': tensor([[119, 192, 352, 513],\n",
      "        [285, 254, 310, 338],\n",
      "        [492, 322, 626, 431],\n",
      "        [  1,   2, 635, 506]], dtype=torch.int32), 'scores': tensor([0.9071, 0.9504, 0.5602, 0.4195]), 'objectness_scores': tensor([0.2755, 0.3865, 0.6572, 0.3387]), 'labels': tensor([7, 7, 7, 7], dtype=torch.int32)}\n",
      "344268\n",
      "{'image_id': 344621, 'boxes': tensor([[247, 155, 464, 299],\n",
      "        [286, 153, 314, 168],\n",
      "        [222, 116, 252, 169],\n",
      "        [352,  76, 413, 122],\n",
      "        [  1, 268,  90, 333],\n",
      "        [177, 208, 327, 328],\n",
      "        [213, 165, 260, 200],\n",
      "        [368, 184, 424, 230],\n",
      "        [474, 138, 486, 154],\n",
      "        [340,  60, 426, 138],\n",
      "        [328, 161, 383, 212],\n",
      "        [202,   0, 234,  20],\n",
      "        [178,   0, 270,  17],\n",
      "        [  0, 171,  36, 228],\n",
      "        [284, 163, 315, 200],\n",
      "        [372, 170, 452, 214],\n",
      "        [307, 157, 339, 201]], dtype=torch.int32), 'scores': tensor([0.9997, 0.1593, 0.2805, 0.4628, 0.3276, 0.7298, 0.1425, 0.9967, 0.2559,\n",
      "        0.1373, 0.1710, 0.1621, 0.1659, 0.2253, 0.5557, 0.9907, 0.8479]), 'objectness_scores': tensor([0.5863, 0.2646, 0.4116, 0.3093, 0.3107, 0.6623, 0.2891, 0.4896, 0.3123,\n",
      "        0.5195, 0.2433, 0.3491, 0.4886, 0.4269, 0.4851, 0.2016, 0.2051]), 'labels': tensor([13,  7, 11,  8, 13, 13, 11, 13, 11, 13, 11, 12, 11, 13,  7, 13,  7],\n",
      "       dtype=torch.int32)}\n",
      "344621\n",
      "{'image_id': 344795, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "344795\n",
      "{'image_id': 345027, 'boxes': tensor([[  3, 273,  22, 337],\n",
      "        [  2, 157, 190, 342],\n",
      "        [ 13, 154,  51, 180]], dtype=torch.int32), 'scores': tensor([0.2224, 0.3454, 0.6932]), 'objectness_scores': tensor([0.4442, 0.2180, 0.2092]), 'labels': tensor([ 9,  1, 11], dtype=torch.int32)}\n",
      "345027\n",
      "{'image_id': 345252, 'boxes': tensor([[275, 219, 312, 295],\n",
      "        [ 35, 235,  56, 290],\n",
      "        [425,  83, 449, 117],\n",
      "        [312, 258, 412, 391],\n",
      "        [ 61, 230,  94, 283],\n",
      "        [  2, 232,  37, 295]], dtype=torch.int32), 'scores': tensor([0.2748, 0.3969, 0.3097, 0.6946, 0.3838, 0.3839]), 'objectness_scores': tensor([0.2073, 0.2064, 0.3013, 0.2151, 0.2754, 0.2719]), 'labels': tensor([ 7,  8, 11, 14,  8, 14], dtype=torch.int32)}\n",
      "345252\n",
      "{'image_id': 345356, 'boxes': tensor([[327, 383, 400, 481],\n",
      "        [497, 463, 640, 476],\n",
      "        [157, 193, 214, 251],\n",
      "        [418, 189, 478, 246]], dtype=torch.int32), 'scores': tensor([0.9822, 0.2816, 0.1334, 0.1447]), 'objectness_scores': tensor([0.2291, 0.2315, 0.3049, 0.3183]), 'labels': tensor([10, 11, 12, 10], dtype=torch.int32)}\n",
      "345356\n",
      "{'image_id': 345361, 'boxes': tensor([[ 83, 206, 103, 232],\n",
      "        [ 30, 209,  88, 226],\n",
      "        [198, 282, 275, 310],\n",
      "        [200, 251, 223, 283],\n",
      "        [239,  91, 273, 139],\n",
      "        [105, 244, 132, 263],\n",
      "        [ 90, 229, 165, 254],\n",
      "        [316,  43, 399, 138],\n",
      "        [115, 232, 146, 251],\n",
      "        [ 54, 101,  84, 141],\n",
      "        [132, 252, 208, 280],\n",
      "        [ 79, 207, 103, 239],\n",
      "        [ 45, 101,  92, 163],\n",
      "        [117, 102, 147, 141],\n",
      "        [228,  93, 281, 166],\n",
      "        [  5, 198,  24, 207],\n",
      "        [105, 102, 156, 166],\n",
      "        [ 47, 188,  66, 211],\n",
      "        [ 36, 123,  97, 194],\n",
      "        [  9, 240,  73, 300],\n",
      "        [  3, 198, 495, 358]], dtype=torch.int32), 'scores': tensor([0.2970, 0.2897, 0.5267, 0.1808, 0.2763, 0.4946, 0.1841, 0.5865, 0.4492,\n",
      "        0.4659, 0.7341, 0.2180, 0.9128, 0.3176, 0.4427, 0.7276, 0.4610, 0.2048,\n",
      "        0.2515, 0.4682, 0.4503]), 'objectness_scores': tensor([0.2067, 0.2761, 0.2051, 0.3803, 0.3045, 0.2079, 0.2732, 0.4327, 0.3259,\n",
      "        0.2313, 0.2900, 0.3621, 0.3945, 0.2330, 0.3622, 0.2667, 0.4418, 0.2850,\n",
      "        0.5455, 0.2661, 0.3195]), 'labels': tensor([11, 11, 11, 11, 11,  4,  7, 12,  4, 12, 11, 11, 12, 12,  6, 11,  6, 12,\n",
      "        11, 12, 12], dtype=torch.int32)}\n",
      "345361\n",
      "{'image_id': 345397, 'boxes': tensor([[146, 168, 237, 375],\n",
      "        [234, 125, 498, 266],\n",
      "        [129,  27, 270,  63]], dtype=torch.int32), 'scores': tensor([0.9993, 0.4056, 0.2600]), 'objectness_scores': tensor([0.6215, 0.5770, 0.4318]), 'labels': tensor([7, 8, 7], dtype=torch.int32)}\n",
      "345397\n",
      "{'image_id': 345466, 'boxes': tensor([[189,  82, 300, 174],\n",
      "        [211,  46, 254,  80],\n",
      "        [350, 293, 400, 318],\n",
      "        [126, 102, 137, 115],\n",
      "        [327,  15, 391,  57],\n",
      "        [221, 170, 282, 180],\n",
      "        [111, 278, 145, 315],\n",
      "        [409,   7, 430,  14],\n",
      "        [137, 173, 373, 312],\n",
      "        [287, 103, 328, 151]], dtype=torch.int32), 'scores': tensor([0.3868, 0.1503, 0.1992, 0.2016, 0.1556, 0.1674, 0.5154, 0.1606, 0.3075,\n",
      "        0.3126]), 'objectness_scores': tensor([0.3650, 0.3690, 0.2119, 0.6432, 0.3203, 0.4528, 0.2096, 0.2941, 0.2352,\n",
      "        0.8304]), 'labels': tensor([ 3,  3,  9, 11,  8, 14,  9, 11,  5,  3], dtype=torch.int32)}\n",
      "345466\n",
      "{'image_id': 346232, 'boxes': tensor([[332, 537, 347, 570],\n",
      "        [ 85, 531, 104, 570],\n",
      "        [ 21, 294,  26, 311],\n",
      "        [305, 320, 341, 344],\n",
      "        [ 29, 296,  34, 315],\n",
      "        [ 81, 321,  91, 330],\n",
      "        [216, 316, 243, 341],\n",
      "        [269, 196, 425, 300],\n",
      "        [ 88, 304, 124, 332],\n",
      "        [268, 443, 278, 451],\n",
      "        [103, 550, 122, 576],\n",
      "        [198, 563, 223, 581],\n",
      "        [254, 496, 265, 503],\n",
      "        [155, 319, 169, 330]], dtype=torch.int32), 'scores': tensor([0.2576, 0.2967, 0.1707, 0.2164, 0.1966, 0.2105, 0.1614, 0.9992, 0.2624,\n",
      "        0.2243, 0.2500, 0.3251, 0.1875, 0.2704]), 'objectness_scores': tensor([0.2506, 0.2216, 0.3359, 0.3144, 0.3086, 0.2867, 0.2447, 0.2368, 0.4072,\n",
      "        0.3045, 0.2295, 0.2056, 0.3036, 0.2603]), 'labels': tensor([11, 11, 11,  8, 11, 11,  2,  6,  8, 11,  7, 11, 11,  0],\n",
      "       dtype=torch.int32)}\n",
      "346232\n",
      "{'image_id': 346638, 'boxes': tensor([[232,  87, 357, 313],\n",
      "        [  5, 313, 638, 478],\n",
      "        [161, 229, 224, 304],\n",
      "        [130, 306, 467, 437]], dtype=torch.int32), 'scores': tensor([0.4608, 0.9966, 0.2860, 0.9962]), 'objectness_scores': tensor([0.2870, 0.2443, 0.2964, 0.3812]), 'labels': tensor([14, 14,  8, 14], dtype=torch.int32)}\n",
      "346638\n",
      "{'image_id': 346703, 'boxes': tensor([[378, 504, 549, 639],\n",
      "        [209, 368, 368, 559],\n",
      "        [404,  46, 435,  72],\n",
      "        [  0, 491, 174, 616],\n",
      "        [230, 560, 350, 630],\n",
      "        [  0, 375, 180, 641],\n",
      "        [107, 393, 174, 445],\n",
      "        [432, 201, 456, 308],\n",
      "        [320,   1, 475, 122],\n",
      "        [  1, 398, 110, 460],\n",
      "        [103, 527, 177, 640],\n",
      "        [203, 557, 349, 640],\n",
      "        [112, 392, 155, 490],\n",
      "        [443, 172, 453, 208],\n",
      "        [479, 293, 507, 316],\n",
      "        [414, 510, 544, 593],\n",
      "        [384, 526, 552, 598],\n",
      "        [472, 212, 532, 261],\n",
      "        [403, 446, 443, 477],\n",
      "        [288, 236, 305, 345],\n",
      "        [282, 157, 353, 209],\n",
      "        [432, 173, 457, 307]], dtype=torch.int32), 'scores': tensor([0.9980, 0.1780, 0.2560, 0.9879, 0.9652, 0.9919, 0.6982, 0.3522, 0.2431,\n",
      "        0.8502, 0.9942, 0.9956, 0.7539, 0.3014, 0.2865, 0.9860, 0.9944, 0.3608,\n",
      "        0.2149, 0.2109, 0.2117, 0.3142]), 'objectness_scores': tensor([0.2090, 0.2435, 0.2055, 0.3071, 0.4346, 0.2679, 0.2584, 0.3200, 0.3054,\n",
      "        0.4042, 0.3882, 0.3061, 0.4220, 0.2009, 0.3247, 0.5322, 0.3385, 0.3762,\n",
      "        0.3884, 0.5441, 0.2452, 0.3148]), 'labels': tensor([12,  7, 11, 12, 12, 12, 10,  7, 10, 10, 10, 12, 10, 11,  2, 12, 12, 10,\n",
      "        12,  7,  7,  7], dtype=torch.int32)}\n",
      "346703\n",
      "{'image_id': 347254, 'boxes': tensor([[  0, 161, 329, 499],\n",
      "        [ 67, 101, 207, 153],\n",
      "        [194, 236, 246, 284],\n",
      "        [145, 247, 306, 498],\n",
      "        [243, 234, 303, 338]], dtype=torch.int32), 'scores': tensor([0.7328, 0.2424, 0.1982, 0.9080, 0.2016]), 'objectness_scores': tensor([0.2284, 0.3286, 0.2496, 0.3299, 0.4473]), 'labels': tensor([ 7,  7, 12,  7,  7], dtype=torch.int32)}\n",
      "347254\n",
      "{'image_id': 347335, 'boxes': tensor([[  0, 166, 483, 642],\n",
      "        [  0,   0, 141, 185],\n",
      "        [264,   0, 479, 115],\n",
      "        [191,  16, 367, 150],\n",
      "        [  0,  16, 482, 635]], dtype=torch.int32), 'scores': tensor([0.3431, 0.9044, 0.3459, 0.5970, 0.2778]), 'objectness_scores': tensor([0.3011, 0.4285, 0.2462, 0.4542, 0.2640]), 'labels': tensor([12, 10, 11, 11, 12], dtype=torch.int32)}\n",
      "347335\n",
      "{'image_id': 347544, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "347544\n",
      "{'image_id': 348881, 'boxes': tensor([[116,  36, 202,  66],\n",
      "        [279,  53, 325,  70],\n",
      "        [  0,  24,  76,  70],\n",
      "        [  2,   3, 633, 280],\n",
      "        [247,  49, 331,  85],\n",
      "        [  1,   1, 282, 263]], dtype=torch.int32), 'scores': tensor([0.2342, 0.5493, 0.2135, 0.4310, 0.8637, 0.9656]), 'objectness_scores': tensor([0.2174, 0.3083, 0.4104, 0.2314, 0.2366, 0.3764]), 'labels': tensor([ 0, 11,  0,  1,  0,  0], dtype=torch.int32)}\n",
      "348881\n",
      "{'image_id': 349152, 'boxes': tensor([[  1,   6, 479, 635],\n",
      "        [  1, 379, 229, 636]], dtype=torch.int32), 'scores': tensor([0.7584, 0.9034]), 'objectness_scores': tensor([0.2761, 0.2258]), 'labels': tensor([12, 12], dtype=torch.int32)}\n",
      "349152\n",
      "{'image_id': 349480, 'boxes': tensor([[266, 275, 321, 319],\n",
      "        [433,  28, 594, 103],\n",
      "        [345, 110, 626, 371],\n",
      "        [262, 344, 361, 448],\n",
      "        [210, 317, 246, 345],\n",
      "        [361, 287, 486, 405],\n",
      "        [339, 155, 365, 174],\n",
      "        [418, 344, 489, 449]], dtype=torch.int32), 'scores': tensor([0.4955, 0.3525, 0.9187, 0.6289, 0.9832, 0.5161, 0.5517, 0.1603]), 'objectness_scores': tensor([0.3085, 0.2187, 0.2401, 0.2949, 0.2439, 0.2913, 0.2409, 0.2271]), 'labels': tensor([10,  3, 12, 12, 12,  2, 12, 10], dtype=torch.int32)}\n",
      "349480\n",
      "{'image_id': 349860, 'boxes': tensor([[338, 107, 454, 194],\n",
      "        [330, 171, 340, 381],\n",
      "        [296, 138, 305, 147]], dtype=torch.int32), 'scores': tensor([0.5877, 0.4832, 0.1866]), 'objectness_scores': tensor([0.6644, 0.2160, 0.2872]), 'labels': tensor([ 8, 11, 14], dtype=torch.int32)}\n",
      "349860\n",
      "{'image_id': 350023, 'boxes': tensor([[408, 350, 414, 364],\n",
      "        [406, 131, 423, 220],\n",
      "        [576, 178, 593, 222],\n",
      "        [485, 356, 505, 362],\n",
      "        [398, 325, 409, 336],\n",
      "        [345, 343, 351, 358]], dtype=torch.int32), 'scores': tensor([0.2934, 0.7522, 0.2279, 0.2230, 0.2683, 0.2264]), 'objectness_scores': tensor([0.3557, 0.2566, 0.2681, 0.2814, 0.2288, 0.3834]), 'labels': tensor([11, 11,  8,  0,  6, 14], dtype=torch.int32)}\n",
      "350023\n",
      "{'image_id': 350054, 'boxes': tensor([[287, 142, 313, 160],\n",
      "        [365,  50, 415, 143],\n",
      "        [192, 137, 212, 154],\n",
      "        [181, 189, 343, 315],\n",
      "        [ 67, 173, 112, 210],\n",
      "        [324, 144, 349, 168],\n",
      "        [320, 147, 348, 188],\n",
      "        [344, 180, 439, 222],\n",
      "        [199, 216, 244, 260],\n",
      "        [  0, 229, 160, 375],\n",
      "        [288, 142, 321, 190],\n",
      "        [  0, 151, 123, 228],\n",
      "        [228, 109, 294, 198]], dtype=torch.int32), 'scores': tensor([0.2454, 0.4784, 0.1609, 0.3515, 0.9859, 0.1866, 0.4343, 0.5825, 0.4443,\n",
      "        0.1095, 0.4431, 0.1999, 0.6482]), 'objectness_scores': tensor([0.2037, 0.3347, 0.2142, 0.2583, 0.2374, 0.2285, 0.3526, 0.2125, 0.2146,\n",
      "        0.3544, 0.3575, 0.2130, 0.5042]), 'labels': tensor([13,  7, 11, 10,  2, 11,  3, 14,  2,  3,  2,  2,  2], dtype=torch.int32)}\n",
      "350054\n",
      "{'image_id': 350122, 'boxes': tensor([[325,  97, 412, 170],\n",
      "        [556, 187, 595, 224],\n",
      "        [481, 190, 541, 224]], dtype=torch.int32), 'scores': tensor([0.2733, 0.6024, 0.2178]), 'objectness_scores': tensor([0.2593, 0.2074, 0.2356]), 'labels': tensor([ 7,  1, 14], dtype=torch.int32)}\n",
      "350122\n",
      "{'image_id': 350148, 'boxes': tensor([[389, 392, 407, 409],\n",
      "        [253, 360, 297, 391],\n",
      "        [309, 397, 329, 423],\n",
      "        [284, 395, 309, 421],\n",
      "        [249, 238, 288, 279],\n",
      "        [245, 385, 270, 408],\n",
      "        [118, 364, 244, 449],\n",
      "        [  1, 375, 473, 647],\n",
      "        [179, 131, 279, 231]], dtype=torch.int32), 'scores': tensor([0.1801, 0.6815, 0.4932, 0.2449, 0.3936, 0.2829, 0.2894, 0.6065, 0.2164]), 'objectness_scores': tensor([0.3589, 0.2277, 0.2012, 0.2172, 0.2178, 0.4906, 0.2845, 0.2193, 0.4490]), 'labels': tensor([14, 12, 11,  7, 11, 11, 11, 10, 10], dtype=torch.int32)}\n",
      "350148\n",
      "{'image_id': 350405, 'boxes': tensor([[202,  85, 336, 230],\n",
      "        [186,  92, 217, 118],\n",
      "        [303, 195, 352, 237],\n",
      "        [207, 220, 236, 247],\n",
      "        [258, 169, 282, 206],\n",
      "        [185,  85, 218, 108],\n",
      "        [365, 196, 398, 237]], dtype=torch.int32), 'scores': tensor([0.9921, 0.2580, 0.5274, 0.2066, 0.2567, 0.4002, 0.4277]), 'objectness_scores': tensor([0.2500, 0.5375, 0.3009, 0.4222, 0.3903, 0.2658, 0.2882]), 'labels': tensor([ 8,  8,  8, 11,  7, 14,  8], dtype=torch.int32)}\n",
      "350405\n",
      "{'image_id': 350679, 'boxes': tensor([[259, 249, 548, 426],\n",
      "        [278,  60, 335, 137],\n",
      "        [411, 203, 499, 343],\n",
      "        [348, 381, 427, 432],\n",
      "        [350, 386, 366, 399],\n",
      "        [379, 416, 400, 428],\n",
      "        [212, 104, 226, 113],\n",
      "        [491, 257, 504, 271],\n",
      "        [383, 390, 401, 406],\n",
      "        [128, 109, 139, 119],\n",
      "        [333, 209, 507, 423],\n",
      "        [297, 403, 320, 428],\n",
      "        [389, 146, 406, 162],\n",
      "        [368, 381, 386, 397],\n",
      "        [490, 257, 506, 276],\n",
      "        [344, 397, 364, 412],\n",
      "        [490, 248, 553, 285],\n",
      "        [ 67, 175,  84, 186],\n",
      "        [362, 405, 381, 421],\n",
      "        [343, 409, 362, 425],\n",
      "        [339, 418, 359, 428],\n",
      "        [358, 394, 376, 407],\n",
      "        [365, 351, 402, 381],\n",
      "        [386, 405, 403, 421],\n",
      "        [363, 397, 382, 411],\n",
      "        [ 63,  88,  88, 162],\n",
      "        [360, 418, 380, 428],\n",
      "        [390, 290, 404, 309],\n",
      "        [ 29, 181, 273, 427],\n",
      "        [401, 395, 419, 414]], dtype=torch.int32), 'scores': tensor([0.9885, 0.3244, 0.9985, 0.6217, 0.2490, 0.2710, 0.3455, 0.3978, 0.1684,\n",
      "        0.2919, 0.9969, 0.3417, 0.2460, 0.1493, 0.5006, 0.2504, 0.3424, 0.3361,\n",
      "        0.2847, 0.2991, 0.2364, 0.2974, 0.2082, 0.1593, 0.2116, 0.2261, 0.2700,\n",
      "        0.3138, 0.7166, 0.1794]), 'objectness_scores': tensor([0.2606, 0.2562, 0.4554, 0.2399, 0.2466, 0.2364, 0.2692, 0.3104, 0.2319,\n",
      "        0.2134, 0.2880, 0.2469, 0.2560, 0.2526, 0.2155, 0.2524, 0.2108, 0.2145,\n",
      "        0.2769, 0.2505, 0.2064, 0.2179, 0.2296, 0.2636, 0.2636, 0.2288, 0.2188,\n",
      "        0.3088, 0.3297, 0.2168]), 'labels': tensor([12, 12, 12, 12, 14, 11, 11, 11,  4, 11, 12, 10, 11,  4, 11, 11, 13, 11,\n",
      "        11, 11, 11, 14, 11,  4, 11,  7, 14, 11, 12,  4], dtype=torch.int32)}\n",
      "350679\n",
      "{'image_id': 350833, 'boxes': tensor([[198, 213, 215, 240],\n",
      "        [  1,   0,  63, 273],\n",
      "        [203,  99, 239, 114],\n",
      "        [192, 263, 446, 363],\n",
      "        [457, 152, 540, 197],\n",
      "        [318, 228, 342, 247],\n",
      "        [541, 373, 590, 417],\n",
      "        [187,  24, 215,  44],\n",
      "        [211, 253, 225, 261],\n",
      "        [ 70, 290, 243, 477],\n",
      "        [  1, 351, 112, 480]], dtype=torch.int32), 'scores': tensor([0.2907, 0.4924, 0.4392, 0.8361, 0.4399, 0.4122, 0.5000, 0.3661, 0.3550,\n",
      "        0.9877, 0.9724]), 'objectness_scores': tensor([0.2306, 0.2785, 0.3257, 0.6172, 0.3223, 0.3367, 0.3105, 0.2281, 0.3307,\n",
      "        0.2636, 0.5506]), 'labels': tensor([11,  7, 11, 15, 11, 11,  9, 11, 11, 15, 15], dtype=torch.int32)}\n",
      "350833\n",
      "{'image_id': 351096, 'boxes': tensor([[234, 137, 248, 151],\n",
      "        [267, 144, 276, 152],\n",
      "        [247, 116, 256, 125],\n",
      "        [219, 176, 460, 373],\n",
      "        [214, 151, 224, 160],\n",
      "        [ 15, 146, 212, 372],\n",
      "        [ 48,  38, 457, 310]], dtype=torch.int32), 'scores': tensor([0.3382, 0.2039, 0.1652, 0.3183, 0.2131, 0.1678, 0.9937]), 'objectness_scores': tensor([0.4384, 0.3177, 0.2637, 0.4344, 0.3608, 0.3597, 0.6407]), 'labels': tensor([11, 11, 11, 10, 11, 11, 16], dtype=torch.int32)}\n",
      "351096\n",
      "{'image_id': 351362, 'boxes': tensor([[309, 406, 318, 413],\n",
      "        [302, 440, 400, 639],\n",
      "        [253,  60, 320, 131],\n",
      "        [125, 408, 337, 525],\n",
      "        [127, 408, 334, 446],\n",
      "        [322, 385, 343, 416],\n",
      "        [372, 347, 388, 389],\n",
      "        [ 15,   2, 114, 633],\n",
      "        [254, 382, 283, 395],\n",
      "        [110, 360, 124, 419],\n",
      "        [305, 418, 406, 503],\n",
      "        [255,   2, 321, 129],\n",
      "        [119, 146, 380, 534],\n",
      "        [  8,   1, 418, 634],\n",
      "        [392, 389, 408, 423]], dtype=torch.int32), 'scores': tensor([0.1612, 0.3383, 0.1435, 0.8275, 0.2346, 0.5251, 0.5936, 0.3539, 0.5823,\n",
      "        0.4185, 0.9606, 0.2052, 0.8249, 0.8460, 0.1595]), 'objectness_scores': tensor([0.4741, 0.3664, 0.2787, 0.2208, 0.5457, 0.2911, 0.3123, 0.2161, 0.3867,\n",
      "        0.3196, 0.4896, 0.3710, 0.2233, 0.2131, 0.4840]), 'labels': tensor([11,  7,  6, 15, 14,  6, 11,  7, 11, 11, 15, 10, 15, 15,  8],\n",
      "       dtype=torch.int32)}\n",
      "351362\n",
      "{'image_id': 351609, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "351609\n",
      "{'image_id': 352684, 'boxes': tensor([[183, 282, 203, 374],\n",
      "        [319, 487, 352, 503],\n",
      "        [186, 565, 219, 584],\n",
      "        [326, 506, 352, 525],\n",
      "        [292, 334, 312, 397],\n",
      "        [405, 324, 424, 334],\n",
      "        [223, 611, 260, 636],\n",
      "        [195, 378, 239, 392]], dtype=torch.int32), 'scores': tensor([0.9730, 0.2873, 0.5938, 0.3583, 0.7388, 0.2669, 0.3906, 0.3589]), 'objectness_scores': tensor([0.4018, 0.2258, 0.2313, 0.2109, 0.2512, 0.2088, 0.2001, 0.3204]), 'labels': tensor([ 7, 11, 11, 11, 11, 11,  9,  0], dtype=torch.int32)}\n",
      "352684\n",
      "{'image_id': 352900, 'boxes': tensor([[ 47,  50, 567, 410],\n",
      "        [  4,  29, 638, 425]], dtype=torch.int32), 'scores': tensor([0.3114, 0.2065]), 'objectness_scores': tensor([0.4428, 0.3607]), 'labels': tensor([16, 10], dtype=torch.int32)}\n",
      "352900\n",
      "{'image_id': 353096, 'boxes': tensor([[ 87, 229, 112, 242],\n",
      "        [422, 139, 466, 259],\n",
      "        [ 70, 235, 134, 262],\n",
      "        [369, 231, 407, 263],\n",
      "        [ 20, 140,  61, 252],\n",
      "        [  3, 246, 498, 343],\n",
      "        [103, 277, 394, 322]], dtype=torch.int32), 'scores': tensor([0.2300, 0.5340, 0.6643, 0.2619, 0.4647, 0.9990, 0.8365]), 'objectness_scores': tensor([0.2332, 0.6312, 0.2756, 0.2711, 0.6552, 0.3659, 0.7937]), 'labels': tensor([14,  8, 14, 12,  8, 14, 14], dtype=torch.int32)}\n",
      "353096\n",
      "{'image_id': 353180, 'boxes': tensor([[244, 367, 261, 384],\n",
      "        [218, 337, 242, 379],\n",
      "        [ 49, 395,  94, 417],\n",
      "        [354, 355, 376, 391],\n",
      "        [140, 345, 161, 364],\n",
      "        [340, 215, 381, 225],\n",
      "        [515, 227, 531, 235],\n",
      "        [290, 343, 310, 380],\n",
      "        [458, 203, 475, 215],\n",
      "        [ 91, 371, 125, 389],\n",
      "        [160, 346, 187, 398],\n",
      "        [369, 329, 386, 366],\n",
      "        [476, 331, 503, 380],\n",
      "        [347, 182, 368, 188],\n",
      "        [407, 352, 426, 384],\n",
      "        [108, 229, 140, 242],\n",
      "        [422, 330, 436, 361],\n",
      "        [509, 325, 530, 336],\n",
      "        [394, 236, 430, 244],\n",
      "        [295, 228, 334, 235],\n",
      "        [541, 336, 561, 354],\n",
      "        [182, 226, 224, 243],\n",
      "        [246, 230, 284, 241],\n",
      "        [225, 200, 238, 207],\n",
      "        [119, 332, 135, 368],\n",
      "        [609, 131, 639, 164],\n",
      "        [406, 193, 420, 203],\n",
      "        [469, 208, 491, 222],\n",
      "        [510, 236, 539, 249],\n",
      "        [560, 319, 585, 357],\n",
      "        [ 37, 356,  62, 380],\n",
      "        [307, 353, 327, 367],\n",
      "        [135,  67, 169, 199],\n",
      "        [143, 184, 169, 201],\n",
      "        [557, 132, 568, 146],\n",
      "        [432, 217, 468, 237],\n",
      "        [262, 174, 282, 191]], dtype=torch.int32), 'scores': tensor([0.4986, 0.4352, 0.2338, 0.1799, 0.1847, 0.2060, 0.1660, 0.3104, 0.1436,\n",
      "        0.2053, 0.3659, 0.2926, 0.2272, 0.1759, 0.3991, 0.2259, 0.1617, 0.2184,\n",
      "        0.1861, 0.3309, 0.3557, 0.1966, 0.3283, 0.1811, 0.5095, 0.2432, 0.1288,\n",
      "        0.1999, 0.2044, 0.3051, 0.2536, 0.2507, 0.4338, 0.1518, 0.1821, 0.2938,\n",
      "        0.2244]), 'objectness_scores': tensor([0.2366, 0.2493, 0.3007, 0.2491, 0.2131, 0.5754, 0.2626, 0.2292, 0.2322,\n",
      "        0.2529, 0.2932, 0.2330, 0.2655, 0.2822, 0.2043, 0.5138, 0.2201, 0.2105,\n",
      "        0.6030, 0.6728, 0.2095, 0.7021, 0.5710, 0.2179, 0.2810, 0.2402, 0.2280,\n",
      "        0.4171, 0.7044, 0.2859, 0.2348, 0.2063, 0.4398, 0.2214, 0.2348, 0.5792,\n",
      "        0.3450]), 'labels': tensor([10,  7, 11,  3, 11,  0, 11, 11, 11,  2, 11,  2, 11, 11, 11, 11,  3, 14,\n",
      "        11, 14, 11, 11, 14, 11, 12, 11, 14, 11, 11, 11,  7, 11, 16,  0, 14, 11,\n",
      "         2], dtype=torch.int32)}\n",
      "353180\n",
      "{'image_id': 353970, 'boxes': tensor([[ 43,   0, 478, 387]], dtype=torch.int32), 'scores': tensor([0.9708]), 'objectness_scores': tensor([0.5330]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "353970\n",
      "{'image_id': 354072, 'boxes': tensor([[  3, 309, 351, 636],\n",
      "        [ 63, 349, 157, 470],\n",
      "        [ 14,  79, 202, 157],\n",
      "        [234, 376, 357, 560],\n",
      "        [ 27, 316, 240, 472],\n",
      "        [154, 338, 239, 448],\n",
      "        [ 84, 282, 184, 342],\n",
      "        [139, 249, 169, 284]], dtype=torch.int32), 'scores': tensor([0.9010, 0.2232, 0.2485, 0.4034, 0.3004, 0.2560, 0.8091, 0.5264]), 'objectness_scores': tensor([0.2278, 0.2337, 0.5728, 0.5434, 0.5153, 0.2366, 0.6317, 0.6516]), 'labels': tensor([15, 11, 15, 16, 15,  7, 10,  7], dtype=torch.int32)}\n",
      "354072\n",
      "{'image_id': 354547, 'boxes': tensor([[103, 125, 267, 382],\n",
      "        [209, 157, 234, 263],\n",
      "        [ 97, 134, 271, 633],\n",
      "        [234, 178, 248, 199]], dtype=torch.int32), 'scores': tensor([0.9799, 0.4619, 0.8762, 0.1665]), 'objectness_scores': tensor([0.2016, 0.3516, 0.2609, 0.2094]), 'labels': tensor([ 7, 11,  7,  7], dtype=torch.int32)}\n",
      "354547\n",
      "{'image_id': 355240, 'boxes': tensor([[112,  85, 221, 243],\n",
      "        [ 18,  55,  52,  89],\n",
      "        [195,  57, 378, 283],\n",
      "        [190, 148, 240, 232],\n",
      "        [137, 130, 165, 137],\n",
      "        [211, 163, 231, 185]], dtype=torch.int32), 'scores': tensor([0.7949, 0.1816, 0.9633, 0.5878, 0.2270, 0.2227]), 'objectness_scores': tensor([0.3652, 0.2062, 0.4713, 0.2180, 0.2215, 0.2457]), 'labels': tensor([ 3,  7,  3,  7, 11,  6], dtype=torch.int32)}\n",
      "355240\n",
      "{'image_id': 355325, 'boxes': tensor([[185,   0, 348, 277],\n",
      "        [ 28, 368, 392, 637],\n",
      "        [ 31, 501, 185, 564],\n",
      "        [168,   2, 316, 284],\n",
      "        [312, 208, 389, 237],\n",
      "        [  1, 373,  78, 585],\n",
      "        [400,  80, 478, 185],\n",
      "        [  0, 373, 476, 641],\n",
      "        [ -1, 172, 476, 635],\n",
      "        [292,  95, 463, 283],\n",
      "        [453, 138, 478, 158],\n",
      "        [ 79,   1, 358, 351]], dtype=torch.int32), 'scores': tensor([0.7756, 0.2927, 0.2721, 0.7135, 0.6093, 0.2044, 0.9715, 0.2986, 0.3985,\n",
      "        0.9697, 0.2482, 0.6221]), 'objectness_scores': tensor([0.2986, 0.2300, 0.3087, 0.3421, 0.5274, 0.2257, 0.3450, 0.4823, 0.3985,\n",
      "        0.6274, 0.2369, 0.5400]), 'labels': tensor([10, 11, 11, 10, 11,  8, 10,  7,  7, 10, 11, 10], dtype=torch.int32)}\n",
      "355325\n",
      "{'image_id': 355817, 'boxes': tensor([[146, 132, 629, 332]], dtype=torch.int32), 'scores': tensor([0.9985]), 'objectness_scores': tensor([0.6303]), 'labels': tensor([1], dtype=torch.int32)}\n",
      "355817\n",
      "{'image_id': 356125, 'boxes': tensor([[ 24, 393,  70, 408],\n",
      "        [334, 143, 602, 444],\n",
      "        [ 38, 156, 227, 245],\n",
      "        [ 35, 159, 231, 346],\n",
      "        [  9, 271, 634, 480],\n",
      "        [  3, 429,  54, 449]], dtype=torch.int32), 'scores': tensor([0.2694, 0.9990, 0.9865, 0.9764, 0.5832, 0.5140]), 'objectness_scores': tensor([0.4579, 0.5975, 0.2111, 0.5233, 0.2015, 0.4236]), 'labels': tensor([ 7,  5,  5,  5,  4, 11], dtype=torch.int32)}\n",
      "356125\n",
      "{'image_id': 356248, 'boxes': tensor([[335, 282, 381, 341],\n",
      "        [ 12,   0,  97, 165],\n",
      "        [104, 250, 145, 289],\n",
      "        [ 62,  79, 115, 135],\n",
      "        [  0, 253, 352, 371],\n",
      "        [ 74, 238, 109, 284],\n",
      "        [175, 232, 188, 250],\n",
      "        [161, 250, 191, 295]], dtype=torch.int32), 'scores': tensor([0.2545, 0.2505, 0.9758, 0.6456, 0.3968, 0.9501, 0.2505, 0.9019]), 'objectness_scores': tensor([0.2719, 0.3409, 0.3415, 0.2283, 0.2049, 0.3073, 0.2023, 0.2973]), 'labels': tensor([16, 12, 10, 12,  7, 10, 11, 10], dtype=torch.int32)}\n",
      "356248\n",
      "{'image_id': 356424, 'boxes': tensor([[232, 502, 276, 571],\n",
      "        [132, 459, 237, 641],\n",
      "        [330, 513, 360, 537],\n",
      "        [ 21, 471, 114, 589],\n",
      "        [239, 481, 261, 503],\n",
      "        [272, 482, 342, 524],\n",
      "        [319, 529, 355, 553]], dtype=torch.int32), 'scores': tensor([0.9018, 0.9566, 0.7185, 0.9049, 0.3971, 0.6707, 0.5218]), 'objectness_scores': tensor([0.3003, 0.3472, 0.3009, 0.3041, 0.2895, 0.3016, 0.2823]), 'labels': tensor([10, 10, 12, 10,  7, 12, 11], dtype=torch.int32)}\n",
      "356424\n",
      "{'image_id': 356531, 'boxes': tensor([[441, 242, 501, 333],\n",
      "        [  3, 175, 298, 482],\n",
      "        [316, 380, 328, 395],\n",
      "        [571, 312, 609, 334]], dtype=torch.int32), 'scores': tensor([0.4545, 0.6235, 0.1600, 0.4143]), 'objectness_scores': tensor([0.2846, 0.2471, 0.3928, 0.2278]), 'labels': tensor([10,  7, 11, 15], dtype=torch.int32)}\n",
      "356531\n",
      "{'image_id': 356612, 'boxes': tensor([[315, 195, 398, 340],\n",
      "        [ 56, 187, 130, 313],\n",
      "        [202, 179, 238, 213],\n",
      "        [224, 196, 286, 306],\n",
      "        [509,  15, 618,  68],\n",
      "        [  1, 128, 259, 219],\n",
      "        [116, 194, 159, 307],\n",
      "        [202, 172, 260, 214],\n",
      "        [144, 191, 207, 312]], dtype=torch.int32), 'scores': tensor([0.9509, 0.9922, 0.2499, 0.5982, 0.1452, 0.7560, 0.4208, 0.3831, 0.9698]), 'objectness_scores': tensor([0.4759, 0.4647, 0.3503, 0.2662, 0.2075, 0.3804, 0.3678, 0.2003, 0.5045]), 'labels': tensor([ 4,  4,  8,  4, 14,  4,  7,  4,  4], dtype=torch.int32)}\n",
      "356612\n",
      "{'image_id': 357459, 'boxes': tensor([[  1,   0, 636, 426],\n",
      "        [266, 100, 465, 388],\n",
      "        [  2, 150, 172, 285]], dtype=torch.int32), 'scores': tensor([0.8381, 0.9809, 0.2890]), 'objectness_scores': tensor([0.2150, 0.5176, 0.3089]), 'labels': tensor([9, 3, 7], dtype=torch.int32)}\n",
      "357459\n",
      "{'image_id': 357567, 'boxes': tensor([[410, 368, 481, 430],\n",
      "        [ 39, 364,  68, 409],\n",
      "        [332, 573, 384, 641],\n",
      "        [ 53,   0, 464, 514],\n",
      "        [307, 567, 383, 637],\n",
      "        [392, 424, 477, 564],\n",
      "        [ 43, 377,  66, 409],\n",
      "        [377, 426, 478, 640]], dtype=torch.int32), 'scores': tensor([0.7628, 0.2473, 0.5552, 0.3964, 0.5071, 0.3852, 0.3644, 0.2963]), 'objectness_scores': tensor([0.2319, 0.4302, 0.3127, 0.5163, 0.3417, 0.2202, 0.2290, 0.2905]), 'labels': tensor([ 7, 11,  7,  7,  7,  7, 11,  8], dtype=torch.int32)}\n",
      "357567\n",
      "{'image_id': 357748, 'boxes': tensor([[344, 122, 416, 277]], dtype=torch.int32), 'scores': tensor([0.8513]), 'objectness_scores': tensor([0.2124]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "357748\n",
      "{'image_id': 357816, 'boxes': tensor([[ 15,  99,  41, 110],\n",
      "        [422,  45, 452,  66],\n",
      "        [  0,  25, 123, 143],\n",
      "        [221, 155, 256, 189],\n",
      "        [315,  22, 341,  32],\n",
      "        [ 98,  67, 183, 122],\n",
      "        [404, 188, 426, 211],\n",
      "        [311,   3, 342,  23],\n",
      "        [ 97, 229, 163, 248],\n",
      "        [229, 166, 348, 235],\n",
      "        [ 44, 233, 259, 422],\n",
      "        [349, 105, 383, 135]], dtype=torch.int32), 'scores': tensor([0.2475, 0.1791, 0.4463, 0.2082, 0.2992, 0.4557, 0.2565, 0.2756, 0.2397,\n",
      "        0.2093, 0.3936, 0.2134]), 'objectness_scores': tensor([0.3053, 0.2952, 0.3005, 0.2728, 0.2240, 0.2897, 0.5968, 0.2820, 0.2387,\n",
      "        0.5316, 0.2073, 0.4433]), 'labels': tensor([11, 11,  6,  9, 11,  8,  8, 14,  7,  7,  5, 11], dtype=torch.int32)}\n",
      "357816\n",
      "{'image_id': 357888, 'boxes': tensor([[532, 417, 553, 432],\n",
      "        [135, 193, 224, 250],\n",
      "        [590, 174, 608, 200],\n",
      "        [147, 349, 296, 479],\n",
      "        [242, 371, 257, 408],\n",
      "        [161, 286, 169, 356],\n",
      "        [600,  67, 634,  91],\n",
      "        [167, 372, 182, 398],\n",
      "        [187, 372, 204, 401],\n",
      "        [204, 370, 222, 399],\n",
      "        [266, 295, 270, 350],\n",
      "        [604, 172, 629, 198],\n",
      "        [593, 325, 625, 368],\n",
      "        [224, 368, 241, 398],\n",
      "        [167, 370, 255, 402],\n",
      "        [542,  83, 583, 110],\n",
      "        [130, 163, 267, 359],\n",
      "        [104, 123, 316, 177],\n",
      "        [234, 208, 281, 256]], dtype=torch.int32), 'scores': tensor([0.6072, 0.4796, 0.4278, 0.4791, 0.1876, 0.3393, 0.2699, 0.2645, 0.3120,\n",
      "        0.2290, 0.4804, 0.1758, 0.3736, 0.2652, 0.4615, 0.2508, 0.3748, 0.4493,\n",
      "        0.2094]), 'objectness_scores': tensor([0.3988, 0.2128, 0.2207, 0.2201, 0.3730, 0.2422, 0.2413, 0.3554, 0.3487,\n",
      "        0.3474, 0.2382, 0.2355, 0.3191, 0.3777, 0.2542, 0.2599, 0.3003, 0.2389,\n",
      "        0.3052]), 'labels': tensor([11,  7, 11,  8, 11, 11, 11, 11,  0,  0, 11, 10,  2,  0,  7,  2,  6,  8,\n",
      "         7], dtype=torch.int32)}\n",
      "357888\n",
      "{'image_id': 357941, 'boxes': tensor([[ 89,   0, 351, 156],\n",
      "        [ 13, 276,  95, 374],\n",
      "        [ 15, 211,  89, 280],\n",
      "        [161, 134, 394, 209]], dtype=torch.int32), 'scores': tensor([0.9242, 0.3256, 0.3751, 0.3987]), 'objectness_scores': tensor([0.2268, 0.6260, 0.5738, 0.5417]), 'labels': tensor([2, 7, 7, 2], dtype=torch.int32)}\n",
      "357941\n",
      "{'image_id': 357978, 'boxes': tensor([[  0, 182,  91, 258],\n",
      "        [  0, 209,  93, 259],\n",
      "        [123, 272, 205, 346],\n",
      "        [ 97, 270, 124, 285]], dtype=torch.int32), 'scores': tensor([0.9987, 0.9991, 0.6376, 0.6910]), 'objectness_scores': tensor([0.2434, 0.2042, 0.2666, 0.2018]), 'labels': tensor([13, 13,  7, 11], dtype=torch.int32)}\n",
      "357978\n",
      "{'image_id': 358195, 'boxes': tensor([[266, 472, 365, 556],\n",
      "        [375,  83, 420, 171],\n",
      "        [234, 315, 329, 518],\n",
      "        [212, 173, 333, 330]], dtype=torch.int32), 'scores': tensor([0.7003, 0.2645, 0.9307, 0.2687]), 'objectness_scores': tensor([0.5934, 0.2005, 0.3347, 0.2606]), 'labels': tensor([ 9, 14,  7,  7], dtype=torch.int32)}\n",
      "358195\n",
      "{'image_id': 358923, 'boxes': tensor([[222,  18, 621, 224],\n",
      "        [401, 141, 489, 233]], dtype=torch.int32), 'scores': tensor([0.8662, 0.2936]), 'objectness_scores': tensor([0.3831, 0.2286]), 'labels': tensor([6, 7], dtype=torch.int32)}\n",
      "358923\n",
      "{'image_id': 359219, 'boxes': tensor([[434,   5, 642, 379],\n",
      "        [321,  19, 639, 354],\n",
      "        [  0,   0, 238, 102]], dtype=torch.int32), 'scores': tensor([0.9675, 0.8736, 0.5516]), 'objectness_scores': tensor([0.5815, 0.4013, 0.2045]), 'labels': tensor([11, 12, 12], dtype=torch.int32)}\n",
      "359219\n",
      "{'image_id': 360137, 'boxes': tensor([[306, 288, 578, 526],\n",
      "        [379, 396, 621, 639]], dtype=torch.int32), 'scores': tensor([0.9962, 0.9828]), 'objectness_scores': tensor([0.6129, 0.2416]), 'labels': tensor([6, 6], dtype=torch.int32)}\n",
      "360137\n",
      "{'image_id': 360564, 'boxes': tensor([[328, 135, 392, 158],\n",
      "        [ 25, 346, 232, 426],\n",
      "        [361, 111, 371, 133],\n",
      "        [334, 121, 357, 144],\n",
      "        [  5, 265, 244, 426],\n",
      "        [235, 338, 262, 367],\n",
      "        [278, 132, 423, 293],\n",
      "        [438,  43, 457,  63],\n",
      "        [309, 205, 333, 223],\n",
      "        [182, 249, 203, 260],\n",
      "        [290,   0, 383,  93],\n",
      "        [  0, 389,  27, 427],\n",
      "        [  2,   2, 635, 429],\n",
      "        [357,  45, 369,  61],\n",
      "        [545, 138, 582, 162],\n",
      "        [  1,   2, 260, 429]], dtype=torch.int32), 'scores': tensor([0.1935, 0.7774, 0.1372, 0.4171, 0.7162, 0.4745, 0.9795, 0.5908, 0.3601,\n",
      "        0.2516, 0.2272, 0.2104, 0.9644, 0.2681, 0.3814, 0.7132]), 'objectness_scores': tensor([0.5920, 0.3997, 0.5625, 0.5315, 0.2431, 0.2114, 0.3349, 0.2981, 0.7251,\n",
      "        0.2102, 0.2920, 0.2497, 0.2107, 0.2720, 0.2789, 0.3063]), 'labels': tensor([11, 15,  8, 11, 15, 11, 15, 12, 11, 14,  7, 11, 15, 11, 11, 15],\n",
      "       dtype=torch.int32)}\n",
      "360564\n",
      "{'image_id': 360951, 'boxes': tensor([[ 49, 150,  85, 212],\n",
      "        [567, 241, 638, 301],\n",
      "        [380, 142, 424, 216],\n",
      "        [587, 242, 638, 275],\n",
      "        [157, 228, 269, 258],\n",
      "        [ -1, 182, 504, 373],\n",
      "        [ 19, 152,  65, 219],\n",
      "        [100, 131, 139, 200]], dtype=torch.int32), 'scores': tensor([0.2743, 0.5753, 0.2383, 0.3359, 0.9302, 0.9322, 0.4495, 0.3614]), 'objectness_scores': tensor([0.3121, 0.2448, 0.3149, 0.2017, 0.4723, 0.2797, 0.3680, 0.4907]), 'labels': tensor([ 8, 14,  8, 14, 14, 14, 11, 11], dtype=torch.int32)}\n",
      "360951\n",
      "{'image_id': 360960, 'boxes': tensor([[ 70, 105,  99, 132],\n",
      "        [  0, 325,  38, 425],\n",
      "        [  2, 105,  31, 125],\n",
      "        [ 71,  70, 393, 232],\n",
      "        [ 96, 400, 122, 435],\n",
      "        [ 30, 404,  77, 439],\n",
      "        [175, 210, 354, 473],\n",
      "        [ 29, 349,  81, 438]], dtype=torch.int32), 'scores': tensor([0.6247, 0.2598, 0.1825, 0.9998, 0.2232, 0.3045, 0.7447, 0.2694]), 'objectness_scores': tensor([0.4681, 0.2320, 0.4536, 0.5551, 0.3226, 0.2516, 0.2061, 0.2606]), 'labels': tensor([7, 7, 7, 6, 2, 7, 7, 7], dtype=torch.int32)}\n",
      "360960\n",
      "{'image_id': 361238, 'boxes': tensor([[  0, 290,  96, 451]], dtype=torch.int32), 'scores': tensor([0.2420]), 'objectness_scores': tensor([0.2744]), 'labels': tensor([6], dtype=torch.int32)}\n",
      "361238\n",
      "{'image_id': 361506, 'boxes': tensor([[293, 112, 316, 132],\n",
      "        [255,  93, 296, 144]], dtype=torch.int32), 'scores': tensor([0.4455, 0.2755]), 'objectness_scores': tensor([0.2087, 0.2056]), 'labels': tensor([11, 11], dtype=torch.int32)}\n",
      "361506\n",
      "{'image_id': 361919, 'boxes': tensor([[ 41, 237, 133, 425],\n",
      "        [199, 348, 203, 352],\n",
      "        [ 41, 245, 136, 347],\n",
      "        [461, 372, 472, 387],\n",
      "        [525, 360, 537, 374],\n",
      "        [405, 334, 422, 344],\n",
      "        [504, 318, 518, 332],\n",
      "        [615, 346, 628, 362],\n",
      "        [482, 311, 501, 326],\n",
      "        [377, 387, 386, 398],\n",
      "        [406, 330, 423, 346],\n",
      "        [448, 325, 458, 332],\n",
      "        [449, 323, 458, 331],\n",
      "        [618, 298, 630, 309],\n",
      "        [617, 301, 629, 308],\n",
      "        [504, 320, 518, 330],\n",
      "        [483, 320, 501, 329],\n",
      "        [612, 392, 629, 410]], dtype=torch.int32), 'scores': tensor([0.3089, 0.1404, 0.9445, 0.2824, 0.2005, 0.2454, 0.5726, 0.1936, 0.2071,\n",
      "        0.2831, 0.5088, 0.2361, 0.1746, 0.1768, 0.3330, 0.3047, 0.1904, 0.2079]), 'objectness_scores': tensor([0.2171, 0.2253, 0.2723, 0.3157, 0.3492, 0.4304, 0.3321, 0.3885, 0.3980,\n",
      "        0.3085, 0.3319, 0.2051, 0.3931, 0.3471, 0.3226, 0.2136, 0.4479, 0.2823]), 'labels': tensor([11, 10,  8,  8, 14, 11,  3, 11, 11, 11,  8, 11, 11, 14, 14,  8, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "361919\n",
      "{'image_id': 362520, 'boxes': tensor([[ 80, 356, 133, 441],\n",
      "        [216, 135, 323, 251],\n",
      "        [221, 199, 328, 308]], dtype=torch.int32), 'scores': tensor([0.5716, 0.5956, 0.6193]), 'objectness_scores': tensor([0.2321, 0.4922, 0.2622]), 'labels': tensor([9, 8, 8], dtype=torch.int32)}\n",
      "362520\n",
      "{'image_id': 362682, 'boxes': tensor([[ 77,  57, 463, 322]], dtype=torch.int32), 'scores': tensor([0.9923]), 'objectness_scores': tensor([0.4870]), 'labels': tensor([1], dtype=torch.int32)}\n",
      "362682\n",
      "{'image_id': 363207, 'boxes': tensor([[  0, 309, 230, 472],\n",
      "        [375, 338, 391, 389],\n",
      "        [360, 342, 376, 398],\n",
      "        [202, 411, 227, 449],\n",
      "        [339, 226, 413, 357],\n",
      "        [216, 165, 322, 352],\n",
      "        [520, 182, 580, 241],\n",
      "        [ 56, 359, 447, 479],\n",
      "        [451, 360, 470, 390],\n",
      "        [224, 284, 322, 345],\n",
      "        [400,   6, 455,  42],\n",
      "        [422, 319, 512, 366]], dtype=torch.int32), 'scores': tensor([0.7885, 0.2092, 0.2207, 0.3236, 0.9184, 0.9989, 0.3953, 0.4906, 0.4137,\n",
      "        0.3518, 0.4347, 0.2754]), 'objectness_scores': tensor([0.2280, 0.2813, 0.2697, 0.4792, 0.2083, 0.4153, 0.2123, 0.2808, 0.2833,\n",
      "        0.2039, 0.2380, 0.3774]), 'labels': tensor([12,  7,  7, 10, 10, 12, 11, 12, 11, 14,  6, 12], dtype=torch.int32)}\n",
      "363207\n",
      "{'image_id': 363461, 'boxes': tensor([[427,  24, 467,  78],\n",
      "        [352, 310, 407, 357],\n",
      "        [  3, 285, 633, 478],\n",
      "        [229, 255, 629, 485],\n",
      "        [  3, 391, 342, 478],\n",
      "        [217, 239, 276, 306],\n",
      "        [148,  20, 250, 103],\n",
      "        [211, 193, 267, 239],\n",
      "        [440,  47, 486,  85]], dtype=torch.int32), 'scores': tensor([0.2704, 0.9980, 0.4891, 0.6814, 0.4761, 0.6187, 0.3977, 0.3388, 0.1851]), 'objectness_scores': tensor([0.2457, 0.4003, 0.3595, 0.2516, 0.2007, 0.4804, 0.2272, 0.3009, 0.2064]), 'labels': tensor([ 8, 14, 14, 14, 14,  7,  5, 14,  9], dtype=torch.int32)}\n",
      "363461\n",
      "{'image_id': 363666, 'boxes': tensor([[ 54, 108, 114, 171],\n",
      "        [ 45,   8, 142,  41],\n",
      "        [339, 179, 361, 218],\n",
      "        [ 44, 161, 409, 415],\n",
      "        [152, 265, 175, 294],\n",
      "        [476, 209, 499, 233],\n",
      "        [ 86,   7,  96,  19]], dtype=torch.int32), 'scores': tensor([0.6381, 0.1589, 0.9700, 0.4789, 0.2842, 0.3875, 0.2698]), 'objectness_scores': tensor([0.2038, 0.2027, 0.2272, 0.2329, 0.2138, 0.3389, 0.2012]), 'labels': tensor([ 7, 15, 10, 12, 11,  7, 14], dtype=torch.int32)}\n",
      "363666\n",
      "{'image_id': 363784, 'boxes': tensor([[ 99, 269, 242, 372],\n",
      "        [284, 342, 310, 367],\n",
      "        [253, 331, 576, 479],\n",
      "        [186, 297, 202, 317],\n",
      "        [126, 301, 142, 324],\n",
      "        [  0, 333, 107, 464]], dtype=torch.int32), 'scores': tensor([0.9173, 0.4005, 0.3368, 0.2410, 0.4411, 0.1444]), 'objectness_scores': tensor([0.5758, 0.3092, 0.3498, 0.2164, 0.2124, 0.3678]), 'labels': tensor([15, 11,  9, 11, 11,  8], dtype=torch.int32)}\n",
      "363784\n",
      "{'image_id': 363840, 'boxes': tensor([[ 44, 268, 217, 409],\n",
      "        [164, 162, 223, 243],\n",
      "        [151, 369, 218, 420],\n",
      "        [  2, 152, 625, 479],\n",
      "        [330, 311, 587, 414]], dtype=torch.int32), 'scores': tensor([0.4669, 0.2097, 0.2311, 0.9321, 0.9926]), 'objectness_scores': tensor([0.2623, 0.4535, 0.2156, 0.2885, 0.4328]), 'labels': tensor([14,  8, 14, 14, 14], dtype=torch.int32)}\n",
      "363840\n",
      "{'image_id': 363875, 'boxes': tensor([[139, 452, 184, 514],\n",
      "        [178,  13, 278,  88],\n",
      "        [419, 158, 460, 180]], dtype=torch.int32), 'scores': tensor([0.3921, 0.4773, 0.4148]), 'objectness_scores': tensor([0.2219, 0.4543, 0.2247]), 'labels': tensor([ 7,  8, 11], dtype=torch.int32)}\n",
      "363875\n",
      "{'image_id': 364297, 'boxes': tensor([[  0, 253, 623, 429],\n",
      "        [186,   0, 525, 168],\n",
      "        [ 16,  84, 640, 406],\n",
      "        [  1, 260, 420, 429]], dtype=torch.int32), 'scores': tensor([0.9345, 0.3608, 0.6119, 0.7680]), 'objectness_scores': tensor([0.2451, 0.2481, 0.5596, 0.6607]), 'labels': tensor([14,  2,  2, 14], dtype=torch.int32)}\n",
      "364297\n",
      "{'image_id': 364636, 'boxes': tensor([[119,  90, 641, 533],\n",
      "        [314, 311, 353, 361],\n",
      "        [296, 147, 406, 358],\n",
      "        [132, 250, 240, 317]], dtype=torch.int32), 'scores': tensor([0.9848, 0.9751, 0.6510, 0.5024]), 'objectness_scores': tensor([0.5173, 0.2252, 0.3783, 0.2990]), 'labels': tensor([ 3, 12,  3,  8], dtype=torch.int32)}\n",
      "364636\n",
      "{'image_id': 364884, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "364884\n",
      "{'image_id': 365207, 'boxes': tensor([[465, 270, 556, 364]], dtype=torch.int32), 'scores': tensor([0.9564]), 'objectness_scores': tensor([0.5153]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "365207\n",
      "{'image_id': 365208, 'boxes': tensor([[280, 178, 382, 333],\n",
      "        [469,   2, 562, 390],\n",
      "        [316,   1, 406, 436],\n",
      "        [ 76, 355, 279, 619],\n",
      "        [470,   0, 596, 466],\n",
      "        [546,   0, 597, 458],\n",
      "        [386,   0, 469, 438],\n",
      "        [274, 221, 289, 243],\n",
      "        [321,   0, 596, 477]], dtype=torch.int32), 'scores': tensor([0.4018, 0.2223, 0.5131, 0.7429, 0.2574, 0.4056, 0.5421, 0.2240, 0.3445]), 'objectness_scores': tensor([0.4075, 0.2756, 0.3094, 0.5795, 0.2468, 0.2502, 0.2548, 0.3033, 0.2085]), 'labels': tensor([ 6, 16, 10,  6,  7,  7, 10, 11,  6], dtype=torch.int32)}\n",
      "365208\n",
      "{'image_id': 365385, 'boxes': tensor([[372, 168, 588, 352],\n",
      "        [355, 180, 458, 327],\n",
      "        [302, 319, 638, 426],\n",
      "        [  0, 319, 630, 425]], dtype=torch.int32), 'scores': tensor([0.9921, 0.3563, 0.7700, 0.5622]), 'objectness_scores': tensor([0.6499, 0.5023, 0.2631, 0.2264]), 'labels': tensor([15, 15, 15,  8], dtype=torch.int32)}\n",
      "365385\n",
      "{'image_id': 365387, 'boxes': tensor([[295,   9, 364,  38],\n",
      "        [  4,   0, 637, 425],\n",
      "        [274,   0, 294,  18]], dtype=torch.int32), 'scores': tensor([0.4682, 0.9762, 0.3871]), 'objectness_scores': tensor([0.4822, 0.2221, 0.2933]), 'labels': tensor([11, 15, 11], dtype=torch.int32)}\n",
      "365387\n",
      "{'image_id': 365521, 'boxes': tensor([[327,  38, 356,  72],\n",
      "        [ 92, 246, 107, 266],\n",
      "        [ 25, 152,  36, 162],\n",
      "        [ 84, 195,  99, 205],\n",
      "        [ 58, 236,  72, 248],\n",
      "        [ 33, 146,  41, 155],\n",
      "        [ 14, 219,  24, 226],\n",
      "        [287, 222, 324, 250],\n",
      "        [375, 299, 385, 307],\n",
      "        [ 27, 142,  45, 161],\n",
      "        [325, 289, 339, 299],\n",
      "        [213, 231, 247, 259],\n",
      "        [ 23, 221,  35, 229],\n",
      "        [329, 302, 342, 313],\n",
      "        [253, 269, 261, 277],\n",
      "        [ 35, 141,  48, 149],\n",
      "        [251, 271, 261, 278]], dtype=torch.int32), 'scores': tensor([0.5450, 0.1756, 0.1924, 0.3854, 0.2416, 0.1527, 0.2480, 0.2532, 0.1279,\n",
      "        0.1842, 0.1771, 0.3336, 0.1671, 0.1717, 0.1300, 0.1290, 0.1415]), 'objectness_scores': tensor([0.4191, 0.2028, 0.2442, 0.3403, 0.2349, 0.4069, 0.2176, 0.2946, 0.2553,\n",
      "        0.2910, 0.4200, 0.2965, 0.2222, 0.2029, 0.2026, 0.3350, 0.2003]), 'labels': tensor([ 8, 11, 11, 14,  3, 14, 14,  9, 11,  2, 11, 11, 11, 14, 14,  4, 14],\n",
      "       dtype=torch.int32)}\n",
      "365521\n",
      "{'image_id': 365655, 'boxes': tensor([[ 53, 156, 449, 312]], dtype=torch.int32), 'scores': tensor([0.9990]), 'objectness_scores': tensor([0.5514]), 'labels': tensor([1], dtype=torch.int32)}\n",
      "365655\n",
      "{'image_id': 365766, 'boxes': tensor([[381, 204, 415, 267],\n",
      "        [ 40, 259,  53, 281],\n",
      "        [331, 265, 439, 285],\n",
      "        [333, 222, 342, 238],\n",
      "        [541, 233, 553, 253],\n",
      "        [442,  51, 600, 210],\n",
      "        [526, 310, 591, 471],\n",
      "        [ 75, 276, 238, 336],\n",
      "        [  8,  77, 201, 236],\n",
      "        [536, 289, 585, 307],\n",
      "        [263,   0, 284,  35],\n",
      "        [222, 228, 229, 243],\n",
      "        [481, 229, 493, 248],\n",
      "        [ 72,  92, 190, 154]], dtype=torch.int32), 'scores': tensor([0.4090, 0.2438, 0.9012, 0.2322, 0.4588, 0.2104, 0.5020, 0.9629, 0.5793,\n",
      "        0.3689, 0.5605, 0.3038, 0.2518, 0.3860]), 'objectness_scores': tensor([0.4271, 0.4662, 0.4318, 0.2267, 0.4059, 0.2906, 0.2476, 0.4203, 0.2106,\n",
      "        0.2345, 0.2456, 0.2430, 0.2659, 0.2153]), 'labels': tensor([ 7, 11, 11, 11, 11, 13,  7, 14, 15,  9, 11,  0, 14, 13],\n",
      "       dtype=torch.int32)}\n",
      "365766\n",
      "{'image_id': 366141, 'boxes': tensor([[ 42, 184, 106, 230],\n",
      "        [149, 201, 421, 337],\n",
      "        [ 31, 233, 170, 319],\n",
      "        [ 84, 218, 139, 260],\n",
      "        [344, 222, 394, 262],\n",
      "        [311, 283, 480, 371],\n",
      "        [186, 336, 331, 479],\n",
      "        [367, 171, 413, 242]], dtype=torch.int32), 'scores': tensor([0.2425, 0.9996, 0.7775, 0.8384, 0.7040, 0.2417, 0.2378, 0.5190]), 'objectness_scores': tensor([0.2197, 0.4191, 0.2248, 0.4257, 0.2020, 0.3249, 0.2370, 0.2114]), 'labels': tensor([13, 13,  2,  2, 13, 14, 12, 13], dtype=torch.int32)}\n",
      "366141\n",
      "{'image_id': 366199, 'boxes': tensor([[238, 171, 416, 246]], dtype=torch.int32), 'scores': tensor([0.9366]), 'objectness_scores': tensor([0.5495]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "366199\n",
      "{'image_id': 366225, 'boxes': tensor([[432, 100, 539, 359],\n",
      "        [116, 399, 190, 454],\n",
      "        [430, 196, 539, 360],\n",
      "        [  2, 292, 540, 639],\n",
      "        [ 51, 251,  94, 323],\n",
      "        [464, 127, 492, 201],\n",
      "        [ 29, 253, 117, 335],\n",
      "        [ 89, 529, 431, 609]], dtype=torch.int32), 'scores': tensor([0.5841, 0.8849, 0.4949, 0.9966, 0.3955, 0.4668, 0.4954, 0.9994]), 'objectness_scores': tensor([0.2295, 0.2766, 0.2846, 0.2379, 0.2806, 0.2953, 0.2185, 0.6779]), 'labels': tensor([14, 14, 14, 14, 11,  7, 14, 14], dtype=torch.int32)}\n",
      "366225\n",
      "{'image_id': 366884, 'boxes': tensor([[  0, 254, 133, 295],\n",
      "        [305, 444, 344, 474],\n",
      "        [102, 340, 169, 384],\n",
      "        [278, 267, 303, 308],\n",
      "        [281, 225, 356, 250],\n",
      "        [277, 304, 302, 340],\n",
      "        [102, 291, 170, 344],\n",
      "        [297, 395, 399, 478]], dtype=torch.int32), 'scores': tensor([0.9828, 0.2320, 0.2069, 0.2727, 0.5542, 0.2699, 0.2355, 0.9723]), 'objectness_scores': tensor([0.3456, 0.2052, 0.2546, 0.2329, 0.2683, 0.2686, 0.2165, 0.3357]), 'labels': tensor([14, 11, 10,  8, 11, 11, 14,  3], dtype=torch.int32)}\n",
      "366884\n",
      "{'image_id': 367082, 'boxes': tensor([[ 99,  74, 466, 426],\n",
      "        [174, 126, 202, 172],\n",
      "        [  1,  44, 294, 475],\n",
      "        [400, 324, 490, 500],\n",
      "        [152, 190, 220, 211],\n",
      "        [  0,  67,  28, 122]], dtype=torch.int32), 'scores': tensor([0.6350, 0.2164, 0.9501, 0.4386, 0.3351, 0.1431]), 'objectness_scores': tensor([0.4796, 0.2685, 0.3652, 0.5484, 0.2688, 0.2512]), 'labels': tensor([ 3,  7,  3,  7, 11, 10], dtype=torch.int32)}\n",
      "367082\n",
      "{'image_id': 367095, 'boxes': tensor([[428, 263, 450, 291],\n",
      "        [313, 274, 387, 311],\n",
      "        [428, 172, 493, 301],\n",
      "        [503, 164, 557, 304],\n",
      "        [414, 231, 638, 423],\n",
      "        [  1, 155, 295, 287]], dtype=torch.int32), 'scores': tensor([0.1706, 0.9744, 0.2455, 0.7366, 0.2645, 0.5380]), 'objectness_scores': tensor([0.2000, 0.2628, 0.2096, 0.2438, 0.2329, 0.2258]), 'labels': tensor([11, 14, 11, 13, 15,  7], dtype=torch.int32)}\n",
      "367095\n",
      "{'image_id': 367195, 'boxes': tensor([[129,  64, 312, 191]], dtype=torch.int32), 'scores': tensor([0.9744]), 'objectness_scores': tensor([0.4929]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "367195\n",
      "{'image_id': 367386, 'boxes': tensor([[104, 283, 144, 323],\n",
      "        [207, 268, 246, 307],\n",
      "        [455, 236, 592, 276],\n",
      "        [304, 294, 386, 352],\n",
      "        [  0, 356, 210, 479],\n",
      "        [241, 347, 427, 480],\n",
      "        [318, 246, 642, 466],\n",
      "        [161, 249, 227, 315],\n",
      "        [462, 103, 581, 196],\n",
      "        [319, 306, 410, 337],\n",
      "        [ 71, 250, 290, 400],\n",
      "        [494, 259, 627, 360],\n",
      "        [  0, 212,  28, 282],\n",
      "        [ 94, 262, 175, 318],\n",
      "        [184, 335, 274, 423]], dtype=torch.int32), 'scores': tensor([0.2744, 0.4705, 0.4910, 0.9028, 0.2625, 0.3541, 0.9971, 0.7886, 0.6147,\n",
      "        0.3717, 0.9018, 0.9477, 0.4515, 0.4875, 0.5399]), 'objectness_scores': tensor([0.2670, 0.2609, 0.2622, 0.2125, 0.2745, 0.3561, 0.4588, 0.2038, 0.2085,\n",
      "        0.2481, 0.4600, 0.2733, 0.2296, 0.2063, 0.3292]), 'labels': tensor([10, 13, 13, 13, 12, 14, 13, 13,  7,  7, 13, 13, 11,  8, 14],\n",
      "       dtype=torch.int32)}\n",
      "367386\n",
      "{'image_id': 367569, 'boxes': tensor([[358, 165, 433, 282],\n",
      "        [249,  74, 261,  87],\n",
      "        [190,  69, 207,  88],\n",
      "        [  0, 171, 147, 488],\n",
      "        [190,  29, 266,  90],\n",
      "        [225,  43, 247,  67],\n",
      "        [357, 457, 379, 504],\n",
      "        [312, 313, 344, 333],\n",
      "        [125, 505, 148, 517],\n",
      "        [  0, 481, 249, 638],\n",
      "        [165, 508, 212, 522],\n",
      "        [124, 485, 286, 613],\n",
      "        [167, 317, 184, 369],\n",
      "        [249,  60, 262,  87],\n",
      "        [148, 405, 221, 479],\n",
      "        [ 42, 363, 210, 492],\n",
      "        [194,  25, 267,  70],\n",
      "        [292, 328, 469, 540],\n",
      "        [331, 479, 345, 496],\n",
      "        [  0, 568, 189, 639],\n",
      "        [167, 317, 184, 336]], dtype=torch.int32), 'scores': tensor([0.7317, 0.9957, 0.2294, 0.4094, 0.3658, 0.2557, 0.1769, 0.8448, 0.3228,\n",
      "        0.5362, 0.5997, 0.3503, 0.2656, 0.1201, 0.4404, 0.2072, 0.7010, 0.2723,\n",
      "        0.1963, 0.9944, 0.4345]), 'objectness_scores': tensor([0.2517, 0.2150, 0.2861, 0.2097, 0.3492, 0.2437, 0.2953, 0.2008, 0.2103,\n",
      "        0.4417, 0.3299, 0.4937, 0.3329, 0.2894, 0.3873, 0.4472, 0.2206, 0.3086,\n",
      "        0.2170, 0.3871, 0.2188]), 'labels': tensor([ 8,  6, 11,  7, 10, 11, 11, 11, 11, 13, 11, 14, 11,  7, 13,  3, 10, 13,\n",
      "        14, 13, 11], dtype=torch.int32)}\n",
      "367569\n",
      "{'image_id': 367680, 'boxes': tensor([[141, 149, 242, 219],\n",
      "        [318, 201, 331, 213],\n",
      "        [374, 202, 386, 213]], dtype=torch.int32), 'scores': tensor([0.7109, 0.3292, 0.2974]), 'objectness_scores': tensor([0.4421, 0.4135, 0.2988]), 'labels': tensor([ 9, 11, 11], dtype=torch.int32)}\n",
      "367680\n",
      "{'image_id': 368294, 'boxes': tensor([[  0,   0, 173, 167],\n",
      "        [  0, 170, 259, 426],\n",
      "        [306, 136, 375, 171],\n",
      "        [467,  38, 636, 194],\n",
      "        [294, 265, 361, 330],\n",
      "        [349, 116, 422, 164],\n",
      "        [294, 218, 370, 329],\n",
      "        [254, 258, 268, 290]], dtype=torch.int32), 'scores': tensor([0.3273, 0.2478, 0.3369, 0.7432, 0.5980, 0.2300, 0.6465, 0.4795]), 'objectness_scores': tensor([0.2761, 0.2115, 0.2057, 0.2285, 0.4060, 0.2056, 0.2121, 0.2309]), 'labels': tensor([ 6,  7, 11, 14, 16, 15, 16, 11], dtype=torch.int32)}\n",
      "368294\n",
      "{'image_id': 368752, 'boxes': tensor([[ 87, 455, 311, 595],\n",
      "        [147, 404, 270, 473],\n",
      "        [255, 334, 273, 350],\n",
      "        [172, 330, 337, 410],\n",
      "        [  0, 264,  84, 458],\n",
      "        [326, 328, 425, 422],\n",
      "        [232, 330, 285, 367],\n",
      "        [  0, 288, 480, 641]], dtype=torch.int32), 'scores': tensor([0.4641, 0.3069, 0.1745, 0.9426, 0.9803, 0.4609, 0.9402, 0.1996]), 'objectness_scores': tensor([0.2778, 0.2948, 0.3549, 0.3124, 0.4363, 0.2221, 0.2192, 0.3476]), 'labels': tensor([12, 14,  4, 12, 10, 11, 12, 12], dtype=torch.int32)}\n",
      "368752\n",
      "{'image_id': 368900, 'boxes': tensor([[354, 405, 427, 470],\n",
      "        [245, 106, 292, 172],\n",
      "        [353, 287, 454, 474],\n",
      "        [299, 380, 352, 461],\n",
      "        [454, 359, 626, 480],\n",
      "        [466,  22, 547,  91],\n",
      "        [ 31, 334,  87, 389]], dtype=torch.int32), 'scores': tensor([0.2121, 0.4391, 0.3593, 0.4119, 0.3863, 0.2505, 0.9963]), 'objectness_scores': tensor([0.2801, 0.2480, 0.3490, 0.3281, 0.2420, 0.2159, 0.3109]), 'labels': tensor([ 7,  7, 13,  7,  7,  3, 10], dtype=torch.int32)}\n",
      "368900\n",
      "{'image_id': 368961, 'boxes': tensor([[210, 189, 411, 408],\n",
      "        [216, 336, 264, 390],\n",
      "        [166, 202, 267, 375]], dtype=torch.int32), 'scores': tensor([0.9965, 0.1591, 0.9994]), 'objectness_scores': tensor([0.5698, 0.2999, 0.6060]), 'labels': tensor([5, 7, 5], dtype=torch.int32)}\n",
      "368961\n",
      "{'image_id': 369037, 'boxes': tensor([[  3,   3, 424, 637],\n",
      "        [180,  47, 424, 643],\n",
      "        [307, 273, 364, 289],\n",
      "        [181, 303, 284, 421]], dtype=torch.int32), 'scores': tensor([0.9989, 0.9885, 0.3275, 0.5206]), 'objectness_scores': tensor([0.6150, 0.2099, 0.4685, 0.2262]), 'labels': tensor([ 5,  5, 11,  4], dtype=torch.int32)}\n",
      "369037\n",
      "{'image_id': 369503, 'boxes': tensor([[303, 120, 330, 150],\n",
      "        [  2, 252,  70, 376],\n",
      "        [ 58, 249, 108, 374],\n",
      "        [334, 151, 397, 163],\n",
      "        [320, 151, 340, 162],\n",
      "        [125, 212, 140, 333],\n",
      "        [271, 150, 344, 162],\n",
      "        [285, 117, 300, 151],\n",
      "        [104, 189, 126, 237],\n",
      "        [151, 105, 162, 123],\n",
      "        [269, 179, 290, 191],\n",
      "        [303, 118, 314, 135],\n",
      "        [487, 116, 492, 124],\n",
      "        [257, 175, 412, 304],\n",
      "        [268, 149, 397, 163],\n",
      "        [270, 211, 399, 298],\n",
      "        [103, 216, 132, 363],\n",
      "        [101, 177, 140, 368],\n",
      "        [ 33,   0, 204,  88],\n",
      "        [318, 126, 332, 150],\n",
      "        [123, 176, 139, 223],\n",
      "        [347, 132, 357, 151],\n",
      "        [ 66, 216, 104, 295]], dtype=torch.int32), 'scores': tensor([0.3877, 0.2805, 0.5110, 0.4393, 0.3775, 0.3416, 0.4326, 0.2914, 0.1877,\n",
      "        0.2704, 0.2620, 0.2392, 0.1604, 0.3427, 0.2835, 0.2894, 0.1782, 0.4587,\n",
      "        0.3036, 0.1942, 0.2680, 0.1298, 0.1361]), 'objectness_scores': tensor([0.4122, 0.2670, 0.2415, 0.3024, 0.2250, 0.2310, 0.2553, 0.5314, 0.2320,\n",
      "        0.3663, 0.2921, 0.2096, 0.4518, 0.3489, 0.2416, 0.2271, 0.2536, 0.2160,\n",
      "        0.3453, 0.2673, 0.2125, 0.3048, 0.2439]), 'labels': tensor([ 9,  7,  6, 14, 11, 11, 14,  0, 11,  0, 14, 14, 11, 11, 11,  8,  6, 11,\n",
      "        14,  0, 11,  0, 11], dtype=torch.int32)}\n",
      "369503\n",
      "{'image_id': 369541, 'boxes': tensor([[167,  53, 194,  85],\n",
      "        [ 14, 165, 157, 266],\n",
      "        [183,  68, 201,  85],\n",
      "        [  1, 117, 218, 389],\n",
      "        [131,  60, 159,  80],\n",
      "        [ 83,  19,  98,  35],\n",
      "        [  7,   1, 120,  78]], dtype=torch.int32), 'scores': tensor([0.2272, 0.3696, 0.3465, 0.9553, 0.5620, 0.2046, 0.3305]), 'objectness_scores': tensor([0.2441, 0.3163, 0.2637, 0.4744, 0.3499, 0.2399, 0.5654]), 'labels': tensor([ 9,  7, 11,  3, 11, 11,  4], dtype=torch.int32)}\n",
      "369541\n",
      "{'image_id': 369812, 'boxes': tensor([[253, 457, 265, 503],\n",
      "        [168, 466, 192, 489],\n",
      "        [568, 552, 584, 574],\n",
      "        [137,  33, 266, 310],\n",
      "        [208, 423, 235, 446],\n",
      "        [167, 491, 176, 508],\n",
      "        [209, 376, 236, 427],\n",
      "        [348, 540, 356, 549],\n",
      "        [260, 496, 275, 508],\n",
      "        [176, 310, 328, 372],\n",
      "        [222, 373, 251, 390]], dtype=torch.int32), 'scores': tensor([0.2015, 0.2850, 0.3144, 0.8001, 0.3442, 0.4804, 0.5213, 0.2066, 0.2580,\n",
      "        0.1897, 0.3781]), 'objectness_scores': tensor([0.2009, 0.3507, 0.3504, 0.3311, 0.2912, 0.2314, 0.3222, 0.2380, 0.2561,\n",
      "        0.3163, 0.2229]), 'labels': tensor([ 0,  8,  9,  7,  8, 14,  8,  0, 14,  1, 11], dtype=torch.int32)}\n",
      "369812\n",
      "{'image_id': 370486, 'boxes': tensor([[312,  13, 323,  25],\n",
      "        [352,   4, 406,  69],\n",
      "        [ 28, 133,  44, 149],\n",
      "        [395,  79, 420, 134],\n",
      "        [ 28,  86,  43, 105],\n",
      "        [ 75,  88,  90, 107],\n",
      "        [ 62,  90,  76, 107],\n",
      "        [ 64, 148,  80, 178],\n",
      "        [352,   0, 367,  13],\n",
      "        [ 71, 113, 109, 158]], dtype=torch.int32), 'scores': tensor([0.4813, 0.7429, 0.2466, 0.2955, 0.2459, 0.2308, 0.2627, 0.2377, 0.1891,\n",
      "        0.4011]), 'objectness_scores': tensor([0.2716, 0.3794, 0.2857, 0.2071, 0.3016, 0.3122, 0.2984, 0.2571, 0.2176,\n",
      "        0.3714]), 'labels': tensor([ 6,  6, 14, 14,  6, 14,  6, 11,  6,  8], dtype=torch.int32)}\n",
      "370486\n",
      "{'image_id': 370711, 'boxes': tensor([[572, 209, 597, 381],\n",
      "        [614, 218, 639, 342],\n",
      "        [ 54, 129,  76, 280],\n",
      "        [394, 115, 426, 179],\n",
      "        [521, 370, 534, 429],\n",
      "        [208, 166, 242, 325],\n",
      "        [ 79, 132,  95, 248],\n",
      "        [576, 210, 597, 347],\n",
      "        [497, 210, 520, 350],\n",
      "        [ 75, 138,  97, 227],\n",
      "        [ 78, 139, 100, 230],\n",
      "        [163, 138, 194, 221],\n",
      "        [186, 122, 198, 202],\n",
      "        [377, 190, 401, 242],\n",
      "        [152, 321, 177, 399],\n",
      "        [234, 102, 248, 199],\n",
      "        [577, 211, 597, 276],\n",
      "        [ 93, 220, 129, 300],\n",
      "        [134, 149, 218, 339],\n",
      "        [445, 116, 482, 179],\n",
      "        [570, 374, 581, 426],\n",
      "        [237, 245, 281, 339],\n",
      "        [171, 196, 212, 331],\n",
      "        [511, 210, 534, 315],\n",
      "        [560, 277, 582, 386],\n",
      "        [165, 139, 188, 210],\n",
      "        [394, 179, 424, 241],\n",
      "        [ 85, 216, 130, 354],\n",
      "        [ 59, 130,  75, 211],\n",
      "        [ 64, 133, 101, 282],\n",
      "        [452, 116, 482, 147],\n",
      "        [368, 112, 396, 156],\n",
      "        [400, 148, 426, 180],\n",
      "        [135, 200, 201, 340],\n",
      "        [173, 196, 221, 333],\n",
      "        [309, 224, 327, 240],\n",
      "        [188,  99, 220, 229],\n",
      "        [310, 225, 327, 240],\n",
      "        [553,  81, 587, 373],\n",
      "        [426, 117, 457, 178],\n",
      "        [  3, 350,  44, 432],\n",
      "        [ 10, 132,  28, 202],\n",
      "        [615, 219, 639, 303],\n",
      "        [  0, 135,  37, 352],\n",
      "        [508, 211, 535, 378],\n",
      "        [ 79, 144, 156, 369],\n",
      "        [  1, 141,  34, 332],\n",
      "        [256, 120, 292, 201],\n",
      "        [ 92, 132, 131, 248],\n",
      "        [ 40, 188,  67, 283],\n",
      "        [446, 133, 475, 179],\n",
      "        [396, 115, 424, 151],\n",
      "        [191, 104, 220, 201],\n",
      "        [ 93, 145, 157, 308],\n",
      "        [165, 142, 222, 334],\n",
      "        [571, 293, 592, 394],\n",
      "        [561, 212, 594, 380],\n",
      "        [458, 128, 490, 180],\n",
      "        [556, 339, 572, 433],\n",
      "        [108, 364, 164, 413],\n",
      "        [135, 193, 223, 343],\n",
      "        [ 66, 218,  99, 281],\n",
      "        [117, 147, 159, 233],\n",
      "        [238, 239, 285, 346],\n",
      "        [222, 106, 250, 284],\n",
      "        [  1, 274,  46, 431],\n",
      "        [ 63, 222, 127, 429],\n",
      "        [512, 287, 537, 425],\n",
      "        [ 65, 283, 113, 424],\n",
      "        [  3, 238,  47, 424],\n",
      "        [191, 150, 219, 249],\n",
      "        [257, 118, 298, 336],\n",
      "        [244, 125, 292, 329],\n",
      "        [494, 224, 533, 404],\n",
      "        [  0, 238,  32, 358],\n",
      "        [448, 179, 482, 241],\n",
      "        [430, 115, 456, 149],\n",
      "        [200, 152, 241, 326],\n",
      "        [426, 178, 452, 241],\n",
      "        [232, 113, 250, 273],\n",
      "        [248, 155, 292, 305],\n",
      "        [226, 102, 247, 203],\n",
      "        [498, 248, 518, 353],\n",
      "        [614, 279, 636, 344],\n",
      "        [ 64, 137,  97, 283],\n",
      "        [213, 129, 239, 250],\n",
      "        [188, 124, 221, 262]], dtype=torch.int32), 'scores': tensor([0.7007, 0.1683, 0.2852, 0.1580, 0.5755, 0.2481, 0.3750, 0.3482, 0.3282,\n",
      "        0.4431, 0.5458, 0.3577, 0.2592, 0.3555, 0.3829, 0.3715, 0.5913, 0.7459,\n",
      "        0.4475, 0.2966, 0.2884, 0.5089, 0.3120, 0.3242, 0.4237, 0.4091, 0.2594,\n",
      "        0.6331, 0.3760, 0.2705, 0.2862, 0.3542, 0.2450, 0.4548, 0.2170, 0.1425,\n",
      "        0.5460, 0.2220, 0.7187, 0.3078, 0.5496, 0.5821, 0.3789, 0.2903, 0.3559,\n",
      "        0.6221, 0.1615, 0.4529, 0.2271, 0.2378, 0.3372, 0.2197, 0.4487, 0.2770,\n",
      "        0.3696, 0.2746, 0.4592, 0.3298, 0.5723, 0.2876, 0.7062, 0.3324, 0.2896,\n",
      "        0.6623, 0.4556, 0.1902, 0.3157, 0.3774, 0.2744, 0.3418, 0.6496, 0.1918,\n",
      "        0.3466, 0.4123, 0.3036, 0.1724, 0.2799, 0.2121, 0.2199, 0.6035, 0.2376,\n",
      "        0.4620, 0.4951, 0.5342, 0.4801, 0.5196, 0.7521]), 'objectness_scores': tensor([0.2845, 0.2659, 0.3231, 0.2981, 0.2383, 0.3352, 0.2887, 0.3194, 0.3584,\n",
      "        0.2321, 0.2319, 0.2889, 0.2723, 0.2412, 0.2320, 0.2294, 0.2312, 0.2781,\n",
      "        0.3083, 0.2609, 0.2428, 0.2430, 0.2733, 0.2505, 0.3066, 0.2749, 0.3505,\n",
      "        0.3372, 0.3394, 0.3989, 0.3543, 0.3072, 0.2541, 0.4111, 0.4247, 0.3385,\n",
      "        0.3003, 0.3475, 0.2615, 0.2995, 0.2324, 0.2842, 0.2840, 0.3249, 0.3679,\n",
      "        0.3410, 0.2680, 0.3902, 0.3716, 0.2950, 0.2656, 0.2974, 0.4140, 0.3813,\n",
      "        0.3268, 0.3299, 0.2496, 0.2558, 0.2542, 0.2921, 0.4394, 0.2314, 0.3438,\n",
      "        0.3511, 0.3348, 0.3090, 0.3601, 0.2828, 0.2273, 0.3303, 0.2934, 0.3208,\n",
      "        0.3683, 0.2646, 0.3301, 0.3637, 0.3202, 0.3457, 0.3448, 0.2423, 0.3200,\n",
      "        0.3332, 0.2550, 0.2589, 0.2899, 0.2646, 0.2433]), 'labels': tensor([ 7,  8, 11, 11, 11,  9,  7,  7,  7, 11,  7,  7, 11, 11, 11, 11,  7,  7,\n",
      "         6,  8, 11,  7,  7,  7,  7, 11,  7,  7, 11, 11,  8, 11,  8,  7,  8, 11,\n",
      "         7, 11,  7,  9,  0, 11,  7,  9,  7,  7,  7,  9, 11,  9,  9, 11,  7,  7,\n",
      "         6, 14,  7,  9, 11, 14,  7, 11, 11,  7, 11,  7,  7, 11,  9,  7,  7,  7,\n",
      "         7, 11,  9,  7,  9,  7, 11, 11,  8, 11, 11, 11,  6,  7,  7],\n",
      "       dtype=torch.int32)}\n",
      "370711\n",
      "{'image_id': 370813, 'boxes': tensor([[244, 210, 308, 284],\n",
      "        [225, 186, 307, 281],\n",
      "        [168,  84, 356, 188]], dtype=torch.int32), 'scores': tensor([0.1636, 0.4626, 0.1578]), 'objectness_scores': tensor([0.2492, 0.2409, 0.3286]), 'labels': tensor([ 7,  8, 11], dtype=torch.int32)}\n",
      "370813\n",
      "{'image_id': 370818, 'boxes': tensor([[124, 380, 217, 438],\n",
      "        [122, 486, 216, 560],\n",
      "        [ 29,  34, 330, 605],\n",
      "        [293, 102, 401, 370],\n",
      "        [ 40, 360, 309, 603],\n",
      "        [222, 370, 299, 421],\n",
      "        [290, 456, 473, 547],\n",
      "        [123, 433, 216, 500],\n",
      "        [399, 138, 418, 172],\n",
      "        [221, 420, 299, 479]], dtype=torch.int32), 'scores': tensor([0.2804, 0.4076, 0.4258, 0.5402, 0.7832, 0.2749, 0.9876, 0.3010, 0.4528,\n",
      "        0.2271]), 'objectness_scores': tensor([0.2534, 0.2462, 0.2873, 0.2113, 0.2044, 0.2660, 0.2303, 0.2719, 0.2003,\n",
      "        0.2678]), 'labels': tensor([ 7, 14, 15,  8, 15, 13, 15, 14, 11,  7], dtype=torch.int32)}\n",
      "370818\n",
      "{'image_id': 371677, 'boxes': tensor([[  3, 280, 636, 475],\n",
      "        [295,   0, 374,  87],\n",
      "        [304, 233, 415, 368],\n",
      "        [ 56, 355, 217, 430],\n",
      "        [393, 261, 547, 350]], dtype=torch.int32), 'scores': tensor([0.6759, 0.7710, 0.9284, 0.3408, 0.7651]), 'objectness_scores': tensor([0.2965, 0.4864, 0.4012, 0.2111, 0.2054]), 'labels': tensor([14,  3, 10, 14,  1], dtype=torch.int32)}\n",
      "371677\n",
      "{'image_id': 371699, 'boxes': tensor([[352, 554, 376, 578],\n",
      "        [174, 437, 215, 492],\n",
      "        [120, 463, 157, 512],\n",
      "        [314, 320, 481, 522],\n",
      "        [251, 184, 275, 225],\n",
      "        [402, 238, 440, 262],\n",
      "        [ 57, 307,  93, 331],\n",
      "        [173, 388, 215, 445],\n",
      "        [235, 239, 371, 331],\n",
      "        [399, 152, 439, 190],\n",
      "        [258, 339, 280, 366],\n",
      "        [  2, 337, 232, 615],\n",
      "        [121, 515, 154, 563],\n",
      "        [ 79,  46, 236, 142]], dtype=torch.int32), 'scores': tensor([0.1708, 0.6989, 0.2957, 0.2288, 0.3845, 0.2384, 0.8478, 0.9913, 0.2948,\n",
      "        0.9998, 0.4534, 0.3387, 0.2791, 0.4186]), 'objectness_scores': tensor([0.2264, 0.4229, 0.2769, 0.2204, 0.2016, 0.2508, 0.3763, 0.4504, 0.2188,\n",
      "        0.2452, 0.2368, 0.2322, 0.3710, 0.3893]), 'labels': tensor([ 8, 14, 15, 14, 11,  8, 14, 14,  8,  5, 10,  7,  7,  8],\n",
      "       dtype=torch.int32)}\n",
      "371699\n",
      "{'image_id': 371749, 'boxes': tensor([[ 91,  -1, 261, 150],\n",
      "        [319,   1, 355,  35],\n",
      "        [367,  57, 386,  97],\n",
      "        [318,   5, 388,  98],\n",
      "        [329, 191, 336, 198],\n",
      "        [114,  22, 211, 131]], dtype=torch.int32), 'scores': tensor([0.9743, 0.2239, 0.3992, 0.5028, 0.1534, 0.2538]), 'objectness_scores': tensor([0.2181, 0.2208, 0.2244, 0.2101, 0.2051, 0.5143]), 'labels': tensor([ 3, 11, 11,  7, 14, 11], dtype=torch.int32)}\n",
      "371749\n",
      "{'image_id': 372466, 'boxes': tensor([[102,  11, 113,  29],\n",
      "        [  0,  75, 159, 158],\n",
      "        [ 52,   5,  90,  18],\n",
      "        [ -1,  43, 183,  98],\n",
      "        [  4,  87, 639, 358]], dtype=torch.int32), 'scores': tensor([0.2636, 0.4509, 0.4389, 0.3488, 0.3521]), 'objectness_scores': tensor([0.2462, 0.6093, 0.2513, 0.2415, 0.4529]), 'labels': tensor([11,  8, 11,  8, 14], dtype=torch.int32)}\n",
      "372466\n",
      "{'image_id': 372819, 'boxes': tensor([[280, 110, 315, 186],\n",
      "        [214, 230, 272, 319],\n",
      "        [425, 192, 465, 276],\n",
      "        [225, 138, 268, 229],\n",
      "        [517,  71, 638, 169]], dtype=torch.int32), 'scores': tensor([0.9519, 0.9637, 0.9691, 0.9838, 0.3006]), 'objectness_scores': tensor([0.5075, 0.5126, 0.4939, 0.5071, 0.2409]), 'labels': tensor([ 3,  3, 10,  3,  7], dtype=torch.int32)}\n",
      "372819\n",
      "{'image_id': 373315, 'boxes': tensor([[212, 346, 227, 422],\n",
      "        [167, 410, 214, 446],\n",
      "        [167, 395, 204, 418],\n",
      "        [130, 211, 161, 236]], dtype=torch.int32), 'scores': tensor([0.4472, 0.1781, 0.2436, 0.2931]), 'objectness_scores': tensor([0.2695, 0.6924, 0.3463, 0.4565]), 'labels': tensor([11, 15,  2, 11], dtype=torch.int32)}\n",
      "373315\n",
      "{'image_id': 373353, 'boxes': tensor([[481, 395, 502, 424],\n",
      "        [445, 395, 471, 424],\n",
      "        [427, 398, 447, 418]], dtype=torch.int32), 'scores': tensor([0.3718, 0.2892, 0.3633]), 'objectness_scores': tensor([0.2021, 0.2299, 0.2191]), 'labels': tensor([ 8, 11,  8], dtype=torch.int32)}\n",
      "373353\n",
      "{'image_id': 374052, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "374052\n",
      "{'image_id': 374083, 'boxes': tensor([[ 62, 331, 201, 597],\n",
      "        [268, 479, 284, 496],\n",
      "        [141, 487, 415, 641],\n",
      "        [289, 359, 399, 433],\n",
      "        [181, 596, 198, 613],\n",
      "        [205, 458, 381, 632],\n",
      "        [327, 211, 345, 239],\n",
      "        [281, 359, 402, 444],\n",
      "        [111, 326, 161, 389],\n",
      "        [230, 351, 244, 382],\n",
      "        [243, 264, 345, 395]], dtype=torch.int32), 'scores': tensor([0.5828, 0.1840, 0.9982, 0.9960, 0.2704, 0.9990, 0.4785, 0.9989, 0.4145,\n",
      "        0.4070, 0.3970]), 'objectness_scores': tensor([0.2288, 0.2470, 0.3068, 0.2042, 0.2221, 0.4980, 0.3091, 0.4836, 0.2497,\n",
      "        0.3756, 0.3592]), 'labels': tensor([12, 11, 12, 12, 11, 12, 11, 12,  7, 11, 10], dtype=torch.int32)}\n",
      "374083\n",
      "{'image_id': 374982, 'boxes': tensor([[297, 419, 338, 478],\n",
      "        [ 93, 315, 132, 348],\n",
      "        [  0, 264, 375, 500],\n",
      "        [103, 391, 147, 426],\n",
      "        [ 25, 363,  65, 411],\n",
      "        [128, 420, 168, 450],\n",
      "        [254, 314, 294, 353],\n",
      "        [214, 338, 269, 356],\n",
      "        [  0,   0, 140, 117],\n",
      "        [ 55, 307,  86, 339],\n",
      "        [190, 375, 234, 413],\n",
      "        [232, 396, 286, 427],\n",
      "        [266,   0, 374, 148]], dtype=torch.int32), 'scores': tensor([0.2202, 0.2459, 0.5656, 0.2310, 0.1702, 0.2205, 0.1813, 0.4224, 0.2620,\n",
      "        0.1617, 0.2130, 0.3708, 0.2045]), 'objectness_scores': tensor([0.2618, 0.2208, 0.2027, 0.2500, 0.2485, 0.2101, 0.2177, 0.2399, 0.3244,\n",
      "        0.2862, 0.2126, 0.2936, 0.2134]), 'labels': tensor([11, 11, 12, 11, 10,  7,  7, 11, 10, 11, 11, 11, 10], dtype=torch.int32)}\n",
      "374982\n",
      "{'image_id': 375278, 'boxes': tensor([[  2,  35, 220, 362]], dtype=torch.int32), 'scores': tensor([0.5098]), 'objectness_scores': tensor([0.4514]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "375278\n",
      "{'image_id': 375493, 'boxes': tensor([[341, 289, 425, 447],\n",
      "        [301,  41, 365,  62],\n",
      "        [266,  86, 342, 219],\n",
      "        [  0, 260,  21, 296],\n",
      "        [173, 311, 250, 358],\n",
      "        [163, 263, 228, 288],\n",
      "        [254, 205, 366, 341]], dtype=torch.int32), 'scores': tensor([0.3306, 0.1885, 0.4608, 0.2763, 0.6408, 0.4917, 0.3802]), 'objectness_scores': tensor([0.5840, 0.4298, 0.3195, 0.4127, 0.4484, 0.4471, 0.3761]), 'labels': tensor([ 7, 11,  7, 11,  3,  4,  7], dtype=torch.int32)}\n",
      "375493\n",
      "{'image_id': 376093, 'boxes': tensor([[356, 387, 379, 418],\n",
      "        [297, 350, 321, 389],\n",
      "        [420, 229, 444, 260],\n",
      "        [129, 316, 136, 334],\n",
      "        [378, 168, 455, 226],\n",
      "        [431, 138, 451, 159],\n",
      "        [132, 223, 157, 253],\n",
      "        [314, 230, 336, 257],\n",
      "        [245, 153, 315, 213],\n",
      "        [356, 372, 379, 388],\n",
      "        [355, 363, 380, 417]], dtype=torch.int32), 'scores': tensor([0.9280, 0.1975, 0.8560, 0.4444, 0.5773, 0.2536, 0.5507, 0.9663, 0.7559,\n",
      "        0.2442, 0.7472]), 'objectness_scores': tensor([0.2085, 0.2948, 0.3474, 0.2395, 0.4062, 0.3005, 0.3260, 0.3053, 0.3798,\n",
      "        0.2072, 0.3032]), 'labels': tensor([10,  7, 10, 11, 10, 11,  7, 10, 10,  0, 10], dtype=torch.int32)}\n",
      "376093\n",
      "{'image_id': 376264, 'boxes': tensor([[125, 115, 181, 152],\n",
      "        [ 96,  19, 269, 182],\n",
      "        [202, 388, 295, 473],\n",
      "        [237, 160, 321, 331],\n",
      "        [439, 310, 643, 477],\n",
      "        [431,  49, 440, 143],\n",
      "        [187, 226, 247, 283],\n",
      "        [  0, 124,  95, 241],\n",
      "        [126, 118, 152, 147],\n",
      "        [438,  22, 452, 142],\n",
      "        [196, 291, 247, 347],\n",
      "        [  0, 123, 113, 274],\n",
      "        [121, 217, 196, 293],\n",
      "        [310,  49, 437, 227]], dtype=torch.int32), 'scores': tensor([0.2733, 0.8217, 0.9573, 0.7364, 0.9965, 0.3764, 0.3787, 0.3843, 0.5190,\n",
      "        0.2689, 0.6293, 0.9014, 0.6428, 0.5112]), 'objectness_scores': tensor([0.2206, 0.2447, 0.3619, 0.2031, 0.2601, 0.2102, 0.2774, 0.2732, 0.2111,\n",
      "        0.4444, 0.2017, 0.2199, 0.2282, 0.2141]), 'labels': tensor([ 7, 12, 10,  9, 14, 11, 10, 12,  7, 11, 12, 12, 12, 12],\n",
      "       dtype=torch.int32)}\n",
      "376264\n",
      "{'image_id': 376307, 'boxes': tensor([[ 95, 278, 116, 296],\n",
      "        [187, 336, 222, 384],\n",
      "        [287, 411, 326, 468],\n",
      "        [ 13, 214,  60, 276],\n",
      "        [163, 200, 218, 303],\n",
      "        [211, 337, 255, 373],\n",
      "        [ 44, 257, 101, 304],\n",
      "        [ 68, 356, 135, 450],\n",
      "        [129, 240, 161, 282],\n",
      "        [172, 203, 212, 260],\n",
      "        [228, 312, 275, 368],\n",
      "        [ 75, 291, 138, 326],\n",
      "        [252, 354, 332, 465]], dtype=torch.int32), 'scores': tensor([0.4348, 0.3553, 0.1561, 0.3130, 0.7337, 0.2433, 0.5298, 0.2922, 0.6141,\n",
      "        0.2437, 0.4521, 0.7115, 0.3075]), 'objectness_scores': tensor([0.4110, 0.2044, 0.2156, 0.2395, 0.3857, 0.2990, 0.3934, 0.3896, 0.2163,\n",
      "        0.2082, 0.3345, 0.4241, 0.2644]), 'labels': tensor([ 9,  7, 10, 13, 10, 12, 12, 11, 10,  7, 12, 11, 11], dtype=torch.int32)}\n",
      "376307\n",
      "{'image_id': 376310, 'boxes': tensor([[497, 125, 640, 316],\n",
      "        [321,  94, 371, 108],\n",
      "        [354, 367, 440, 403],\n",
      "        [382, 178, 419, 213],\n",
      "        [456, 378, 552, 419],\n",
      "        [337, 286, 361, 325],\n",
      "        [528,  58, 586,  78],\n",
      "        [399, 331, 423, 360],\n",
      "        [483,   1, 637, 113],\n",
      "        [386, 116, 639, 319],\n",
      "        [425,  63, 509,  89],\n",
      "        [574, 390, 639, 434],\n",
      "        [292,   0, 636, 134],\n",
      "        [447, 355, 480, 366],\n",
      "        [210, 252, 328, 315],\n",
      "        [361,   5, 636, 320],\n",
      "        [625, 346, 640, 366],\n",
      "        [291,   0, 404, 112],\n",
      "        [412, 244, 469, 281],\n",
      "        [ 55, 285,  78, 316],\n",
      "        [  0,  58, 135, 474],\n",
      "        [347, 286, 359, 318],\n",
      "        [474, 185, 514, 303],\n",
      "        [624, 346, 640, 382],\n",
      "        [506, 338, 524, 359],\n",
      "        [378,  70, 465, 134],\n",
      "        [465, 182, 517, 305]], dtype=torch.int32), 'scores': tensor([0.2859, 0.3254, 0.3838, 0.1677, 0.2505, 0.2026, 0.2701, 0.2771, 0.2099,\n",
      "        0.3891, 0.2692, 0.3016, 0.3702, 0.3733, 0.7706, 0.1798, 0.3031, 0.2415,\n",
      "        0.4050, 0.2488, 0.2164, 0.2898, 0.3741, 0.2904, 0.4799, 0.6594, 0.1492]), 'objectness_scores': tensor([0.2869, 0.2189, 0.6170, 0.2037, 0.6093, 0.2498, 0.2260, 0.3396, 0.2909,\n",
      "        0.3344, 0.2316, 0.5299, 0.2980, 0.2720, 0.3853, 0.3299, 0.2138, 0.3232,\n",
      "        0.2852, 0.2281, 0.3216, 0.2172, 0.2014, 0.2931, 0.3942, 0.3222, 0.2555]), 'labels': tensor([14, 11, 11, 11, 11,  7, 14, 11, 16, 15, 11, 11, 15, 14,  1,  7, 11, 10,\n",
      "         1, 11,  7, 11, 14, 11, 11, 10,  7], dtype=torch.int32)}\n",
      "376310\n",
      "{'image_id': 376322, 'boxes': tensor([[259, 346, 344, 364],\n",
      "        [  4, 301, 471, 640],\n",
      "        [ 49, 502, 192, 572],\n",
      "        [ 14, 385,  38, 415],\n",
      "        [427, 313, 454, 325],\n",
      "        [372, 525, 473, 632],\n",
      "        [291, 496, 316, 512],\n",
      "        [400, 268, 405, 276],\n",
      "        [162, 282, 183, 310],\n",
      "        [142, 270, 156, 293],\n",
      "        [163, 319, 191, 371],\n",
      "        [346, 435, 475, 467],\n",
      "        [355, 197, 401, 213],\n",
      "        [286, 367, 343, 379],\n",
      "        [ 74, 384, 170, 407],\n",
      "        [ 54, 419, 203, 465],\n",
      "        [245, 393, 312, 451],\n",
      "        [271, 312, 282, 327],\n",
      "        [240, 379, 289, 456],\n",
      "        [232, 331, 260, 379],\n",
      "        [118, 346, 151, 357],\n",
      "        [229, 236, 255, 244],\n",
      "        [187, 303, 206, 330],\n",
      "        [171, 461, 382, 549],\n",
      "        [288, 389, 372, 399],\n",
      "        [194, 363, 241, 460],\n",
      "        [247, 485, 278, 505],\n",
      "        [146, 335, 203, 353],\n",
      "        [113, 294, 144, 301],\n",
      "        [344, 428, 468, 452],\n",
      "        [  3, 228,  72, 243],\n",
      "        [113, 287, 141, 294],\n",
      "        [ 35, 561, 257, 641],\n",
      "        [180, 282, 197, 304],\n",
      "        [124, 512, 161, 541],\n",
      "        [ 63, 467, 157, 503],\n",
      "        [424, 451, 477, 634],\n",
      "        [416, 215, 450, 232],\n",
      "        [429, 449, 478, 538],\n",
      "        [257, 334, 279, 343],\n",
      "        [162, 253, 177, 267],\n",
      "        [370, 401, 421, 508],\n",
      "        [282, 368, 374, 393]], dtype=torch.int32), 'scores': tensor([0.4140, 0.4107, 0.7883, 0.2973, 0.8883, 0.6610, 0.2113, 0.2453, 0.5318,\n",
      "        0.1978, 0.4306, 0.1626, 0.3160, 0.3564, 0.6919, 0.3607, 0.9928, 0.3689,\n",
      "        0.7855, 0.3798, 0.5031, 0.2779, 0.1886, 0.8230, 0.4484, 0.3522, 0.3830,\n",
      "        0.3373, 0.2135, 0.6911, 0.5318, 0.2079, 0.8529, 0.2855, 0.4432, 0.7957,\n",
      "        0.2192, 0.9876, 0.6128, 0.3047, 0.3864, 0.4534, 0.2934]), 'objectness_scores': tensor([0.2413, 0.3788, 0.4171, 0.3538, 0.3232, 0.3952, 0.2700, 0.3937, 0.3094,\n",
      "        0.2428, 0.4297, 0.3022, 0.3449, 0.2366, 0.4113, 0.2197, 0.4019, 0.4019,\n",
      "        0.3268, 0.4270, 0.2661, 0.2898, 0.2659, 0.3924, 0.2032, 0.4659, 0.3333,\n",
      "        0.2431, 0.2161, 0.2037, 0.2733, 0.2178, 0.3853, 0.2339, 0.2434, 0.4496,\n",
      "        0.3226, 0.2759, 0.3562, 0.2821, 0.2803, 0.5392, 0.3126]), 'labels': tensor([14, 12, 12,  7, 11, 11, 11, 11, 10, 14, 15, 14, 11, 14, 11, 11, 10,  3,\n",
      "        10, 10, 11, 11, 11, 12, 11, 10, 11, 11,  0,  7, 11,  0,  7, 11,  7,  7,\n",
      "        11, 10, 10, 14, 11,  7,  8], dtype=torch.int32)}\n",
      "376322\n",
      "{'image_id': 376365, 'boxes': tensor([[ 68, 328, 163, 375],\n",
      "        [ 66, 199, 168, 332],\n",
      "        [ 71, 210, 162, 318],\n",
      "        [243,   1, 491,  70]], dtype=torch.int32), 'scores': tensor([0.2808, 0.6549, 0.2784, 0.1630]), 'objectness_scores': tensor([0.2124, 0.4407, 0.3113, 0.2170]), 'labels': tensor([11, 10,  3,  6], dtype=torch.int32)}\n",
      "376365\n",
      "{'image_id': 377239, 'boxes': tensor([[ 83, 159, 122, 180],\n",
      "        [378, 305, 406, 368],\n",
      "        [ 83, 171, 115, 179],\n",
      "        [100,  70, 334, 305]], dtype=torch.int32), 'scores': tensor([0.3318, 0.2905, 0.3479, 0.7678]), 'objectness_scores': tensor([0.4343, 0.2165, 0.2065, 0.3849]), 'labels': tensor([11,  7, 11,  6], dtype=torch.int32)}\n",
      "377239\n",
      "{'image_id': 377368, 'boxes': tensor([[ 45,  69, 634, 477],\n",
      "        [580,  33, 639, 109],\n",
      "        [571, 159, 640, 252],\n",
      "        [379, 114, 471, 234],\n",
      "        [247, 227, 303, 265],\n",
      "        [ 81, 153, 487, 462],\n",
      "        [564, 143, 630, 187],\n",
      "        [600, 293, 638, 401]], dtype=torch.int32), 'scores': tensor([0.9893, 0.9646, 0.6468, 0.9973, 0.4019, 0.9885, 0.4824, 0.4506]), 'objectness_scores': tensor([0.2712, 0.4212, 0.2453, 0.4017, 0.3955, 0.2850, 0.3479, 0.2788]), 'labels': tensor([12, 10, 10, 12, 16, 12, 10, 11], dtype=torch.int32)}\n",
      "377368\n",
      "{'image_id': 377393, 'boxes': tensor([[145, 236, 257, 354],\n",
      "        [449, 125, 578, 346],\n",
      "        [  0,   3, 630, 471]], dtype=torch.int32), 'scores': tensor([0.9330, 0.2665, 0.7400]), 'objectness_scores': tensor([0.2673, 0.3658, 0.2087]), 'labels': tensor([6, 6, 6], dtype=torch.int32)}\n",
      "377393\n",
      "{'image_id': 377486, 'boxes': tensor([[ 29,   0,  42,   8],\n",
      "        [422,  13, 517,  56]], dtype=torch.int32), 'scores': tensor([0.1843, 0.2100]), 'objectness_scores': tensor([0.2540, 0.2085]), 'labels': tensor([11,  4], dtype=torch.int32)}\n",
      "377486\n",
      "{'image_id': 377635, 'boxes': tensor([[256, 150, 280, 171]], dtype=torch.int32), 'scores': tensor([0.3126]), 'objectness_scores': tensor([0.2051]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "377635\n",
      "{'image_id': 377723, 'boxes': tensor([[511,  44, 527, 144],\n",
      "        [370, 146, 607, 341],\n",
      "        [207, 138, 249, 197],\n",
      "        [610, 137, 630, 160],\n",
      "        [450,   0, 479, 116]], dtype=torch.int32), 'scores': tensor([0.2539, 0.9996, 0.2586, 0.2188, 0.3445]), 'objectness_scores': tensor([0.2232, 0.6053, 0.2447, 0.2048, 0.2274]), 'labels': tensor([11,  1, 14,  8,  7], dtype=torch.int32)}\n",
      "377723\n",
      "{'image_id': 377946, 'boxes': tensor([[  0, 142,  92, 201],\n",
      "        [169,  44, 180,  77],\n",
      "        [391,   0, 460,  58],\n",
      "        [267, 106, 276, 189],\n",
      "        [184, 189, 196, 207],\n",
      "        [553, 100, 568, 132],\n",
      "        [159,  43, 170,  69],\n",
      "        [408,   1, 443,  10]], dtype=torch.int32), 'scores': tensor([0.9797, 0.2553, 0.5391, 0.3217, 0.2645, 0.2246, 0.1638, 0.3399]), 'objectness_scores': tensor([0.3897, 0.4099, 0.3369, 0.3039, 0.3110, 0.4555, 0.4161, 0.2435]), 'labels': tensor([ 1, 11,  1, 11, 14, 11, 11, 11], dtype=torch.int32)}\n",
      "377946\n",
      "{'image_id': 378099, 'boxes': tensor([[ 35,  72, 528, 250],\n",
      "        [  2,  -1, 637, 339]], dtype=torch.int32), 'scores': tensor([0.9995, 0.9995]), 'objectness_scores': tensor([0.8150, 0.4643]), 'labels': tensor([14, 14], dtype=torch.int32)}\n",
      "378099\n",
      "{'image_id': 378244, 'boxes': tensor([[195, 259, 224, 285],\n",
      "        [198, 273, 223, 287],\n",
      "        [149, 306, 169, 324],\n",
      "        [234, 355, 250, 373],\n",
      "        [ 91, 318, 148, 339],\n",
      "        [241, 369, 246, 396]], dtype=torch.int32), 'scores': tensor([0.6818, 0.2976, 0.1951, 0.1927, 0.4962, 0.5163]), 'objectness_scores': tensor([0.4095, 0.6301, 0.5228, 0.5104, 0.2768, 0.2653]), 'labels': tensor([ 8, 11, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "378244\n",
      "{'image_id': 378284, 'boxes': tensor([[  5,  91, 634, 428],\n",
      "        [485, 224, 503, 245],\n",
      "        [442, 168, 469, 187],\n",
      "        [243,  90, 445, 139],\n",
      "        [372, 233, 425, 268],\n",
      "        [ 79, 187, 520, 344],\n",
      "        [398, 215, 436, 252],\n",
      "        [255, 110, 319, 154],\n",
      "        [452, 201, 463, 215],\n",
      "        [109, 169, 198, 234],\n",
      "        [206, 259, 253, 302],\n",
      "        [319, 233, 375, 270],\n",
      "        [ 45,  59, 632, 405],\n",
      "        [339, 212, 362, 229],\n",
      "        [428, 223, 449, 236],\n",
      "        [210, 244, 238, 268],\n",
      "        [428,  57, 607, 197],\n",
      "        [355, 164, 443, 228],\n",
      "        [545, 289, 641, 399],\n",
      "        [208, 191, 325, 264],\n",
      "        [155, 144, 227, 173]], dtype=torch.int32), 'scores': tensor([0.3329, 0.5446, 0.2826, 0.3228, 0.3683, 0.3659, 0.3310, 0.4347, 0.2634,\n",
      "        0.4007, 0.7320, 0.5788, 0.4918, 0.3539, 0.2019, 0.3536, 0.8519, 0.2620,\n",
      "        0.3825, 0.4980, 0.3293]), 'objectness_scores': tensor([0.4711, 0.2833, 0.2798, 0.4172, 0.2406, 0.2704, 0.3226, 0.2623, 0.2431,\n",
      "        0.2898, 0.2586, 0.2300, 0.2173, 0.3314, 0.2433, 0.3494, 0.5222, 0.3001,\n",
      "        0.2179, 0.2993, 0.2239]), 'labels': tensor([12, 11, 11,  7, 12, 12, 11, 12, 11, 11, 12, 12, 12, 11, 11, 11, 11,  7,\n",
      "         7, 11, 11], dtype=torch.int32)}\n",
      "378284\n",
      "{'image_id': 378605, 'boxes': tensor([[ 95, 117, 277, 244],\n",
      "        [266, 123, 425, 391],\n",
      "        [  0, 148, 332, 350],\n",
      "        [  0, 322, 426, 571],\n",
      "        [  1, 191, 421, 634]], dtype=torch.int32), 'scores': tensor([0.9057, 0.9184, 0.7250, 0.8470, 0.8832]), 'objectness_scores': tensor([0.2652, 0.4285, 0.3117, 0.3665, 0.2242]), 'labels': tensor([ 7, 10, 12, 12, 12], dtype=torch.int32)}\n",
      "378605\n",
      "{'image_id': 378673, 'boxes': tensor([[312, 264, 408, 290],\n",
      "        [605, 150, 611, 156],\n",
      "        [288, 109, 311, 126],\n",
      "        [398, 216, 414, 244]], dtype=torch.int32), 'scores': tensor([0.6756, 0.3007, 0.4326, 0.2073]), 'objectness_scores': tensor([0.5757, 0.3009, 0.2403, 0.2207]), 'labels': tensor([11, 11, 11, 11], dtype=torch.int32)}\n",
      "378673\n",
      "{'image_id': 379441, 'boxes': tensor([[538, 191, 572, 268],\n",
      "        [285, 212, 329, 246],\n",
      "        [558, 262, 640, 448],\n",
      "        [441,  11, 564, 298],\n",
      "        [270,  98, 443, 346],\n",
      "        [535, 445, 561, 469],\n",
      "        [372,  72, 445, 122],\n",
      "        [495, 343, 639, 432],\n",
      "        [ 55, 371,  68, 396],\n",
      "        [338, 292, 638, 482]], dtype=torch.int32), 'scores': tensor([0.3051, 0.6922, 0.8769, 0.6608, 0.5289, 0.4262, 0.6844, 0.5410, 0.2535,\n",
      "        0.9891]), 'objectness_scores': tensor([0.2565, 0.2007, 0.2508, 0.2249, 0.2038, 0.2390, 0.2386, 0.2874, 0.4772,\n",
      "        0.3625]), 'labels': tensor([11,  8,  6,  8, 13,  7,  8, 13, 11, 13], dtype=torch.int32)}\n",
      "379441\n",
      "{'image_id': 379533, 'boxes': tensor([[155, 253, 204, 307],\n",
      "        [ 51, 218, 173, 314]], dtype=torch.int32), 'scores': tensor([0.9750, 0.9130]), 'objectness_scores': tensor([0.7567, 0.7657]), 'labels': tensor([5, 5], dtype=torch.int32)}\n",
      "379533\n",
      "{'image_id': 380706, 'boxes': tensor([[139,   5, 204,  33],\n",
      "        [319,  76, 338,  88],\n",
      "        [ 36, 134,  52, 149],\n",
      "        [314, 170, 355, 197],\n",
      "        [ 66, 108,  82, 115],\n",
      "        [131, 181, 180, 259],\n",
      "        [ 85,  26, 150,  95],\n",
      "        [ 77, 157, 110, 216],\n",
      "        [ 78,  27,  87,  70],\n",
      "        [134,  38, 180,  83]], dtype=torch.int32), 'scores': tensor([0.2123, 0.4104, 0.5756, 0.2389, 0.2924, 0.2587, 0.2748, 0.1494, 0.3146,\n",
      "        0.6516]), 'objectness_scores': tensor([0.3647, 0.2875, 0.2353, 0.2088, 0.2150, 0.5156, 0.3601, 0.3055, 0.2227,\n",
      "        0.3033]), 'labels': tensor([14, 11, 11, 11, 14,  7, 14,  0, 11,  9], dtype=torch.int32)}\n",
      "380706\n",
      "{'image_id': 381587, 'boxes': tensor([[188, 274, 298, 283],\n",
      "        [ 96,  23, 212, 166],\n",
      "        [ 57, 202, 121, 248],\n",
      "        [238, 206, 309, 238],\n",
      "        [232,  21, 373, 143],\n",
      "        [  6, 535,  79, 613],\n",
      "        [ 90, 246, 131, 277],\n",
      "        [ 88, 452, 141, 516],\n",
      "        [  5, 617, 175, 630],\n",
      "        [  9, 232, 409, 412],\n",
      "        [ 22, 165, 194, 191],\n",
      "        [ 91, 533, 161, 605],\n",
      "        [217, 486, 316, 635],\n",
      "        [206, 205, 228, 230],\n",
      "        [ 28, 554,  57, 581],\n",
      "        [210, 312, 246, 345],\n",
      "        [  9, 299,  60, 356],\n",
      "        [232, 262, 266, 306],\n",
      "        [312, 431, 424, 596],\n",
      "        [261, 245, 293, 287],\n",
      "        [216,  17, 419, 192],\n",
      "        [398, 319, 416, 363],\n",
      "        [ 47,   4,  74,  20],\n",
      "        [210, 307, 264, 343],\n",
      "        [181, 348, 301, 405],\n",
      "        [129, 457, 167, 516]], dtype=torch.int32), 'scores': tensor([0.2041, 0.3646, 0.2137, 0.9890, 0.4044, 0.7174, 0.9400, 0.3049, 0.3730,\n",
      "        0.3038, 0.2025, 0.3179, 0.3681, 0.5216, 0.2974, 0.4051, 0.6604, 0.6156,\n",
      "        0.5168, 0.5081, 0.4620, 0.4004, 0.5712, 0.2525, 0.6839, 0.2353]), 'objectness_scores': tensor([0.3960, 0.2557, 0.4840, 0.2023, 0.2679, 0.2165, 0.3251, 0.2143, 0.2641,\n",
      "        0.3026, 0.2098, 0.2251, 0.2610, 0.3658, 0.2690, 0.2173, 0.3795, 0.3005,\n",
      "        0.3010, 0.4057, 0.2271, 0.2210, 0.2214, 0.2036, 0.2771, 0.2045]), 'labels': tensor([11, 10, 11,  6, 10, 12, 10, 12, 11, 11, 11,  4, 10, 10, 14, 11, 10, 10,\n",
      "        10, 15, 10, 11, 11, 12, 12,  7], dtype=torch.int32)}\n",
      "381587\n",
      "{'image_id': 381639, 'boxes': tensor([[473, 103, 535, 176],\n",
      "        [223, 201, 241, 234],\n",
      "        [369, 112, 384, 155],\n",
      "        [463, 118, 486, 178],\n",
      "        [176, 324, 284, 499],\n",
      "        [317, 124, 348, 209],\n",
      "        [466, 180, 551, 377],\n",
      "        [189, 119, 195, 135],\n",
      "        [353, 118, 371, 176],\n",
      "        [118, 249, 177, 340],\n",
      "        [ 19,  63,  78,  96],\n",
      "        [ 19, 138,  97, 163],\n",
      "        [334, 118, 348, 168],\n",
      "        [346, 118, 360, 174],\n",
      "        [ 39,  14, 450, 155],\n",
      "        [477, 187, 540, 298],\n",
      "        [460, 120, 490, 207],\n",
      "        [198, 118, 206, 137],\n",
      "        [458, 112, 473, 159],\n",
      "        [201, 549, 254, 590],\n",
      "        [418,  20, 441,  52],\n",
      "        [110, 296, 184, 364],\n",
      "        [ 18,  63, 129, 161],\n",
      "        [407,  50, 463,  87],\n",
      "        [226, 526, 281, 557],\n",
      "        [268, 133, 307, 242],\n",
      "        [421, 110, 439, 156],\n",
      "        [481, 386, 561, 621],\n",
      "        [471, 130, 518, 260],\n",
      "        [305, 117, 322, 165],\n",
      "        [ 20,  63,  37,  88]], dtype=torch.int32), 'scores': tensor([0.1917, 0.3130, 0.2129, 0.4325, 0.2171, 0.1883, 0.4454, 0.2628, 0.4306,\n",
      "        0.7640, 0.3648, 0.3690, 0.1674, 0.2977, 0.7552, 0.5299, 0.2882, 0.2794,\n",
      "        0.2755, 0.3850, 0.2903, 0.4628, 0.9718, 0.2620, 0.5670, 0.3941, 0.2212,\n",
      "        0.2251, 0.3588, 0.3729, 0.2905]), 'objectness_scores': tensor([0.2244, 0.5404, 0.4593, 0.2427, 0.3813, 0.4284, 0.3194, 0.2023, 0.3210,\n",
      "        0.7267, 0.2701, 0.2382, 0.2193, 0.2766, 0.5308, 0.6309, 0.4654, 0.2833,\n",
      "        0.3950, 0.2922, 0.2622, 0.3989, 0.3169, 0.2929, 0.3172, 0.5449, 0.3929,\n",
      "        0.6370, 0.2374, 0.4354, 0.2150]), 'labels': tensor([11, 11,  7,  7, 11, 14,  7, 10,  7,  7,  8,  9,  7,  7,  0,  7,  9, 11,\n",
      "         7,  9,  7,  7,  0, 10,  9,  7,  9,  9,  7,  7,  8], dtype=torch.int32)}\n",
      "381639\n",
      "{'image_id': 382125, 'boxes': tensor([[324, 119, 362, 152],\n",
      "        [346, 438, 501, 481],\n",
      "        [332, 247, 351, 263],\n",
      "        [494, 415, 607, 478],\n",
      "        [409, 428, 475, 479],\n",
      "        [  0, 219,  20, 244],\n",
      "        [171, 341, 344, 426]], dtype=torch.int32), 'scores': tensor([0.3872, 0.1690, 0.2654, 0.5845, 0.8376, 0.3072, 0.8087]), 'objectness_scores': tensor([0.2086, 0.2726, 0.2692, 0.2840, 0.2808, 0.3123, 0.3298]), 'labels': tensor([ 7, 15, 11, 10, 10, 11, 12], dtype=torch.int32)}\n",
      "382125\n",
      "{'image_id': 382696, 'boxes': tensor([[  4,   0, 636, 482],\n",
      "        [148, 282, 262, 449]], dtype=torch.int32), 'scores': tensor([0.7001, 0.3644]), 'objectness_scores': tensor([0.2024, 0.3498]), 'labels': tensor([15, 14], dtype=torch.int32)}\n",
      "382696\n",
      "{'image_id': 382743, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "382743\n",
      "{'image_id': 383443, 'boxes': tensor([[447, 230, 632, 335],\n",
      "        [358,   0, 453,  55],\n",
      "        [ 24, 144,  42, 161],\n",
      "        [468, 241, 505, 277],\n",
      "        [130, 150, 144, 161],\n",
      "        [  0, 242, 220, 426],\n",
      "        [ 11, 250,  27, 267],\n",
      "        [  0, 268,  53, 283],\n",
      "        [347, 129, 386, 157],\n",
      "        [314, 123, 345, 154],\n",
      "        [308, 196, 410, 289],\n",
      "        [430, 192, 449, 221],\n",
      "        [  4,  -4, 638, 434],\n",
      "        [ 30,  83, 132, 150],\n",
      "        [122,  65, 138,  98],\n",
      "        [313,  67, 373, 193],\n",
      "        [242, 199, 279, 263],\n",
      "        [418, 192, 434, 221],\n",
      "        [  0,   0, 149, 237]], dtype=torch.int32), 'scores': tensor([0.8570, 0.2057, 0.2071, 0.2749, 0.1821, 0.8210, 0.2414, 0.2684, 0.1988,\n",
      "        0.2084, 0.8967, 0.5042, 0.9935, 0.3106, 0.3205, 0.1555, 0.2780, 0.4532,\n",
      "        0.2295]), 'objectness_scores': tensor([0.6216, 0.3202, 0.2214, 0.2859, 0.2135, 0.2468, 0.3326, 0.3567, 0.2574,\n",
      "        0.2997, 0.2230, 0.3349, 0.2052, 0.3105, 0.2150, 0.3173, 0.3354, 0.3394,\n",
      "        0.4325]), 'labels': tensor([15,  6,  3, 13, 14, 15,  9, 11,  7,  9, 15, 11, 15,  6, 11, 13,  7, 11,\n",
      "         6], dtype=torch.int32)}\n",
      "383443\n",
      "{'image_id': 383606, 'boxes': tensor([[168, 178, 179, 219],\n",
      "        [329, 150, 342, 160],\n",
      "        [384, 312, 419, 367],\n",
      "        [194, 309, 310, 346],\n",
      "        [240,   0, 351, 281],\n",
      "        [188, 277, 203, 286],\n",
      "        [333, 436, 376, 480],\n",
      "        [120, 365, 134, 470],\n",
      "        [179,   0, 240, 285],\n",
      "        [239, 266, 256, 279],\n",
      "        [216, 287, 241, 315],\n",
      "        [135,   1, 181, 322],\n",
      "        [232, 384, 251, 426],\n",
      "        [175, 274, 184, 287],\n",
      "        [137,   0, 352, 330],\n",
      "        [304, 284, 324, 312],\n",
      "        [239, 200, 263, 268]], dtype=torch.int32), 'scores': tensor([0.4079, 0.1945, 0.4087, 0.2749, 0.3454, 0.2074, 0.8697, 0.3856, 0.2826,\n",
      "        0.1939, 0.2190, 0.3011, 0.3835, 0.2179, 0.3186, 0.3291, 0.5443]), 'objectness_scores': tensor([0.2931, 0.3999, 0.3103, 0.5806, 0.2818, 0.2891, 0.4644, 0.2214, 0.2094,\n",
      "        0.2926, 0.5279, 0.4008, 0.2562, 0.2159, 0.2405, 0.2106, 0.3992]), 'labels': tensor([11, 11, 11, 11,  7, 11, 10, 11,  7, 11,  8, 11, 11, 14, 15, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "383606\n",
      "{'image_id': 383842, 'boxes': tensor([[ 59, 288, 199, 379],\n",
      "        [296, 359, 314, 377],\n",
      "        [  2, 149, 255, 431],\n",
      "        [490, 164, 531, 207],\n",
      "        [289, 105, 308, 205],\n",
      "        [356, 153, 373, 200],\n",
      "        [298, 223, 303, 228],\n",
      "        [312, 200, 324, 214],\n",
      "        [512, 273, 645, 433],\n",
      "        [526, 132, 539, 161],\n",
      "        [ 72, 177, 101, 208],\n",
      "        [336, 369, 354, 388],\n",
      "        [250, 370, 290, 398]], dtype=torch.int32), 'scores': tensor([0.9776, 0.2294, 0.7619, 0.8212, 0.9409, 0.6184, 0.1912, 0.2650, 0.5091,\n",
      "        0.3826, 0.4432, 0.2500, 0.3973]), 'objectness_scores': tensor([0.2284, 0.3594, 0.3986, 0.5490, 0.5173, 0.2555, 0.2070, 0.4331, 0.2001,\n",
      "        0.2217, 0.2607, 0.3598, 0.3350]), 'labels': tensor([14, 11, 14,  7,  7, 11, 11, 11, 11, 11,  1, 11, 11], dtype=torch.int32)}\n",
      "383842\n",
      "{'image_id': 384468, 'boxes': tensor([[208, 193, 402, 341],\n",
      "        [ 29, 205, 520, 482]], dtype=torch.int32), 'scores': tensor([0.8376, 0.9979]), 'objectness_scores': tensor([0.2831, 0.6592]), 'labels': tensor([13,  5], dtype=torch.int32)}\n",
      "384468\n",
      "{'image_id': 384527, 'boxes': tensor([[329, 222, 352, 250],\n",
      "        [315, 193, 495, 343],\n",
      "        [410, 230, 436, 253],\n",
      "        [361, 243, 399, 259],\n",
      "        [188,   1, 305, 341],\n",
      "        [369, 231, 394, 253],\n",
      "        [149,   2, 275, 327],\n",
      "        [407, 239, 444, 256],\n",
      "        [126, 154, 171, 204],\n",
      "        [  0, 178, 207, 418],\n",
      "        [438, 190, 453, 206],\n",
      "        [325,  61, 398, 143],\n",
      "        [467, 205, 485, 222],\n",
      "        [229,   0, 321,  84],\n",
      "        [438, 200, 456, 210],\n",
      "        [459, 212, 491, 226],\n",
      "        [528, 263, 638, 328],\n",
      "        [434,  25, 491,  89],\n",
      "        [ 22,  63, 121, 181]], dtype=torch.int32), 'scores': tensor([0.9624, 0.4796, 0.9691, 0.2993, 0.4485, 0.3808, 0.6041, 0.3391, 0.4627,\n",
      "        0.5076, 0.2125, 0.3477, 0.2918, 0.3666, 0.1831, 0.1802, 0.9670, 0.2669,\n",
      "        0.2189]), 'objectness_scores': tensor([0.3166, 0.2834, 0.3207, 0.2500, 0.2183, 0.3169, 0.2344, 0.2435, 0.3084,\n",
      "        0.3092, 0.3144, 0.3422, 0.3064, 0.2444, 0.2168, 0.2159, 0.2265, 0.2246,\n",
      "        0.2692]), 'labels': tensor([10, 10, 10, 10,  7,  7,  7, 10,  8, 13,  7, 10, 11,  9, 14, 11, 13, 16,\n",
      "         9], dtype=torch.int32)}\n",
      "384527\n",
      "{'image_id': 384651, 'boxes': tensor([[233,   0, 445, 145],\n",
      "        [447,   1, 589, 122],\n",
      "        [129, 141, 324, 286],\n",
      "        [ 71, 126, 212, 274],\n",
      "        [128, 143, 263, 281],\n",
      "        [233,   2, 443, 327]], dtype=torch.int32), 'scores': tensor([0.1247, 0.3332, 0.2951, 0.3116, 0.3417, 0.3018]), 'objectness_scores': tensor([0.2847, 0.3029, 0.4974, 0.3473, 0.2342, 0.5825]), 'labels': tensor([ 7, 13,  7,  7,  7,  7], dtype=torch.int32)}\n",
      "384651\n",
      "{'image_id': 384808, 'boxes': tensor([[280,  65, 325,  80],\n",
      "        [ 27,  26,  71, 228],\n",
      "        [ 77, 310, 278, 386],\n",
      "        [109, 169, 183, 300],\n",
      "        [115, 362, 175, 437],\n",
      "        [  2,   2, 356, 394],\n",
      "        [344, 259, 374, 336],\n",
      "        [276,  84, 293, 116],\n",
      "        [184, 104, 324, 313],\n",
      "        [ 80, 212, 102, 296],\n",
      "        [152, 310, 203, 374],\n",
      "        [  0, 192,  36, 291],\n",
      "        [356, 306, 374, 354],\n",
      "        [  0, 416, 275, 498]], dtype=torch.int32), 'scores': tensor([0.1974, 0.7663, 0.9932, 0.1575, 0.9633, 0.4387, 0.2654, 0.2203, 0.7825,\n",
      "        0.3558, 0.7858, 0.3611, 0.3419, 0.9860]), 'objectness_scores': tensor([0.2224, 0.4522, 0.5846, 0.5227, 0.5494, 0.5091, 0.2684, 0.4411, 0.2018,\n",
      "        0.2532, 0.3117, 0.3280, 0.2194, 0.3386]), 'labels': tensor([14,  7, 15, 11, 15,  7,  1,  8,  7, 11, 15,  7, 11, 15],\n",
      "       dtype=torch.int32)}\n",
      "384808\n",
      "{'image_id': 385205, 'boxes': tensor([[  6,  97,  78, 158],\n",
      "        [235,  21, 617, 392],\n",
      "        [ 34,  11, 359, 370]], dtype=torch.int32), 'scores': tensor([0.5915, 0.9077, 0.9501]), 'objectness_scores': tensor([0.4570, 0.2043, 0.2427]), 'labels': tensor([9, 2, 2], dtype=torch.int32)}\n",
      "385205\n",
      "{'image_id': 385719, 'boxes': tensor([[106,   1, 216,  90],\n",
      "        [221, 191, 253, 285],\n",
      "        [387, 317, 637, 418],\n",
      "        [595, 249, 639, 330],\n",
      "        [122, 249, 180, 275],\n",
      "        [257, 118, 306, 208],\n",
      "        [ 46, 285, 233, 307],\n",
      "        [559,  99, 621, 187],\n",
      "        [386, 191, 418, 287]], dtype=torch.int32), 'scores': tensor([0.2416, 0.3333, 0.3314, 0.2170, 0.3139, 0.3835, 0.4149, 0.4679, 0.4563]), 'objectness_scores': tensor([0.2118, 0.3049, 0.2090, 0.3703, 0.2271, 0.2266, 0.2882, 0.2621, 0.4008]), 'labels': tensor([14, 11,  9, 12, 14, 14, 11,  7,  7], dtype=torch.int32)}\n",
      "385719\n",
      "{'image_id': 385997, 'boxes': tensor([[103, 182, 158, 227],\n",
      "        [133,  -3, 186, 248],\n",
      "        [112,   2, 155,  62],\n",
      "        [203, 339, 215, 351],\n",
      "        [ 60,   4, 182, 232],\n",
      "        [444, 161, 518, 340],\n",
      "        [175, 281, 426, 480],\n",
      "        [525, 135, 634, 267]], dtype=torch.int32), 'scores': tensor([0.1901, 0.1722, 0.4124, 0.2160, 0.2803, 0.1676, 0.6415, 0.3728]), 'objectness_scores': tensor([0.3907, 0.2210, 0.2847, 0.2598, 0.2376, 0.6469, 0.3614, 0.2362]), 'labels': tensor([ 7, 11, 11,  6, 12,  7,  3, 10], dtype=torch.int32)}\n",
      "385997\n",
      "{'image_id': 386912, 'boxes': tensor([[282, 379, 287, 386],\n",
      "        [120, 184, 177, 252],\n",
      "        [392,  45, 471, 258],\n",
      "        [  3, 358, 523, 480],\n",
      "        [597, 241, 639, 264],\n",
      "        [211, 369, 308, 422],\n",
      "        [  0,  91,  79, 216],\n",
      "        [315, 368, 327, 391],\n",
      "        [175,   0, 256, 151],\n",
      "        [307, 404, 312, 428],\n",
      "        [489, 164, 565, 223],\n",
      "        [545, 191, 582, 227],\n",
      "        [138, 246, 156, 272]], dtype=torch.int32), 'scores': tensor([0.2285, 0.3187, 0.3502, 0.9442, 0.3854, 0.9933, 0.2881, 0.2995, 0.6447,\n",
      "        0.2236, 0.2429, 0.2135, 0.2433]), 'objectness_scores': tensor([0.3238, 0.2362, 0.2180, 0.2515, 0.2721, 0.4580, 0.2677, 0.2356, 0.2189,\n",
      "        0.2538, 0.2032, 0.3582, 0.2128]), 'labels': tensor([11, 14,  7, 14, 11, 14,  7, 11,  8, 11,  7,  2, 11], dtype=torch.int32)}\n",
      "386912\n",
      "{'image_id': 387098, 'boxes': tensor([[308, 398, 492, 479],\n",
      "        [494, 130, 603, 222],\n",
      "        [257,  77, 324, 163]], dtype=torch.int32), 'scores': tensor([0.5613, 0.5557, 0.4531]), 'objectness_scores': tensor([0.3052, 0.2305, 0.2663]), 'labels': tensor([14, 14,  7], dtype=torch.int32)}\n",
      "387098\n",
      "{'image_id': 387383, 'boxes': tensor([[ 68, 252, 278, 332],\n",
      "        [199, 110, 387, 205],\n",
      "        [364, 213, 640, 480]], dtype=torch.int32), 'scores': tensor([0.9775, 0.9692, 0.9628]), 'objectness_scores': tensor([0.5267, 0.5043, 0.4929]), 'labels': tensor([2, 2, 2], dtype=torch.int32)}\n",
      "387383\n",
      "{'image_id': 387916, 'boxes': tensor([[343, 257, 354, 266],\n",
      "        [170, 274, 185, 286],\n",
      "        [148, 277, 166, 290],\n",
      "        [344, 366, 359, 377],\n",
      "        [292, 322, 308, 377],\n",
      "        [417, 360, 432, 370],\n",
      "        [495, 306, 503, 372],\n",
      "        [226, 309, 237, 319],\n",
      "        [219, 365, 227, 374],\n",
      "        [206, 328, 213, 335],\n",
      "        [504, 357, 518, 373],\n",
      "        [442, 320, 448, 331],\n",
      "        [375, 257, 397, 271],\n",
      "        [508, 256, 520, 267],\n",
      "        [276, 273, 285, 283],\n",
      "        [238, 344, 244, 351],\n",
      "        [241, 347, 252, 375],\n",
      "        [428, 274, 440, 283],\n",
      "        [ 89, 286,  99, 295],\n",
      "        [456, 260, 469, 271]], dtype=torch.int32), 'scores': tensor([0.1808, 0.3071, 0.2952, 0.2515, 0.5688, 0.2970, 0.2127, 0.1907, 0.3268,\n",
      "        0.7975, 0.1401, 0.2198, 0.3396, 0.3379, 0.2406, 0.1941, 0.2362, 0.2999,\n",
      "        0.2242, 0.2249]), 'objectness_scores': tensor([0.2434, 0.2566, 0.2493, 0.2031, 0.2191, 0.2038, 0.2053, 0.2667, 0.2154,\n",
      "        0.2229, 0.2048, 0.2176, 0.2528, 0.2687, 0.2412, 0.2025, 0.2872, 0.2658,\n",
      "        0.2587, 0.2248]), 'labels': tensor([11, 11, 11, 11,  8, 11, 11, 11, 11,  7,  0, 11, 11, 11,  8, 14, 11, 11,\n",
      "        11, 11], dtype=torch.int32)}\n",
      "387916\n",
      "{'image_id': 388258, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "388258\n",
      "{'image_id': 388846, 'boxes': tensor([[248, 269, 300, 310],\n",
      "        [305, 264, 331, 282],\n",
      "        [  5, 252, 633, 427],\n",
      "        [101, 276, 153, 302],\n",
      "        [554, 221, 606, 237],\n",
      "        [184, 273, 255, 311],\n",
      "        [  0, 286, 115, 413],\n",
      "        [514, 240, 542, 252],\n",
      "        [ 75, 280, 138, 309],\n",
      "        [441, 249, 473, 267],\n",
      "        [345, 260, 367, 273],\n",
      "        [250, 267, 309, 307],\n",
      "        [ 66, 279, 140, 340],\n",
      "        [149, 322, 235, 339],\n",
      "        [ 51, 281, 113, 311],\n",
      "        [443, 250, 480, 270],\n",
      "        [448, 248, 525, 298],\n",
      "        [584, 196, 616, 212],\n",
      "        [443, 248, 521, 307],\n",
      "        [455, 241, 472, 248],\n",
      "        [590, 229, 637, 254],\n",
      "        [  1, 261, 327, 370],\n",
      "        [384, 231, 404, 239],\n",
      "        [  0, 284, 119, 429],\n",
      "        [513, 241, 533, 252],\n",
      "        [443, 250, 491, 284],\n",
      "        [110, 275, 158, 294],\n",
      "        [139, 275, 240, 347],\n",
      "        [324, 260, 367, 282],\n",
      "        [364, 259, 388, 271],\n",
      "        [581, 194, 615, 227],\n",
      "        [385, 230, 406, 268],\n",
      "        [313, 263, 344, 281],\n",
      "        [529, 237, 563, 251],\n",
      "        [583, 222, 608, 231],\n",
      "        [554, 236, 580, 246],\n",
      "        [364, 259, 386, 272],\n",
      "        [464, 241, 638, 312],\n",
      "        [284, 266, 321, 287],\n",
      "        [ 18, 282, 100, 307],\n",
      "        [148, 276, 171, 287],\n",
      "        [232, 272, 284, 302],\n",
      "        [575, 231, 615, 249],\n",
      "        [209, 271, 286, 340],\n",
      "        [553, 222, 587, 237],\n",
      "        [ 17, 282, 121, 347],\n",
      "        [ 98, 276, 160, 332],\n",
      "        [439, 251, 463, 265],\n",
      "        [464, 239, 637, 371],\n",
      "        [  0, 287, 114, 353]], dtype=torch.int32), 'scores': tensor([0.5595, 0.2720, 0.6022, 0.1946, 0.6480, 0.9198, 0.8806, 0.2191, 0.2495,\n",
      "        0.1908, 0.2531, 0.5083, 0.9236, 0.2495, 0.2152, 0.4096, 0.4022, 0.4323,\n",
      "        0.1604, 0.2419, 0.9561, 0.9104, 0.1821, 0.9728, 0.2355, 0.6473, 0.1851,\n",
      "        0.8158, 0.1389, 0.4338, 0.3209, 0.3089, 0.8407, 0.2006, 0.3373, 0.2354,\n",
      "        0.6007, 0.9979, 0.3012, 0.2410, 0.1529, 0.4991, 0.1822, 0.7055, 0.5272,\n",
      "        0.3449, 0.8779, 0.2748, 0.9751, 0.5544]), 'objectness_scores': tensor([0.2724, 0.2044, 0.3005, 0.3009, 0.2375, 0.2222, 0.3782, 0.2719, 0.2420,\n",
      "        0.2987, 0.2261, 0.2901, 0.3584, 0.2160, 0.2430, 0.2749, 0.3695, 0.2120,\n",
      "        0.2090, 0.3550, 0.3539, 0.2494, 0.2359, 0.2164, 0.2328, 0.2670, 0.2165,\n",
      "        0.3892, 0.2102, 0.2422, 0.2062, 0.3266, 0.2334, 0.2847, 0.2987, 0.2689,\n",
      "        0.2335, 0.2034, 0.2257, 0.2561, 0.2246, 0.2377, 0.3115, 0.3126, 0.3126,\n",
      "        0.2477, 0.2951, 0.2152, 0.4528, 0.2779]), 'labels': tensor([ 1,  7,  6, 10,  6,  6,  6, 11,  0,  7,  7,  6,  6, 11,  7,  7,  6, 11,\n",
      "        11,  6,  6,  6, 11,  6, 11,  6, 14,  6, 10,  6,  8,  8,  6, 11, 11, 14,\n",
      "         6,  6, 11,  7, 11,  1, 14,  6, 11,  1,  6, 11,  6,  6],\n",
      "       dtype=torch.int32)}\n",
      "388846\n",
      "{'image_id': 389316, 'boxes': tensor([[ 95,  86, 215, 335],\n",
      "        [241,  60, 515, 300],\n",
      "        [487,  76, 531, 131],\n",
      "        [584,  59, 621,  85]], dtype=torch.int32), 'scores': tensor([0.9997, 0.9998, 0.2719, 0.2396]), 'objectness_scores': tensor([0.7453, 0.7106, 0.2033, 0.2252]), 'labels': tensor([ 5,  5,  5, 11], dtype=torch.int32)}\n",
      "389316\n",
      "{'image_id': 389451, 'boxes': tensor([[354, 154, 387, 165],\n",
      "        [452, 260, 534, 327],\n",
      "        [551, 255, 619, 316],\n",
      "        [ 11, 269,  87, 327]], dtype=torch.int32), 'scores': tensor([0.2460, 0.9981, 0.9968, 0.9927]), 'objectness_scores': tensor([0.2651, 0.6065, 0.6089, 0.5775]), 'labels': tensor([11,  4,  4,  4], dtype=torch.int32)}\n",
      "389451\n",
      "{'image_id': 389684, 'boxes': tensor([[ 19,   0, 165, 198]], dtype=torch.int32), 'scores': tensor([0.6693]), 'objectness_scores': tensor([0.4099]), 'labels': tensor([4], dtype=torch.int32)}\n",
      "389684\n",
      "{'image_id': 389804, 'boxes': tensor([[  0,  85,  47, 256],\n",
      "        [505, 237, 641, 418],\n",
      "        [ 33, 167,  92, 240],\n",
      "        [ 34, 179, 101, 266],\n",
      "        [369, 216, 433, 369],\n",
      "        [387,   5, 406,  22],\n",
      "        [477, 354, 572, 425],\n",
      "        [104, 280, 147, 332],\n",
      "        [347, 217, 398, 374]], dtype=torch.int32), 'scores': tensor([0.2667, 0.3299, 0.5983, 0.4864, 0.2138, 0.2400, 0.2722, 0.4142, 0.7211]), 'objectness_scores': tensor([0.2079, 0.4092, 0.4299, 0.4789, 0.2305, 0.2045, 0.3846, 0.3422, 0.2720]), 'labels': tensor([11, 16,  7,  7, 14, 14,  8, 11, 14], dtype=torch.int32)}\n",
      "389804\n",
      "{'image_id': 390555, 'boxes': tensor([[139, 103, 148, 118],\n",
      "        [ 66, 165,  96, 180],\n",
      "        [463, 325, 482, 348],\n",
      "        [ 69,  97,  77, 120],\n",
      "        [241, 329, 254, 359],\n",
      "        [366,  98, 375, 127],\n",
      "        [494,  86, 505, 122],\n",
      "        [395, 169, 408, 179],\n",
      "        [254,  92, 267, 132],\n",
      "        [161, 341, 173, 371],\n",
      "        [ 38,  23, 609, 430],\n",
      "        [ 76, 294,  86, 320],\n",
      "        [130, 158, 171, 198],\n",
      "        [329, 335, 339, 360],\n",
      "        [ 45, 162, 120, 282],\n",
      "        [196,  97, 205, 116],\n",
      "        [547, 338, 563, 391]], dtype=torch.int32), 'scores': tensor([0.3022, 0.2214, 0.2663, 0.1837, 0.2060, 0.2065, 0.2428, 0.3255, 0.4002,\n",
      "        0.2380, 0.9517, 0.2727, 0.2779, 0.1747, 0.7318, 0.1801, 0.3579]), 'objectness_scores': tensor([0.3028, 0.2465, 0.2666, 0.3496, 0.3799, 0.2880, 0.3375, 0.2352, 0.3237,\n",
      "        0.3783, 0.2489, 0.3923, 0.2156, 0.3148, 0.2008, 0.3293, 0.2052]), 'labels': tensor([11, 11, 11,  7, 11, 11, 11, 11, 14, 11,  7, 11,  7, 11,  7, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "390555\n",
      "{'image_id': 391290, 'boxes': tensor([[263, 147, 341, 212],\n",
      "        [302,  99, 363, 175],\n",
      "        [207, 192, 222, 207],\n",
      "        [253, 273, 276, 285],\n",
      "        [ 33, 152,  42, 168],\n",
      "        [  0,  21,  90, 105],\n",
      "        [384, 267, 412, 285],\n",
      "        [  0,  21,  86,  55],\n",
      "        [266, 197, 275, 205],\n",
      "        [228,  84, 264, 108],\n",
      "        [433, 342, 438, 347]], dtype=torch.int32), 'scores': tensor([0.3677, 0.2796, 0.1994, 0.2964, 0.1901, 0.5487, 0.2014, 0.2901, 0.1855,\n",
      "        0.3480, 0.1626]), 'objectness_scores': tensor([0.2857, 0.3666, 0.2344, 0.2166, 0.6728, 0.2247, 0.2328, 0.2575, 0.2010,\n",
      "        0.3625, 0.2703]), 'labels': tensor([ 7,  7,  4, 11, 11,  6, 11,  8, 11,  8, 11], dtype=torch.int32)}\n",
      "391290\n",
      "{'image_id': 391722, 'boxes': tensor([[223, 309, 239, 386],\n",
      "        [250, 320, 259, 388],\n",
      "        [243, 307, 258, 386],\n",
      "        [490, 469, 501, 494],\n",
      "        [261, 309, 276, 386],\n",
      "        [178, 299, 192, 381],\n",
      "        [181, 125, 229, 366],\n",
      "        [198, 304, 211, 385],\n",
      "        [275, 315, 290, 385],\n",
      "        [154, 304, 300, 439],\n",
      "        [275, 312, 290, 385],\n",
      "        [426, 584, 486, 633],\n",
      "        [152, 367, 300, 439]], dtype=torch.int32), 'scores': tensor([0.2396, 0.2002, 0.2059, 0.3596, 0.3507, 0.2345, 0.7096, 0.5667, 0.4918,\n",
      "        0.9971, 0.9787, 0.3920, 0.9617]), 'objectness_scores': tensor([0.5007, 0.4086, 0.2396, 0.2305, 0.4176, 0.4760, 0.3236, 0.4496, 0.3862,\n",
      "        0.3430, 0.2273, 0.2569, 0.3712]), 'labels': tensor([ 7, 11,  7, 11,  7, 11,  7, 11, 11, 12,  2,  7, 12], dtype=torch.int32)}\n",
      "391722\n",
      "{'image_id': 392722, 'boxes': tensor([[424, 145, 638, 346],\n",
      "        [455, 282, 468, 294]], dtype=torch.int32), 'scores': tensor([0.9996, 0.2796]), 'objectness_scores': tensor([0.5737, 0.2006]), 'labels': tensor([1, 4], dtype=torch.int32)}\n",
      "392722\n",
      "{'image_id': 393115, 'boxes': tensor([[456, 336, 515, 399],\n",
      "        [ 66, 456, 333, 524],\n",
      "        [545, 536, 630, 579],\n",
      "        [240, 459, 336, 520],\n",
      "        [227, 522, 270, 567],\n",
      "        [ 85, 514, 131, 562],\n",
      "        [363, 495, 474, 574]], dtype=torch.int32), 'scores': tensor([0.8489, 0.1900, 0.7336, 0.4379, 0.8353, 0.7472, 0.4457]), 'objectness_scores': tensor([0.2109, 0.2716, 0.2145, 0.2182, 0.2080, 0.2095, 0.2308]), 'labels': tensor([9, 8, 7, 7, 9, 9, 9], dtype=torch.int32)}\n",
      "393115\n",
      "{'image_id': 393469, 'boxes': tensor([[219, 396, 284, 521],\n",
      "        [  1,   8, 481, 637],\n",
      "        [225, 391, 256, 405],\n",
      "        [226, 374, 257, 401]], dtype=torch.int32), 'scores': tensor([0.7477, 0.9897, 0.4020, 0.1721]), 'objectness_scores': tensor([0.2051, 0.2066, 0.4295, 0.2031]), 'labels': tensor([ 8,  8, 11,  8], dtype=torch.int32)}\n",
      "393469\n",
      "{'image_id': 393569, 'boxes': tensor([[ 52, 384,  70, 448],\n",
      "        [ 61, 444, 116, 480],\n",
      "        [110, 174, 133, 231],\n",
      "        [ 24, 310,  62, 346],\n",
      "        [  7,   1, 261, 479],\n",
      "        [ 38, 296, 101, 379],\n",
      "        [ 83, 185, 106, 234]], dtype=torch.int32), 'scores': tensor([0.4024, 0.2708, 0.2434, 0.3342, 0.9459, 0.9433, 0.2842]), 'objectness_scores': tensor([0.2446, 0.3962, 0.4048, 0.3319, 0.2246, 0.4407, 0.3668]), 'labels': tensor([11,  7,  8, 15, 15, 15, 11], dtype=torch.int32)}\n",
      "393569\n",
      "{'image_id': 394275, 'boxes': tensor([[ 96, 109, 290, 236],\n",
      "        [148, 305, 208, 324],\n",
      "        [ 91,  79, 609, 370]], dtype=torch.int32), 'scores': tensor([0.8803, 0.3558, 0.9991]), 'objectness_scores': tensor([0.2126, 0.2328, 0.6082]), 'labels': tensor([ 1, 11,  1], dtype=torch.int32)}\n",
      "394275\n",
      "{'image_id': 394510, 'boxes': tensor([[292, 310, 404, 421],\n",
      "        [431,  52, 459,  69]], dtype=torch.int32), 'scores': tensor([0.9770, 0.6292]), 'objectness_scores': tensor([0.6439, 0.2187]), 'labels': tensor([ 9, 11], dtype=torch.int32)}\n",
      "394510\n",
      "{'image_id': 394677, 'boxes': tensor([[286, 170, 299, 190],\n",
      "        [112, 132, 128, 147],\n",
      "        [231, 194, 236, 203],\n",
      "        [114,  89, 151,  98]], dtype=torch.int32), 'scores': tensor([0.3710, 0.2218, 0.1467, 0.1582]), 'objectness_scores': tensor([0.4216, 0.4811, 0.2551, 0.2787]), 'labels': tensor([11,  3, 10, 14], dtype=torch.int32)}\n",
      "394677\n",
      "{'image_id': 394940, 'boxes': tensor([[137, 398, 414, 524],\n",
      "        [  1, 411, 421, 639]], dtype=torch.int32), 'scores': tensor([0.8296, 0.3155]), 'objectness_scores': tensor([0.2319, 0.2133]), 'labels': tensor([12, 12], dtype=torch.int32)}\n",
      "394940\n",
      "{'image_id': 395343, 'boxes': tensor([[255,  62, 474, 283],\n",
      "        [111, 160, 247, 310],\n",
      "        [  0, 152, 247, 311],\n",
      "        [  0, 154, 245, 479],\n",
      "        [260,   0, 592, 281],\n",
      "        [411,   1, 589, 172],\n",
      "        [  0, 152, 138, 307],\n",
      "        [  6, 355, 637, 478]], dtype=torch.int32), 'scores': tensor([0.8283, 0.3671, 0.3456, 0.7676, 0.7966, 0.3330, 0.3702, 0.2892]), 'objectness_scores': tensor([0.3373, 0.2062, 0.3175, 0.2859, 0.3120, 0.3383, 0.2577, 0.3002]), 'labels': tensor([10, 10,  7, 10, 10, 10, 10, 10], dtype=torch.int32)}\n",
      "395343\n",
      "{'image_id': 395388, 'boxes': tensor([[ 73, 405,  96, 419],\n",
      "        [ 34, 264,  56, 276],\n",
      "        [ 67, 212, 114, 246],\n",
      "        [ -2,   4, 479, 632],\n",
      "        [383,  52, 482, 239]], dtype=torch.int32), 'scores': tensor([0.2838, 0.1477, 0.3312, 0.9531, 0.2838]), 'objectness_scores': tensor([0.2010, 0.2024, 0.2090, 0.2108, 0.2080]), 'labels': tensor([11, 11,  7,  4, 11], dtype=torch.int32)}\n",
      "395388\n",
      "{'image_id': 395701, 'boxes': tensor([[555, 200, 583, 242],\n",
      "        [478, 107, 495, 144],\n",
      "        [ 74, 353,  98, 394],\n",
      "        [607, 228, 622, 245],\n",
      "        [322, 191, 538, 431],\n",
      "        [119, 113, 150, 267],\n",
      "        [392, 125, 510, 207],\n",
      "        [463,   0, 494,  13],\n",
      "        [165, 119, 197, 266],\n",
      "        [ 91, 400, 165, 444],\n",
      "        [ 62, 373, 213, 479],\n",
      "        [433,  85, 536, 117]], dtype=torch.int32), 'scores': tensor([0.2810, 0.2483, 0.6238, 0.3069, 0.8876, 0.2512, 0.2390, 0.2130, 0.2709,\n",
      "        0.7570, 0.2434, 0.2245]), 'objectness_scores': tensor([0.2044, 0.2196, 0.4438, 0.2960, 0.3564, 0.2878, 0.2141, 0.2126, 0.2885,\n",
      "        0.2674, 0.2099, 0.7345]), 'labels': tensor([ 7, 11, 11, 14, 13, 13,  2, 11, 13, 14, 14,  9], dtype=torch.int32)}\n",
      "395701\n",
      "{'image_id': 395801, 'boxes': tensor([[ 48, 319,  65, 344],\n",
      "        [ 24, 324,  38, 346],\n",
      "        [497, 232, 517, 254],\n",
      "        [336, 305, 342, 316],\n",
      "        [243, 313, 252, 329],\n",
      "        [253, 312, 261, 326],\n",
      "        [  0, 329,  11, 348],\n",
      "        [155, 218, 210, 257],\n",
      "        [122, 178, 194, 223],\n",
      "        [321, 306, 328, 318],\n",
      "        [ 77, 319,  91, 342],\n",
      "        [366, 301, 372, 311],\n",
      "        [ 98, 318, 112, 339],\n",
      "        [300, 308, 309, 322],\n",
      "        [205, 310, 227, 336],\n",
      "        [311, 307, 319, 320],\n",
      "        [357, 302, 363, 313],\n",
      "        [245, 461, 299, 479],\n",
      "        [357, 302, 363, 312],\n",
      "        [346, 304, 352, 314],\n",
      "        [272, 310, 280, 324],\n",
      "        [137, 303, 146, 322],\n",
      "        [196, 313, 206, 331],\n",
      "        [387, 295, 393, 305]], dtype=torch.int32), 'scores': tensor([0.2264, 0.2815, 0.2162, 0.1594, 0.1621, 0.3001, 0.1737, 0.3372, 0.5666,\n",
      "        0.1680, 0.2309, 0.2290, 0.2111, 0.3529, 0.3185, 0.1668, 0.1943, 0.2523,\n",
      "        0.2417, 0.2002, 0.3199, 0.2692, 0.2440, 0.2050]), 'objectness_scores': tensor([0.3912, 0.5569, 0.2473, 0.2524, 0.5378, 0.5188, 0.4853, 0.2689, 0.3188,\n",
      "        0.2459, 0.7294, 0.2394, 0.3180, 0.3939, 0.4058, 0.3466, 0.2150, 0.3006,\n",
      "        0.2641, 0.2605, 0.4269, 0.3685, 0.6533, 0.2643]), 'labels': tensor([ 7,  8,  8, 11, 11, 14, 11,  4,  1, 11,  9, 11,  9, 14,  8,  0, 14,  7,\n",
      "        14, 11, 14, 14, 11, 14], dtype=torch.int32)}\n",
      "395801\n",
      "{'image_id': 396200, 'boxes': tensor([[474,  66, 485,  97],\n",
      "        [341, 271, 364, 285],\n",
      "        [ 42,   7,  51,  14],\n",
      "        [315, 176, 327, 189],\n",
      "        [338, 273, 364, 300],\n",
      "        [537, 311, 575, 341],\n",
      "        [302,  45, 330,  57],\n",
      "        [563,   0, 585,  35],\n",
      "        [538, 307, 578, 323],\n",
      "        [456, 267, 499, 296],\n",
      "        [527,  72, 539,  99],\n",
      "        [256, 233, 281, 257]], dtype=torch.int32), 'scores': tensor([0.4240, 0.2327, 0.2024, 0.2814, 0.3429, 0.4773, 0.3112, 0.6493, 0.6206,\n",
      "        0.6672, 0.1934, 0.2348]), 'objectness_scores': tensor([0.5376, 0.2944, 0.2094, 0.2774, 0.4897, 0.4032, 0.3698, 0.3163, 0.2696,\n",
      "        0.4519, 0.5074, 0.2376]), 'labels': tensor([ 8, 14, 11, 11,  9,  9, 14, 11, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "396200\n",
      "{'image_id': 396903, 'boxes': tensor([[546, 285, 597, 317],\n",
      "        [591,  89, 603, 116],\n",
      "        [373, 324, 389, 385],\n",
      "        [  9, 138, 362, 244],\n",
      "        [412, 123, 440, 176],\n",
      "        [ 25, 280, 406, 403],\n",
      "        [ 43, 277, 138, 338]], dtype=torch.int32), 'scores': tensor([0.3515, 0.3110, 0.1224, 0.4722, 0.1692, 0.8217, 0.8337]), 'objectness_scores': tensor([0.2518, 0.2249, 0.5207, 0.2651, 0.2213, 0.5492, 0.2308]), 'labels': tensor([ 6, 14,  3, 14,  8,  0,  0], dtype=torch.int32)}\n",
      "396903\n",
      "{'image_id': 397133, 'boxes': tensor([[ 59,   0, 125, 130],\n",
      "        [185, 128, 258, 193],\n",
      "        [532,  44, 555, 128],\n",
      "        [ 90,   4, 141, 100],\n",
      "        [250, 337, 300, 421],\n",
      "        [135,   6, 184,  79],\n",
      "        [ 61,  12, 124,  87],\n",
      "        [328,  62, 365, 148],\n",
      "        [467,  44, 513, 140],\n",
      "        [135, 302, 229, 348],\n",
      "        [500, 205, 601, 226],\n",
      "        [345,  51, 369, 108],\n",
      "        [337,  46, 358,  81],\n",
      "        [255,  95, 293, 156],\n",
      "        [241,  32, 282,  89],\n",
      "        [561,  38, 613, 112]], dtype=torch.int32), 'scores': tensor([0.2517, 0.3049, 0.3876, 0.5462, 0.3902, 0.5148, 0.3832, 0.3378, 0.2148,\n",
      "        0.3912, 0.9124, 0.3191, 0.3629, 0.1036, 0.3391, 0.2976]), 'objectness_scores': tensor([0.3265, 0.2110, 0.2644, 0.2552, 0.3095, 0.2773, 0.2053, 0.2527, 0.3114,\n",
      "        0.2218, 0.2146, 0.2006, 0.2006, 0.2739, 0.2233, 0.2530]), 'labels': tensor([11,  8, 11, 11, 10,  8, 15, 10, 11, 12, 11, 11, 10,  6, 11,  7],\n",
      "       dtype=torch.int32)}\n",
      "397133\n",
      "{'image_id': 397303, 'boxes': tensor([[521,  54, 599, 149],\n",
      "        [110, 174, 134, 210],\n",
      "        [ 35,  78,  94, 113]], dtype=torch.int32), 'scores': tensor([0.6862, 0.5116, 0.2153]), 'objectness_scores': tensor([0.2267, 0.2722, 0.2034]), 'labels': tensor([ 7, 10,  7], dtype=torch.int32)}\n",
      "397303\n",
      "{'image_id': 397327, 'boxes': tensor([[334, 143, 552, 340],\n",
      "        [473, 221, 535, 287],\n",
      "        [424,  46, 455,  84],\n",
      "        [107, 284, 140, 327],\n",
      "        [  0,   3, 146, 426],\n",
      "        [324,  69, 573, 168],\n",
      "        [  3,   1, 634, 426],\n",
      "        [104, 228, 141, 325],\n",
      "        [255,   0, 313,  22],\n",
      "        [481, 161, 546, 229],\n",
      "        [ 19, 344,  69, 392],\n",
      "        [ 13, 308,  79, 394],\n",
      "        [322,  79, 566, 339],\n",
      "        [607, 188, 638, 229],\n",
      "        [365,  78, 390,  88],\n",
      "        [518,  16, 641, 429],\n",
      "        [258,  13, 325, 137]], dtype=torch.int32), 'scores': tensor([0.6610, 0.8042, 0.3325, 0.5495, 0.5010, 0.9537, 0.9520, 0.3076, 0.4646,\n",
      "        0.6586, 0.2585, 0.3089, 0.9907, 0.2530, 0.2284, 0.1512, 0.9473]), 'objectness_scores': tensor([0.4678, 0.2057, 0.6955, 0.3573, 0.2302, 0.6447, 0.2035, 0.4179, 0.2194,\n",
      "        0.2124, 0.2297, 0.2133, 0.2150, 0.2189, 0.5337, 0.2684, 0.5268]), 'labels': tensor([15,  0,  8, 15, 15, 15, 15, 10,  8,  0, 11, 11, 15,  6, 11,  7,  7],\n",
      "       dtype=torch.int32)}\n",
      "397327\n",
      "{'image_id': 397354, 'boxes': tensor([[ 83, 270, 131, 374]], dtype=torch.int32), 'scores': tensor([0.8276]), 'objectness_scores': tensor([0.2976]), 'labels': tensor([10], dtype=torch.int32)}\n",
      "397354\n",
      "{'image_id': 397681, 'boxes': tensor([[417, 207, 423, 213],\n",
      "        [130, 393, 183, 435],\n",
      "        [291,  29, 338,  91],\n",
      "        [130, 143, 205, 183]], dtype=torch.int32), 'scores': tensor([0.1908, 0.2706, 0.8924, 0.3597]), 'objectness_scores': tensor([0.3443, 0.3548, 0.3872, 0.4245]), 'labels': tensor([11,  7, 12, 11], dtype=torch.int32)}\n",
      "397681\n",
      "{'image_id': 398377, 'boxes': tensor([[199, 151, 235, 177],\n",
      "        [199, 151, 243, 213],\n",
      "        [193,  83, 235, 113],\n",
      "        [ 41, 167,  71, 195],\n",
      "        [ 19, 130,  32, 149],\n",
      "        [  0, 155, 152, 354]], dtype=torch.int32), 'scores': tensor([0.3644, 0.8267, 0.1992, 0.4565, 0.3262, 0.3521]), 'objectness_scores': tensor([0.3292, 0.2908, 0.4195, 0.4348, 0.3772, 0.2190]), 'labels': tensor([ 7,  7, 10,  7, 11,  7], dtype=torch.int32)}\n",
      "398377\n",
      "{'image_id': 398438, 'boxes': tensor([[  0,   3, 176, 291],\n",
      "        [  0, 169,  91, 260],\n",
      "        [156, 184, 229, 227],\n",
      "        [  0, 172, 176, 289],\n",
      "        [ 15,  69, 107, 132],\n",
      "        [  0,   2, 171, 322],\n",
      "        [  1,  11, 145,  88]], dtype=torch.int32), 'scores': tensor([0.9721, 0.7029, 0.4612, 0.3933, 0.8009, 0.9677, 0.7976]), 'objectness_scores': tensor([0.2344, 0.2051, 0.4644, 0.2095, 0.2212, 0.4768, 0.2385]), 'labels': tensor([12, 12, 11, 12, 12, 12, 12], dtype=torch.int32)}\n",
      "398438\n",
      "{'image_id': 399560, 'boxes': tensor([[  4,  -1, 631, 469],\n",
      "        [145, 115, 606, 334],\n",
      "        [  0,   0, 200, 100]], dtype=torch.int32), 'scores': tensor([0.9165, 0.9612, 0.3122]), 'objectness_scores': tensor([0.4479, 0.4533, 0.3985]), 'labels': tensor([ 2,  2, 10], dtype=torch.int32)}\n",
      "399560\n",
      "{'image_id': 399764, 'boxes': tensor([[293, 346, 376, 430],\n",
      "        [  0, 348,  66, 530],\n",
      "        [320,  48, 401,  77],\n",
      "        [138,  81, 408, 500]], dtype=torch.int32), 'scores': tensor([0.4999, 0.9420, 0.4600, 0.9542]), 'objectness_scores': tensor([0.2453, 0.2366, 0.2081, 0.2155]), 'labels': tensor([ 7,  7, 16,  4], dtype=torch.int32)}\n",
      "399764\n",
      "{'image_id': 400044, 'boxes': tensor([[287, 484, 331, 537],\n",
      "        [398, 475, 433, 502],\n",
      "        [242, 310, 275, 330],\n",
      "        [285, 324, 325, 352],\n",
      "        [282, 315, 326, 354],\n",
      "        [336, 506, 364, 538],\n",
      "        [365, 467, 431, 515]], dtype=torch.int32), 'scores': tensor([0.8432, 0.5022, 0.2622, 0.2974, 0.9321, 0.3276, 0.5894]), 'objectness_scores': tensor([0.4742, 0.2133, 0.4693, 0.5968, 0.4638, 0.3219, 0.3904]), 'labels': tensor([ 8,  4,  8, 16,  8,  8,  8], dtype=torch.int32)}\n",
      "400044\n",
      "{'image_id': 400082, 'boxes': tensor([[ 26,  20, 213, 197],\n",
      "        [422,  47, 433,  56],\n",
      "        [248,   3, 423, 152],\n",
      "        [380,  83, 498, 240],\n",
      "        [257,  71, 392, 140],\n",
      "        [ 71,  92, 194, 173]], dtype=torch.int32), 'scores': tensor([0.4969, 0.2938, 0.2824, 0.9860, 0.4012, 0.4236]), 'objectness_scores': tensor([0.3785, 0.2863, 0.3411, 0.4490, 0.3436, 0.2192]), 'labels': tensor([ 3, 11,  7, 10,  7, 11], dtype=torch.int32)}\n",
      "400082\n",
      "{'image_id': 400922, 'boxes': tensor([[249, 202, 384, 287],\n",
      "        [286, 374, 328, 414],\n",
      "        [559, 436, 589, 480]], dtype=torch.int32), 'scores': tensor([0.9709, 0.6239, 0.2305]), 'objectness_scores': tensor([0.2789, 0.2426, 0.2144]), 'labels': tensor([14,  6,  1], dtype=torch.int32)}\n",
      "400922\n",
      "{'image_id': 401446, 'boxes': tensor([[286, 147, 326, 167],\n",
      "        [298, 433, 323, 470],\n",
      "        [251, 155, 376, 307],\n",
      "        [394, 261, 443, 403],\n",
      "        [154,   1, 370, 122],\n",
      "        [321, 417, 351, 459],\n",
      "        [452, 269, 545, 324],\n",
      "        [305,  21, 349,  32]], dtype=torch.int32), 'scores': tensor([0.3721, 0.4367, 0.4396, 0.3030, 0.9652, 0.3530, 0.7352, 0.4252]), 'objectness_scores': tensor([0.3237, 0.3003, 0.3098, 0.2427, 0.4896, 0.3179, 0.2108, 0.3670]), 'labels': tensor([11,  4,  7,  6,  6, 11,  4, 11], dtype=torch.int32)}\n",
      "401446\n",
      "{'image_id': 401991, 'boxes': tensor([[388,   0, 618,  73],\n",
      "        [189, 129, 437, 318],\n",
      "        [415, 246, 579, 354],\n",
      "        [192, 131, 576, 350]], dtype=torch.int32), 'scores': tensor([0.4662, 0.9589, 0.9831, 0.9665]), 'objectness_scores': tensor([0.4252, 0.3879, 0.2547, 0.3015]), 'labels': tensor([7, 3, 3, 3], dtype=torch.int32)}\n",
      "401991\n",
      "{'image_id': 402118, 'boxes': tensor([[408, 261, 459, 289],\n",
      "        [260,  66, 314, 112],\n",
      "        [289, 281, 332, 306],\n",
      "        [187, 170, 218, 206],\n",
      "        [262,  72, 314, 116],\n",
      "        [450,  75, 487,  97]], dtype=torch.int32), 'scores': tensor([0.5870, 0.3082, 0.3686, 0.1716, 0.2436, 0.3046]), 'objectness_scores': tensor([0.3134, 0.4634, 0.2913, 0.6268, 0.2619, 0.5124]), 'labels': tensor([11,  8, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "402118\n",
      "{'image_id': 402720, 'boxes': tensor([[129, 490, 218, 530],\n",
      "        [464, 460, 489, 487],\n",
      "        [186, 334, 215, 409],\n",
      "        [581, 276, 607, 329],\n",
      "        [130, 415, 227, 489],\n",
      "        [493, 308, 538, 327],\n",
      "        [493, 290, 608, 371],\n",
      "        [247, 401, 265, 464],\n",
      "        [ 99, 400, 461, 533],\n",
      "        [462, 322, 512, 378],\n",
      "        [115, 434, 230, 494],\n",
      "        [291, 414, 328, 485],\n",
      "        [ 96, 394, 576, 532],\n",
      "        [424, 471, 429, 481],\n",
      "        [257, 423, 303, 537],\n",
      "        [275, 382, 295, 410],\n",
      "        [207, 344, 245, 439],\n",
      "        [235, 401, 265, 464],\n",
      "        [290, 414, 318, 450],\n",
      "        [493, 289, 610, 429],\n",
      "        [295, 412, 346, 533],\n",
      "        [530, 294, 590, 311],\n",
      "        [401, 379, 449, 501]], dtype=torch.int32), 'scores': tensor([0.2126, 0.4243, 0.1951, 0.4197, 0.7070, 0.5620, 0.2684, 0.3866, 0.3372,\n",
      "        0.3116, 0.7457, 0.4730, 0.6168, 0.1444, 0.8060, 0.1635, 0.9422, 0.6321,\n",
      "        0.1355, 0.3777, 0.6768, 0.8665, 0.2566]), 'objectness_scores': tensor([0.4053, 0.5988, 0.5265, 0.5353, 0.3339, 0.5398, 0.3023, 0.2038, 0.3543,\n",
      "        0.6666, 0.5745, 0.2594, 0.2829, 0.4475, 0.5538, 0.4673, 0.5923, 0.3360,\n",
      "        0.2104, 0.2081, 0.5842, 0.5694, 0.5659]), 'labels': tensor([11, 14, 11, 10, 12, 11, 11, 11,  7,  7, 12, 10,  7, 11, 10, 11, 10, 11,\n",
      "         2,  7, 10, 11,  7], dtype=torch.int32)}\n",
      "402720\n",
      "{'image_id': 402774, 'boxes': tensor([[136, 337, 239, 601],\n",
      "        [107,  25, 366, 196],\n",
      "        [129, 167, 271, 378]], dtype=torch.int32), 'scores': tensor([0.8326, 0.9999, 0.2836]), 'objectness_scores': tensor([0.2418, 0.4848, 0.2718]), 'labels': tensor([7, 6, 7], dtype=torch.int32)}\n",
      "402774\n",
      "{'image_id': 403385, 'boxes': tensor([[288,  27, 391, 484],\n",
      "        [ 36,  88,  69, 173],\n",
      "        [ 99, 188, 209, 506],\n",
      "        [440, 189, 456, 204],\n",
      "        [602, 339, 636, 372],\n",
      "        [195, 218, 238, 233],\n",
      "        [167, 354, 298, 456],\n",
      "        [  2, 313, 145, 398],\n",
      "        [385, 343, 397, 408],\n",
      "        [435, 211, 459, 237],\n",
      "        [462,  97, 548, 183],\n",
      "        [574, 290, 617, 359],\n",
      "        [  4,   4, 635, 512],\n",
      "        [  9, 280,  45, 334],\n",
      "        [412, 212, 436, 238],\n",
      "        [576, 318, 616, 359],\n",
      "        [583, 290, 615, 328],\n",
      "        [  0,  62,  71, 177]], dtype=torch.int32), 'scores': tensor([0.7497, 0.2393, 0.5328, 0.2455, 0.3765, 0.2269, 0.9482, 0.9954, 0.3887,\n",
      "        0.2183, 0.2768, 0.4143, 0.9182, 0.9667, 0.2020, 0.4840, 0.5012, 0.5748]), 'objectness_scores': tensor([0.3487, 0.3519, 0.3105, 0.2369, 0.3638, 0.2469, 0.2453, 0.4740, 0.2528,\n",
      "        0.2800, 0.3685, 0.2957, 0.2399, 0.3317, 0.2585, 0.2102, 0.5318, 0.3598]), 'labels': tensor([ 7, 11, 15, 14, 11,  0, 15, 15, 11, 11,  2, 15, 15, 15, 11, 11, 10, 15],\n",
      "       dtype=torch.int32)}\n",
      "403385\n",
      "{'image_id': 403817, 'boxes': tensor([[192,   1, 315, 139],\n",
      "        [170,  66, 324, 377],\n",
      "        [213, 157, 298, 180],\n",
      "        [211,  64, 224,  75],\n",
      "        [ 45,  65, 326, 376]], dtype=torch.int32), 'scores': tensor([0.9447, 0.7259, 0.2680, 0.2423, 0.8767]), 'objectness_scores': tensor([0.2070, 0.2219, 0.2599, 0.2538, 0.4329]), 'labels': tensor([ 2,  2,  8, 11,  2], dtype=torch.int32)}\n",
      "403817\n",
      "{'image_id': 404249, 'boxes': tensor([[ 48, 190, 277, 334],\n",
      "        [111, 330, 208, 501],\n",
      "        [ 90, 483, 227, 560]], dtype=torch.int32), 'scores': tensor([0.2721, 0.6177, 0.9942]), 'objectness_scores': tensor([0.2240, 0.2027, 0.6563]), 'labels': tensor([9, 7, 9], dtype=torch.int32)}\n",
      "404249\n",
      "{'image_id': 404479, 'boxes': tensor([[187, 230, 626, 366],\n",
      "        [234, 318, 293, 345],\n",
      "        [363, 309, 420, 343]], dtype=torch.int32), 'scores': tensor([0.9918, 0.9992, 0.2533]), 'objectness_scores': tensor([0.5818, 0.2001, 0.2426]), 'labels': tensor([ 0, 14, 10], dtype=torch.int32)}\n",
      "404479\n",
      "{'image_id': 404484, 'boxes': tensor([[ 53, 115,  91, 146],\n",
      "        [111, 126, 123, 141],\n",
      "        [  0,   0,  65, 191],\n",
      "        [  0, 136, 306, 239],\n",
      "        [ 86,  91, 169, 164],\n",
      "        [ 56, 130,  88, 146],\n",
      "        [217,  77, 310, 150]], dtype=torch.int32), 'scores': tensor([0.4906, 0.1759, 0.2928, 0.5141, 0.8835, 0.2810, 0.1461]), 'objectness_scores': tensor([0.4007, 0.2046, 0.2344, 0.3935, 0.4879, 0.2286, 0.5710]), 'labels': tensor([ 2, 11, 11,  3,  3,  3, 10], dtype=torch.int32)}\n",
      "404484\n",
      "{'image_id': 404678, 'boxes': tensor([[224, 160, 411, 263],\n",
      "        [395, 266, 445, 307],\n",
      "        [322, 239, 353, 305],\n",
      "        [314, 287, 391, 321],\n",
      "        [362, 215, 388, 269],\n",
      "        [347, 160, 362, 192],\n",
      "        [371, 167, 386, 176]], dtype=torch.int32), 'scores': tensor([0.2835, 0.7477, 0.4369, 0.7105, 0.8253, 0.2928, 0.3246]), 'objectness_scores': tensor([0.2061, 0.2164, 0.2094, 0.2307, 0.2315, 0.2189, 0.2756]), 'labels': tensor([12,  7, 10, 11, 10, 11, 11], dtype=torch.int32)}\n",
      "404678\n",
      "{'image_id': 405205, 'boxes': tensor([[ 59, 139,  76, 199],\n",
      "        [ 63,  17, 509, 369]], dtype=torch.int32), 'scores': tensor([0.2228, 0.5985]), 'objectness_scores': tensor([0.2205, 0.6304]), 'labels': tensor([11, 11], dtype=torch.int32)}\n",
      "405205\n",
      "{'image_id': 405249, 'boxes': tensor([[249, 175, 395, 337],\n",
      "        [  2, 156, 487, 375],\n",
      "        [ 76, 137,  86, 164],\n",
      "        [102, 271, 128, 291],\n",
      "        [475,  25, 480,  31],\n",
      "        [ 65, 145,  71, 173],\n",
      "        [ 54, 144, 145, 203],\n",
      "        [171, 146, 368, 231]], dtype=torch.int32), 'scores': tensor([0.3837, 0.4207, 0.2255, 0.2387, 0.2522, 0.1911, 0.9996, 0.7859]), 'objectness_scores': tensor([0.2080, 0.3140, 0.2050, 0.2248, 0.2058, 0.2099, 0.5069, 0.3502]), 'labels': tensor([ 7, 12, 11,  8, 11, 11, 12, 12], dtype=torch.int32)}\n",
      "405249\n",
      "{'image_id': 405306, 'boxes': tensor([[ 18,   2, 468, 341]], dtype=torch.int32), 'scores': tensor([0.9901]), 'objectness_scores': tensor([0.2569]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "405306\n",
      "{'image_id': 405970, 'boxes': tensor([[313, 205, 320, 213],\n",
      "        [558, 154, 621, 207],\n",
      "        [292, 206, 299, 213],\n",
      "        [  9, 211,  79, 333],\n",
      "        [617, 158, 625, 171],\n",
      "        [574, 200, 640, 263],\n",
      "        [339, 262, 554, 393],\n",
      "        [557, 153, 584, 180],\n",
      "        [416, 225, 505, 269],\n",
      "        [367, 189, 387, 212],\n",
      "        [349, 190, 368, 212],\n",
      "        [302, 206, 310, 213],\n",
      "        [501, 204, 639, 337],\n",
      "        [559, 154, 599, 180],\n",
      "        [232, 292, 596, 425],\n",
      "        [  7, 333, 155, 426],\n",
      "        [ 14, 373, 139, 427],\n",
      "        [162, 211, 397, 278],\n",
      "        [  2, 314, 117, 425]], dtype=torch.int32), 'scores': tensor([0.1899, 0.5112, 0.2740, 0.3505, 0.1661, 0.9942, 0.2334, 0.2561, 0.3768,\n",
      "        0.2328, 0.3324, 0.3272, 0.4702, 0.3127, 0.2157, 0.8768, 0.5663, 0.3312,\n",
      "        0.8992]), 'objectness_scores': tensor([0.2734, 0.2333, 0.2844, 0.2964, 0.5952, 0.4244, 0.5696, 0.2960, 0.7141,\n",
      "        0.2685, 0.2669, 0.2372, 0.5017, 0.2512, 0.3880, 0.2715, 0.2654, 0.3956,\n",
      "        0.4786]), 'labels': tensor([14, 13, 14,  6, 11, 13, 15,  6, 13,  8,  8, 11, 12, 10, 13,  2, 13,  9,\n",
      "         2], dtype=torch.int32)}\n",
      "405970\n",
      "{'image_id': 406417, 'boxes': tensor([[ 61, 332,  89, 356],\n",
      "        [233, 407, 300, 429],\n",
      "        [435, 431, 498, 453],\n",
      "        [219, 317, 265, 421],\n",
      "        [ 49, 441, 144, 637],\n",
      "        [ 74, 440, 145, 462],\n",
      "        [377, 432, 513, 637]], dtype=torch.int32), 'scores': tensor([0.4857, 0.3810, 0.4066, 0.9601, 0.2064, 0.3280, 0.3189]), 'objectness_scores': tensor([0.4201, 0.5786, 0.5620, 0.6432, 0.2053, 0.5428, 0.2132]), 'labels': tensor([ 7,  7, 11,  7, 11, 11, 11], dtype=torch.int32)}\n",
      "406417\n",
      "{'image_id': 407083, 'boxes': tensor([[  5, 216, 413, 639],\n",
      "        [213, 282, 329, 395],\n",
      "        [280,  91, 402, 153],\n",
      "        [159, 334, 313, 407],\n",
      "        [112, 283, 153, 342]], dtype=torch.int32), 'scores': tensor([0.9532, 0.6753, 0.2797, 0.4755, 0.4230]), 'objectness_scores': tensor([0.5063, 0.2704, 0.2396, 0.2683, 0.3154]), 'labels': tensor([3, 3, 9, 7, 8], dtype=torch.int32)}\n",
      "407083\n",
      "{'image_id': 407614, 'boxes': tensor([[357, 251, 379, 301],\n",
      "        [357, 223, 403, 251],\n",
      "        [139, 366, 162, 382],\n",
      "        [570,  73, 620, 140],\n",
      "        [192, 182, 201, 195],\n",
      "        [347, 246, 366, 286],\n",
      "        [370,   1, 526, 124],\n",
      "        [ 97,  30, 115, 134],\n",
      "        [132, 354, 200, 418],\n",
      "        [269, 214, 336, 223],\n",
      "        [264, 227, 349, 314],\n",
      "        [142, 226, 196, 314],\n",
      "        [339, 244, 356, 282],\n",
      "        [221, 182, 233, 194],\n",
      "        [145,  45, 265, 169],\n",
      "        [340,  59, 398, 176],\n",
      "        [114,  22, 133, 184],\n",
      "        [306,  12, 337,  49],\n",
      "        [269,  56, 345, 142]], dtype=torch.int32), 'scores': tensor([0.3678, 0.7859, 0.2228, 0.4041, 0.2127, 0.4430, 0.1854, 0.6416, 0.5084,\n",
      "        0.2384, 0.1490, 0.6287, 0.3262, 0.8375, 0.2754, 0.1990, 0.5004, 0.4183,\n",
      "        0.1945]), 'objectness_scores': tensor([0.2634, 0.2713, 0.2658, 0.3155, 0.3934, 0.2076, 0.2134, 0.2547, 0.3716,\n",
      "        0.2316, 0.3396, 0.2764, 0.2747, 0.4338, 0.2954, 0.3096, 0.2912, 0.2548,\n",
      "        0.2553]), 'labels': tensor([ 7, 14, 12,  7, 14,  7, 10, 11, 10, 11,  7,  9, 11, 14,  8,  7, 11,  6,\n",
      "         8], dtype=torch.int32)}\n",
      "407614\n",
      "{'image_id': 407650, 'boxes': tensor([[323, 284, 338, 294],\n",
      "        [329, 210, 342, 228],\n",
      "        [284, 273, 303, 286],\n",
      "        [327, 218, 341, 233],\n",
      "        [291, 212, 356, 289]], dtype=torch.int32), 'scores': tensor([0.1762, 0.2006, 0.4606, 0.1646, 0.9960]), 'objectness_scores': tensor([0.2564, 0.3542, 0.2979, 0.4301, 0.2187]), 'labels': tensor([11,  8,  7, 11,  4], dtype=torch.int32)}\n",
      "407650\n",
      "{'image_id': 407943, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "407943\n",
      "{'image_id': 407960, 'boxes': tensor([[493, 106, 602, 319],\n",
      "        [  0, 141, 125, 194],\n",
      "        [ 52, 152, 352, 377]], dtype=torch.int32), 'scores': tensor([0.3646, 0.3383, 0.9878]), 'objectness_scores': tensor([0.5602, 0.3210, 0.5430]), 'labels': tensor([ 7, 11,  2], dtype=torch.int32)}\n",
      "407960\n",
      "{'image_id': 408112, 'boxes': tensor([[  0, 101, 407, 324],\n",
      "        [412, 169, 620, 240],\n",
      "        [  2, 100,  34, 285],\n",
      "        [434, 251, 445, 268],\n",
      "        [457, 364, 504, 431]], dtype=torch.int32), 'scores': tensor([0.9898, 0.9692, 0.2426, 0.2441, 0.2374]), 'objectness_scores': tensor([0.4966, 0.5182, 0.4579, 0.8437, 0.7043]), 'labels': tensor([ 0,  0, 13,  7, 10], dtype=torch.int32)}\n",
      "408112\n",
      "{'image_id': 408120, 'boxes': tensor([[292, 121, 316, 167],\n",
      "        [309, 188, 316, 197],\n",
      "        [292, 199, 301, 207]], dtype=torch.int32), 'scores': tensor([0.2724, 0.2585, 0.1242]), 'objectness_scores': tensor([0.2590, 0.2041, 0.2181]), 'labels': tensor([ 7, 11, 14], dtype=torch.int32)}\n",
      "408120\n",
      "{'image_id': 409358, 'boxes': tensor([[560, 241, 607, 374],\n",
      "        [  3,   6, 607, 612],\n",
      "        [378,   0, 512, 184],\n",
      "        [317, 349, 611, 434],\n",
      "        [412, 125, 442, 186],\n",
      "        [240,   0, 608, 192],\n",
      "        [386,  20, 437,  62],\n",
      "        [303, 347, 611, 612]], dtype=torch.int32), 'scores': tensor([0.5843, 0.9905, 0.2144, 0.2092, 0.5955, 0.5968, 0.2020, 0.9125]), 'objectness_scores': tensor([0.5872, 0.2071, 0.2397, 0.2504, 0.2759, 0.3728, 0.2343, 0.4098]), 'labels': tensor([ 9, 15, 11, 11,  7, 15,  6, 15], dtype=torch.int32)}\n",
      "409358\n",
      "{'image_id': 409630, 'boxes': tensor([[  2,   3, 497, 387],\n",
      "        [ 76,   4,  86,  20],\n",
      "        [ 27, 140, 386, 288],\n",
      "        [110,   1, 347,  44],\n",
      "        [371,   0, 406,  29],\n",
      "        [370,   0, 404,  20]], dtype=torch.int32), 'scores': tensor([0.9896, 0.1298, 0.9992, 0.9891, 0.3835, 0.3100]), 'objectness_scores': tensor([0.3222, 0.2437, 0.7429, 0.3674, 0.2439, 0.2052]), 'labels': tensor([14, 11, 14, 14, 14,  0], dtype=torch.int32)}\n",
      "409630\n",
      "{'image_id': 411530, 'boxes': tensor([[492, 434, 507, 456]], dtype=torch.int32), 'scores': tensor([0.1834]), 'objectness_scores': tensor([0.2031]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "411530\n",
      "{'image_id': 411938, 'boxes': tensor([[209, 149, 226, 156],\n",
      "        [410, 144, 451, 167],\n",
      "        [118, 224, 149, 277]], dtype=torch.int32), 'scores': tensor([0.2066, 0.2621, 0.7267]), 'objectness_scores': tensor([0.2182, 0.2265, 0.3880]), 'labels': tensor([11, 10, 10], dtype=torch.int32)}\n",
      "411938\n",
      "{'image_id': 411953, 'boxes': tensor([[174,  72, 193,  96],\n",
      "        [ 26,  58,  64,  96],\n",
      "        [180, 163, 242, 341],\n",
      "        [ 70,  67, 104,  99],\n",
      "        [210, 219, 470, 376],\n",
      "        [257, 100, 305, 158],\n",
      "        [382,  77, 412, 114]], dtype=torch.int32), 'scores': tensor([0.2683, 0.2924, 0.2695, 0.1665, 0.4534, 0.1806, 0.1726]), 'objectness_scores': tensor([0.2084, 0.2396, 0.4132, 0.2311, 0.5103, 0.3978, 0.2166]), 'labels': tensor([11,  7, 11, 10,  7, 11,  8], dtype=torch.int32)}\n",
      "411953\n",
      "{'image_id': 412362, 'boxes': tensor([[449, 213, 642, 498],\n",
      "        [460, 362, 511, 477],\n",
      "        [384, 298, 431, 350],\n",
      "        [110, 417, 156, 493],\n",
      "        [190,  22, 288, 137],\n",
      "        [166, 139, 199, 186],\n",
      "        [152, 484, 160, 498],\n",
      "        [325, 241, 356, 391],\n",
      "        [ 89, 171, 175, 193]], dtype=torch.int32), 'scores': tensor([0.9261, 0.5409, 0.3693, 0.9174, 0.1880, 0.1932, 0.1799, 0.3116, 0.1836]), 'objectness_scores': tensor([0.2225, 0.4501, 0.2351, 0.3203, 0.3797, 0.2231, 0.4479, 0.2433, 0.2081]), 'labels': tensor([ 7, 10,  7, 10,  6,  7,  7, 11,  7], dtype=torch.int32)}\n",
      "412362\n",
      "{'image_id': 413395, 'boxes': tensor([[ 33, 239, 193, 422],\n",
      "        [175, 197, 383, 419],\n",
      "        [413, 227, 459, 314],\n",
      "        [357, 333, 422, 378],\n",
      "        [ 34, 209, 377, 422]], dtype=torch.int32), 'scores': tensor([0.9788, 0.9518, 0.4651, 0.5779, 0.8910]), 'objectness_scores': tensor([0.2643, 0.4384, 0.3327, 0.2311, 0.3291]), 'labels': tensor([ 2,  2, 16,  7,  2], dtype=torch.int32)}\n",
      "413395\n",
      "{'image_id': 413689, 'boxes': tensor([[402, 113, 412, 129],\n",
      "        [332, 158, 425, 203],\n",
      "        [433, 139, 523, 199],\n",
      "        [555, 174, 565, 192],\n",
      "        [317,  60, 342,  73]], dtype=torch.int32), 'scores': tensor([0.4288, 0.9993, 0.9935, 0.2970, 0.3423]), 'objectness_scores': tensor([0.2331, 0.3509, 0.3509, 0.4178, 0.2003]), 'labels': tensor([14,  6,  6, 11, 14], dtype=torch.int32)}\n",
      "413689\n",
      "{'image_id': 414034, 'boxes': tensor([[137,   0, 397, 110],\n",
      "        [138, 139, 359, 442],\n",
      "        [  1, 209, 154, 327],\n",
      "        [618, 198, 640, 218],\n",
      "        [  1, 262,  83, 382]], dtype=torch.int32), 'scores': tensor([0.3461, 0.6330, 0.9751, 0.3703, 0.7515]), 'objectness_scores': tensor([0.3300, 0.2320, 0.3723, 0.4604, 0.2581]), 'labels': tensor([ 5,  7, 13, 14, 13], dtype=torch.int32)}\n",
      "414034\n",
      "{'image_id': 414385, 'boxes': tensor([[153, 292, 165, 302],\n",
      "        [203, 294, 215, 304],\n",
      "        [ 29, 287,  46, 296],\n",
      "        [442, 347, 465, 378]], dtype=torch.int32), 'scores': tensor([0.1373, 0.2788, 0.1799, 0.1821]), 'objectness_scores': tensor([0.2218, 0.2311, 0.2612, 0.2123]), 'labels': tensor([11, 11, 11,  9], dtype=torch.int32)}\n",
      "414385\n",
      "{'image_id': 414638, 'boxes': tensor([[488, 264, 550, 611],\n",
      "        [ 34, 156, 487, 589],\n",
      "        [108, 204, 334, 341],\n",
      "        [419, 296, 613, 610],\n",
      "        [ 25,   0, 218, 185],\n",
      "        [  7,   9, 610, 609]], dtype=torch.int32), 'scores': tensor([0.6340, 0.9502, 0.9913, 0.8612, 0.9630, 0.6087]), 'objectness_scores': tensor([0.5690, 0.2915, 0.2202, 0.3734, 0.4131, 0.2146]), 'labels': tensor([11, 12, 12, 11, 10, 12], dtype=torch.int32)}\n",
      "414638\n",
      "{'image_id': 414795, 'boxes': tensor([[520, 313, 640, 453],\n",
      "        [415,  98, 516, 140],\n",
      "        [335,  94, 360, 135],\n",
      "        [277,  23, 506, 159],\n",
      "        [388,  62, 419,  87],\n",
      "        [502, 240, 605, 285],\n",
      "        [251, 237, 422, 326],\n",
      "        [326, 217, 488, 298],\n",
      "        [453, 201, 564, 279],\n",
      "        [427, 452, 545, 480],\n",
      "        [427, 135, 542, 192],\n",
      "        [426,  52, 467,  99],\n",
      "        [560, 264, 639, 316],\n",
      "        [172, 422, 183, 433],\n",
      "        [329, 384, 520, 468],\n",
      "        [170, 211, 321, 269],\n",
      "        [567, 199, 640, 257],\n",
      "        [541, 462, 551, 469],\n",
      "        [408, 274, 576, 351],\n",
      "        [617, 153, 639, 189],\n",
      "        [ 11, 187, 639, 469],\n",
      "        [  0, 329,  60, 375],\n",
      "        [  0, 349, 197, 459],\n",
      "        [424,  15, 489,  54],\n",
      "        [409, 298, 603, 434],\n",
      "        [468,  28, 490,  55],\n",
      "        [ 82, 260, 261, 339],\n",
      "        [507, 196, 565, 242],\n",
      "        [400,  80, 458, 120],\n",
      "        [181, 335, 404, 464],\n",
      "        [322, 207, 406, 243],\n",
      "        [  1, 166, 132, 212],\n",
      "        [425,  16, 471,  51],\n",
      "        [130, 192, 280, 266],\n",
      "        [354, 404, 418, 479],\n",
      "        [605, 214, 639, 274],\n",
      "        [274, 308, 424, 397],\n",
      "        [413, 389, 523, 464],\n",
      "        [ 86, 274, 289, 373]], dtype=torch.int32), 'scores': tensor([0.9986, 0.9582, 0.3990, 0.9990, 0.4102, 0.1575, 0.3885, 0.7977, 0.7006,\n",
      "        0.1839, 0.9634, 0.2215, 0.5042, 0.1781, 0.3040, 0.6035, 0.4998, 0.1245,\n",
      "        0.4116, 0.2311, 0.2555, 0.2785, 0.9877, 0.3757, 0.7494, 0.1803, 0.4579,\n",
      "        0.3492, 0.5780, 0.9670, 0.1340, 0.2515, 0.4814, 0.3280, 0.4957, 0.2013,\n",
      "        0.8174, 0.8750, 0.4492]), 'objectness_scores': tensor([0.4548, 0.5238, 0.2398, 0.2002, 0.5126, 0.4749, 0.4341, 0.4401, 0.3333,\n",
      "        0.4097, 0.5286, 0.3675, 0.3650, 0.4043, 0.2733, 0.4728, 0.5226, 0.2198,\n",
      "        0.4046, 0.3540, 0.2670, 0.3505, 0.5037, 0.5100, 0.5031, 0.4596, 0.4918,\n",
      "        0.2265, 0.5535, 0.4774, 0.3753, 0.2345, 0.2975, 0.4815, 0.2846, 0.2008,\n",
      "        0.3908, 0.3382, 0.3433]), 'labels': tensor([ 5,  5,  5,  5,  3, 10,  5,  5,  5, 11,  5,  3,  5, 14,  5,  5,  3, 11,\n",
      "         4,  2, 11,  3,  5,  5,  3,  3,  5,  9,  3,  5, 10, 11,  2,  3,  7,  3,\n",
      "         5,  5,  4], dtype=torch.int32)}\n",
      "414795\n",
      "{'image_id': 415194, 'boxes': tensor([[  0,  89,  46, 132],\n",
      "        [582, 181, 627, 199],\n",
      "        [356, 159, 384, 193]], dtype=torch.int32), 'scores': tensor([0.6269, 0.7306, 0.2808]), 'objectness_scores': tensor([0.2043, 0.2246, 0.2398]), 'labels': tensor([ 7, 11, 11], dtype=torch.int32)}\n",
      "415194\n",
      "{'image_id': 415536, 'boxes': tensor([[287, 228, 298, 258]], dtype=torch.int32), 'scores': tensor([0.1850]), 'objectness_scores': tensor([0.2160]), 'labels': tensor([0], dtype=torch.int32)}\n",
      "415536\n",
      "{'image_id': 415716, 'boxes': tensor([[224, 145, 377, 292],\n",
      "        [500, 115, 605, 485],\n",
      "        [ 90, 257, 361, 449],\n",
      "        [506, 113, 604, 193],\n",
      "        [133, 185, 156, 254]], dtype=torch.int32), 'scores': tensor([0.3893, 0.4976, 0.8857, 0.6287, 0.1714]), 'objectness_scores': tensor([0.3159, 0.3697, 0.3393, 0.2949, 0.2235]), 'labels': tensor([10,  7,  3, 14,  2], dtype=torch.int32)}\n",
      "415716\n",
      "{'image_id': 415748, 'boxes': tensor([[ 84, 191, 269, 296],\n",
      "        [ 40, 311, 310, 614]], dtype=torch.int32), 'scores': tensor([0.3492, 0.9994]), 'objectness_scores': tensor([0.3221, 0.6902]), 'labels': tensor([5, 5], dtype=torch.int32)}\n",
      "415748\n",
      "{'image_id': 415990, 'boxes': tensor([[358, 174, 427, 229],\n",
      "        [ 65, 190,  83, 222],\n",
      "        [291, 169, 302, 178],\n",
      "        [ 60, 167,  93, 186],\n",
      "        [  4, 165, 489, 231],\n",
      "        [ 82, 168,  93, 183],\n",
      "        [468, 201, 488, 232],\n",
      "        [319, 192, 357, 227],\n",
      "        [  6, 168,  47, 220],\n",
      "        [452, 157, 462, 166],\n",
      "        [262, 171, 301, 230],\n",
      "        [429, 202, 486, 234],\n",
      "        [191, 171, 226, 195],\n",
      "        [119, 174, 133, 184],\n",
      "        [313, 159, 324, 170],\n",
      "        [416, 173, 485, 234],\n",
      "        [  5, 197, 497, 231],\n",
      "        [275, 170, 306, 187],\n",
      "        [477, 177, 498, 226],\n",
      "        [ 45, 168,  88, 216],\n",
      "        [159, 172, 221, 229],\n",
      "        [272, 170, 323, 230],\n",
      "        [227, 173, 284, 231],\n",
      "        [391, 171, 404, 178],\n",
      "        [395, 204, 428, 228],\n",
      "        [389, 172, 409, 178],\n",
      "        [123, 172, 182, 223],\n",
      "        [222, 174, 239, 195],\n",
      "        [327, 170, 344, 190],\n",
      "        [322, 193, 338, 226],\n",
      "        [374, 173, 422, 227],\n",
      "        [417, 174, 482, 233]], dtype=torch.int32), 'scores': tensor([0.9992, 0.3340, 0.1904, 0.8386, 0.9941, 0.4596, 0.3528, 0.5741, 0.9851,\n",
      "        0.2342, 0.7572, 0.3147, 0.6632, 0.1801, 0.2123, 0.9976, 0.9815, 0.3086,\n",
      "        0.2032, 0.9957, 0.9977, 0.9948, 0.9966, 0.1645, 0.4587, 0.1208, 0.9920,\n",
      "        0.6677, 0.1715, 0.1789, 0.9963, 0.9967]), 'objectness_scores': tensor([0.5851, 0.2295, 0.2333, 0.2166, 0.3132, 0.2168, 0.2400, 0.2151, 0.6063,\n",
      "        0.2501, 0.2845, 0.2151, 0.3109, 0.3322, 0.2438, 0.5583, 0.2096, 0.2107,\n",
      "        0.3349, 0.5781, 0.6108, 0.4649, 0.6109, 0.2062, 0.2002, 0.2978, 0.5559,\n",
      "        0.2671, 0.3099, 0.4627, 0.2654, 0.2118]), 'labels': tensor([ 4,  4, 11,  4,  4,  4,  4,  4,  4, 11,  4,  7,  4, 11,  4,  4,  4,  4,\n",
      "        11,  4,  4,  4,  4, 11, 11, 11,  4,  4, 11,  4,  4,  4],\n",
      "       dtype=torch.int32)}\n",
      "415990\n",
      "{'image_id': 416104, 'boxes': tensor([[129, 161, 266, 247],\n",
      "        [  0, 347,  19, 357],\n",
      "        [489, 182, 577, 215],\n",
      "        [123, 159, 282, 251],\n",
      "        [ 11, 317,  94, 455]], dtype=torch.int32), 'scores': tensor([0.7811, 0.2646, 0.2825, 0.8935, 0.3080]), 'objectness_scores': tensor([0.2466, 0.2053, 0.2403, 0.2064, 0.2284]), 'labels': tensor([12, 11,  8, 12,  8], dtype=torch.int32)}\n",
      "416104\n",
      "{'image_id': 416330, 'boxes': tensor([[118,  18, 503, 154]], dtype=torch.int32), 'scores': tensor([0.8492]), 'objectness_scores': tensor([0.3879]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "416330\n",
      "{'image_id': 416451, 'boxes': tensor([[600, 368, 620, 406],\n",
      "        [421, 407, 639, 480],\n",
      "        [ 19,  68,  93, 175],\n",
      "        [  0, 229,  62, 476],\n",
      "        [  0, 241,  43, 463],\n",
      "        [140, 270, 492, 475]], dtype=torch.int32), 'scores': tensor([0.3263, 0.7143, 0.4919, 0.6622, 0.9166, 0.3349]), 'objectness_scores': tensor([0.2211, 0.2113, 0.2242, 0.2891, 0.2424, 0.4005]), 'labels': tensor([11,  8,  6, 14, 14, 13], dtype=torch.int32)}\n",
      "416451\n",
      "{'image_id': 416534, 'boxes': tensor([[510, 200, 639, 355],\n",
      "        [  0, 272,  64, 320]], dtype=torch.int32), 'scores': tensor([0.6255, 0.3975]), 'objectness_scores': tensor([0.3276, 0.2225]), 'labels': tensor([13, 14], dtype=torch.int32)}\n",
      "416534\n",
      "{'image_id': 416745, 'boxes': tensor([[294, 162, 372, 321],\n",
      "        [201,  86, 236, 142],\n",
      "        [177, 393, 226, 407],\n",
      "        [171,  85, 235, 142],\n",
      "        [175, 163, 240, 320],\n",
      "        [386, 390, 416, 564],\n",
      "        [307, 330, 326, 359],\n",
      "        [201, 373, 214, 379],\n",
      "        [402, 168, 421, 318],\n",
      "        [244, 217, 281, 258],\n",
      "        [178, 372, 213, 391],\n",
      "        [386, 138, 422, 589],\n",
      "        [176, 393, 261, 606]], dtype=torch.int32), 'scores': tensor([0.3993, 0.1845, 0.3778, 0.2900, 0.3297, 0.2961, 0.5292, 0.2481, 0.4777,\n",
      "        0.4924, 0.1251, 0.9880, 0.3270]), 'objectness_scores': tensor([0.4858, 0.2005, 0.7010, 0.5523, 0.5023, 0.3119, 0.5005, 0.3244, 0.2648,\n",
      "        0.2553, 0.3991, 0.4104, 0.5267]), 'labels': tensor([11,  7, 11,  7, 11, 11, 11, 11, 11, 10,  0, 10,  7], dtype=torch.int32)}\n",
      "416745\n",
      "{'image_id': 416885, 'boxes': tensor([[ 21, 138, 188, 180],\n",
      "        [  2, 149, 496, 375],\n",
      "        [ 60,   0, 183, 323],\n",
      "        [184, 235, 498, 374],\n",
      "        [ 37,  13,  93, 208],\n",
      "        [ 77, 160, 371, 248]], dtype=torch.int32), 'scores': tensor([0.3211, 0.9941, 0.8637, 0.9751, 0.1842, 0.8322]), 'objectness_scores': tensor([0.3340, 0.2555, 0.4931, 0.2655, 0.4320, 0.2927]), 'labels': tensor([10, 12, 10, 12, 11, 12], dtype=torch.int32)}\n",
      "416885\n",
      "{'image_id': 416991, 'boxes': tensor([[310, 228, 348, 239],\n",
      "        [340, 237, 388, 249],\n",
      "        [263,  93, 300, 108],\n",
      "        [335, 102, 357, 109],\n",
      "        [401,  98, 428, 108],\n",
      "        [335, 264, 395, 291],\n",
      "        [195, 203, 228, 212],\n",
      "        [338,  86, 392, 141],\n",
      "        [335, 271, 393, 291],\n",
      "        [452, 298, 533, 329],\n",
      "        [240,  98, 273, 140],\n",
      "        [304, 101, 346, 142],\n",
      "        [206, 228, 243, 239],\n",
      "        [531,  72, 632, 101],\n",
      "        [402, 145, 455, 175],\n",
      "        [369, 100, 391, 109],\n",
      "        [362, 100, 391, 133],\n",
      "        [234,  95, 268, 109],\n",
      "        [391,  82, 461, 149],\n",
      "        [205, 221, 250, 239],\n",
      "        [392,  81, 459, 102],\n",
      "        [261,  93, 303, 139],\n",
      "        [390,  85, 418, 111],\n",
      "        [172, 216, 211, 228],\n",
      "        [120, 201, 135, 208],\n",
      "        [339, 233, 389, 263],\n",
      "        [389, 283, 460, 311],\n",
      "        [207,  97, 240, 110],\n",
      "        [152, 100, 181, 112],\n",
      "        [232,  96, 271, 138],\n",
      "        [310, 103, 329, 110],\n",
      "        [532,  72, 632, 151],\n",
      "        [441,  94, 467, 117],\n",
      "        [294,  90, 342, 106],\n",
      "        [118, 103, 143, 135],\n",
      "        [237, 235, 268, 246],\n",
      "        [232, 226, 268, 240],\n",
      "        [388,  92, 404, 107],\n",
      "        [293, 251, 349, 273],\n",
      "        [125,  81, 479, 116],\n",
      "        [118, 103, 142, 112],\n",
      "        [468, 149, 520, 181],\n",
      "        [134, 203, 168, 215],\n",
      "        [124, 102, 163, 136],\n",
      "        [366, 100, 392, 122],\n",
      "        [339,  85, 392, 104],\n",
      "        [171,  99, 207, 112],\n",
      "        [131, 192, 530, 322],\n",
      "        [204,  97, 240, 136],\n",
      "        [322, 103, 349, 119],\n",
      "        [171, 100, 209, 137],\n",
      "        [293,  90, 343, 143],\n",
      "        [199, 108, 225, 133],\n",
      "        [155, 209, 175, 222],\n",
      "        [393, 249, 462, 309],\n",
      "        [451,  95, 468, 104],\n",
      "        [400, 248, 460, 266],\n",
      "        [259, 236, 311, 260],\n",
      "        [250, 216, 280, 226],\n",
      "        [308, 220, 350, 251],\n",
      "        [282, 219, 314, 232],\n",
      "        [151, 100, 182, 136],\n",
      "        [452,  78, 534, 155]], dtype=torch.int32), 'scores': tensor([0.3871, 0.2320, 0.5015, 0.3116, 0.3301, 0.1691, 0.6722, 0.3107, 0.3322,\n",
      "        0.1564, 0.1700, 0.1453, 0.3208, 0.2614, 0.1598, 0.2623, 0.3784, 0.4044,\n",
      "        0.9665, 0.3132, 0.3718, 0.5631, 0.2868, 0.3579, 0.2672, 0.3641, 0.2727,\n",
      "        0.3955, 0.4328, 0.1763, 0.1165, 0.9919, 0.1463, 0.2566, 0.5239, 0.3198,\n",
      "        0.2500, 0.1847, 0.2447, 0.3280, 0.3123, 0.1277, 0.2240, 0.2736, 0.2946,\n",
      "        0.3354, 0.3407, 0.3845, 0.1850, 0.1459, 0.5006, 0.9073, 0.2649, 0.3869,\n",
      "        0.2056, 0.2282, 0.4212, 0.3389, 0.2922, 0.7462, 0.2288, 0.3200, 0.8972]), 'objectness_scores': tensor([0.3466, 0.3473, 0.2951, 0.2243, 0.2722, 0.3635, 0.3649, 0.3349, 0.2632,\n",
      "        0.4214, 0.2184, 0.3144, 0.2588, 0.2122, 0.2367, 0.2688, 0.2192, 0.2930,\n",
      "        0.4273, 0.3904, 0.2398, 0.3787, 0.2029, 0.3553, 0.2921, 0.2923, 0.4000,\n",
      "        0.3549, 0.3104, 0.3930, 0.2039, 0.5021, 0.3156, 0.2589, 0.4317, 0.2976,\n",
      "        0.2260, 0.2260, 0.4153, 0.2242, 0.2787, 0.2271, 0.3773, 0.3273, 0.2724,\n",
      "        0.2488, 0.2321, 0.2142, 0.2861, 0.2368, 0.4206, 0.3460, 0.2275, 0.3280,\n",
      "        0.2063, 0.2150, 0.4068, 0.4300, 0.3596, 0.2217, 0.3460, 0.3465, 0.4712]), 'labels': tensor([11, 14, 11, 11, 14, 11,  7,  6, 11, 11,  8, 10, 11,  9,  7, 11,  9, 11,\n",
      "         6, 11, 11,  6,  9, 11, 14, 11,  9, 14, 14,  6, 11,  6,  1, 11,  6, 14,\n",
      "        14,  7,  0,  9, 14,  1, 14,  1,  1, 11, 11,  6,  6,  1,  6,  6, 11, 14,\n",
      "        11, 11, 11, 11, 11, 11,  7, 14,  6], dtype=torch.int32)}\n",
      "416991\n",
      "{'image_id': 417285, 'boxes': tensor([[213,   8, 423, 319],\n",
      "        [243,  39, 371, 217],\n",
      "        [218, 110, 426, 262],\n",
      "        [423,  44, 641, 278],\n",
      "        [281, 232, 425, 315],\n",
      "        [  8,  68, 209, 142],\n",
      "        [  0,  87, 214, 256],\n",
      "        [257,  72, 369, 196],\n",
      "        [211,  82, 422, 271]], dtype=torch.int32), 'scores': tensor([0.9856, 0.9564, 0.9721, 0.2709, 0.3568, 0.8276, 0.8450, 0.9120, 0.9575]), 'objectness_scores': tensor([0.2187, 0.4482, 0.2933, 0.4512, 0.3054, 0.3494, 0.4933, 0.2893, 0.4800]), 'labels': tensor([10, 10, 10, 14,  8, 12, 12, 10, 10], dtype=torch.int32)}\n",
      "417285\n",
      "{'image_id': 417632, 'boxes': tensor([[131, 343, 181, 419],\n",
      "        [332, 246, 341, 256],\n",
      "        [369, 308, 489, 385],\n",
      "        [ 26, 398, 132, 481],\n",
      "        [344, 184, 390, 297],\n",
      "        [130, 343, 184, 476],\n",
      "        [504, 143, 550, 180],\n",
      "        [407, 176, 465, 309],\n",
      "        [186, 311, 300, 481],\n",
      "        [583, 293, 639, 431],\n",
      "        [ 75, 376, 163, 483]], dtype=torch.int32), 'scores': tensor([0.3337, 0.3536, 0.1482, 0.6993, 0.7410, 0.2951, 0.2242, 0.6085, 0.4138,\n",
      "        0.1261, 0.5105]), 'objectness_scores': tensor([0.2694, 0.3156, 0.2546, 0.2308, 0.4430, 0.3031, 0.2124, 0.4248, 0.2064,\n",
      "        0.2013, 0.2488]), 'labels': tensor([11, 11,  7, 10, 10, 11,  3, 10,  7,  8, 10], dtype=torch.int32)}\n",
      "417632\n",
      "{'image_id': 419312, 'boxes': tensor([[153,  37, 370, 161],\n",
      "        [107, 113, 206, 169],\n",
      "        [  0,  69,  92, 225],\n",
      "        [  0,   2, 372, 495],\n",
      "        [ 80, 370, 184, 445],\n",
      "        [124, 232, 281, 316],\n",
      "        [163, 176, 246, 250],\n",
      "        [  0, 172, 375, 487],\n",
      "        [ 20, 283,  89, 336],\n",
      "        [188, 264, 356, 364],\n",
      "        [ 88, 168, 199, 258],\n",
      "        [ 48, 224, 130, 304],\n",
      "        [ 22,  10, 114, 145]], dtype=torch.int32), 'scores': tensor([0.9956, 0.1952, 0.6576, 0.5524, 0.6531, 0.6836, 0.4774, 0.2671, 0.6390,\n",
      "        0.3278, 0.2324, 0.7758, 0.9375]), 'objectness_scores': tensor([0.4345, 0.2616, 0.4742, 0.3275, 0.3601, 0.2342, 0.2112, 0.3878, 0.3251,\n",
      "        0.2750, 0.2595, 0.2153, 0.5121]), 'labels': tensor([12,  8, 10,  8, 12, 12, 12,  8, 12, 11, 11, 12, 10], dtype=torch.int32)}\n",
      "419312\n",
      "{'image_id': 419408, 'boxes': tensor([[232, 256, 322, 292],\n",
      "        [570, 300, 631, 320],\n",
      "        [239, 112, 279, 139]], dtype=torch.int32), 'scores': tensor([0.3955, 0.2557, 0.1858]), 'objectness_scores': tensor([0.5110, 0.5753, 0.2650]), 'labels': tensor([9, 9, 9], dtype=torch.int32)}\n",
      "419408\n",
      "{'image_id': 419601, 'boxes': tensor([[260, 173, 322, 223],\n",
      "        [219, 191, 268, 214],\n",
      "        [393, 195, 456, 247],\n",
      "        [ 39, 132, 203, 226],\n",
      "        [134, 192, 223, 249]], dtype=torch.int32), 'scores': tensor([0.9775, 0.5918, 0.2124, 0.9968, 0.9721]), 'objectness_scores': tensor([0.3036, 0.3714, 0.2685, 0.5014, 0.3778]), 'labels': tensor([13, 11, 14, 13, 10], dtype=torch.int32)}\n",
      "419601\n",
      "{'image_id': 419974, 'boxes': tensor([[293, 528, 368, 635],\n",
      "        [ 60, 389, 192, 527]], dtype=torch.int32), 'scores': tensor([0.3990, 0.9565]), 'objectness_scores': tensor([0.2088, 0.3243]), 'labels': tensor([10,  3], dtype=torch.int32)}\n",
      "419974\n",
      "{'image_id': 420840, 'boxes': tensor([[235,  25, 269, 109],\n",
      "        [170, 230, 462, 424]], dtype=torch.int32), 'scores': tensor([0.4727, 0.6633]), 'objectness_scores': tensor([0.3122, 0.2755]), 'labels': tensor([ 7, 12], dtype=torch.int32)}\n",
      "420840\n",
      "{'image_id': 421455, 'boxes': tensor([[ 46, 179, 172, 329]], dtype=torch.int32), 'scores': tensor([0.5952]), 'objectness_scores': tensor([0.5178]), 'labels': tensor([14], dtype=torch.int32)}\n",
      "421455\n",
      "{'image_id': 421923, 'boxes': tensor([[255, 302, 423, 616],\n",
      "        [ 65, 403, 151, 522],\n",
      "        [325,  35, 427, 229]], dtype=torch.int32), 'scores': tensor([0.2881, 0.3322, 0.3598]), 'objectness_scores': tensor([0.3608, 0.2093, 0.2418]), 'labels': tensor([10,  7,  8], dtype=torch.int32)}\n",
      "421923\n",
      "{'image_id': 422886, 'boxes': tensor([[ 33,  40, 337, 291],\n",
      "        [409, 119, 639, 641]], dtype=torch.int32), 'scores': tensor([0.2701, 0.2865]), 'objectness_scores': tensor([0.4289, 0.2019]), 'labels': tensor([12,  7], dtype=torch.int32)}\n",
      "422886\n",
      "{'image_id': 422998, 'boxes': tensor([[  0,   0, 435, 334],\n",
      "        [358, 226, 382, 269],\n",
      "        [350, 220, 426, 285],\n",
      "        [378, 265, 395, 280],\n",
      "        [434, 203, 499, 257],\n",
      "        [235, 238, 526, 373],\n",
      "        [378, 216, 398, 256],\n",
      "        [521,  12, 639, 275],\n",
      "        [385, 237, 404, 275],\n",
      "        [ 97, 169, 637, 425]], dtype=torch.int32), 'scores': tensor([0.4225, 0.2628, 0.3472, 0.4227, 0.4057, 0.4552, 0.2438, 0.4418, 0.2565,\n",
      "        0.6722]), 'objectness_scores': tensor([0.2238, 0.2099, 0.3421, 0.2088, 0.3988, 0.3137, 0.3705, 0.2608, 0.4286,\n",
      "        0.2767]), 'labels': tensor([12, 11,  4, 11, 10,  3,  7, 12,  7, 11], dtype=torch.int32)}\n",
      "422998\n",
      "{'image_id': 423506, 'boxes': tensor([[ 91, 266, 165, 500],\n",
      "        [185, 251, 372, 499],\n",
      "        [251, 286, 314, 373],\n",
      "        [  0, 182, 236, 500]], dtype=torch.int32), 'scores': tensor([0.9887, 0.9996, 0.9998, 0.9955]), 'objectness_scores': tensor([0.6156, 0.2097, 0.4598, 0.2008]), 'labels': tensor([7, 7, 7, 7], dtype=torch.int32)}\n",
      "423506\n",
      "{'image_id': 423617, 'boxes': tensor([[133,  18, 150,  36],\n",
      "        [ 54,  50, 210, 196],\n",
      "        [ 18,  61,  26,  68]], dtype=torch.int32), 'scores': tensor([0.2731, 0.9966, 0.1739]), 'objectness_scores': tensor([0.3824, 0.5209, 0.2053]), 'labels': tensor([9, 1, 7], dtype=torch.int32)}\n",
      "423617\n",
      "{'image_id': 424162, 'boxes': tensor([[ 93, 191, 112, 252],\n",
      "        [468, 442, 498, 475],\n",
      "        [221, 240, 323, 327],\n",
      "        [339, 189, 422, 323],\n",
      "        [386, 456, 408, 471],\n",
      "        [487, 265, 566, 324],\n",
      "        [516, 146, 555, 185],\n",
      "        [345,  65, 388, 106],\n",
      "        [ 78, 294, 230, 478],\n",
      "        [412, 105, 423, 135],\n",
      "        [448,  78, 541, 105],\n",
      "        [295, 440, 324, 469],\n",
      "        [604,  93, 629, 119]], dtype=torch.int32), 'scores': tensor([0.3168, 0.7064, 0.4223, 0.1670, 0.1509, 0.1254, 0.3122, 0.3866, 0.9967,\n",
      "        0.4477, 0.4674, 0.4934, 0.2616]), 'objectness_scores': tensor([0.2548, 0.3383, 0.2716, 0.2300, 0.2313, 0.3616, 0.2430, 0.3425, 0.4743,\n",
      "        0.2655, 0.3155, 0.2548, 0.3331]), 'labels': tensor([11,  2, 11,  9, 11, 14,  6,  8,  3, 14, 14,  9, 11], dtype=torch.int32)}\n",
      "424162\n",
      "{'image_id': 424521, 'boxes': tensor([[ 97, 168, 156, 181],\n",
      "        [ 46, 275,  72, 300],\n",
      "        [238, 325, 289, 443],\n",
      "        [ 26, 264, 139, 309]], dtype=torch.int32), 'scores': tensor([0.5116, 0.2263, 0.2882, 0.4348]), 'objectness_scores': tensor([0.2295, 0.2204, 0.2406, 0.6517]), 'labels': tensor([11, 11,  9,  9], dtype=torch.int32)}\n",
      "424521\n",
      "{'image_id': 425221, 'boxes': tensor([[153, 295, 215, 313],\n",
      "        [ 53, 442,  69, 470]], dtype=torch.int32), 'scores': tensor([0.6604, 0.2292]), 'objectness_scores': tensor([0.5547, 0.2767]), 'labels': tensor([11,  4], dtype=torch.int32)}\n",
      "425221\n",
      "{'image_id': 425361, 'boxes': tensor([[294, 186, 339, 329],\n",
      "        [466, 154, 580, 257],\n",
      "        [ 29,  42, 120, 129]], dtype=torch.int32), 'scores': tensor([0.2070, 0.6285, 0.7301]), 'objectness_scores': tensor([0.3596, 0.2579, 0.4546]), 'labels': tensor([ 2, 10, 14], dtype=torch.int32)}\n",
      "425361\n",
      "{'image_id': 425390, 'boxes': tensor([[  0,  61, 451, 376],\n",
      "        [  5, 120, 496, 374]], dtype=torch.int32), 'scores': tensor([0.8193, 0.6647]), 'objectness_scores': tensor([0.5400, 0.4475]), 'labels': tensor([2, 2], dtype=torch.int32)}\n",
      "425390\n",
      "{'image_id': 425906, 'boxes': tensor([[ 16, 401,  46, 426],\n",
      "        [121, 408, 144, 431],\n",
      "        [159, 415, 183, 431],\n",
      "        [  1, 445, 460, 640],\n",
      "        [ 99, 204, 111, 215],\n",
      "        [253, 446, 290, 478],\n",
      "        [207, 417, 229, 433],\n",
      "        [ 68, 145,  97, 171],\n",
      "        [ 61, 134,  93, 171],\n",
      "        [315, 459, 341, 477],\n",
      "        [405, 467, 424, 485],\n",
      "        [379, 464, 407, 490],\n",
      "        [ 53, 406,  76, 421],\n",
      "        [331, 449, 367, 477],\n",
      "        [ 79, 411, 102, 432],\n",
      "        [156, 186, 171, 200]], dtype=torch.int32), 'scores': tensor([0.3523, 0.1619, 0.1428, 0.9381, 0.2621, 0.1943, 0.2323, 0.4295, 0.4494,\n",
      "        0.1430, 0.2062, 0.1949, 0.2057, 0.4605, 0.1362, 0.2038]), 'objectness_scores': tensor([0.3835, 0.3111, 0.2170, 0.2845, 0.2345, 0.2564, 0.3058, 0.4419, 0.3572,\n",
      "        0.3267, 0.2553, 0.3895, 0.2424, 0.3197, 0.2183, 0.3666]), 'labels': tensor([11, 11, 14,  8, 11, 10, 14, 11, 11, 14, 11, 11, 10, 11, 14,  8],\n",
      "       dtype=torch.int32)}\n",
      "425906\n",
      "{'image_id': 426203, 'boxes': tensor([[ 80, 178, 158, 516],\n",
      "        [211, 247, 279, 353],\n",
      "        [172, 360, 198, 514],\n",
      "        [138, 457, 168, 503],\n",
      "        [214, 394, 245, 500]], dtype=torch.int32), 'scores': tensor([0.2634, 0.6048, 0.3531, 0.7436, 0.2345]), 'objectness_scores': tensor([0.2238, 0.6046, 0.2056, 0.3036, 0.2146]), 'labels': tensor([ 7,  9, 11, 11,  0], dtype=torch.int32)}\n",
      "426203\n",
      "{'image_id': 426241, 'boxes': tensor([[362, 174, 384, 192],\n",
      "        [252, 175, 499, 370],\n",
      "        [  7, 212, 129, 259],\n",
      "        [  3, 168, 496, 376],\n",
      "        [  0, 156,  89, 207],\n",
      "        [136, 146, 186, 168],\n",
      "        [  1, 156, 242, 372],\n",
      "        [ 94, 132, 121, 176],\n",
      "        [317, 194, 437, 230],\n",
      "        [416, 183, 441, 204],\n",
      "        [ 59, 286,  76, 311]], dtype=torch.int32), 'scores': tensor([0.2474, 0.7614, 0.6254, 0.6698, 0.3614, 0.2945, 0.8144, 0.3725, 0.2593,\n",
      "        0.2512, 0.4308]), 'objectness_scores': tensor([0.4424, 0.3483, 0.6596, 0.2693, 0.2646, 0.2690, 0.3194, 0.4027, 0.6616,\n",
      "        0.3943, 0.3138]), 'labels': tensor([14, 14, 14, 14, 14, 11, 14, 11,  9, 14, 11], dtype=torch.int32)}\n",
      "426241\n",
      "{'image_id': 426329, 'boxes': tensor([[259, 270, 290, 345],\n",
      "        [408, 234, 552, 387],\n",
      "        [176, 138, 262, 182],\n",
      "        [269, 214, 405, 295],\n",
      "        [  2,  62, 209, 138],\n",
      "        [468, 209, 597, 244],\n",
      "        [465, 160, 570, 210],\n",
      "        [  3, 111, 635, 427],\n",
      "        [532, 116, 610, 163],\n",
      "        [436, 108, 528, 162],\n",
      "        [377, 180, 403, 198],\n",
      "        [530,  95, 610, 163],\n",
      "        [367, 156, 461, 197],\n",
      "        [  6, 181, 128, 244],\n",
      "        [510, 200, 539, 215],\n",
      "        [117, 226, 142, 253],\n",
      "        [485, 311, 566, 390],\n",
      "        [297, 177, 377, 203],\n",
      "        [127, 201, 250, 250],\n",
      "        [567, 159, 639, 213],\n",
      "        [263, 173, 288, 189],\n",
      "        [451, 219, 560, 320],\n",
      "        [109, 169, 210, 208],\n",
      "        [232, 183, 349, 282],\n",
      "        [139, 162, 159, 175],\n",
      "        [353, 142, 425, 180],\n",
      "        [561, 210, 630, 228],\n",
      "        [202, 176, 262, 204],\n",
      "        [  0, 224, 115, 347],\n",
      "        [407, 234, 535, 345],\n",
      "        [262, 144, 354, 182],\n",
      "        [587, 168, 641, 214],\n",
      "        [443, 150, 509, 190],\n",
      "        [209, 170, 363, 205],\n",
      "        [ -1, 298, 109, 429],\n",
      "        [601,  94, 639, 130],\n",
      "        [ 14, 158, 120, 188],\n",
      "        [  0, 212,  21, 236],\n",
      "        [418, 194, 507, 227],\n",
      "        [ 14, 160, 210, 210],\n",
      "        [283, 270, 455, 426],\n",
      "        [531,  92, 583, 122],\n",
      "        [ 89, 132, 177, 172],\n",
      "        [  0,  63,  45,  94],\n",
      "        [ 46, 151,  69, 165],\n",
      "        [149, 241, 212, 263],\n",
      "        [104, 239, 257, 373],\n",
      "        [345, 195, 464, 272],\n",
      "        [ 52,  78, 134, 131]], dtype=torch.int32), 'scores': tensor([0.2066, 0.9794, 0.1713, 0.3432, 0.2598, 0.3942, 0.3551, 0.6519, 0.2148,\n",
      "        0.3628, 0.4215, 0.1409, 0.1893, 0.2605, 0.3260, 0.1746, 0.5636, 0.2321,\n",
      "        0.2316, 0.2528, 0.3564, 0.9405, 0.1919, 0.9326, 0.3620, 0.4996, 0.3999,\n",
      "        0.1772, 0.6619, 0.8325, 0.2708, 0.1957, 0.2150, 0.3474, 0.3571, 0.1555,\n",
      "        0.1959, 0.3427, 0.1660, 0.3550, 0.6900, 0.3248, 0.1771, 0.4409, 0.3340,\n",
      "        0.7668, 0.9705, 0.4221, 0.1837]), 'objectness_scores': tensor([0.2069, 0.2835, 0.3625, 0.3520, 0.2451, 0.3729, 0.3690, 0.3738, 0.3967,\n",
      "        0.2297, 0.2472, 0.2470, 0.3464, 0.3469, 0.2192, 0.2460, 0.2897, 0.3484,\n",
      "        0.3543, 0.4228, 0.2196, 0.2734, 0.2423, 0.3824, 0.2349, 0.3417, 0.2481,\n",
      "        0.3021, 0.3626, 0.2884, 0.3642, 0.2963, 0.2824, 0.2001, 0.4500, 0.2783,\n",
      "        0.3381, 0.2371, 0.3393, 0.3409, 0.3851, 0.2950, 0.3713, 0.2133, 0.2808,\n",
      "        0.2005, 0.3711, 0.3728, 0.2061]), 'labels': tensor([11, 12,  7, 10,  7,  9, 12, 12,  7,  0, 11,  7, 12, 11, 11, 12, 12, 11,\n",
      "        11, 11, 11, 12, 11, 12, 11, 11, 11,  3, 12, 12, 11, 12, 11, 11,  2,  3,\n",
      "         9, 12, 13, 10, 12, 11,  7, 11, 11, 11, 12, 12,  7], dtype=torch.int32)}\n",
      "426329\n",
      "{'image_id': 426376, 'boxes': tensor([[231, 392, 249, 403],\n",
      "        [174, 294, 187, 307],\n",
      "        [234, 261, 246, 280],\n",
      "        [207, 294, 225, 309],\n",
      "        [210, 303, 224, 311]], dtype=torch.int32), 'scores': tensor([0.5586, 0.2010, 0.2092, 0.1895, 0.6314]), 'objectness_scores': tensor([0.2287, 0.3712, 0.3724, 0.2681, 0.3017]), 'labels': tensor([12,  2, 11, 11,  2], dtype=torch.int32)}\n",
      "426376\n",
      "{'image_id': 427034, 'boxes': tensor([[236,  21, 271,  83],\n",
      "        [ 62, 144,  75, 174],\n",
      "        [359,  25, 521, 182],\n",
      "        [205,  26, 240,  85],\n",
      "        [551,  17, 640, 186],\n",
      "        [266, 177, 636, 352],\n",
      "        [  6, 328, 633, 480],\n",
      "        [265,  22, 302,  82],\n",
      "        [  4, 327, 464, 480]], dtype=torch.int32), 'scores': tensor([0.3205, 0.4362, 0.2262, 0.5527, 0.3688, 0.9557, 0.9909, 0.6639, 0.8841]), 'objectness_scores': tensor([0.4663, 0.2279, 0.3688, 0.4372, 0.2367, 0.4863, 0.3123, 0.4602, 0.3404]), 'labels': tensor([ 2, 11,  6,  3,  8,  3, 14,  2, 14], dtype=torch.int32)}\n",
      "427034\n",
      "{'image_id': 427655, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "427655\n",
      "{'image_id': 428111, 'boxes': tensor([[  1, 161, 637, 428],\n",
      "        [ 75, 170, 127, 202],\n",
      "        [  1,   1,  46, 168]], dtype=torch.int32), 'scores': tensor([0.8177, 0.4069, 0.4019]), 'objectness_scores': tensor([0.2531, 0.2054, 0.2004]), 'labels': tensor([ 9,  8, 11], dtype=torch.int32)}\n",
      "428111\n",
      "{'image_id': 428280, 'boxes': tensor([[111, 166, 180, 236],\n",
      "        [175, 185, 274, 227]], dtype=torch.int32), 'scores': tensor([0.5559, 0.6034]), 'objectness_scores': tensor([0.2924, 0.2779]), 'labels': tensor([14, 13], dtype=torch.int32)}\n",
      "428280\n",
      "{'image_id': 428454, 'boxes': tensor([[317, 294, 338, 309],\n",
      "        [319, 196, 334, 209],\n",
      "        [370, 298, 389, 313],\n",
      "        [358, 132, 388, 149],\n",
      "        [357, 128, 389, 152],\n",
      "        [  0, 118, 497, 333]], dtype=torch.int32), 'scores': tensor([0.6789, 0.1564, 0.2715, 0.6428, 0.3045, 0.9967]), 'objectness_scores': tensor([0.2892, 0.3098, 0.2718, 0.2345, 0.4578, 0.2360]), 'labels': tensor([11,  3, 11, 11,  8,  8], dtype=torch.int32)}\n",
      "428454\n",
      "{'image_id': 429011, 'boxes': tensor([[212,  40, 619, 240],\n",
      "        [ 39, 113,  48, 194],\n",
      "        [505, 155, 533, 313],\n",
      "        [331, 127, 403, 252]], dtype=torch.int32), 'scores': tensor([0.4356, 0.3672, 0.2805, 0.3114]), 'objectness_scores': tensor([0.2023, 0.2101, 0.2390, 0.3198]), 'labels': tensor([ 1, 11, 11,  1], dtype=torch.int32)}\n",
      "429011\n",
      "{'image_id': 429109, 'boxes': tensor([[628,   0, 637,  11],\n",
      "        [598,   0, 602,  12],\n",
      "        [459, 293, 486, 338],\n",
      "        [457, 332, 480, 371],\n",
      "        [459, 294, 484, 337],\n",
      "        [396, 144, 507, 188]], dtype=torch.int32), 'scores': tensor([0.1733, 0.2714, 0.2166, 0.2979, 0.2446, 0.9903]), 'objectness_scores': tensor([0.2096, 0.2040, 0.2366, 0.2491, 0.2018, 0.2106]), 'labels': tensor([11, 10,  1, 14, 11,  1], dtype=torch.int32)}\n",
      "429109\n",
      "{'image_id': 429598, 'boxes': tensor([[355, 221, 494, 273],\n",
      "        [221, 187, 246, 216],\n",
      "        [613, 106, 636, 193],\n",
      "        [497, 277, 638, 354],\n",
      "        [122,   0, 360, 151]], dtype=torch.int32), 'scores': tensor([0.6619, 0.3286, 0.4197, 0.7085, 0.3284]), 'objectness_scores': tensor([0.5809, 0.3647, 0.5663, 0.3699, 0.2155]), 'labels': tensor([15, 12,  7, 15,  7], dtype=torch.int32)}\n",
      "429598\n",
      "{'image_id': 430056, 'boxes': tensor([[ 48, 208, 398, 325],\n",
      "        [327, 239, 368, 270],\n",
      "        [  1,  83, 498, 373],\n",
      "        [239, 216, 295, 239],\n",
      "        [190,  95, 401, 228],\n",
      "        [ 99, 114, 502, 164],\n",
      "        [ 51, 165, 220, 193],\n",
      "        [344, 175, 400, 227],\n",
      "        [ 21,  93,  71, 109]], dtype=torch.int32), 'scores': tensor([0.9526, 0.2207, 0.8390, 0.4964, 0.5810, 0.2193, 0.2959, 0.2084, 0.4096]), 'objectness_scores': tensor([0.4281, 0.2367, 0.4862, 0.2230, 0.2416, 0.8387, 0.2237, 0.3205, 0.2333]), 'labels': tensor([12,  7, 12, 11, 12,  7,  7, 10, 14], dtype=torch.int32)}\n",
      "430056\n",
      "{'image_id': 430073, 'boxes': tensor([[459, 173, 482, 188],\n",
      "        [491, 168, 525, 189]], dtype=torch.int32), 'scores': tensor([0.4118, 0.1982]), 'objectness_scores': tensor([0.2863, 0.2950]), 'labels': tensor([11, 11], dtype=torch.int32)}\n",
      "430073\n",
      "{'image_id': 431140, 'boxes': tensor([[ 41, 254,  91, 299],\n",
      "        [101,  89, 156, 170],\n",
      "        [ 71, 144, 265, 330],\n",
      "        [ 76,  58, 395, 211],\n",
      "        [571, 168, 615, 203],\n",
      "        [488, 233, 576, 317],\n",
      "        [482,   2, 542,  81],\n",
      "        [433,   2, 638, 245],\n",
      "        [190,  74, 319, 265],\n",
      "        [275, 175, 642, 478]], dtype=torch.int32), 'scores': tensor([0.2107, 0.6160, 0.9377, 0.8743, 0.8476, 0.9698, 0.4407, 0.9528, 0.8624,\n",
      "        0.9993]), 'objectness_scores': tensor([0.2250, 0.4392, 0.2799, 0.2919, 0.2896, 0.5089, 0.3490, 0.3689, 0.2110,\n",
      "        0.4969]), 'labels': tensor([ 8, 12, 14, 15, 11, 15, 10, 15, 15, 15], dtype=torch.int32)}\n",
      "431140\n",
      "{'image_id': 431848, 'boxes': tensor([[187, 375, 328, 521],\n",
      "        [285, 465, 333, 502],\n",
      "        [185, 359, 242, 407]], dtype=torch.int32), 'scores': tensor([0.7495, 0.2781, 0.2408]), 'objectness_scores': tensor([0.7057, 0.3749, 0.4235]), 'labels': tensor([9, 9, 9], dtype=torch.int32)}\n",
      "431848\n",
      "{'image_id': 432468, 'boxes': tensor([[  0,  27, 416, 239]], dtype=torch.int32), 'scores': tensor([0.9422]), 'objectness_scores': tensor([0.5327]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "432468\n",
      "{'image_id': 432553, 'boxes': tensor([[125, 264, 210, 335],\n",
      "        [ 20, 240,  74, 284],\n",
      "        [143,   0, 258, 451],\n",
      "        [  1, 197, 218, 472],\n",
      "        [268, 436, 377, 514],\n",
      "        [134, 257, 189, 288],\n",
      "        [  0, 216, 106, 307]], dtype=torch.int32), 'scores': tensor([0.7139, 0.3985, 0.8113, 0.9504, 0.4111, 0.6504, 0.8064]), 'objectness_scores': tensor([0.2606, 0.2657, 0.2177, 0.4354, 0.2665, 0.2228, 0.3483]), 'labels': tensor([ 4,  7,  3,  3,  9, 11,  3], dtype=torch.int32)}\n",
      "432553\n",
      "{'image_id': 433915, 'boxes': tensor([[175, 173, 267, 225],\n",
      "        [219, 354, 282, 410]], dtype=torch.int32), 'scores': tensor([0.5115, 0.2680]), 'objectness_scores': tensor([0.2758, 0.3213]), 'labels': tensor([7, 6], dtype=torch.int32)}\n",
      "433915\n",
      "{'image_id': 434204, 'boxes': tensor([[190, 187, 233, 207],\n",
      "        [147, 202, 186, 224],\n",
      "        [175, 198, 229, 235]], dtype=torch.int32), 'scores': tensor([0.2377, 0.2832, 0.5586]), 'objectness_scores': tensor([0.2499, 0.2421, 0.5858]), 'labels': tensor([9, 9, 9], dtype=torch.int32)}\n",
      "434204\n",
      "{'image_id': 434459, 'boxes': tensor([[334, 348, 362, 382],\n",
      "        [373, 233, 386, 248],\n",
      "        [283, 208, 297, 216],\n",
      "        [390, 223, 405, 236],\n",
      "        [ 84,  96,  92, 104],\n",
      "        [267, 260, 420, 334],\n",
      "        [240, 285, 338, 344],\n",
      "        [108, 367, 222, 418],\n",
      "        [ 21, 268, 437, 459],\n",
      "        [293, 216, 319, 227],\n",
      "        [400, 225, 417, 237],\n",
      "        [238, 213, 314, 228],\n",
      "        [257, 364, 313, 403],\n",
      "        [ 58, 336, 154, 373],\n",
      "        [104,  58, 114,  77]], dtype=torch.int32), 'scores': tensor([0.6468, 0.2177, 0.2606, 0.2713, 0.2517, 0.7942, 0.5164, 0.9645, 0.9986,\n",
      "        0.3094, 0.2048, 0.7805, 0.4138, 0.3178, 0.2118]), 'objectness_scores': tensor([0.4295, 0.2668, 0.2120, 0.2876, 0.2037, 0.2209, 0.3926, 0.2164, 0.3082,\n",
      "        0.2199, 0.2756, 0.4058, 0.4270, 0.2247, 0.2001]), 'labels': tensor([12, 14, 11, 14, 11, 12, 12, 12, 12, 14, 11, 11,  8, 12, 11],\n",
      "       dtype=torch.int32)}\n",
      "434459\n",
      "{'image_id': 434996, 'boxes': tensor([[ 71, 111, 186, 205],\n",
      "        [ 55, 112, 236, 375],\n",
      "        [ 50,  65, 320, 379],\n",
      "        [  0, 183, 100, 315],\n",
      "        [ 71, 112, 229, 300],\n",
      "        [169, 117, 329, 242],\n",
      "        [ 43, 327, 164, 374],\n",
      "        [408, 177, 501, 375],\n",
      "        [135, 143, 439, 375],\n",
      "        [393,  80, 498, 373],\n",
      "        [293, 101, 416, 190],\n",
      "        [114,  67, 318, 156],\n",
      "        [333, 138, 439, 306]], dtype=torch.int32), 'scores': tensor([0.2393, 0.8671, 0.7566, 0.4569, 0.9131, 0.9714, 0.1295, 0.4797, 0.7962,\n",
      "        0.3723, 0.5119, 0.8911, 0.6350]), 'objectness_scores': tensor([0.2808, 0.2447, 0.2100, 0.4962, 0.4060, 0.5017, 0.2308, 0.2244, 0.4611,\n",
      "        0.3822, 0.6563, 0.2541, 0.3054]), 'labels': tensor([3, 2, 2, 4, 2, 2, 6, 5, 2, 3, 3, 2, 5], dtype=torch.int32)}\n",
      "434996\n",
      "{'image_id': 435003, 'boxes': tensor([[  3, 230, 454, 408],\n",
      "        [251, 246, 395, 288],\n",
      "        [294, 103, 310, 123],\n",
      "        [623, 148, 639, 187],\n",
      "        [449, 195, 478, 240]], dtype=torch.int32), 'scores': tensor([0.6665, 0.8102, 0.2602, 0.2478, 0.3688]), 'objectness_scores': tensor([0.2432, 0.3567, 0.2037, 0.3410, 0.2580]), 'labels': tensor([14, 14, 11, 11,  8], dtype=torch.int32)}\n",
      "435003\n",
      "{'image_id': 435081, 'boxes': tensor([[261, 182, 279, 199],\n",
      "        [  2,  87,  15, 105],\n",
      "        [409, 321, 421, 334],\n",
      "        [105,  30, 120,  46],\n",
      "        [128, 388, 204, 444],\n",
      "        [ 61, 273,  83, 291],\n",
      "        [250, 378, 294, 445],\n",
      "        [469, 297, 498, 326],\n",
      "        [259, 379, 375, 500],\n",
      "        [416, 329, 430, 343],\n",
      "        [445,   8, 497,  64],\n",
      "        [426, 135, 459, 162],\n",
      "        [457, 282, 469, 294],\n",
      "        [126,  21, 246, 119],\n",
      "        [376, 296, 475, 338],\n",
      "        [421, 339, 434, 354],\n",
      "        [ 54, 426,  82, 457],\n",
      "        [ 37,  60,  57,  77],\n",
      "        [449, 288, 464, 301],\n",
      "        [258, 157, 367, 248],\n",
      "        [305, 219, 338, 244],\n",
      "        [329, 179, 351, 200],\n",
      "        [ 12, 443,  34, 467],\n",
      "        [ 38, 342,  65, 370],\n",
      "        [403, 290, 418, 306],\n",
      "        [ 69,  19,  86,  35],\n",
      "        [200,  52, 217,  64],\n",
      "        [426, 271, 441, 305],\n",
      "        [ 96, 250, 117, 267],\n",
      "        [ 31, 255,  62, 313],\n",
      "        [436, 352, 452, 368],\n",
      "        [ 31, 253,  61, 306],\n",
      "        [343, 209, 362, 226],\n",
      "        [  3, 211,  68, 247],\n",
      "        [422, 317, 435, 330],\n",
      "        [412, 280, 429, 298],\n",
      "        [ 86,  30, 101,  46],\n",
      "        [441, 277, 456, 292],\n",
      "        [ 22, 314,  46, 339],\n",
      "        [ 89,  17, 105,  31],\n",
      "        [287, 200, 301, 213],\n",
      "        [376, 142, 496, 243],\n",
      "        [401, 334, 415, 348],\n",
      "        [444, 326, 458, 339],\n",
      "        [434, 339, 450, 353],\n",
      "        [ 21, 101,  39, 120],\n",
      "        [270, 296, 304, 330],\n",
      "        [142, 265, 225, 302],\n",
      "        [ 22,  23,  59,  53],\n",
      "        [106,  17, 120,  31]], dtype=torch.int32), 'scores': tensor([0.6516, 0.5464, 0.2836, 0.2196, 0.3532, 0.2459, 0.9702, 0.1926, 0.9988,\n",
      "        0.2681, 0.3869, 0.9794, 0.2774, 0.3813, 0.5480, 0.2550, 0.9643, 0.8668,\n",
      "        0.2949, 0.9455, 0.8925, 0.7735, 0.3939, 0.9132, 0.3071, 0.3673, 0.2147,\n",
      "        0.3724, 0.3989, 0.6123, 0.2118, 0.8962, 0.2187, 0.9445, 0.2298, 0.3131,\n",
      "        0.6185, 0.2555, 0.3558, 0.3130, 0.3427, 0.4530, 0.1760, 0.3911, 0.3987,\n",
      "        0.3388, 0.8177, 0.3932, 0.8952, 0.5181]), 'objectness_scores': tensor([0.2923, 0.2924, 0.3744, 0.3493, 0.4625, 0.3237, 0.3554, 0.3622, 0.3666,\n",
      "        0.4046, 0.2920, 0.3509, 0.4264, 0.3053, 0.4680, 0.4378, 0.3346, 0.2944,\n",
      "        0.4852, 0.4464, 0.3112, 0.3101, 0.3101, 0.3464, 0.2941, 0.3234, 0.2944,\n",
      "        0.4212, 0.3325, 0.3581, 0.4107, 0.3048, 0.3046, 0.2945, 0.3828, 0.4458,\n",
      "        0.3683, 0.4752, 0.3283, 0.3640, 0.2988, 0.3044, 0.4556, 0.3153, 0.3733,\n",
      "        0.3152, 0.4141, 0.2856, 0.5510, 0.3699]), 'labels': tensor([12, 11, 11,  4, 12,  9, 12, 11, 12, 11, 12, 10, 14, 11, 11, 11, 12, 12,\n",
      "        11, 12, 11, 12, 10, 12, 14, 12, 11, 11, 11, 10, 14, 10, 12, 12, 11, 14,\n",
      "        12, 11, 12, 12, 11, 10, 12, 11, 11, 12, 12, 12, 10, 12],\n",
      "       dtype=torch.int32)}\n",
      "435081\n",
      "{'image_id': 435206, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "435206\n",
      "{'image_id': 435208, 'boxes': tensor([[215, 199, 312, 270],\n",
      "        [321,  93, 415, 231],\n",
      "        [135, 205, 189, 226],\n",
      "        [  1, 576, 149, 639],\n",
      "        [309, 284, 334, 313],\n",
      "        [  1, 404, 198, 637],\n",
      "        [268, 395, 479, 636],\n",
      "        [336, 312, 398, 323],\n",
      "        [280, 410, 461, 534],\n",
      "        [211,  82, 296, 199],\n",
      "        [425, 303, 454, 369],\n",
      "        [ 33, 144,  94, 185],\n",
      "        [ 88, 104, 195, 244]], dtype=torch.int32), 'scores': tensor([0.3700, 0.2290, 0.2064, 0.6577, 0.1819, 0.8711, 0.5366, 0.2304, 0.7907,\n",
      "        0.8063, 0.2065, 0.2090, 0.2099]), 'objectness_scores': tensor([0.2299, 0.2286, 0.2638, 0.2024, 0.2096, 0.4214, 0.3206, 0.2485, 0.2665,\n",
      "        0.2426, 0.2840, 0.2016, 0.2598]), 'labels': tensor([ 7,  6, 11,  7, 11, 13,  7, 14,  7,  7, 11,  4,  7], dtype=torch.int32)}\n",
      "435208\n",
      "{'image_id': 435299, 'boxes': tensor([[571,  60, 639, 175],\n",
      "        [  4,  87, 637, 386],\n",
      "        [271,  33, 417, 320]], dtype=torch.int32), 'scores': tensor([0.8269, 0.9276, 0.9036]), 'objectness_scores': tensor([0.2273, 0.2082, 0.5189]), 'labels': tensor([7, 2, 2], dtype=torch.int32)}\n",
      "435299\n",
      "{'image_id': 435880, 'boxes': tensor([[555, 250, 590, 335],\n",
      "        [166, 383, 254, 481],\n",
      "        [ 14, 106,  56, 139],\n",
      "        [ 17, 145,  55, 200],\n",
      "        [  0, 350,  50, 386],\n",
      "        [496, 121, 531, 144],\n",
      "        [557, 111, 637, 206],\n",
      "        [254, 128, 300, 205],\n",
      "        [283, 268, 292, 284],\n",
      "        [159, 204, 217, 241]], dtype=torch.int32), 'scores': tensor([0.2163, 0.5873, 0.4562, 0.3745, 0.3339, 0.1627, 0.2335, 0.3402, 0.3390,\n",
      "        0.2624]), 'objectness_scores': tensor([0.2333, 0.3427, 0.2009, 0.2330, 0.2110, 0.3145, 0.2203, 0.2111, 0.4451,\n",
      "        0.2302]), 'labels': tensor([ 7, 10,  6,  6,  8, 11,  8,  8, 11, 12], dtype=torch.int32)}\n",
      "435880\n",
      "{'image_id': 436617, 'boxes': tensor([[376, 225, 406, 244],\n",
      "        [203, 189, 546, 420],\n",
      "        [235, 347, 324, 373],\n",
      "        [362, 191, 386, 204],\n",
      "        [387, 299, 465, 335],\n",
      "        [306, 270, 338, 335],\n",
      "        [366, 277, 438, 300],\n",
      "        [486,   0, 552, 112],\n",
      "        [305, 240, 331, 273],\n",
      "        [363, 201, 379, 235],\n",
      "        [279, 252, 311, 281],\n",
      "        [ 39,  18, 139, 124],\n",
      "        [343, 193, 358, 226],\n",
      "        [325, 204, 345, 252],\n",
      "        [372, 257, 402, 323],\n",
      "        [297, 207, 319, 215]], dtype=torch.int32), 'scores': tensor([0.8370, 0.6116, 0.6252, 0.4873, 0.5616, 0.8257, 0.7060, 0.3581, 0.2070,\n",
      "        0.2113, 0.2512, 0.4253, 0.2537, 0.4989, 0.6001, 0.4340]), 'objectness_scores': tensor([0.3085, 0.2290, 0.2899, 0.2559, 0.3272, 0.2990, 0.2709, 0.2171, 0.2362,\n",
      "        0.2322, 0.2432, 0.2364, 0.2275, 0.2067, 0.3140, 0.2544]), 'labels': tensor([11,  7, 11, 11, 11, 10, 11,  8,  2, 11,  8, 15, 11,  7, 10, 11],\n",
      "       dtype=torch.int32)}\n",
      "436617\n",
      "{'image_id': 436738, 'boxes': tensor([[153, 295, 391, 403],\n",
      "        [103, 285, 112, 310],\n",
      "        [120, 284, 133, 311]], dtype=torch.int32), 'scores': tensor([0.9975, 0.2532, 0.2953]), 'objectness_scores': tensor([0.5967, 0.5757, 0.5697]), 'labels': tensor([ 1, 11, 14], dtype=torch.int32)}\n",
      "436738\n",
      "{'image_id': 436883, 'boxes': tensor([[ 81, 321, 252, 420],\n",
      "        [344, 194, 457, 228]], dtype=torch.int32), 'scores': tensor([0.5003, 0.5955]), 'objectness_scores': tensor([0.2098, 0.2121]), 'labels': tensor([ 9, 11], dtype=torch.int32)}\n",
      "436883\n",
      "{'image_id': 437205, 'boxes': tensor([[ 21, 128,  68, 170]], dtype=torch.int32), 'scores': tensor([0.2466]), 'objectness_scores': tensor([0.2181]), 'labels': tensor([14], dtype=torch.int32)}\n",
      "437205\n",
      "{'image_id': 437898, 'boxes': tensor([[339, 224, 542, 298],\n",
      "        [ 39, 274, 116, 307],\n",
      "        [466, 224, 502, 272],\n",
      "        [311, 246, 344, 383],\n",
      "        [576, 203, 595, 233],\n",
      "        [308,  42, 359, 104],\n",
      "        [507,   0, 636, 196],\n",
      "        [  0, 253, 101, 280],\n",
      "        [399,   4, 519,  99],\n",
      "        [  0, 252, 122, 310],\n",
      "        [ 13, 332,  57, 382],\n",
      "        [361,  31, 442, 170],\n",
      "        [299,  94, 318, 125],\n",
      "        [405, 179, 414, 200],\n",
      "        [  0, 271,  57, 350],\n",
      "        [  0, 250,  29, 273]], dtype=torch.int32), 'scores': tensor([0.9844, 0.9089, 0.6187, 0.3079, 0.3364, 0.2454, 0.2352, 0.4766, 0.3723,\n",
      "        0.2543, 0.9948, 0.4404, 0.1566, 0.2137, 0.9089, 0.2893]), 'objectness_scores': tensor([0.2528, 0.2577, 0.3518, 0.2604, 0.3380, 0.2662, 0.2639, 0.3353, 0.2646,\n",
      "        0.3065, 0.2100, 0.2903, 0.2470, 0.2824, 0.2194, 0.2733]), 'labels': tensor([15, 11, 10,  8, 14,  8,  8, 11,  8, 11, 10, 15, 14,  0, 10, 11],\n",
      "       dtype=torch.int32)}\n",
      "437898\n",
      "{'image_id': 438774, 'boxes': tensor([[232,  41, 302,  90],\n",
      "        [543, 232, 567, 265],\n",
      "        [  0,   0,  70,  78],\n",
      "        [272,   0, 343,  70],\n",
      "        [ 37, 126,  64, 183],\n",
      "        [263, 160, 281, 205],\n",
      "        [324, 164, 341, 201],\n",
      "        [370, 247, 637, 424],\n",
      "        [416, 230, 491, 279]], dtype=torch.int32), 'scores': tensor([0.3227, 0.4923, 0.2246, 0.5153, 0.4813, 0.2514, 0.2425, 0.9696, 0.9817]), 'objectness_scores': tensor([0.2014, 0.2655, 0.2063, 0.2073, 0.3480, 0.2278, 0.2335, 0.2820, 0.4905]), 'labels': tensor([15, 10,  8, 15,  8, 11, 11, 12, 12], dtype=torch.int32)}\n",
      "438774\n",
      "{'image_id': 438907, 'boxes': tensor([[ 28, 346, 259, 422],\n",
      "        [ 28, 347, 163, 394],\n",
      "        [134, 358, 260, 430],\n",
      "        [108,   0, 249,  39]], dtype=torch.int32), 'scores': tensor([0.9907, 0.2577, 0.9979, 0.3429]), 'objectness_scores': tensor([0.2686, 0.2875, 0.4755, 0.2138]), 'labels': tensor([9, 9, 9, 8], dtype=torch.int32)}\n",
      "438907\n",
      "{'image_id': 439525, 'boxes': tensor([[154, 123, 202, 382],\n",
      "        [188,  23, 326, 156],\n",
      "        [ 67, 486, 193, 567],\n",
      "        [  2, 498, 238, 637],\n",
      "        [205, 479, 212, 485],\n",
      "        [162,  32, 320, 387],\n",
      "        [225, 243, 407, 636],\n",
      "        [264, 223, 312, 281],\n",
      "        [242,  17, 337, 157]], dtype=torch.int32), 'scores': tensor([0.6821, 0.2143, 0.9984, 0.9992, 0.2298, 0.6834, 0.6963, 0.5037, 0.2417]), 'objectness_scores': tensor([0.2064, 0.3724, 0.5702, 0.2254, 0.3317, 0.3102, 0.2664, 0.5391, 0.2953]), 'labels': tensor([ 7,  7, 12, 12, 11,  7,  7,  7,  7], dtype=torch.int32)}\n",
      "439525\n",
      "{'image_id': 439715, 'boxes': tensor([[328, 231, 412, 275],\n",
      "        [113, 261, 153, 289],\n",
      "        [507, 267, 570, 294]], dtype=torch.int32), 'scores': tensor([0.9972, 0.3304, 0.9917]), 'objectness_scores': tensor([0.3130, 0.2096, 0.2607]), 'labels': tensor([6, 6, 6], dtype=torch.int32)}\n",
      "439715\n",
      "{'image_id': 439854, 'boxes': tensor([[118, 262, 136, 284],\n",
      "        [425, 230, 432, 233],\n",
      "        [423, 241, 440, 268],\n",
      "        [307, 200, 321, 217]], dtype=torch.int32), 'scores': tensor([0.1628, 0.2769, 0.3865, 0.2357]), 'objectness_scores': tensor([0.3880, 0.2594, 0.2581, 0.2001]), 'labels': tensor([ 9, 11, 11, 14], dtype=torch.int32)}\n",
      "439854\n",
      "{'image_id': 440171, 'boxes': tensor([[ 97,   7, 153,  49],\n",
      "        [  1,  73, 407, 146],\n",
      "        [  0, 148, 406, 610]], dtype=torch.int32), 'scores': tensor([0.2198, 0.3273, 0.9997]), 'objectness_scores': tensor([0.2726, 0.2352, 0.6675]), 'labels': tensor([4, 9, 5], dtype=torch.int32)}\n",
      "440171\n",
      "{'image_id': 440184, 'boxes': tensor([[385, 190, 403, 204],\n",
      "        [495, 211, 540, 238],\n",
      "        [281, 167, 289, 174],\n",
      "        [  7, 166,  27, 193],\n",
      "        [234, 145, 264, 165],\n",
      "        [381, 157, 389, 163],\n",
      "        [264, 218, 315, 239],\n",
      "        [ 61, 214,  72, 235]], dtype=torch.int32), 'scores': tensor([0.3895, 0.3056, 0.1668, 0.3594, 0.1285, 0.1755, 0.3437, 0.1745]), 'objectness_scores': tensor([0.4616, 0.4779, 0.5805, 0.2491, 0.2264, 0.2115, 0.5061, 0.3977]), 'labels': tensor([11, 16, 14, 14,  2, 11, 11, 11], dtype=torch.int32)}\n",
      "440184\n",
      "{'image_id': 440475, 'boxes': tensor([[ 41,  31, 120, 335],\n",
      "        [334,   2, 452,  83],\n",
      "        [411, 169, 472, 289],\n",
      "        [ 56, 268, 176, 372],\n",
      "        [518, 251, 587, 340],\n",
      "        [498,   4, 515,  42],\n",
      "        [570, 342, 636, 408],\n",
      "        [413, 169, 473, 213],\n",
      "        [ 96, 184, 169, 225],\n",
      "        [445, 342, 545, 413],\n",
      "        [252, 205, 265, 225],\n",
      "        [ 96, 183, 170, 290],\n",
      "        [462,   5, 476,  27],\n",
      "        [105, 173, 138, 199],\n",
      "        [586,   7, 602,  52]], dtype=torch.int32), 'scores': tensor([0.2801, 0.2326, 0.2520, 0.2770, 0.9693, 0.3441, 0.3242, 0.3654, 0.3007,\n",
      "        0.3139, 0.3677, 0.6460, 0.4481, 0.3305, 0.4706]), 'objectness_scores': tensor([0.2126, 0.3987, 0.2276, 0.2083, 0.2543, 0.3236, 0.2082, 0.2147, 0.2120,\n",
      "        0.2321, 0.3584, 0.2224, 0.2750, 0.2620, 0.2902]), 'labels': tensor([11,  6,  6, 10, 13, 11,  7,  8, 14, 12, 11,  6, 11, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "440475\n",
      "{'image_id': 440507, 'boxes': tensor([[129, 249, 197, 298],\n",
      "        [332, 119, 369, 154],\n",
      "        [190, 216, 218, 271],\n",
      "        [299, 114, 333, 149],\n",
      "        [305, 159, 339, 314],\n",
      "        [ 44,   0, 132, 108],\n",
      "        [101, 271, 171, 318],\n",
      "        [415, 301, 441, 321],\n",
      "        [166, 222, 208, 279]], dtype=torch.int32), 'scores': tensor([0.2821, 0.6129, 0.1585, 0.2236, 0.8829, 0.3889, 0.5932, 0.2744, 0.4142]), 'objectness_scores': tensor([0.3407, 0.2570, 0.2844, 0.2841, 0.3517, 0.3401, 0.3080, 0.2027, 0.2894]), 'labels': tensor([ 8, 11,  7,  7,  7,  7,  9, 11,  8], dtype=torch.int32)}\n",
      "440507\n",
      "{'image_id': 441247, 'boxes': tensor([[561, 142, 573, 148],\n",
      "        [227,  94, 318, 135],\n",
      "        [139,   0, 318,  45],\n",
      "        [  0, 364,  68, 423],\n",
      "        [528, 180, 636, 420],\n",
      "        [208, 256, 222, 268],\n",
      "        [ 23, 281, 224, 422],\n",
      "        [360, 260, 419, 293]], dtype=torch.int32), 'scores': tensor([0.2203, 0.8333, 0.1628, 0.3038, 0.9931, 0.2872, 0.9995, 0.2753]), 'objectness_scores': tensor([0.2790, 0.5324, 0.3365, 0.2006, 0.3406, 0.3570, 0.3900, 0.2581]), 'labels': tensor([11,  0, 12, 13, 13, 14, 13,  7], dtype=torch.int32)}\n",
      "441247\n",
      "{'image_id': 441491, 'boxes': tensor([[127, 271, 140, 331],\n",
      "        [297, 410, 321, 437],\n",
      "        [341, 400, 428, 480],\n",
      "        [431, 444, 446, 480]], dtype=torch.int32), 'scores': tensor([0.4587, 0.3974, 0.7407, 0.4795]), 'objectness_scores': tensor([0.4595, 0.4307, 0.4609, 0.2621]), 'labels': tensor([11, 11, 10, 11], dtype=torch.int32)}\n",
      "441491\n",
      "{'image_id': 441543, 'boxes': tensor([[119, 105, 144, 133],\n",
      "        [ 16, 172,  36, 196],\n",
      "        [ 38, 178,  68, 218],\n",
      "        [622, 123, 638, 144],\n",
      "        [579, 168, 597, 191],\n",
      "        [141,  64, 563, 291],\n",
      "        [ 94, 166, 111, 191],\n",
      "        [608, 183, 627, 203],\n",
      "        [554, 177, 565, 185],\n",
      "        [ 59,  61, 128, 148],\n",
      "        [254,  79, 276,  88],\n",
      "        [204, 278, 271, 320],\n",
      "        [555, 140, 575, 162],\n",
      "        [524, 185, 588, 256],\n",
      "        [628, 161, 640, 185],\n",
      "        [105, 126, 168, 196],\n",
      "        [362, 262, 401, 308],\n",
      "        [567, 172, 579, 185],\n",
      "        [600, 168, 619, 191],\n",
      "        [  0, 106,  91, 146],\n",
      "        [581, 150, 598, 169],\n",
      "        [548, 144, 558, 157],\n",
      "        [  0, 263, 124, 375],\n",
      "        [128,  49, 200, 140],\n",
      "        [ 85, 106, 144, 174],\n",
      "        [290,   0, 309,  74]], dtype=torch.int32), 'scores': tensor([0.3942, 0.3044, 0.3288, 0.4331, 0.1571, 0.9995, 0.1605, 0.1277, 0.1516,\n",
      "        0.6904, 0.4520, 0.4937, 0.2894, 0.7086, 0.2302, 0.3700, 0.8917, 0.2814,\n",
      "        0.1920, 0.3040, 0.4737, 0.1592, 0.6508, 0.2967, 0.5895, 0.2344]), 'objectness_scores': tensor([0.2394, 0.4149, 0.4162, 0.4366, 0.4264, 0.2079, 0.3794, 0.3784, 0.2080,\n",
      "        0.5119, 0.2351, 0.4763, 0.4101, 0.4988, 0.2094, 0.5278, 0.2709, 0.2452,\n",
      "        0.4013, 0.2451, 0.3960, 0.2594, 0.2734, 0.5137, 0.4062, 0.2734]), 'labels': tensor([ 6,  6, 12, 11, 11,  6,  7, 11, 13,  6, 11,  7,  6,  6, 11,  6,  6, 11,\n",
      "         6,  8, 11, 11,  7,  6,  6, 11], dtype=torch.int32)}\n",
      "441543\n",
      "{'image_id': 442009, 'boxes': tensor([[565, 145, 592, 251],\n",
      "        [533, 220, 565, 260],\n",
      "        [570, 142, 590, 171],\n",
      "        [533, 198, 597, 222],\n",
      "        [ 85, 318, 127, 362],\n",
      "        [477, 204, 547, 234],\n",
      "        [348, 231, 379, 251],\n",
      "        [435, 180, 485, 241],\n",
      "        [512,  57, 594, 194],\n",
      "        [439,  84, 494, 171],\n",
      "        [475, 227, 536, 251],\n",
      "        [ 95, 246, 381, 390],\n",
      "        [271, 273, 333, 362]], dtype=torch.int32), 'scores': tensor([0.3473, 0.2967, 0.2573, 0.2135, 0.5095, 0.2613, 0.4595, 0.2129, 0.1663,\n",
      "        0.4462, 0.3120, 0.8919, 0.6728]), 'objectness_scores': tensor([0.2020, 0.2006, 0.4649, 0.2322, 0.2258, 0.2425, 0.3217, 0.3228, 0.3946,\n",
      "        0.2311, 0.2783, 0.5478, 0.3275]), 'labels': tensor([11,  7, 11,  2, 12, 12, 16, 13,  5,  8, 11, 15,  7], dtype=torch.int32)}\n",
      "442009\n",
      "{'image_id': 442306, 'boxes': tensor([[297, 500, 337, 602],\n",
      "        [ 85,  78, 462, 366],\n",
      "        [373, 487, 418, 601],\n",
      "        [247, 189, 414, 426]], dtype=torch.int32), 'scores': tensor([0.5329, 0.9890, 0.6327, 0.2755]), 'objectness_scores': tensor([0.6506, 0.6558, 0.7081, 0.2945]), 'labels': tensor([9, 6, 8, 6], dtype=torch.int32)}\n",
      "442306\n",
      "{'image_id': 442463, 'boxes': tensor([[215, 449, 376, 487],\n",
      "        [253, 247, 310, 307],\n",
      "        [ 77,  92, 107, 130]], dtype=torch.int32), 'scores': tensor([0.4425, 0.2783, 0.3625]), 'objectness_scores': tensor([0.6108, 0.2681, 0.2352]), 'labels': tensor([11,  9,  9], dtype=torch.int32)}\n",
      "442463\n",
      "{'image_id': 442480, 'boxes': tensor([[452, 132, 475, 239],\n",
      "        [ 36, 125, 636, 284],\n",
      "        [478, 250, 487, 269],\n",
      "        [516, 250, 528, 273],\n",
      "        [208, 134, 442, 287],\n",
      "        [495, 249, 505, 271]], dtype=torch.int32), 'scores': tensor([0.1851, 0.9748, 0.4233, 0.4812, 0.9777, 0.4623]), 'objectness_scores': tensor([0.2833, 0.4827, 0.4943, 0.6518, 0.2088, 0.6777]), 'labels': tensor([11,  0, 11, 11,  0, 11], dtype=torch.int32)}\n",
      "442480\n",
      "{'image_id': 443303, 'boxes': tensor([[438,  28, 473,  65],\n",
      "        [193,  96, 498, 316],\n",
      "        [305,  68, 404, 122]], dtype=torch.int32), 'scores': tensor([0.1604, 0.9560, 0.2534]), 'objectness_scores': tensor([0.2319, 0.5075, 0.4392]), 'labels': tensor([10,  2,  7], dtype=torch.int32)}\n",
      "443303\n",
      "{'image_id': 443426, 'boxes': tensor([[393, 503, 413, 528],\n",
      "        [111, 251, 202, 284],\n",
      "        [ 31, 333, 330, 635],\n",
      "        [436, 497, 455, 516],\n",
      "        [419, 378, 446, 384],\n",
      "        [196, 370, 334, 505],\n",
      "        [299, 387, 333, 393],\n",
      "        [369, 382, 404, 388],\n",
      "        [130,   3, 482, 392]], dtype=torch.int32), 'scores': tensor([0.3004, 0.2170, 0.9794, 0.1823, 0.2065, 0.8717, 0.2257, 0.2635, 0.6479]), 'objectness_scores': tensor([0.2921, 0.2901, 0.2138, 0.3918, 0.2487, 0.5489, 0.4571, 0.3809, 0.4051]), 'labels': tensor([11,  7,  7, 11, 11,  7, 14, 14,  7], dtype=torch.int32)}\n",
      "443426\n",
      "{'image_id': 443844, 'boxes': tensor([[538, 102, 571, 128],\n",
      "        [474, 270, 549, 301],\n",
      "        [549, 222, 602, 300]], dtype=torch.int32), 'scores': tensor([0.1452, 0.4101, 0.3883]), 'objectness_scores': tensor([0.2816, 0.3351, 0.4461]), 'labels': tensor([10,  9, 10], dtype=torch.int32)}\n",
      "443844\n",
      "{'image_id': 443969, 'boxes': tensor([[364, 396, 384, 409],\n",
      "        [324, 202, 347, 221],\n",
      "        [122, 128, 201, 237],\n",
      "        [197,  26, 224,  72],\n",
      "        [182,  26, 472, 211],\n",
      "        [146, 217, 489, 613],\n",
      "        [ 32, 167,  87, 285],\n",
      "        [ 24,  94,  88, 167],\n",
      "        [ 18, 210,  77, 331],\n",
      "        [ 68,  47, 106,  70],\n",
      "        [ 44, 530, 108, 583],\n",
      "        [474, 221, 481, 226]], dtype=torch.int32), 'scores': tensor([0.3452, 0.3134, 0.4114, 0.5184, 0.9877, 0.1614, 0.3097, 0.2390, 0.2097,\n",
      "        0.3068, 0.4213, 0.1969]), 'objectness_scores': tensor([0.2000, 0.2784, 0.2685, 0.2678, 0.5354, 0.3324, 0.3147, 0.2481, 0.2633,\n",
      "        0.3011, 0.5398, 0.3497]), 'labels': tensor([11, 11,  9, 11,  6,  9,  9, 10,  3, 11,  9, 11], dtype=torch.int32)}\n",
      "443969\n",
      "{'image_id': 445658, 'boxes': tensor([[409, 150, 447, 222],\n",
      "        [ 50,   5, 144, 149],\n",
      "        [146,  16, 213,  91],\n",
      "        [365, 171, 386, 216],\n",
      "        [168, 158, 195, 187],\n",
      "        [424, 228, 467, 365],\n",
      "        [470,  18, 522,  98],\n",
      "        [441,  33, 472, 151],\n",
      "        [274,  28, 400, 150],\n",
      "        [580,  -1, 639, 146],\n",
      "        [333, 170, 344, 187],\n",
      "        [519,   0, 585,  90],\n",
      "        [142,  95, 273, 128],\n",
      "        [419, 227, 518, 404],\n",
      "        [ 52, 238, 149, 393],\n",
      "        [  0,   3,  51,  58],\n",
      "        [464, 239, 523, 400],\n",
      "        [144,  14, 272,  94],\n",
      "        [320, 227, 417, 367],\n",
      "        [192, 233, 255, 294],\n",
      "        [ 85, 170,  98, 188],\n",
      "        [516, 194, 555, 226],\n",
      "        [368,  38, 443, 150],\n",
      "        [466,   1, 583, 102]], dtype=torch.int32), 'scores': tensor([0.9203, 0.3865, 0.2980, 0.2777, 0.5897, 0.2441, 0.3156, 0.3870, 0.3634,\n",
      "        0.1743, 0.1804, 0.2842, 0.6456, 0.2175, 0.2306, 0.2686, 0.3659, 0.3037,\n",
      "        0.2667, 0.2665, 0.6985, 0.6954, 0.3667, 0.3022]), 'objectness_scores': tensor([0.3007, 0.2979, 0.2074, 0.3756, 0.3022, 0.2247, 0.2237, 0.2347, 0.2626,\n",
      "        0.2317, 0.2889, 0.2103, 0.4320, 0.2448, 0.2902, 0.2321, 0.2323, 0.2583,\n",
      "        0.2816, 0.2982, 0.2746, 0.2730, 0.2061, 0.2487]), 'labels': tensor([15,  8,  9, 11,  3,  7,  8,  7,  8,  7, 14,  7, 14,  7,  3,  8,  8,  7,\n",
      "         7, 10,  3, 15,  8,  8], dtype=torch.int32)}\n",
      "445658\n",
      "{'image_id': 445792, 'boxes': tensor([[  0,  52,  63, 194],\n",
      "        [261, 120, 269, 132]], dtype=torch.int32), 'scores': tensor([0.1824, 0.1397]), 'objectness_scores': tensor([0.2055, 0.3034]), 'labels': tensor([ 7, 14], dtype=torch.int32)}\n",
      "445792\n",
      "{'image_id': 445834, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "445834\n",
      "{'image_id': 445846, 'boxes': tensor([[537, 326, 543, 345],\n",
      "        [283, 275, 344, 372],\n",
      "        [ 66, 345,  72, 355],\n",
      "        [558, 322, 568, 346],\n",
      "        [177, 275, 223, 373],\n",
      "        [188, 131, 198, 146],\n",
      "        [  0, 283, 141, 426],\n",
      "        [342, 277, 404, 374],\n",
      "        [529, 288, 579, 428],\n",
      "        [225, 275, 284, 372],\n",
      "        [404, 277, 466, 377],\n",
      "        [344, 276, 465, 380],\n",
      "        [476, 165, 509, 198],\n",
      "        [531, 292, 542, 417],\n",
      "        [ 63, 266, 167, 294],\n",
      "        [162, 277, 179, 385],\n",
      "        [ 65, 285, 139, 427],\n",
      "        [365, 266, 440, 272],\n",
      "        [291, 267, 350, 271],\n",
      "        [223, 274, 343, 372],\n",
      "        [  0, 305,  65, 427],\n",
      "        [329, 251, 351, 269]], dtype=torch.int32), 'scores': tensor([0.2494, 0.2393, 0.3364, 0.4995, 0.1841, 0.2376, 0.8009, 0.2211, 0.2654,\n",
      "        0.2328, 0.2031, 0.1764, 0.2078, 0.3438, 0.3094, 0.4425, 0.2407, 0.1806,\n",
      "        0.2852, 0.2555, 0.2991, 0.1648]), 'objectness_scores': tensor([0.2665, 0.2390, 0.2037, 0.2020, 0.2977, 0.2311, 0.2472, 0.2596, 0.2942,\n",
      "        0.2409, 0.2388, 0.2396, 0.3118, 0.2038, 0.3729, 0.3591, 0.2502, 0.3429,\n",
      "        0.2066, 0.2339, 0.2090, 0.4995]), 'labels': tensor([11,  7, 11, 11,  7, 11, 16,  7, 16,  8,  7, 11, 11, 11, 11, 11, 16,  4,\n",
      "        11, 11, 16, 14], dtype=torch.int32)}\n",
      "445846\n",
      "{'image_id': 446005, 'boxes': tensor([[358,  17, 401,  95],\n",
      "        [405,   3, 476, 149],\n",
      "        [181, 205, 208, 295],\n",
      "        [208, 165, 215, 176],\n",
      "        [472, 170, 483, 185],\n",
      "        [155, 168, 161, 181],\n",
      "        [ 93, 186, 101, 206],\n",
      "        [  0,   0,  24, 157],\n",
      "        [100, 202, 174, 214],\n",
      "        [285, 166, 293, 179],\n",
      "        [392, 216, 497, 333],\n",
      "        [215, 205, 254, 291],\n",
      "        [255, 208, 302, 303],\n",
      "        [143, 211, 181, 311],\n",
      "        [144, 206, 209, 312],\n",
      "        [ 90, 219, 145, 308],\n",
      "        [257,  30, 316, 148],\n",
      "        [203,  39, 256, 149],\n",
      "        [213, 204, 302, 306],\n",
      "        [313,  14, 401,  99],\n",
      "        [146,  37, 202, 152],\n",
      "        [315,  23, 355,  97],\n",
      "        [394, 219, 475, 332],\n",
      "        [ 54, 207, 134, 220]], dtype=torch.int32), 'scores': tensor([0.3255, 0.2407, 0.4112, 0.2018, 0.2105, 0.2552, 0.2056, 0.3213, 0.2817,\n",
      "        0.2240, 0.3486, 0.4056, 0.9894, 0.3851, 0.1644, 0.3079, 0.2411, 0.2987,\n",
      "        0.2758, 0.2809, 0.3839, 0.2987, 0.1689, 0.2629]), 'objectness_scores': tensor([0.2129, 0.3557, 0.2513, 0.2921, 0.3630, 0.3189, 0.2135, 0.2171, 0.3636,\n",
      "        0.2930, 0.2409, 0.2658, 0.2516, 0.2261, 0.2437, 0.2564, 0.3467, 0.3460,\n",
      "        0.2506, 0.3648, 0.3376, 0.2233, 0.3213, 0.3230]), 'labels': tensor([ 8,  8,  7, 14, 11,  0, 11,  7, 11, 14, 15,  7, 13,  7,  7,  8,  8,  7,\n",
      "        15, 15,  7,  8, 15, 11], dtype=torch.int32)}\n",
      "446005\n",
      "{'image_id': 446206, 'boxes': tensor([[297,  68, 473, 377],\n",
      "        [186, 288, 199, 303],\n",
      "        [451, 306, 466, 318],\n",
      "        [ 95, 277, 105, 282],\n",
      "        [450, 289, 461, 353],\n",
      "        [  7, 131, 104, 277],\n",
      "        [267, 360, 273, 369],\n",
      "        [190, 317, 195, 327]], dtype=torch.int32), 'scores': tensor([0.9380, 0.1634, 0.4674, 0.1667, 0.3447, 0.2532, 0.1589, 0.1848]), 'objectness_scores': tensor([0.2088, 0.2942, 0.2435, 0.2100, 0.2060, 0.2383, 0.2045, 0.2572]), 'labels': tensor([ 1,  9, 11, 10, 11,  6, 11, 11], dtype=torch.int32)}\n",
      "446206\n",
      "{'image_id': 446522, 'boxes': tensor([[164,   0, 381, 163],\n",
      "        [426,   0, 480, 174],\n",
      "        [161, 338, 357, 509],\n",
      "        [364, 450, 419, 576]], dtype=torch.int32), 'scores': tensor([0.2895, 0.4269, 0.9591, 0.5606]), 'objectness_scores': tensor([0.2162, 0.2294, 0.4357, 0.2705]), 'labels': tensor([13,  7,  3, 13], dtype=torch.int32)}\n",
      "446522\n",
      "{'image_id': 447342, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "447342\n",
      "{'image_id': 447465, 'boxes': tensor([[107, 356, 139, 396],\n",
      "        [263,  58, 443, 385],\n",
      "        [101, 180, 136, 220],\n",
      "        [338, 365, 384, 415],\n",
      "        [131,  68, 200, 124],\n",
      "        [426, 138, 463, 183],\n",
      "        [316,   5, 379,  67],\n",
      "        [298, 136, 340, 180],\n",
      "        [135,  82, 200, 120],\n",
      "        [275, 364, 316, 413],\n",
      "        [122, 252, 151, 397],\n",
      "        [316,  29, 379,  62],\n",
      "        [  0,   1,  78, 277]], dtype=torch.int32), 'scores': tensor([0.5857, 0.6032, 0.8319, 0.9612, 0.7950, 0.7769, 0.9288, 0.6044, 0.1871,\n",
      "        0.8216, 0.4587, 0.9611, 0.7150]), 'objectness_scores': tensor([0.2372, 0.2056, 0.2671, 0.2923, 0.2524, 0.2806, 0.2246, 0.2239, 0.3247,\n",
      "        0.2670, 0.2449, 0.2825, 0.2092]), 'labels': tensor([ 7,  8,  8,  8,  8,  8,  8,  8,  8,  8, 11,  8,  8], dtype=torch.int32)}\n",
      "447465\n",
      "{'image_id': 447611, 'boxes': tensor([[ 48,   0,  94,  50],\n",
      "        [244,   0, 280, 166],\n",
      "        [  2, 130, 498, 332]], dtype=torch.int32), 'scores': tensor([0.3916, 0.2687, 0.9042]), 'objectness_scores': tensor([0.5337, 0.5377, 0.5264]), 'labels': tensor([11, 14, 14], dtype=torch.int32)}\n",
      "447611\n",
      "{'image_id': 448365, 'boxes': tensor([[189, 158, 294, 257],\n",
      "        [192, 269, 339, 409]], dtype=torch.int32), 'scores': tensor([0.2656, 0.9660]), 'objectness_scores': tensor([0.2193, 0.6321]), 'labels': tensor([9, 9], dtype=torch.int32)}\n",
      "448365\n",
      "{'image_id': 449190, 'boxes': tensor([[418, 104, 451, 123],\n",
      "        [300, 164, 401, 317],\n",
      "        [ 57,  16, 234, 201],\n",
      "        [  6,   0, 282, 254],\n",
      "        [411,  76, 454, 111],\n",
      "        [573,  67, 638,  89],\n",
      "        [356,  63, 390,  93],\n",
      "        [  5,   0, 639, 362]], dtype=torch.int32), 'scores': tensor([0.3747, 0.3327, 0.5470, 0.6238, 0.1838, 0.5025, 0.2598, 0.2865]), 'objectness_scores': tensor([0.2610, 0.2161, 0.4447, 0.2266, 0.3099, 0.2009, 0.3093, 0.4075]), 'labels': tensor([11, 14, 12, 12,  2,  7,  7,  7], dtype=torch.int32)}\n",
      "449190\n",
      "{'image_id': 449432, 'boxes': tensor([[331, 177, 357, 190],\n",
      "        [599, 180, 619, 190],\n",
      "        [284, 331, 306, 341],\n",
      "        [487, 297, 506, 305],\n",
      "        [431, 312, 456, 323],\n",
      "        [629, 110, 637, 126],\n",
      "        [127, 291, 141, 311],\n",
      "        [272, 188, 293, 201],\n",
      "        [597, 298, 606, 305],\n",
      "        [585, 294, 594, 303],\n",
      "        [390, 178, 410, 188],\n",
      "        [342, 320, 366, 329],\n",
      "        [534, 191, 549, 201],\n",
      "        [307, 345, 332, 357],\n",
      "        [483, 183, 500, 192],\n",
      "        [440, 174, 461, 184],\n",
      "        [311, 193, 332, 204],\n",
      "        [576, 177, 592, 186],\n",
      "        [458, 305, 473, 312],\n",
      "        [121, 178, 136, 187],\n",
      "        [212, 181, 236, 191],\n",
      "        [415, 184, 431, 193],\n",
      "        [421, 299, 440, 306],\n",
      "        [215, 338, 232, 351],\n",
      "        [520, 181, 540, 192],\n",
      "        [148, 288, 168, 308]], dtype=torch.int32), 'scores': tensor([0.2857, 0.4300, 0.3199, 0.2618, 0.3066, 0.2915, 0.2967, 0.3513, 0.1969,\n",
      "        0.1344, 0.2909, 0.2771, 0.3316, 0.1894, 0.2823, 0.3895, 0.7401, 0.3123,\n",
      "        0.2439, 0.2225, 0.5911, 0.4164, 0.2240, 0.2578, 0.2665, 0.3245]), 'objectness_scores': tensor([0.4178, 0.4187, 0.2053, 0.2364, 0.2148, 0.2167, 0.2654, 0.3224, 0.2035,\n",
      "        0.2076, 0.3834, 0.2193, 0.3865, 0.2160, 0.4049, 0.4340, 0.3259, 0.3725,\n",
      "        0.2013, 0.3289, 0.3272, 0.3189, 0.2510, 0.2000, 0.4211, 0.2450]), 'labels': tensor([11, 11, 14, 11, 11, 11, 11, 11, 14, 11, 11, 11, 11,  7, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "449432\n",
      "{'image_id': 449661, 'boxes': tensor([[424,  78, 472, 116],\n",
      "        [122,  83, 168, 101],\n",
      "        [194,  98, 258, 135],\n",
      "        [ 50,  85, 120, 168],\n",
      "        [141,  55, 148,  71]], dtype=torch.int32), 'scores': tensor([0.1937, 0.3388, 0.4467, 0.1753, 0.9155]), 'objectness_scores': tensor([0.2802, 0.4987, 0.2795, 0.2403, 0.3429]), 'labels': tensor([13,  0,  9, 15,  8], dtype=torch.int32)}\n",
      "449661\n",
      "{'image_id': 449996, 'boxes': tensor([[142, 250, 262, 295],\n",
      "        [  2, 374, 209, 428],\n",
      "        [391, 273, 461, 295],\n",
      "        [508, 256, 640, 297],\n",
      "        [555, 256, 566, 283],\n",
      "        [557, 258, 641, 295],\n",
      "        [132, 325, 153, 336],\n",
      "        [501, 260, 578, 297],\n",
      "        [115, 292, 245, 338],\n",
      "        [132, 374, 207, 428],\n",
      "        [443, 111, 498, 129]], dtype=torch.int32), 'scores': tensor([0.9778, 0.5786, 0.3546, 0.9661, 0.3432, 0.9812, 0.2596, 0.4113, 0.9774,\n",
      "        0.8205, 0.9606]), 'objectness_scores': tensor([0.5621, 0.2168, 0.5518, 0.5268, 0.2167, 0.3508, 0.2633, 0.3475, 0.5362,\n",
      "        0.2665, 0.5405]), 'labels': tensor([ 0,  0, 14,  0,  7,  0, 11,  1,  0,  0,  0], dtype=torch.int32)}\n",
      "449996\n",
      "{'image_id': 450075, 'boxes': tensor([[210, 274, 303, 320],\n",
      "        [447, 160, 641, 477],\n",
      "        [  5,   1, 639, 477]], dtype=torch.int32), 'scores': tensor([0.8541, 0.6651, 0.6885]), 'objectness_scores': tensor([0.2084, 0.2336, 0.2967]), 'labels': tensor([7, 7, 7], dtype=torch.int32)}\n",
      "450075\n",
      "{'image_id': 450100, 'boxes': tensor([[155,   1, 396, 255],\n",
      "        [  2, 388, 475, 640],\n",
      "        [  0,   4, 479, 632],\n",
      "        [116, 169, 255, 260],\n",
      "        [  0,   2, 381, 227],\n",
      "        [  2, 393, 471, 636],\n",
      "        [ 48, 169, 329, 581]], dtype=torch.int32), 'scores': tensor([0.8816, 0.8874, 0.9204, 0.2799, 0.3035, 0.8200, 0.9643]), 'objectness_scores': tensor([0.5256, 0.2950, 0.2928, 0.2472, 0.3719, 0.4189, 0.5530]), 'labels': tensor([10, 12, 12, 12, 10, 12, 12], dtype=torch.int32)}\n",
      "450100\n",
      "{'image_id': 450488, 'boxes': tensor([[188, 243, 316, 387],\n",
      "        [128, 215, 138, 220],\n",
      "        [  0,  29, 143,  99],\n",
      "        [257, 339, 305, 396],\n",
      "        [ 72, 216, 107, 251]], dtype=torch.int32), 'scores': tensor([0.8574, 0.3051, 0.4535, 0.6803, 0.3565]), 'objectness_scores': tensor([0.2865, 0.4232, 0.7693, 0.5626, 0.2415]), 'labels': tensor([15, 11,  6, 10,  7], dtype=torch.int32)}\n",
      "450488\n",
      "{'image_id': 450559, 'boxes': tensor([[129,  35, 200,  85],\n",
      "        [226, 240, 270, 314],\n",
      "        [ 81, 100, 166, 216],\n",
      "        [187, 211, 342, 372]], dtype=torch.int32), 'scores': tensor([0.7899, 0.7929, 0.4803, 0.9957]), 'objectness_scores': tensor([0.3643, 0.2201, 0.4620, 0.6335]), 'labels': tensor([8, 9, 9, 9], dtype=torch.int32)}\n",
      "450559\n",
      "{'image_id': 451043, 'boxes': tensor([[165, 147, 191, 165],\n",
      "        [167, 153, 193, 175],\n",
      "        [166, 225, 185, 249]], dtype=torch.int32), 'scores': tensor([0.3872, 0.3132, 0.4313]), 'objectness_scores': tensor([0.3099, 0.6058, 0.4821]), 'labels': tensor([8, 8, 8], dtype=torch.int32)}\n",
      "451043\n",
      "{'image_id': 451084, 'boxes': tensor([[165, 256, 212, 306],\n",
      "        [183, 194, 316, 337],\n",
      "        [246, 334, 303, 381],\n",
      "        [186, 303, 286, 421]], dtype=torch.int32), 'scores': tensor([0.5205, 0.9534, 0.6983, 0.5800]), 'objectness_scores': tensor([0.2593, 0.2220, 0.2079, 0.6368]), 'labels': tensor([9, 9, 9, 8], dtype=torch.int32)}\n",
      "451084\n",
      "{'image_id': 452784, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "452784\n",
      "{'image_id': 452793, 'boxes': tensor([[180,  39, 208,  59],\n",
      "        [353, 295, 379, 426],\n",
      "        [308, 164, 350, 210],\n",
      "        [235, 183, 251, 194],\n",
      "        [250,   0, 269,  64],\n",
      "        [249, 209, 327, 223],\n",
      "        [226, 222, 337, 364],\n",
      "        [296, 216, 359, 228],\n",
      "        [334, 241, 379, 425],\n",
      "        [245, 203, 256, 207],\n",
      "        [169, 215, 231, 335],\n",
      "        [398,   0, 422,  56]], dtype=torch.int32), 'scores': tensor([0.3313, 0.2692, 0.8553, 0.2999, 0.2965, 0.2370, 0.2290, 0.2974, 0.2990,\n",
      "        0.2482, 0.2391, 0.5519]), 'objectness_scores': tensor([0.2797, 0.2120, 0.4542, 0.2688, 0.3109, 0.3648, 0.3690, 0.3758, 0.3029,\n",
      "        0.3267, 0.2907, 0.3062]), 'labels': tensor([10,  7, 15, 14, 16, 11, 12, 11,  7, 11,  7, 16], dtype=torch.int32)}\n",
      "452793\n",
      "{'image_id': 452891, 'boxes': tensor([[186, 224, 351, 362],\n",
      "        [  0, 366, 276, 636],\n",
      "        [ 58,  84, 409, 540]], dtype=torch.int32), 'scores': tensor([0.9498, 0.7944, 0.9619]), 'objectness_scores': tensor([0.2315, 0.2328, 0.4836]), 'labels': tensor([3, 3, 3], dtype=torch.int32)}\n",
      "452891\n",
      "{'image_id': 453166, 'boxes': tensor([[396, 207, 408, 229],\n",
      "        [371, 117, 386, 153],\n",
      "        [532, 165, 547, 182],\n",
      "        [228, 237, 233, 243],\n",
      "        [505, 116, 517, 135],\n",
      "        [224, 190, 282, 231],\n",
      "        [323, 163, 381, 202],\n",
      "        [248, 115, 261, 154],\n",
      "        [277, 143, 306, 162],\n",
      "        [ 86, 144, 108, 224],\n",
      "        [100, 167, 135, 200],\n",
      "        [295, 226, 308, 241],\n",
      "        [601, 302, 606, 307]], dtype=torch.int32), 'scores': tensor([0.2988, 0.2033, 0.1806, 0.2577, 0.2307, 0.2634, 0.2707, 0.3288, 0.4273,\n",
      "        0.7429, 0.2617, 0.4007, 0.1751]), 'objectness_scores': tensor([0.4783, 0.3121, 0.2046, 0.2676, 0.3415, 0.3272, 0.3190, 0.3926, 0.2114,\n",
      "        0.3177, 0.2467, 0.3814, 0.2985]), 'labels': tensor([ 2, 11,  8, 13, 11, 13, 13,  7, 14,  7, 12, 11, 11], dtype=torch.int32)}\n",
      "453166\n",
      "{'image_id': 453302, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "453302\n",
      "{'image_id': 453341, 'boxes': tensor([[364, 340, 380, 364],\n",
      "        [569, 273, 602, 319],\n",
      "        [460, 197, 486, 230],\n",
      "        [397, 328, 424, 352],\n",
      "        [563, 352, 586, 379],\n",
      "        [241, 201, 279, 266],\n",
      "        [ 70, 231, 168, 343],\n",
      "        [378, 129, 528, 373],\n",
      "        [261, 318, 283, 355],\n",
      "        [  1, 317, 169, 410],\n",
      "        [ 69, 390, 206, 478],\n",
      "        [461, 196, 481, 228],\n",
      "        [ 90, 193, 115, 236],\n",
      "        [156, 227, 200, 334],\n",
      "        [124, 192, 144, 216],\n",
      "        [ 72,  60, 151, 193],\n",
      "        [161, 127, 206, 199],\n",
      "        [224, 308, 273, 351],\n",
      "        [438, 228, 489, 349],\n",
      "        [456, 157, 477, 186],\n",
      "        [461, 135, 493, 150],\n",
      "        [ 90, 219, 103, 241],\n",
      "        [103, 309, 142, 354],\n",
      "        [349, 342, 393, 395],\n",
      "        [378, 207, 426, 274],\n",
      "        [204, 197, 231, 243],\n",
      "        [519, 207, 534, 234],\n",
      "        [  0, 316,  62, 337],\n",
      "        [266,  28, 292,  75],\n",
      "        [598,   4, 639,  97],\n",
      "        [246, 114, 290, 181],\n",
      "        [171,  23, 224, 114],\n",
      "        [346,  24, 386, 101],\n",
      "        [343, 358, 386, 391],\n",
      "        [478, 198, 488, 228],\n",
      "        [ 86, 202, 100, 221],\n",
      "        [567, 248, 612, 322],\n",
      "        [153, 330, 336, 479],\n",
      "        [374, 201, 438, 277],\n",
      "        [154, 329, 328, 411]], dtype=torch.int32), 'scores': tensor([0.2053, 0.2731, 0.3158, 0.1561, 0.2439, 0.1461, 0.4965, 0.1953, 0.4239,\n",
      "        0.2021, 0.4267, 0.2910, 0.3057, 0.2622, 0.1547, 0.3666, 0.4703, 0.3957,\n",
      "        0.1745, 0.2379, 0.3021, 0.2268, 0.4839, 0.5717, 0.2202, 0.6722, 0.1551,\n",
      "        0.2813, 0.1489, 0.2744, 0.6209, 0.1735, 0.2659, 0.3525, 0.1660, 0.3272,\n",
      "        0.2467, 0.2274, 0.1884, 0.2606]), 'objectness_scores': tensor([0.3304, 0.2276, 0.2768, 0.3142, 0.2816, 0.3615, 0.2927, 0.4372, 0.3309,\n",
      "        0.2788, 0.4354, 0.2975, 0.2536, 0.4917, 0.2180, 0.3129, 0.3307, 0.4278,\n",
      "        0.2386, 0.3128, 0.2765, 0.2156, 0.4111, 0.3144, 0.2067, 0.3234, 0.2428,\n",
      "        0.3512, 0.2863, 0.2349, 0.3179, 0.3167, 0.2114, 0.2052, 0.2557, 0.2552,\n",
      "        0.2151, 0.3462, 0.2242, 0.2122]), 'labels': tensor([14,  7,  3,  3,  3,  7, 14,  2,  7,  9,  7,  3,  7,  7, 14,  7,  7,  4,\n",
      "         9,  8, 11, 11, 11,  2, 16,  7, 14, 11,  8,  7,  7,  7,  8,  2,  0, 11,\n",
      "         7,  7,  6,  9], dtype=torch.int32)}\n",
      "453341\n",
      "{'image_id': 453634, 'boxes': tensor([[  0, 411, 101, 640],\n",
      "        [217, 504, 284, 620],\n",
      "        [262, 248, 329, 410],\n",
      "        [415, 564, 480, 622],\n",
      "        [372, 483, 478, 578],\n",
      "        [151,   1, 191,  61],\n",
      "        [287, 419, 429, 491],\n",
      "        [287, 196, 341, 254],\n",
      "        [  1,   4, 314, 323],\n",
      "        [295, 185, 337, 221],\n",
      "        [  1,   7, 479, 639],\n",
      "        [461, 348, 479, 388]], dtype=torch.int32), 'scores': tensor([0.2932, 0.5889, 0.2429, 0.3823, 0.3004, 0.5875, 0.5958, 0.7162, 0.9772,\n",
      "        0.3655, 0.9954, 0.2212]), 'objectness_scores': tensor([0.3966, 0.2399, 0.2182, 0.5150, 0.3619, 0.2133, 0.2243, 0.2659, 0.3910,\n",
      "        0.2052, 0.2566, 0.2963]), 'labels': tensor([15,  7, 11,  7,  7, 11, 11, 10, 15, 14, 15,  3], dtype=torch.int32)}\n",
      "453634\n",
      "{'image_id': 453722, 'boxes': tensor([[  0, 281,  90, 344],\n",
      "        [  0, 184,  52, 225],\n",
      "        [  0, 260, 207, 427],\n",
      "        [196, 201, 257, 255],\n",
      "        [439,  88, 499, 100],\n",
      "        [560, 230, 639, 399],\n",
      "        [379,  47, 425, 102],\n",
      "        [  0, 184,  51, 268],\n",
      "        [301,  91, 355, 104],\n",
      "        [ 11, 260,  95, 291],\n",
      "        [550, 212, 561, 219],\n",
      "        [211, 211, 250, 225]], dtype=torch.int32), 'scores': tensor([0.8391, 0.1905, 0.9907, 0.5048, 0.2709, 0.9364, 0.1905, 0.2079, 0.2767,\n",
      "        0.1707, 0.3144, 0.5050]), 'objectness_scores': tensor([0.2947, 0.2151, 0.4634, 0.2472, 0.2209, 0.4190, 0.2234, 0.3015, 0.2295,\n",
      "        0.3275, 0.2827, 0.2595]), 'labels': tensor([13,  7, 13, 14, 14, 13,  7,  7, 11,  8, 14, 11], dtype=torch.int32)}\n",
      "453722\n",
      "{'image_id': 454661, 'boxes': tensor([[459, 268, 485, 296],\n",
      "        [ 59, 160,  78, 186],\n",
      "        [169, 115, 193, 183],\n",
      "        [412, 269, 440, 298],\n",
      "        [192, 248, 208, 263],\n",
      "        [614, 265, 638, 294],\n",
      "        [482,  98, 500, 117],\n",
      "        [271, 238, 293, 256],\n",
      "        [ 94, 262, 124, 290],\n",
      "        [ 49, 164,  60, 185],\n",
      "        [233,  59, 270, 160],\n",
      "        [271,  38, 311, 142],\n",
      "        [129, 261, 157, 289],\n",
      "        [212, 248, 227, 263]], dtype=torch.int32), 'scores': tensor([0.1931, 0.3199, 0.3977, 0.1938, 0.2815, 0.1689, 0.2179, 0.2169, 0.5176,\n",
      "        0.4535, 0.2767, 0.3192, 0.2677, 0.2732]), 'objectness_scores': tensor([0.2133, 0.3216, 0.5488, 0.2268, 0.2702, 0.2074, 0.3399, 0.2679, 0.2595,\n",
      "        0.2373, 0.5780, 0.5740, 0.2514, 0.2506]), 'labels': tensor([14, 14, 14, 14, 11, 11, 14, 13, 14, 11,  9,  9, 14, 14],\n",
      "       dtype=torch.int32)}\n",
      "454661\n",
      "{'image_id': 454798, 'boxes': tensor([[544, 137, 552, 142],\n",
      "        [278,  63, 324,  92],\n",
      "        [160, 287, 526, 395]], dtype=torch.int32), 'scores': tensor([0.1920, 0.2246, 0.1803]), 'objectness_scores': tensor([0.2572, 0.2261, 0.3218]), 'labels': tensor([10,  4,  9], dtype=torch.int32)}\n",
      "454798\n",
      "{'image_id': 455085, 'boxes': tensor([[362, 256, 395, 472],\n",
      "        [386, 269, 411, 436],\n",
      "        [348, 246, 375, 479]], dtype=torch.int32), 'scores': tensor([0.2428, 0.3290, 0.2107]), 'objectness_scores': tensor([0.2492, 0.2789, 0.2313]), 'labels': tensor([14, 11, 14], dtype=torch.int32)}\n",
      "455085\n",
      "{'image_id': 455157, 'boxes': tensor([[244, 134, 444, 305],\n",
      "        [261, 278, 279, 292]], dtype=torch.int32), 'scores': tensor([0.9992, 0.4296]), 'objectness_scores': tensor([0.4994, 0.3154]), 'labels': tensor([ 6, 11], dtype=torch.int32)}\n",
      "455157\n",
      "{'image_id': 455219, 'boxes': tensor([[317, 216, 363, 234],\n",
      "        [326, 224, 496, 341],\n",
      "        [242, 217, 439, 362],\n",
      "        [246, 219, 490, 342]], dtype=torch.int32), 'scores': tensor([0.1621, 0.9910, 0.9969, 0.9947]), 'objectness_scores': tensor([0.2034, 0.4660, 0.5803, 0.2332]), 'labels': tensor([7, 4, 4, 4], dtype=torch.int32)}\n",
      "455219\n",
      "{'image_id': 455448, 'boxes': tensor([[452, 231, 474, 252],\n",
      "        [283,  95, 302, 116],\n",
      "        [239,  16, 280,  88]], dtype=torch.int32), 'scores': tensor([0.2448, 0.3137, 0.2398]), 'objectness_scores': tensor([0.2892, 0.2008, 0.2064]), 'labels': tensor([12, 11,  7], dtype=torch.int32)}\n",
      "455448\n",
      "{'image_id': 455555, 'boxes': tensor([[247, 182, 323, 339],\n",
      "        [462, 209, 506, 231],\n",
      "        [188, 358, 240, 446],\n",
      "        [198, 345, 315, 469],\n",
      "        [182, 359, 240, 459],\n",
      "        [511,  47, 565,  77]], dtype=torch.int32), 'scores': tensor([0.2972, 0.3179, 0.2467, 0.5596, 0.2372, 0.2793]), 'objectness_scores': tensor([0.2681, 0.2779, 0.2270, 0.4187, 0.2084, 0.5686]), 'labels': tensor([ 6, 11, 11,  9, 11, 11], dtype=torch.int32)}\n",
      "455555\n",
      "{'image_id': 455597, 'boxes': tensor([[408, 240, 457, 280],\n",
      "        [304, 270, 495, 333],\n",
      "        [ 69,  73, 134, 157],\n",
      "        [206,   0, 638, 175],\n",
      "        [427, 217, 439, 233],\n",
      "        [494, 259, 553, 293],\n",
      "        [152,  65, 186, 105],\n",
      "        [353,  28, 390, 121],\n",
      "        [353,  28, 389,  62],\n",
      "        [506, 300, 614, 389],\n",
      "        [529, 258, 602, 297],\n",
      "        [511,  74, 529,  97],\n",
      "        [319, 280, 379, 306],\n",
      "        [498,   0, 545,  30],\n",
      "        [379, 346, 610, 443],\n",
      "        [171, 170, 187, 175],\n",
      "        [550, 269, 624, 301],\n",
      "        [422, 345, 520, 370],\n",
      "        [239,  85, 255, 104],\n",
      "        [491, 256, 625, 303],\n",
      "        [364,  97, 388, 118],\n",
      "        [103, 224, 134, 232],\n",
      "        [314, 201, 324, 222],\n",
      "        [146,  98, 378, 191]], dtype=torch.int32), 'scores': tensor([0.8116, 0.4365, 0.3290, 0.3798, 0.2488, 0.1973, 0.2459, 0.4907, 0.1792,\n",
      "        0.9476, 0.1652, 0.4045, 0.1470, 0.2275, 0.7092, 0.2149, 0.2978, 0.3722,\n",
      "        0.2775, 0.2235, 0.2733, 0.2371, 0.1450, 0.5351]), 'objectness_scores': tensor([0.3971, 0.3178, 0.6722, 0.2523, 0.3823, 0.2987, 0.3896, 0.2242, 0.3006,\n",
      "        0.4783, 0.2813, 0.2613, 0.2137, 0.2842, 0.2251, 0.2218, 0.2915, 0.3101,\n",
      "        0.2250, 0.2055, 0.2380, 0.2529, 0.6125, 0.2167]), 'labels': tensor([10, 15, 15, 15, 14, 11, 11,  7, 11, 10, 10, 11,  9, 11, 10, 14, 11, 11,\n",
      "        11, 10,  7, 11, 14, 10], dtype=torch.int32)}\n",
      "455597\n",
      "{'image_id': 455937, 'boxes': tensor([[202, 336, 251, 358],\n",
      "        [204,  70, 233, 223],\n",
      "        [ 63, 203,  77, 226],\n",
      "        [363,   9, 441, 106],\n",
      "        [318, 186, 583, 306],\n",
      "        [179, 315, 213, 327],\n",
      "        [579,  26, 611, 265],\n",
      "        [476,  99, 521, 212],\n",
      "        [528, 205, 594, 347],\n",
      "        [561,  35, 617, 226],\n",
      "        [285, 171, 327, 196],\n",
      "        [ 26, 217, 126, 275]], dtype=torch.int32), 'scores': tensor([0.2122, 0.2026, 0.2284, 0.4321, 0.7958, 0.3314, 0.5174, 0.3747, 0.6130,\n",
      "        0.3755, 0.7194, 0.2965]), 'objectness_scores': tensor([0.3412, 0.2422, 0.2241, 0.2122, 0.2853, 0.2310, 0.2435, 0.3261, 0.5288,\n",
      "        0.3057, 0.2533, 0.2225]), 'labels': tensor([ 7,  7, 11, 11, 13, 11,  8, 10, 12,  1, 14,  7], dtype=torch.int32)}\n",
      "455937\n",
      "{'image_id': 456292, 'boxes': tensor([[186, 169, 269, 276]], dtype=torch.int32), 'scores': tensor([0.7942]), 'objectness_scores': tensor([0.3067]), 'labels': tensor([16], dtype=torch.int32)}\n",
      "456292\n",
      "{'image_id': 456303, 'boxes': tensor([[ 93,  93, 209, 232],\n",
      "        [124, 193, 161, 235],\n",
      "        [170, 224, 188, 247],\n",
      "        [115, 309, 140, 325]], dtype=torch.int32), 'scores': tensor([0.7255, 0.2530, 0.2084, 0.3140]), 'objectness_scores': tensor([0.2068, 0.3559, 0.3618, 0.2707]), 'labels': tensor([ 8,  2, 14, 11], dtype=torch.int32)}\n",
      "456303\n",
      "{'image_id': 456559, 'boxes': tensor([[207,   7, 483, 178],\n",
      "        [249, 171, 450, 276]], dtype=torch.int32), 'scores': tensor([0.7183, 0.3009]), 'objectness_scores': tensor([0.4306, 0.4656]), 'labels': tensor([7, 7], dtype=torch.int32)}\n",
      "456559\n",
      "{'image_id': 457078, 'boxes': tensor([[156, 393, 186, 421],\n",
      "        [280,   0, 321,  56],\n",
      "        [ 82,   0, 147,  40],\n",
      "        [242,  83, 316, 147],\n",
      "        [ 96,  74, 126, 105],\n",
      "        [ 71,  19, 141, 103],\n",
      "        [186, 119, 211, 142],\n",
      "        [276, 428, 322, 447],\n",
      "        [268, 221, 309, 278],\n",
      "        [245,  86, 292, 141],\n",
      "        [221, 197, 253, 232],\n",
      "        [385,  39, 414,  93],\n",
      "        [  3,  58,  51,  97],\n",
      "        [109, 424, 151, 479]], dtype=torch.int32), 'scores': tensor([0.8335, 0.2103, 0.6409, 0.2512, 0.6692, 0.4182, 0.2670, 0.6155, 0.9244,\n",
      "        0.1523, 0.2515, 0.2004, 0.1329, 0.8686]), 'objectness_scores': tensor([0.2195, 0.2124, 0.2014, 0.2193, 0.2770, 0.2097, 0.2000, 0.2007, 0.2105,\n",
      "        0.2090, 0.2392, 0.2185, 0.2297, 0.3027]), 'labels': tensor([10, 13,  8,  7,  7,  7,  7, 11,  8, 11,  8, 10,  5, 10],\n",
      "       dtype=torch.int32)}\n",
      "457078\n",
      "{'image_id': 458255, 'boxes': tensor([[ -2,  52, 570, 213],\n",
      "        [249, 151, 487, 275],\n",
      "        [149, 269, 174, 280],\n",
      "        [  0, 166, 221, 319],\n",
      "        [284, 186, 465, 334],\n",
      "        [  2, 178, 129, 319],\n",
      "        [494, 203, 599, 287]], dtype=torch.int32), 'scores': tensor([0.9492, 0.9488, 0.5985, 0.2081, 0.9643, 0.4784, 0.9345]), 'objectness_scores': tensor([0.3102, 0.4706, 0.5680, 0.3170, 0.5565, 0.3340, 0.5659]), 'labels': tensor([13,  2, 11, 13,  2, 13, 13], dtype=torch.int32)}\n",
      "458255\n",
      "{'image_id': 458325, 'boxes': tensor([[283, 143, 292, 153],\n",
      "        [227, 207, 259, 240],\n",
      "        [154,  67, 172,  94],\n",
      "        [341,  62, 352,  87],\n",
      "        [312, 330, 335, 348],\n",
      "        [355,  63, 369,  88]], dtype=torch.int32), 'scores': tensor([0.2331, 0.2212, 0.9234, 0.1811, 0.2035, 0.2274]), 'objectness_scores': tensor([0.2061, 0.3911, 0.4698, 0.3432, 0.3668, 0.3109]), 'labels': tensor([11,  9,  1,  8, 11, 14], dtype=torch.int32)}\n",
      "458325\n",
      "{'image_id': 458410, 'boxes': tensor([[291, 314, 397, 455],\n",
      "        [408, 156, 460, 272],\n",
      "        [123, 125, 136, 147],\n",
      "        [  0, 250,  91, 374],\n",
      "        [ 67, 128,  81, 149],\n",
      "        [408, 156, 460, 217],\n",
      "        [200, 202, 333, 314],\n",
      "        [372, 236, 640, 475],\n",
      "        [197,  39, 257,  64]], dtype=torch.int32), 'scores': tensor([0.7532, 0.2650, 0.2518, 0.4552, 0.3409, 0.3236, 0.4300, 0.9960, 0.4434]), 'objectness_scores': tensor([0.3166, 0.2885, 0.2039, 0.2634, 0.2086, 0.2489, 0.2696, 0.4633, 0.2374]), 'labels': tensor([12,  7, 11,  7, 11,  7, 13, 13, 11], dtype=torch.int32)}\n",
      "458410\n",
      "{'image_id': 458663, 'boxes': tensor([[421,   0, 505,  26],\n",
      "        [573, 201, 584, 213],\n",
      "        [  8,  13,  62,  36],\n",
      "        [408, 276, 434, 373],\n",
      "        [596, 200, 603, 212],\n",
      "        [623, 200, 631, 212],\n",
      "        [ 97, 296, 261, 363],\n",
      "        [394, 303, 414, 354],\n",
      "        [369, 310, 399, 367],\n",
      "        [387, 261, 432, 276],\n",
      "        [161, 274, 195, 309],\n",
      "        [603, 200, 614, 214],\n",
      "        [295, 261, 427, 310],\n",
      "        [228,  77, 257, 121],\n",
      "        [563, 201, 572, 213],\n",
      "        [552, 147, 640, 218],\n",
      "        [ 61, 139, 270, 195],\n",
      "        [424, 233, 436, 247]], dtype=torch.int32), 'scores': tensor([0.1742, 0.2903, 0.5990, 0.4914, 0.2556, 0.2484, 0.4182, 0.4893, 0.6368,\n",
      "        0.3903, 0.5024, 0.3473, 0.4907, 0.2649, 0.2423, 0.3320, 0.9486, 0.4830]), 'objectness_scores': tensor([0.2224, 0.2648, 0.2024, 0.2368, 0.2866, 0.2808, 0.4356, 0.2162, 0.2938,\n",
      "        0.4082, 0.3606, 0.2689, 0.4545, 0.2125, 0.2534, 0.2430, 0.3378, 0.2584]), 'labels': tensor([11, 11, 15,  8, 11, 11,  9,  7,  3, 11,  8, 11, 14,  7, 11,  6,  6, 14],\n",
      "       dtype=torch.int32)}\n",
      "458663\n",
      "{'image_id': 458768, 'boxes': tensor([[203, 331, 309, 369],\n",
      "        [236,  32, 260, 181],\n",
      "        [469, 298, 636, 345],\n",
      "        [ 50, 260, 204, 349],\n",
      "        [198, 279, 256, 346],\n",
      "        [103,   0, 173, 141],\n",
      "        [197, 128, 234, 170],\n",
      "        [200,   2, 236, 170],\n",
      "        [236, 153, 260, 181]], dtype=torch.int32), 'scores': tensor([0.5890, 0.2854, 0.6704, 0.9289, 0.9863, 0.4753, 0.7093, 0.3618, 0.5617]), 'objectness_scores': tensor([0.3538, 0.2105, 0.4653, 0.2935, 0.2744, 0.2384, 0.2183, 0.2321, 0.2188]), 'labels': tensor([11,  7, 14, 13, 15,  6,  8,  7, 11], dtype=torch.int32)}\n",
      "458768\n",
      "{'image_id': 458992, 'boxes': tensor([[ 48, 158, 327, 402],\n",
      "        [  2, 447, 474, 639],\n",
      "        [427, 492, 478, 641],\n",
      "        [181, 177, 263, 394]], dtype=torch.int32), 'scores': tensor([0.5006, 0.9062, 0.4651, 0.7975]), 'objectness_scores': tensor([0.2572, 0.2243, 0.2521, 0.3347]), 'labels': tensor([ 7, 12, 10,  7], dtype=torch.int32)}\n",
      "458992\n",
      "{'image_id': 460147, 'boxes': tensor([[148,  37, 220, 268],\n",
      "        [208, 125, 233, 157],\n",
      "        [ 97,  35, 127,  64],\n",
      "        [185,  91, 214, 119],\n",
      "        [325, 118, 338, 125],\n",
      "        [ 31, 118, 125, 159],\n",
      "        [193, 157, 225, 180],\n",
      "        [176, 126, 208, 161]], dtype=torch.int32), 'scores': tensor([0.2724, 0.3549, 0.3443, 0.2905, 0.4190, 0.1951, 0.2246, 0.3869]), 'objectness_scores': tensor([0.2001, 0.3932, 0.2193, 0.2462, 0.2650, 0.2355, 0.2354, 0.3632]), 'labels': tensor([ 8, 14, 14, 14, 14,  1, 11, 11], dtype=torch.int32)}\n",
      "460147\n",
      "{'image_id': 460347, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "460347\n",
      "{'image_id': 460494, 'boxes': tensor([[147,   0, 284, 151],\n",
      "        [  2,  91, 632, 425],\n",
      "        [274, 195, 499, 315],\n",
      "        [  4,   7, 637, 427],\n",
      "        [ 61, 138, 541, 370]], dtype=torch.int32), 'scores': tensor([0.9758, 0.3563, 0.8116, 0.4515, 0.3834]), 'objectness_scores': tensor([0.4376, 0.3739, 0.3172, 0.3165, 0.3084]), 'labels': tensor([10, 11, 12, 11, 11], dtype=torch.int32)}\n",
      "460494\n",
      "{'image_id': 460683, 'boxes': tensor([[415, 373, 475, 483],\n",
      "        [188, 588, 217, 621],\n",
      "        [300, 443, 370, 546],\n",
      "        [184,  86, 299, 547]], dtype=torch.int32), 'scores': tensor([0.3238, 0.4555, 0.1770, 0.9665]), 'objectness_scores': tensor([0.3322, 0.6830, 0.3409, 0.6183]), 'labels': tensor([13, 10, 11,  7], dtype=torch.int32)}\n",
      "460683\n",
      "{'image_id': 460841, 'boxes': tensor([[272, 176, 408, 286],\n",
      "        [ 55, 111, 176, 230],\n",
      "        [ 71, 236, 239, 359],\n",
      "        [394,  -1, 502, 107]], dtype=torch.int32), 'scores': tensor([0.5229, 0.9710, 0.5586, 0.1864]), 'objectness_scores': tensor([0.3175, 0.5698, 0.2048, 0.3343]), 'labels': tensor([10,  2, 12, 13], dtype=torch.int32)}\n",
      "460841\n",
      "{'image_id': 460967, 'boxes': tensor([[ 63, 393, 177, 489],\n",
      "        [ 59, 354, 560, 553]], dtype=torch.int32), 'scores': tensor([0.5507, 0.9991]), 'objectness_scores': tensor([0.2096, 0.5824]), 'labels': tensor([0, 1], dtype=torch.int32)}\n",
      "460967\n",
      "{'image_id': 462371, 'boxes': tensor([[276, 108, 320, 164],\n",
      "        [108, 167, 149, 222],\n",
      "        [306, 277, 405, 314],\n",
      "        [402, 171, 498, 346],\n",
      "        [204, 122, 221, 149],\n",
      "        [ 87,  24, 171, 105],\n",
      "        [403, 253, 499, 342],\n",
      "        [266, 261, 497, 399],\n",
      "        [267, 308, 407, 394],\n",
      "        [306, 140, 332, 187],\n",
      "        [332, 274, 392, 309]], dtype=torch.int32), 'scores': tensor([0.3351, 0.3618, 0.1405, 0.2013, 0.7025, 0.4369, 0.2752, 0.3055, 0.2104,\n",
      "        0.2025, 0.2219]), 'objectness_scores': tensor([0.7757, 0.2539, 0.3421, 0.4832, 0.3601, 0.2333, 0.2346, 0.2701, 0.2501,\n",
      "        0.6186, 0.2780]), 'labels': tensor([11,  2,  2,  7,  2,  3, 14, 11, 16, 11,  7], dtype=torch.int32)}\n",
      "462371\n",
      "{'image_id': 462576, 'boxes': tensor([[ 68, 180, 562, 428],\n",
      "        [191, 183, 562, 425],\n",
      "        [490, 268, 517, 316],\n",
      "        [411, 392, 473, 421],\n",
      "        [213, 389, 291, 426],\n",
      "        [351, 399, 390, 424],\n",
      "        [452, 313, 476, 339],\n",
      "        [239, 390, 266, 408],\n",
      "        [513,   0, 628,  81],\n",
      "        [192,  73, 424, 171],\n",
      "        [312, 260, 332, 285],\n",
      "        [463,  41, 600, 206],\n",
      "        [ 45,  16,  84,  54],\n",
      "        [ 46,   3, 181,  60],\n",
      "        [139,  14, 182,  50],\n",
      "        [  4, 163, 605, 466],\n",
      "        [464, 235, 494, 251],\n",
      "        [320, 396, 342, 413],\n",
      "        [ 63, 213, 271, 401],\n",
      "        [  0,   5, 636, 483],\n",
      "        [452, 370, 471, 396]], dtype=torch.int32), 'scores': tensor([0.7879, 0.6561, 0.2888, 0.3677, 0.3868, 0.1965, 0.4100, 0.3271, 0.8858,\n",
      "        0.9901, 0.3790, 0.9095, 0.4369, 0.3239, 0.4623, 0.2613, 0.2361, 0.2108,\n",
      "        0.6973, 0.5809, 0.2956]), 'objectness_scores': tensor([0.2611, 0.2652, 0.2014, 0.2283, 0.2780, 0.2448, 0.2023, 0.2498, 0.2926,\n",
      "        0.2970, 0.2231, 0.4563, 0.2432, 0.2199, 0.2057, 0.3171, 0.2101, 0.2313,\n",
      "        0.2716, 0.4093, 0.2325]), 'labels': tensor([12, 12, 11, 12, 11, 11, 11, 11, 10, 12, 11, 10, 10, 10, 10, 11, 11, 11,\n",
      "        12, 12, 11], dtype=torch.int32)}\n",
      "462576\n",
      "{'image_id': 462614, 'boxes': tensor([[569, 117, 603, 156],\n",
      "        [307,  57, 331,  81],\n",
      "        [369, 280, 411, 354],\n",
      "        [405, 242, 528, 291],\n",
      "        [120,  45, 256, 317],\n",
      "        [262, 303, 380, 424],\n",
      "        [401, 280, 425, 337],\n",
      "        [169, 337, 196, 362],\n",
      "        [ 30,  90,  84, 162],\n",
      "        [573, 196, 614, 273],\n",
      "        [502, 280, 536, 350],\n",
      "        [ 13, 286, 117, 383],\n",
      "        [  3,   0, 634, 481],\n",
      "        [ 28, 169,  83, 246],\n",
      "        [364,  51, 408, 354],\n",
      "        [295, 105, 308, 210],\n",
      "        [444,  82, 518, 187],\n",
      "        [553, 344, 638, 456],\n",
      "        [377, 418, 489, 453],\n",
      "        [144, 457, 272, 484],\n",
      "        [314, 285, 334, 302],\n",
      "        [472, 241, 482, 250]], dtype=torch.int32), 'scores': tensor([0.4961, 0.3046, 0.2534, 0.2402, 0.4807, 0.8002, 0.5965, 0.3681, 0.1903,\n",
      "        0.3650, 0.3044, 0.2021, 0.7466, 0.1589, 0.6843, 0.6730, 0.4279, 0.3142,\n",
      "        0.3023, 0.2492, 0.4055, 0.1598]), 'objectness_scores': tensor([0.2050, 0.2280, 0.2167, 0.5533, 0.2728, 0.5249, 0.2769, 0.5682, 0.2684,\n",
      "        0.2043, 0.3380, 0.2429, 0.2156, 0.2612, 0.3083, 0.2039, 0.4270, 0.4649,\n",
      "        0.2274, 0.2448, 0.4111, 0.2718]), 'labels': tensor([ 7,  7,  7,  9,  7, 15, 11,  8,  3, 11,  7, 12, 15,  3,  7, 11,  7,  9,\n",
      "         7, 11, 11, 14], dtype=torch.int32)}\n",
      "462614\n",
      "{'image_id': 462728, 'boxes': tensor([[ 93, 157, 119, 172]], dtype=torch.int32), 'scores': tensor([0.2743]), 'objectness_scores': tensor([0.2434]), 'labels': tensor([8], dtype=torch.int32)}\n",
      "462728\n",
      "{'image_id': 462904, 'boxes': tensor([[ 16, 192,  56, 271],\n",
      "        [466, 105, 545, 177]], dtype=torch.int32), 'scores': tensor([0.8238, 0.9612]), 'objectness_scores': tensor([0.3603, 0.2629]), 'labels': tensor([10,  6], dtype=torch.int32)}\n",
      "462904\n",
      "{'image_id': 463037, 'boxes': tensor([[  1,  97, 634, 414],\n",
      "        [103,  99, 152, 199],\n",
      "        [524, 192, 623, 290]], dtype=torch.int32), 'scores': tensor([0.9712, 0.8592, 0.9181]), 'objectness_scores': tensor([0.5023, 0.2172, 0.2170]), 'labels': tensor([0, 0, 0], dtype=torch.int32)}\n",
      "463037\n",
      "{'image_id': 463199, 'boxes': tensor([[ 60,  98, 138, 122],\n",
      "        [444, 133, 534, 172],\n",
      "        [327, 109, 395, 152],\n",
      "        [333, 148, 392, 161],\n",
      "        [429,  74, 546, 149],\n",
      "        [219, 157, 236, 173],\n",
      "        [ 37, 377, 163, 412],\n",
      "        [429, 391, 439, 399]], dtype=torch.int32), 'scores': tensor([0.2720, 0.2385, 0.1743, 0.2230, 0.2846, 0.1849, 0.2139, 0.1323]), 'objectness_scores': tensor([0.2141, 0.2351, 0.2382, 0.2100, 0.2223, 0.2129, 0.3067, 0.2709]), 'labels': tensor([14, 11,  7, 11,  6, 11,  8, 14], dtype=torch.int32)}\n",
      "463199\n",
      "{'image_id': 463283, 'boxes': tensor([[ 43, 113, 440, 524],\n",
      "        [ 29,  89, 470, 585],\n",
      "        [477,   0, 610, 151],\n",
      "        [  5,  13, 610, 610]], dtype=torch.int32), 'scores': tensor([0.9099, 0.8980, 0.8568, 0.8790]), 'objectness_scores': tensor([0.3852, 0.5047, 0.4290, 0.3709]), 'labels': tensor([10, 10, 10, 10], dtype=torch.int32)}\n",
      "463283\n",
      "{'image_id': 463522, 'boxes': tensor([[523, 284, 566, 315]], dtype=torch.int32), 'scores': tensor([0.5850]), 'objectness_scores': tensor([0.4213]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "463522\n",
      "{'image_id': 463527, 'boxes': tensor([[187, 122, 527, 389],\n",
      "        [  0, 186, 158, 376],\n",
      "        [ 10,  89, 635, 419],\n",
      "        [512, 115, 623, 376],\n",
      "        [  7, 212, 142, 308],\n",
      "        [441, 100, 479, 136],\n",
      "        [ 80,  71, 246, 169]], dtype=torch.int32), 'scores': tensor([0.6940, 0.9947, 0.3528, 0.8498, 0.4070, 0.2457, 0.5801]), 'objectness_scores': tensor([0.3119, 0.5011, 0.4706, 0.5253, 0.2978, 0.2725, 0.3392]), 'labels': tensor([12, 10, 11,  7, 11, 14, 11], dtype=torch.int32)}\n",
      "463527\n",
      "{'image_id': 463542, 'boxes': tensor([[256, 118, 269, 135],\n",
      "        [328, 245, 339, 253],\n",
      "        [244, 122, 251, 128],\n",
      "        [137, 138, 148, 143],\n",
      "        [549,  93, 559, 106],\n",
      "        [428, 144, 492, 164],\n",
      "        [115, 175, 123, 183],\n",
      "        [308, 194, 316, 203],\n",
      "        [278, 101, 283, 106],\n",
      "        [295, 241, 303, 250],\n",
      "        [442,  92, 446,  95],\n",
      "        [255,  51, 258,  54],\n",
      "        [286, 115, 299, 137],\n",
      "        [ 77, 180, 120, 209],\n",
      "        [544, 208, 550, 215],\n",
      "        [481, 213, 515, 254],\n",
      "        [101, 221, 115, 231],\n",
      "        [415, 142, 498, 183],\n",
      "        [527, 158, 539, 168],\n",
      "        [510, 207, 517, 217],\n",
      "        [236, 146, 240, 151],\n",
      "        [236, 166, 243, 171],\n",
      "        [510, 132, 517, 138],\n",
      "        [136, 132, 149, 141],\n",
      "        [333, 193, 340, 202],\n",
      "        [322, 168, 331, 172],\n",
      "        [147, 226, 159, 235],\n",
      "        [546, 211, 562, 250],\n",
      "        [502, 158, 507, 165],\n",
      "        [322, 161, 332, 170],\n",
      "        [149, 182, 155, 192]], dtype=torch.int32), 'scores': tensor([0.3575, 0.1553, 0.2404, 0.2792, 0.2888, 0.3286, 0.2955, 0.3655, 0.2881,\n",
      "        0.1975, 0.2004, 0.2345, 0.4683, 0.7336, 0.2177, 0.5492, 0.2151, 0.2440,\n",
      "        0.1917, 0.2708, 0.2311, 0.1846, 0.3910, 0.2021, 0.1883, 0.2461, 0.2352,\n",
      "        0.5906, 0.4064, 0.2082, 0.2368]), 'objectness_scores': tensor([0.2808, 0.2848, 0.2646, 0.3538, 0.3231, 0.2421, 0.3812, 0.4250, 0.2460,\n",
      "        0.2273, 0.2440, 0.2289, 0.2981, 0.2682, 0.2683, 0.2977, 0.2547, 0.2376,\n",
      "        0.2507, 0.2571, 0.3104, 0.2439, 0.3108, 0.3106, 0.4376, 0.3757, 0.2506,\n",
      "        0.2952, 0.3020, 0.3430, 0.3746]), 'labels': tensor([11, 11, 11, 11, 11, 11, 11, 14, 11,  0, 11, 11, 11, 11, 11,  8, 11,  7,\n",
      "        11, 11, 11, 11, 15, 14, 14, 11, 11, 11, 11,  1, 11], dtype=torch.int32)}\n",
      "463542\n",
      "{'image_id': 463618, 'boxes': tensor([[ 96, 207, 244, 397],\n",
      "        [ 66,   0, 327, 260],\n",
      "        [139, 318, 223, 399],\n",
      "        [  0, 209, 624, 451],\n",
      "        [470,   3, 638, 297],\n",
      "        [306, 262, 328, 307],\n",
      "        [535,  33, 638, 153],\n",
      "        [350, 140, 513, 401],\n",
      "        [133, 135, 269, 168],\n",
      "        [ 50, 145, 262, 448],\n",
      "        [468,  87, 556, 164]], dtype=torch.int32), 'scores': tensor([0.4908, 0.3020, 0.4904, 0.2861, 0.8741, 0.4502, 0.3333, 0.3755, 0.2176,\n",
      "        0.2818, 0.3598]), 'objectness_scores': tensor([0.3002, 0.2004, 0.2005, 0.2126, 0.3985, 0.2211, 0.2674, 0.3020, 0.2067,\n",
      "        0.4373, 0.2388]), 'labels': tensor([ 7,  3,  7,  3, 13,  7, 13,  7, 14,  3,  7], dtype=torch.int32)}\n",
      "463618\n",
      "{'image_id': 463690, 'boxes': tensor([[290, 141, 350, 178],\n",
      "        [274,  85, 330, 142],\n",
      "        [449,  59, 470,  76],\n",
      "        [425,  48, 449,  77],\n",
      "        [190,  60, 208, 115],\n",
      "        [430,  76, 473, 105],\n",
      "        [205,  48, 215,  60],\n",
      "        [  8,  79,  19,  84]], dtype=torch.int32), 'scores': tensor([0.2801, 0.4170, 0.2221, 0.1949, 0.4112, 0.2412, 0.2478, 0.3011]), 'objectness_scores': tensor([0.2132, 0.5859, 0.2128, 0.3878, 0.3429, 0.2664, 0.3715, 0.2135]), 'labels': tensor([ 6, 10, 11,  3, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "463690\n",
      "{'image_id': 463730, 'boxes': tensor([[558, 241, 587, 260],\n",
      "        [  0, 122,  32, 167],\n",
      "        [582,  66, 627,  86],\n",
      "        [436,  70, 476, 247]], dtype=torch.int32), 'scores': tensor([0.2669, 0.3375, 0.3030, 0.3117]), 'objectness_scores': tensor([0.2250, 0.2634, 0.2013, 0.2393]), 'labels': tensor([ 1,  6, 14, 13], dtype=torch.int32)}\n",
      "463730\n",
      "{'image_id': 463918, 'boxes': tensor([[ 90, 109, 129, 160],\n",
      "        [178, 132, 348, 269],\n",
      "        [140, 211, 319, 357],\n",
      "        [312, 235, 400, 338],\n",
      "        [  1, 212, 313, 358],\n",
      "        [468, 142, 474, 165],\n",
      "        [174, 136, 264, 229]], dtype=torch.int32), 'scores': tensor([0.5804, 0.3312, 0.2156, 0.3350, 0.2631, 0.5285, 0.4037]), 'objectness_scores': tensor([0.3551, 0.2006, 0.2206, 0.5650, 0.3139, 0.2021, 0.2223]), 'labels': tensor([ 7, 16, 16, 14,  7, 11,  7], dtype=torch.int32)}\n",
      "463918\n",
      "{'image_id': 465129, 'boxes': tensor([[544, 334, 560, 366],\n",
      "        [598, 307, 630, 371],\n",
      "        [233,  35, 582, 334],\n",
      "        [471, 339, 500, 364],\n",
      "        [420, 361, 607, 392],\n",
      "        [285, 216, 312, 245],\n",
      "        [314, 419, 406, 481]], dtype=torch.int32), 'scores': tensor([0.2538, 0.1823, 0.4257, 0.3079, 0.2491, 0.5183, 0.9122]), 'objectness_scores': tensor([0.2699, 0.4830, 0.2362, 0.3228, 0.3443, 0.2464, 0.2985]), 'labels': tensor([11,  8, 15, 11,  7, 10,  7], dtype=torch.int32)}\n",
      "465129\n",
      "{'image_id': 465180, 'boxes': tensor([[273,   0, 306,  13],\n",
      "        [172, 280, 458, 367],\n",
      "        [106,  58, 359, 207],\n",
      "        [496, 152, 528, 172],\n",
      "        [179, 113, 198, 128],\n",
      "        [434, 224, 486, 257],\n",
      "        [129,  57, 360, 157],\n",
      "        [129,  90, 308, 235],\n",
      "        [285, 263, 330, 300],\n",
      "        [101, 164, 136, 193],\n",
      "        [ -2,   9, 630, 417]], dtype=torch.int32), 'scores': tensor([0.4000, 0.8457, 0.9940, 0.3413, 0.4540, 0.3657, 0.9939, 0.9983, 0.2962,\n",
      "        0.3360, 0.9987]), 'objectness_scores': tensor([0.2005, 0.3281, 0.5015, 0.2122, 0.2375, 0.2111, 0.3544, 0.5836, 0.2170,\n",
      "        0.2067, 0.2078]), 'labels': tensor([11,  5,  5,  7, 11,  7,  5,  5, 11, 11,  5], dtype=torch.int32)}\n",
      "465180\n",
      "{'image_id': 465549, 'boxes': tensor([[ 88, 180, 192, 294],\n",
      "        [490, 195, 637, 417],\n",
      "        [105, 196, 124, 213],\n",
      "        [510,  44, 532,  58],\n",
      "        [204, 209, 223, 235]], dtype=torch.int32), 'scores': tensor([0.3163, 0.9455, 0.3116, 0.4433, 0.2316]), 'objectness_scores': tensor([0.2041, 0.3259, 0.2398, 0.2286, 0.2901]), 'labels': tensor([12, 13, 11, 14, 11], dtype=torch.int32)}\n",
      "465549\n",
      "{'image_id': 465718, 'boxes': tensor([[-11, 270, 568, 432],\n",
      "        [546, 138, 610, 241]], dtype=torch.int32), 'scores': tensor([0.9980, 0.6054]), 'objectness_scores': tensor([0.2478, 0.6306]), 'labels': tensor([14,  8], dtype=torch.int32)}\n",
      "465718\n",
      "{'image_id': 465806, 'boxes': tensor([[ 13, 203, 634, 478],\n",
      "        [  3, 184,  46, 268],\n",
      "        [359, 212, 384, 262],\n",
      "        [183, 288, 279, 405]], dtype=torch.int32), 'scores': tensor([0.7191, 0.2898, 0.3808, 0.8981]), 'objectness_scores': tensor([0.2870, 0.2302, 0.4528, 0.4202]), 'labels': tensor([10, 11,  7, 10], dtype=torch.int32)}\n",
      "465806\n",
      "{'image_id': 466125, 'boxes': tensor([[ 46,   1, 426, 201],\n",
      "        [386, 129, 421, 182]], dtype=torch.int32), 'scores': tensor([0.7321, 0.8122]), 'objectness_scores': tensor([0.2482, 0.2744]), 'labels': tensor([15, 11], dtype=torch.int32)}\n",
      "466125\n",
      "{'image_id': 466156, 'boxes': tensor([[185,  88, 351, 202],\n",
      "        [ 99,  33, 114,  48],\n",
      "        [108,  20, 113,  29]], dtype=torch.int32), 'scores': tensor([0.9863, 0.2747, 0.2925]), 'objectness_scores': tensor([0.5516, 0.3565, 0.2195]), 'labels': tensor([ 2, 14, 11], dtype=torch.int32)}\n",
      "466156\n",
      "{'image_id': 466986, 'boxes': tensor([[147, 252, 249, 315]], dtype=torch.int32), 'scores': tensor([0.6182]), 'objectness_scores': tensor([0.2241]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "466986\n",
      "{'image_id': 467176, 'boxes': tensor([[478, 259, 511, 279],\n",
      "        [ 39, 160,  47, 166],\n",
      "        [562, 176, 581, 206]], dtype=torch.int32), 'scores': tensor([0.9123, 0.2503, 0.3812]), 'objectness_scores': tensor([0.2173, 0.2038, 0.2709]), 'labels': tensor([11, 11, 11], dtype=torch.int32)}\n",
      "467176\n",
      "{'image_id': 467776, 'boxes': tensor([[387, 161, 401, 180]], dtype=torch.int32), 'scores': tensor([0.2169]), 'objectness_scores': tensor([0.3084]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "467776\n",
      "{'image_id': 468124, 'boxes': tensor([[ 68, 134, 612, 370]], dtype=torch.int32), 'scores': tensor([0.9992]), 'objectness_scores': tensor([0.5687]), 'labels': tensor([1], dtype=torch.int32)}\n",
      "468124\n",
      "{'image_id': 468332, 'boxes': tensor([[316, 261, 328, 274],\n",
      "        [  0, 235,  27, 281],\n",
      "        [212, 322, 322, 375],\n",
      "        [490, 131, 533, 155],\n",
      "        [ 54, 282,  68, 318],\n",
      "        [484, 180, 509, 203],\n",
      "        [193, 165, 218, 184],\n",
      "        [331, 260, 343, 274],\n",
      "        [345, 266, 355, 280],\n",
      "        [435, 189, 447, 214],\n",
      "        [307, 258, 358, 312],\n",
      "        [312, 380, 476, 424],\n",
      "        [188, 175, 243, 232]], dtype=torch.int32), 'scores': tensor([0.3755, 0.1566, 0.5438, 0.2379, 0.2395, 0.9754, 0.4115, 0.1809, 0.3141,\n",
      "        0.3515, 0.9981, 0.3620, 0.3286]), 'objectness_scores': tensor([0.2858, 0.2262, 0.3522, 0.2450, 0.2669, 0.3080, 0.4884, 0.2242, 0.2787,\n",
      "        0.3279, 0.2273, 0.3600, 0.2354]), 'labels': tensor([14,  7,  7, 11, 14,  7, 11, 14, 14, 11, 12,  8, 12], dtype=torch.int32)}\n",
      "468332\n",
      "{'image_id': 468501, 'boxes': tensor([[242, 213, 328, 373],\n",
      "        [324,   4, 415, 213],\n",
      "        [ 96, 194, 124, 211],\n",
      "        [373, 240, 390, 276],\n",
      "        [301,  90, 322, 103],\n",
      "        [448, 126, 483, 143],\n",
      "        [430, 311, 467, 333],\n",
      "        [ 37, 205, 128, 291],\n",
      "        [263,  88, 297, 122],\n",
      "        [313, 217, 388, 259],\n",
      "        [385, 147, 498, 303],\n",
      "        [336, 126, 351, 134],\n",
      "        [469, 204, 473, 211],\n",
      "        [258, 126, 323, 217],\n",
      "        [352, 242, 378, 272]], dtype=torch.int32), 'scores': tensor([0.2772, 0.2103, 0.2868, 0.2375, 0.5766, 0.1972, 0.7722, 0.3705, 0.2218,\n",
      "        0.8928, 0.9618, 0.3117, 0.2722, 0.3450, 0.5798]), 'objectness_scores': tensor([0.2326, 0.2607, 0.2100, 0.2334, 0.2488, 0.2073, 0.3215, 0.2679, 0.2621,\n",
      "        0.2138, 0.3788, 0.3576, 0.3200, 0.2656, 0.3487]), 'labels': tensor([11,  3, 14, 11, 14, 11, 11, 14, 11,  7, 13, 11, 11,  7, 11],\n",
      "       dtype=torch.int32)}\n",
      "468501\n",
      "{'image_id': 468505, 'boxes': tensor([[259, 321, 347, 356],\n",
      "        [135, 243, 455, 473],\n",
      "        [247, 237, 278, 297],\n",
      "        [420, 258, 435, 280],\n",
      "        [168, 240, 225, 260],\n",
      "        [394, 290, 470, 324],\n",
      "        [366, 294, 414, 315],\n",
      "        [168, 296, 235, 331],\n",
      "        [263, 196, 290, 231],\n",
      "        [151, 230, 242, 263],\n",
      "        [409, 255, 446, 280]], dtype=torch.int32), 'scores': tensor([0.2479, 0.1683, 0.7075, 0.2906, 0.1976, 0.2090, 0.3809, 0.3168, 0.9557,\n",
      "        0.3933, 0.3854]), 'objectness_scores': tensor([0.2427, 0.2566, 0.2723, 0.2175, 0.2922, 0.2274, 0.3041, 0.2362, 0.3194,\n",
      "        0.2035, 0.2052]), 'labels': tensor([ 7, 12, 10, 11, 12,  4, 11,  7, 10, 12,  7], dtype=torch.int32)}\n",
      "468505\n",
      "{'image_id': 468925, 'boxes': tensor([[430, 126, 622, 276],\n",
      "        [354,  44, 465,  71],\n",
      "        [320, 107, 407, 139],\n",
      "        [505,  33, 638, 108],\n",
      "        [287, 173, 642, 479],\n",
      "        [  5,  61, 637, 488],\n",
      "        [492, 172, 640, 399],\n",
      "        [183,  48, 339,  84],\n",
      "        [288, 335, 548, 480],\n",
      "        [169,  33, 503,  99]], dtype=torch.int32), 'scores': tensor([0.5130, 0.3280, 0.2672, 0.2274, 0.5001, 0.5901, 0.2671, 0.4968, 0.2981,\n",
      "        0.3712]), 'objectness_scores': tensor([0.4841, 0.3488, 0.2721, 0.6595, 0.2670, 0.2825, 0.2996, 0.3291, 0.2716,\n",
      "        0.4607]), 'labels': tensor([12, 11,  7,  2, 12, 12,  4, 11,  7, 12], dtype=torch.int32)}\n",
      "468925\n",
      "{'image_id': 468954, 'boxes': tensor([[  6,  61, 636, 427],\n",
      "        [326, 277, 378, 344],\n",
      "        [392,  68, 637, 425],\n",
      "        [440,  89, 575, 154],\n",
      "        [168,  45, 324, 274]], dtype=torch.int32), 'scores': tensor([0.3680, 0.3445, 0.4492, 0.1588, 0.5449]), 'objectness_scores': tensor([0.3588, 0.2193, 0.2006, 0.2976, 0.2555]), 'labels': tensor([13, 10, 11, 10,  7], dtype=torch.int32)}\n",
      "468954\n",
      "{'image_id': 468965, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "468965\n",
      "{'image_id': 469067, 'boxes': tensor([[183, 198, 384, 429],\n",
      "        [  0, 227, 287, 480],\n",
      "        [291, 237, 548, 467]], dtype=torch.int32), 'scores': tensor([0.4781, 0.5964, 0.9587]), 'objectness_scores': tensor([0.2551, 0.2558, 0.5394]), 'labels': tensor([ 7, 13,  2], dtype=torch.int32)}\n",
      "469067\n",
      "{'image_id': 470121, 'boxes': tensor([[438, 271, 531, 375],\n",
      "        [339,  22, 410,  59],\n",
      "        [276, 161, 390, 266],\n",
      "        [269,  39, 303,  82],\n",
      "        [ 84, 323, 206, 412],\n",
      "        [418, 333, 507, 433],\n",
      "        [300,  46, 349,  80],\n",
      "        [387, 286, 462, 361],\n",
      "        [234,  53, 277,  90],\n",
      "        [339, 337, 419, 439],\n",
      "        [114,  20, 494, 157],\n",
      "        [166,  64, 234, 125],\n",
      "        [438, 272, 531, 346],\n",
      "        [  2, 171, 637, 479],\n",
      "        [495, 171, 580, 271],\n",
      "        [277,   6, 319,  47],\n",
      "        [272,  50, 303,  83],\n",
      "        [265,  79, 350, 129],\n",
      "        [370,  57, 438, 113],\n",
      "        [338, 286, 516, 439],\n",
      "        [214,  19, 266,  58]], dtype=torch.int32), 'scores': tensor([0.5656, 0.4270, 0.8463, 0.6546, 0.2983, 0.7809, 0.3124, 0.7277, 0.4045,\n",
      "        0.6154, 0.9323, 0.5948, 0.5109, 0.8905, 0.6285, 0.7084, 0.4739, 0.3597,\n",
      "        0.4597, 0.3319, 0.1968]), 'objectness_scores': tensor([0.3881, 0.2350, 0.2028, 0.2289, 0.2094, 0.4173, 0.3654, 0.4448, 0.3658,\n",
      "        0.4412, 0.2892, 0.3817, 0.2284, 0.3334, 0.2215, 0.3516, 0.3292, 0.2552,\n",
      "        0.3145, 0.2094, 0.2574]), 'labels': tensor([12,  7, 12, 10, 11, 12, 12, 12, 12, 12,  8, 12, 11, 12, 10, 12, 10, 12,\n",
      "        12, 11, 13], dtype=torch.int32)}\n",
      "470121\n",
      "{'image_id': 470773, 'boxes': tensor([[ 89, 161, 157, 255],\n",
      "        [307, 167, 404, 261],\n",
      "        [403,   2, 629, 217],\n",
      "        [389, 143, 584, 286],\n",
      "        [ 36, 264, 110, 318],\n",
      "        [ 91, 214, 173, 261],\n",
      "        [144, 240, 174, 268],\n",
      "        [372,  92, 466, 141],\n",
      "        [460,  99, 559, 149],\n",
      "        [126,   0, 284, 152],\n",
      "        [171, 219, 246, 268]], dtype=torch.int32), 'scores': tensor([0.7366, 0.4845, 0.4243, 0.8001, 0.3194, 0.9128, 0.6272, 0.8942, 0.9103,\n",
      "        0.5170, 0.4963]), 'objectness_scores': tensor([0.4319, 0.4742, 0.3629, 0.6836, 0.3854, 0.4105, 0.3004, 0.3079, 0.2531,\n",
      "        0.2406, 0.4350]), 'labels': tensor([10, 10, 12, 12, 10, 10, 10, 12, 12,  7, 10], dtype=torch.int32)}\n",
      "470773\n",
      "{'image_id': 470779, 'boxes': tensor([[210,  70, 263, 118],\n",
      "        [131, 326, 163, 392],\n",
      "        [320, 305, 364, 380],\n",
      "        [366, 352, 398, 403],\n",
      "        [ 66, 224, 109, 441],\n",
      "        [211,  74, 264, 101],\n",
      "        [140, 195, 175, 237],\n",
      "        [276, 146, 306, 180],\n",
      "        [268, 175, 302, 206],\n",
      "        [298, 180, 327, 202],\n",
      "        [367,  42, 409,  64],\n",
      "        [317, 174, 358, 205],\n",
      "        [133, 201, 172, 245],\n",
      "        [439, 323, 471, 398],\n",
      "        [171, 347, 201, 398],\n",
      "        [287, 300, 319, 368],\n",
      "        [582, 223, 624, 294],\n",
      "        [322, 338, 362, 378],\n",
      "        [ 87, 331, 118, 401],\n",
      "        [147, 235, 161, 406],\n",
      "        [366,  41, 410,  99],\n",
      "        [366, 130, 395, 165],\n",
      "        [298,  76, 330,  87],\n",
      "        [368, 352, 423, 412],\n",
      "        [240, 363, 275, 405],\n",
      "        [398, 337, 449, 369],\n",
      "        [428,  28, 466,  69],\n",
      "        [ 86, 211, 114, 240],\n",
      "        [ 68, 164, 120, 441],\n",
      "        [292,  56, 334,  85],\n",
      "        [363, 213, 406, 260],\n",
      "        [495, 324, 530, 399],\n",
      "        [449, 194, 497, 229],\n",
      "        [128, 217, 185, 406],\n",
      "        [267, 186, 286, 412],\n",
      "        [ 99, 160, 134, 202]], dtype=torch.int32), 'scores': tensor([0.9152, 0.2748, 0.3223, 0.5823, 0.3204, 0.1845, 0.3328, 0.1551, 0.7369,\n",
      "        0.5040, 0.2743, 0.2871, 0.4642, 0.6883, 0.3716, 0.1560, 0.7361, 0.5015,\n",
      "        0.2252, 0.4283, 0.2183, 0.2955, 0.4662, 0.2903, 0.5275, 0.2325, 0.1541,\n",
      "        0.1403, 0.5964, 0.1443, 0.4068, 0.6890, 0.2019, 0.5001, 0.6728, 0.2480]), 'objectness_scores': tensor([0.4352, 0.4405, 0.3076, 0.3242, 0.3811, 0.5728, 0.2744, 0.3426, 0.4741,\n",
      "        0.2787, 0.4595, 0.2003, 0.2874, 0.4598, 0.4099, 0.3677, 0.9159, 0.2162,\n",
      "        0.4731, 0.2823, 0.3582, 0.5269, 0.2783, 0.2817, 0.3509, 0.3126, 0.3986,\n",
      "        0.4002, 0.2455, 0.2299, 0.5107, 0.4769, 0.4917, 0.2530, 0.2006, 0.4895]), 'labels': tensor([ 8,  7,  7,  7,  7, 11,  7, 11,  7,  2, 11, 11,  7,  8,  7,  7,  7,  9,\n",
      "         7, 11,  7,  7, 11,  8,  7,  2,  8,  3,  7,  2,  7,  8,  7,  7, 11,  7],\n",
      "       dtype=torch.int32)}\n",
      "470779\n",
      "{'image_id': 470924, 'boxes': tensor([[610,  73, 621,  86],\n",
      "        [413, 114, 462, 132],\n",
      "        [105, 308, 405, 479],\n",
      "        [  0, 114,  99, 147],\n",
      "        [135, 152, 187, 170],\n",
      "        [387, 338, 424, 394],\n",
      "        [201, 378, 252, 445],\n",
      "        [326, 191, 348, 252],\n",
      "        [382, 340, 467, 384],\n",
      "        [336, 321, 364, 392],\n",
      "        [197, 418, 281, 477],\n",
      "        [298, 155, 318, 213],\n",
      "        [282, 405, 343, 473],\n",
      "        [300, 100, 340, 125]], dtype=torch.int32), 'scores': tensor([0.2057, 0.1633, 0.3948, 0.5636, 0.2602, 0.5024, 0.9446, 0.2565, 0.3462,\n",
      "        0.5392, 0.3843, 0.4135, 0.4755, 0.4464]), 'objectness_scores': tensor([0.2691, 0.2424, 0.2347, 0.2176, 0.2227, 0.3134, 0.4189, 0.2025, 0.2404,\n",
      "        0.2774, 0.2666, 0.2048, 0.2222, 0.2450]), 'labels': tensor([ 8, 10, 12,  0, 11, 10, 11,  7, 10, 10,  7, 11, 12, 11],\n",
      "       dtype=torch.int32)}\n",
      "470924\n",
      "{'image_id': 471087, 'boxes': tensor([[129, 267, 204, 497]], dtype=torch.int32), 'scores': tensor([0.9955]), 'objectness_scores': tensor([0.6693]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "471087\n",
      "{'image_id': 471789, 'boxes': tensor([[487, 437, 506, 453],\n",
      "        [116, 362, 133, 380]], dtype=torch.int32), 'scores': tensor([0.6506, 0.2353]), 'objectness_scores': tensor([0.5040, 0.4280]), 'labels': tensor([4, 9], dtype=torch.int32)}\n",
      "471789\n",
      "{'image_id': 472046, 'boxes': tensor([[249, 285, 289, 370],\n",
      "        [345, 229, 370, 244],\n",
      "        [168, 250, 185, 256],\n",
      "        [139, 234, 167, 262],\n",
      "        [581, 214, 629, 285],\n",
      "        [335, 286, 482, 357],\n",
      "        [271, 258, 331, 290],\n",
      "        [ 91, 248, 203, 340],\n",
      "        [229, 333, 267, 387],\n",
      "        [287, 231, 473, 311],\n",
      "        [477,   0, 578,  71],\n",
      "        [218, 350, 304, 393],\n",
      "        [520, 277, 640, 332],\n",
      "        [257, 322, 285, 370],\n",
      "        [ 29,  99,  44, 107],\n",
      "        [378, 286, 484, 357],\n",
      "        [107, 264, 134, 271],\n",
      "        [214, 286, 268, 385],\n",
      "        [353, 319, 584, 424],\n",
      "        [337, 239, 378, 280]], dtype=torch.int32), 'scores': tensor([0.3080, 0.2307, 0.1787, 0.1160, 0.1771, 0.6789, 0.2835, 0.6605, 0.4575,\n",
      "        0.9894, 0.3522, 0.9262, 0.4266, 0.1915, 0.1496, 0.6435, 0.1678, 0.1908,\n",
      "        0.5128, 0.9724]), 'objectness_scores': tensor([0.3765, 0.2259, 0.2131, 0.2274, 0.4841, 0.3389, 0.3025, 0.2544, 0.2842,\n",
      "        0.4401, 0.2280, 0.2003, 0.3688, 0.2779, 0.2302, 0.2474, 0.2142, 0.3620,\n",
      "        0.5389, 0.2157]), 'labels': tensor([11, 13, 14,  3,  9, 15,  9, 12, 12, 13,  7, 12, 15,  4,  3, 15, 11, 11,\n",
      "        14, 13], dtype=torch.int32)}\n",
      "472046\n",
      "{'image_id': 472375, 'boxes': tensor([[131, 241, 496, 553],\n",
      "        [218, 122, 236, 145],\n",
      "        [ 54, 289, 159, 437],\n",
      "        [144,  70, 372, 228],\n",
      "        [288,  70, 315,  96],\n",
      "        [452, 297, 546, 428],\n",
      "        [127, 195, 277, 366],\n",
      "        [297, 176, 338, 194]], dtype=torch.int32), 'scores': tensor([0.9711, 0.2540, 0.2419, 0.6842, 0.2210, 0.8041, 0.6596, 0.3558]), 'objectness_scores': tensor([0.5157, 0.2097, 0.2030, 0.2773, 0.2533, 0.2628, 0.4219, 0.2052]), 'labels': tensor([ 3, 14, 16,  8, 14,  9,  3, 11], dtype=torch.int32)}\n",
      "472375\n",
      "{'image_id': 472678, 'boxes': tensor([[522, 321, 634, 394],\n",
      "        [225, 372, 262, 388],\n",
      "        [155, 334, 308, 362],\n",
      "        [436,  48, 537, 135],\n",
      "        [127,  29, 243, 123],\n",
      "        [ 68, 183, 149, 476]], dtype=torch.int32), 'scores': tensor([0.6035, 0.3859, 0.1933, 0.3948, 0.2289, 0.3562]), 'objectness_scores': tensor([0.4800, 0.2090, 0.2066, 0.2028, 0.2121, 0.2130]), 'labels': tensor([14, 11, 11, 15,  8, 10], dtype=torch.int32)}\n",
      "472678\n",
      "{'image_id': 473118, 'boxes': tensor([[ 93, 304, 127, 334],\n",
      "        [105, 223, 220, 357],\n",
      "        [123, 367, 142, 386],\n",
      "        [ 34,   0,  71,  41],\n",
      "        [153, 353, 177, 384],\n",
      "        [119, 133, 137, 161],\n",
      "        [ 73,   0, 107,  46],\n",
      "        [ 68, 306, 160, 385]], dtype=torch.int32), 'scores': tensor([0.3857, 0.9048, 0.3461, 0.4307, 0.9579, 0.4258, 0.2397, 0.8160]), 'objectness_scores': tensor([0.3016, 0.2239, 0.2139, 0.2030, 0.2740, 0.3264, 0.2034, 0.5724]), 'labels': tensor([ 4,  9,  9,  6,  4, 11,  8,  9], dtype=torch.int32)}\n",
      "473118\n",
      "{'image_id': 473219, 'boxes': tensor([[301,   7, 370, 114],\n",
      "        [380,  13, 463, 102],\n",
      "        [213, 227, 229, 257],\n",
      "        [472,  11, 540, 117],\n",
      "        [388, 198, 418, 231],\n",
      "        [215, 186, 219, 195],\n",
      "        [326, 215, 370, 373],\n",
      "        [322, 298, 326, 303],\n",
      "        [ 74,   0, 156,  36],\n",
      "        [227,   6, 299, 112],\n",
      "        [152,   3, 222, 109],\n",
      "        [168, 256, 281, 427],\n",
      "        [265, 350, 273, 381]], dtype=torch.int32), 'scores': tensor([0.3218, 0.2603, 0.2711, 0.2524, 0.1784, 0.1925, 0.1988, 0.1537, 0.1323,\n",
      "        0.2621, 0.2788, 0.6542, 0.4644]), 'objectness_scores': tensor([0.2700, 0.2576, 0.2821, 0.2721, 0.2397, 0.2470, 0.2971, 0.2519, 0.2017,\n",
      "        0.2793, 0.2913, 0.2423, 0.2417]), 'labels': tensor([12,  7,  7,  7,  0, 11,  2, 11,  4,  7,  2,  7, 11], dtype=torch.int32)}\n",
      "473219\n",
      "{'image_id': 473406, 'boxes': tensor([[  0, 235, 168, 334],\n",
      "        [387, 224, 413, 243],\n",
      "        [214, 511, 455, 640],\n",
      "        [  6, 193,  87, 246],\n",
      "        [145, 264, 163, 280],\n",
      "        [  2, 234, 171, 415],\n",
      "        [441, 224, 479, 276],\n",
      "        [163, 339, 292, 463]], dtype=torch.int32), 'scores': tensor([0.5032, 0.4895, 0.3309, 0.3199, 0.2197, 0.9472, 0.1598, 0.3316]), 'objectness_scores': tensor([0.4550, 0.2771, 0.2234, 0.5154, 0.2011, 0.2385, 0.3761, 0.2696]), 'labels': tensor([15, 11, 12,  9,  7, 15, 14,  7], dtype=torch.int32)}\n",
      "473406\n",
      "{'image_id': 473821, 'boxes': tensor([[271, 167, 501, 296],\n",
      "        [168, 180, 222, 230],\n",
      "        [294,  23, 489, 156],\n",
      "        [  0, 173, 100, 290],\n",
      "        [ 17,  98,  61, 132],\n",
      "        [370, 175, 434, 231],\n",
      "        [339, 233, 497, 333],\n",
      "        [235, 127, 275, 203],\n",
      "        [149, 165, 196, 219],\n",
      "        [ 17,  99,  60, 171]], dtype=torch.int32), 'scores': tensor([0.9860, 0.1992, 0.4050, 0.2210, 0.7103, 0.9117, 0.2208, 0.4313, 0.4080,\n",
      "        0.2052]), 'objectness_scores': tensor([0.5078, 0.2700, 0.3618, 0.2461, 0.2165, 0.2990, 0.3042, 0.2821, 0.2160,\n",
      "        0.2814]), 'labels': tensor([13, 14, 13,  1, 11, 13, 13,  7, 13,  6], dtype=torch.int32)}\n",
      "473821\n",
      "{'image_id': 473869, 'boxes': tensor([[ 51,  23, 323, 426],\n",
      "        [361, 309, 443, 428]], dtype=torch.int32), 'scores': tensor([0.4410, 0.7362]), 'objectness_scores': tensor([0.2195, 0.2596]), 'labels': tensor([12, 10], dtype=torch.int32)}\n",
      "473869\n",
      "{'image_id': 474021, 'boxes': tensor([[329, 111, 354, 136],\n",
      "        [140, 106, 190, 117],\n",
      "        [  0, 214,  73, 371],\n",
      "        [  1,  81,  75, 310],\n",
      "        [289, 293, 298, 320],\n",
      "        [ 80, 197, 108, 217],\n",
      "        [ 66, 205,  75, 210],\n",
      "        [ 22, 271, 352, 373],\n",
      "        [399, 196, 429, 224],\n",
      "        [263, 126, 375, 299],\n",
      "        [178, 208, 198, 225]], dtype=torch.int32), 'scores': tensor([0.3292, 0.1604, 0.2554, 0.3078, 0.3141, 0.4941, 0.1649, 0.5769, 0.2695,\n",
      "        0.2578, 0.2915]), 'objectness_scores': tensor([0.2177, 0.4289, 0.3222, 0.4848, 0.3150, 0.2315, 0.2346, 0.5644, 0.5509,\n",
      "        0.3693, 0.5173]), 'labels': tensor([ 2, 14,  9, 11, 11, 11,  3,  7, 11,  7, 11], dtype=torch.int32)}\n",
      "474021\n",
      "{'image_id': 474164, 'boxes': tensor([[360, 577, 427, 601],\n",
      "        [246, 177, 342, 368]], dtype=torch.int32), 'scores': tensor([0.3493, 0.9678]), 'objectness_scores': tensor([0.2762, 0.5077]), 'labels': tensor([11,  3], dtype=torch.int32)}\n",
      "474164\n",
      "{'image_id': 474452, 'boxes': tensor([[254,  41, 320, 144],\n",
      "        [ 25, 180,  30, 186],\n",
      "        [ 74, 181,  80, 188],\n",
      "        [260, 118, 312, 134]], dtype=torch.int32), 'scores': tensor([0.3600, 0.1679, 0.1426, 0.3095]), 'objectness_scores': tensor([0.4348, 0.2867, 0.2513, 0.2420]), 'labels': tensor([ 7, 11, 10, 11], dtype=torch.int32)}\n",
      "474452\n",
      "{'image_id': 474786, 'boxes': tensor([[ 73, 359, 223, 421],\n",
      "        [  0, 383,  52, 425],\n",
      "        [  3, 334, 374, 499],\n",
      "        [307, 476, 348, 496],\n",
      "        [ 69, 354, 116, 393],\n",
      "        [  1, 380,  79, 444],\n",
      "        [  1,   5, 375, 497]], dtype=torch.int32), 'scores': tensor([0.2556, 0.6201, 0.9944, 0.4695, 0.2884, 0.9937, 0.9829]), 'objectness_scores': tensor([0.6262, 0.2406, 0.2108, 0.2192, 0.6087, 0.4419, 0.2260]), 'labels': tensor([ 9, 15, 15, 11, 11, 15, 15], dtype=torch.int32)}\n",
      "474786\n",
      "{'image_id': 476119, 'boxes': tensor([[302, 140, 328, 168],\n",
      "        [419,  95, 447, 148],\n",
      "        [ 76, 357, 199, 415],\n",
      "        [205,  17, 259,  94],\n",
      "        [ 97, 184, 123, 218]], dtype=torch.int32), 'scores': tensor([0.2517, 0.3679, 0.9691, 0.4394, 0.2783]), 'objectness_scores': tensor([0.2807, 0.4052, 0.5876, 0.3388, 0.2788]), 'labels': tensor([8, 4, 9, 9, 8], dtype=torch.int32)}\n",
      "476119\n",
      "{'image_id': 476258, 'boxes': tensor([[424, 257, 457, 288],\n",
      "        [335,  36, 403, 120],\n",
      "        [269, 253, 509, 345],\n",
      "        [343, 276, 372, 307]], dtype=torch.int32), 'scores': tensor([0.2417, 0.1792, 0.9437, 0.4141]), 'objectness_scores': tensor([0.2446, 0.4718, 0.6910, 0.2368]), 'labels': tensor([12, 11,  9,  8], dtype=torch.int32)}\n",
      "476258\n",
      "{'image_id': 476415, 'boxes': tensor([[210,  36, 299, 473],\n",
      "        [ 60,  13, 424, 455],\n",
      "        [115,  27, 424, 642],\n",
      "        [120, 377, 423, 638]], dtype=torch.int32), 'scores': tensor([0.9542, 0.9993, 0.9995, 0.9737]), 'objectness_scores': tensor([0.5456, 0.2653, 0.2102, 0.2326]), 'labels': tensor([7, 7, 7, 7], dtype=torch.int32)}\n",
      "476415\n",
      "{'image_id': 476514, 'boxes': tensor([[302, 208, 323, 336],\n",
      "        [161,  41, 372, 198],\n",
      "        [ 54,  70, 301, 626],\n",
      "        [ 58, 249, 302, 625]], dtype=torch.int32), 'scores': tensor([0.9616, 0.9957, 0.5319, 0.3531]), 'objectness_scores': tensor([0.2244, 0.3557, 0.4266, 0.2556]), 'labels': tensor([ 7,  6, 12, 12], dtype=torch.int32)}\n",
      "476514\n",
      "{'image_id': 476704, 'boxes': tensor([[129,  46, 243,  94],\n",
      "        [500, 135, 509, 162],\n",
      "        [156,  85, 487, 353],\n",
      "        [544, 253, 592, 336],\n",
      "        [610, 201, 617, 217],\n",
      "        [514,  10, 547, 300],\n",
      "        [565, 173, 581, 194]], dtype=torch.int32), 'scores': tensor([0.3347, 0.3616, 0.9995, 0.3622, 0.2954, 0.3582, 0.5905]), 'objectness_scores': tensor([0.2451, 0.2098, 0.5421, 0.3504, 0.3652, 0.2038, 0.2353]), 'labels': tensor([ 1,  8,  1,  6, 14,  6, 14], dtype=torch.int32)}\n",
      "476704\n",
      "{'image_id': 476787, 'boxes': tensor([[185,   6, 243,  62],\n",
      "        [279,  77, 363, 211],\n",
      "        [258,   0, 411, 139],\n",
      "        [121, 254, 531, 480],\n",
      "        [294,  11, 359,  99],\n",
      "        [  1, 165,  99, 232],\n",
      "        [ 70, 243, 532, 479],\n",
      "        [ 25, 241, 219, 265],\n",
      "        [ 38, 193,  70, 221],\n",
      "        [  5, 202,  39, 230],\n",
      "        [154,  91, 234, 138],\n",
      "        [356,  85, 415, 191]], dtype=torch.int32), 'scores': tensor([0.7677, 0.5540, 0.7368, 0.3753, 0.6656, 0.4459, 0.5456, 0.9348, 0.6066,\n",
      "        0.1746, 0.4755, 0.3991]), 'objectness_scores': tensor([0.2300, 0.3556, 0.4057, 0.2041, 0.3628, 0.2092, 0.3696, 0.3991, 0.3386,\n",
      "        0.3428, 0.2329, 0.3089]), 'labels': tensor([10, 12, 12, 12, 12, 12, 12, 11, 11, 11, 12,  7], dtype=torch.int32)}\n",
      "476787\n",
      "{'image_id': 476810, 'boxes': tensor([[  0,  13, 506, 314],\n",
      "        [381, 195, 411, 240]], dtype=torch.int32), 'scores': tensor([0.6455, 0.3283]), 'objectness_scores': tensor([0.5787, 0.3208]), 'labels': tensor([ 2, 16], dtype=torch.int32)}\n",
      "476810\n",
      "{'image_id': 477288, 'boxes': tensor([[138, 245, 173, 332],\n",
      "        [  0, 201,  36, 276],\n",
      "        [372, 258, 395, 300],\n",
      "        [366, 114, 482, 259],\n",
      "        [  0,  30, 110, 168],\n",
      "        [198, 410, 243, 469],\n",
      "        [ 90, 105, 232, 246],\n",
      "        [258, 149, 367, 316],\n",
      "        [  0, 123,  95, 196],\n",
      "        [  2,  98, 226, 248],\n",
      "        [156, 128, 306, 254],\n",
      "        [  2, 171, 127, 337],\n",
      "        [174, 252, 228, 345],\n",
      "        [153, 258, 159, 261],\n",
      "        [334, 374, 486, 633],\n",
      "        [232,   0, 471, 160],\n",
      "        [129, 400, 186, 463],\n",
      "        [ 44, 409,  88, 479],\n",
      "        [189, 456, 289, 590]], dtype=torch.int32), 'scores': tensor([0.9634, 0.4733, 0.9259, 0.9934, 0.9526, 0.6221, 0.9684, 0.6678, 0.2893,\n",
      "        0.7727, 0.9752, 0.5515, 0.3507, 0.2382, 0.5026, 0.9797, 0.3502, 0.3363,\n",
      "        0.4044]), 'objectness_scores': tensor([0.2139, 0.2142, 0.2149, 0.2010, 0.2225, 0.2277, 0.2957, 0.2048, 0.2424,\n",
      "        0.2067, 0.3335, 0.2347, 0.2078, 0.3302, 0.3430, 0.2616, 0.2241, 0.2088,\n",
      "        0.2106]), 'labels': tensor([ 7, 11,  7,  6,  6,  9,  6,  7,  7,  6,  6,  7,  7, 11,  7,  6,  9, 11,\n",
      "         7], dtype=torch.int32)}\n",
      "477288\n",
      "{'image_id': 477441, 'boxes': tensor([[105, 160, 632, 308],\n",
      "        [425, 208, 635, 296],\n",
      "        [  7,   6, 637, 480],\n",
      "        [414, 362, 446, 392],\n",
      "        [458, 334, 464, 346],\n",
      "        [411, 355, 504, 392],\n",
      "        [310, 184, 344, 228],\n",
      "        [122, 235, 126, 242],\n",
      "        [229, 259, 279, 289],\n",
      "        [100, 157, 428, 297],\n",
      "        [253, 292, 259, 302],\n",
      "        [147, 315, 153, 325],\n",
      "        [131, 153, 183, 203]], dtype=torch.int32), 'scores': tensor([0.9524, 0.7064, 0.9879, 0.3402, 0.4788, 0.2706, 0.5065, 0.1302, 0.2408,\n",
      "        0.9794, 0.9462, 0.1864, 0.9254]), 'objectness_scores': tensor([0.2374, 0.2478, 0.2138, 0.2452, 0.5642, 0.2042, 0.2149, 0.7225, 0.4610,\n",
      "        0.5203, 0.8285, 0.8003, 0.2583]), 'labels': tensor([ 0,  0,  0,  0,  8,  7,  9, 14, 11,  0, 13,  7,  0], dtype=torch.int32)}\n",
      "477441\n",
      "{'image_id': 477689, 'boxes': tensor([[ 23,  46, 412, 553],\n",
      "        [199, 316, 361, 574],\n",
      "        [ 12,   9, 440, 627],\n",
      "        [ 46, 267, 402, 576],\n",
      "        [183, 320, 295, 573]], dtype=torch.int32), 'scores': tensor([0.7189, 0.9849, 0.3622, 0.9229, 0.9802]), 'objectness_scores': tensor([0.2668, 0.2040, 0.2141, 0.2588, 0.3983]), 'labels': tensor([ 7,  7, 12,  7,  7], dtype=torch.int32)}\n",
      "477689\n",
      "{'image_id': 478136, 'boxes': tensor([[101, 211, 521, 447]], dtype=torch.int32), 'scores': tensor([0.9857]), 'objectness_scores': tensor([0.2690]), 'labels': tensor([12], dtype=torch.int32)}\n",
      "478136\n",
      "{'image_id': 478393, 'boxes': tensor([[ 98, 162, 245, 233],\n",
      "        [251, 161, 483, 483],\n",
      "        [347, 260, 461, 324],\n",
      "        [  0, 367, 260, 513],\n",
      "        [  0, 117, 345, 410]], dtype=torch.int32), 'scores': tensor([0.9596, 0.8875, 0.4232, 0.9781, 0.4859]), 'objectness_scores': tensor([0.4860, 0.6546, 0.5602, 0.4782, 0.2494]), 'labels': tensor([ 2,  3,  7,  2, 13], dtype=torch.int32)}\n",
      "478393\n",
      "{'image_id': 478862, 'boxes': tensor([[541,  58, 576, 349],\n",
      "        [ 99, 154, 154, 212],\n",
      "        [ 92, 384, 101, 390],\n",
      "        [  4,  60, 602, 360],\n",
      "        [102, 384, 112, 391],\n",
      "        [415, 331, 436, 334],\n",
      "        [351, 120, 375, 348],\n",
      "        [328, 118, 421, 346],\n",
      "        [ 80, 164,  99, 188]], dtype=torch.int32), 'scores': tensor([0.3956, 0.9454, 0.2341, 0.9850, 0.1957, 0.1730, 0.2090, 0.9384, 0.3066]), 'objectness_scores': tensor([0.2576, 0.4861, 0.2855, 0.5127, 0.2773, 0.2228, 0.2770, 0.3070, 0.3425]), 'labels': tensor([11,  0, 11,  0, 13, 11,  0,  0,  7], dtype=torch.int32)}\n",
      "478862\n",
      "{'image_id': 479155, 'boxes': tensor([[151, 136, 250, 231],\n",
      "        [131, 161, 259, 331],\n",
      "        [313, 170, 370, 260],\n",
      "        [139, 157, 258, 234],\n",
      "        [404, 167, 499, 328]], dtype=torch.int32), 'scores': tensor([0.2422, 0.9777, 0.7327, 0.3409, 0.2272]), 'objectness_scores': tensor([0.2248, 0.3200, 0.2253, 0.2718, 0.2216]), 'labels': tensor([16,  3, 12,  7,  6], dtype=torch.int32)}\n",
      "479155\n",
      "{'image_id': 479248, 'boxes': tensor([[446,   0, 548, 154],\n",
      "        [  0,   0,  86, 131],\n",
      "        [ 70, 174, 132, 256],\n",
      "        [  0, 157,  48, 243],\n",
      "        [373,   2, 432,  73],\n",
      "        [575,  33, 639, 109],\n",
      "        [101, 108, 145, 163],\n",
      "        [100,  33, 145,  91],\n",
      "        [ 55, 139,  97, 166],\n",
      "        [123, 322, 455, 478],\n",
      "        [416, 155, 445, 262],\n",
      "        [372,  88, 420, 146],\n",
      "        [562, 106, 639, 290]], dtype=torch.int32), 'scores': tensor([0.2539, 0.4666, 0.2014, 0.2095, 0.2207, 0.2139, 0.3541, 0.5805, 0.5093,\n",
      "        0.6368, 0.6199, 0.2870, 0.3714]), 'objectness_scores': tensor([0.2268, 0.2367, 0.2175, 0.2368, 0.2269, 0.2925, 0.2240, 0.2085, 0.2118,\n",
      "        0.2390, 0.2527, 0.2200, 0.2665]), 'labels': tensor([ 7,  5,  3,  5,  7, 13,  7,  7,  7,  3,  8,  7, 13], dtype=torch.int32)}\n",
      "479248\n",
      "{'image_id': 479448, 'boxes': tensor([[278,   0, 343,  44],\n",
      "        [  2,   2, 497, 375],\n",
      "        [407,  60, 499, 136],\n",
      "        [176, 108, 269, 227],\n",
      "        [349,   7, 435,  77],\n",
      "        [203, 109, 265, 149],\n",
      "        [  1,   0,  77,  78]], dtype=torch.int32), 'scores': tensor([0.4582, 0.6357, 0.9646, 0.5219, 0.8535, 0.3976, 0.2324]), 'objectness_scores': tensor([0.2294, 0.3664, 0.2572, 0.7624, 0.2202, 0.2787, 0.2542]), 'labels': tensor([12, 12, 10, 12, 10, 11, 11], dtype=torch.int32)}\n",
      "479448\n",
      "{'image_id': 479732, 'boxes': tensor([[  3,  76, 636, 427],\n",
      "        [ 73,   1, 232,  96],\n",
      "        [101, 151, 587, 231],\n",
      "        [  0,   0,  40,  58],\n",
      "        [  3,   2, 635, 434],\n",
      "        [ 12, 179, 355, 371],\n",
      "        [546, 234, 591, 271]], dtype=torch.int32), 'scores': tensor([0.4640, 0.9418, 0.4272, 0.4390, 0.3203, 0.6063, 0.4702]), 'objectness_scores': tensor([0.3796, 0.4543, 0.2074, 0.2265, 0.3028, 0.2412, 0.2071]), 'labels': tensor([11, 10, 11, 11,  4, 12, 12], dtype=torch.int32)}\n",
      "479732\n",
      "{'image_id': 479912, 'boxes': tensor([[460, 381, 464, 389],\n",
      "        [185, 384, 189, 395],\n",
      "        [115, 262, 149, 278],\n",
      "        [  3, 365,   9, 373],\n",
      "        [  3, 233, 466, 480],\n",
      "        [405, 385, 410, 394],\n",
      "        [323, 429, 331, 442],\n",
      "        [ 23, 317,  68, 354],\n",
      "        [320, 395, 325, 406],\n",
      "        [  3, 228, 325, 384],\n",
      "        [100, 380, 106, 390],\n",
      "        [118, 339, 161, 381]], dtype=torch.int32), 'scores': tensor([0.2088, 0.1537, 0.8165, 0.2865, 0.9903, 0.1644, 0.1477, 0.6236, 0.3196,\n",
      "        0.9567, 0.1960, 0.9714]), 'objectness_scores': tensor([0.4739, 0.4986, 0.4358, 0.6871, 0.2541, 0.6180, 0.6022, 0.2812, 0.4814,\n",
      "        0.3332, 0.7319, 0.2426]), 'labels': tensor([11, 11,  0, 11,  0, 11,  0,  0, 11,  0, 11,  0], dtype=torch.int32)}\n",
      "479912\n",
      "{'image_id': 480021, 'boxes': tensor([[  0, 215,  52, 288],\n",
      "        [ 73,  89,  80, 110],\n",
      "        [121,  79, 148,  98],\n",
      "        [444,  60, 515, 102],\n",
      "        [558, 375, 584, 425],\n",
      "        [321, 240, 371, 296]], dtype=torch.int32), 'scores': tensor([0.6884, 0.2135, 0.1648, 0.1940, 0.3429, 0.3275]), 'objectness_scores': tensor([0.5797, 0.5096, 0.3023, 0.4013, 0.2508, 0.2391]), 'labels': tensor([10, 11, 11,  7, 11, 10], dtype=torch.int32)}\n",
      "480021\n",
      "{'image_id': 480122, 'boxes': tensor([[115, 269, 240, 338],\n",
      "        [415, 201, 462, 260],\n",
      "        [  0, 364, 611, 637],\n",
      "        [368,   0, 512, 160],\n",
      "        [451, 261, 639, 346],\n",
      "        [220, 153, 250, 180],\n",
      "        [104, 217, 149, 267],\n",
      "        [451, 320, 642, 489],\n",
      "        [439, 170, 467, 188],\n",
      "        [  0,  13, 131,  93],\n",
      "        [ 77, 358, 138, 477],\n",
      "        [ 47,   0, 170, 160],\n",
      "        [516, 215, 544, 256],\n",
      "        [  0, 383,  49, 514]], dtype=torch.int32), 'scores': tensor([0.1824, 0.9876, 0.2252, 0.1728, 0.2973, 0.5715, 0.7400, 0.1988, 0.2475,\n",
      "        0.1785, 0.8071, 0.1860, 0.3962, 0.5431]), 'objectness_scores': tensor([0.3248, 0.5187, 0.2870, 0.2325, 0.2171, 0.2891, 0.2815, 0.2277, 0.2200,\n",
      "        0.3551, 0.3045, 0.2143, 0.2073, 0.2252]), 'labels': tensor([ 9, 10, 11,  9, 14, 11, 15, 13, 11, 11, 13,  3, 11,  7],\n",
      "       dtype=torch.int32)}\n",
      "480122\n",
      "{'image_id': 480944, 'boxes': tensor([[299, 191, 312, 228],\n",
      "        [298, 191, 315, 227],\n",
      "        [241, 179, 266, 210],\n",
      "        [322, 312, 334, 326],\n",
      "        [470, 279, 479, 305],\n",
      "        [212, 202, 240, 252],\n",
      "        [212, 202, 226, 240],\n",
      "        [ 68, 213, 117, 287],\n",
      "        [212, 201, 228, 239],\n",
      "        [ 66, 390, 110, 423],\n",
      "        [213, 203, 227, 238],\n",
      "        [225, 204, 240, 252],\n",
      "        [343,  43, 403, 246],\n",
      "        [322, 307, 334, 322]], dtype=torch.int32), 'scores': tensor([0.4360, 0.4752, 0.2314, 0.2144, 0.2555, 0.3346, 0.2228, 0.3641, 0.2808,\n",
      "        0.2971, 0.2026, 0.3891, 0.3327, 0.3203]), 'objectness_scores': tensor([0.2334, 0.4919, 0.3208, 0.2184, 0.2440, 0.2876, 0.2238, 0.4145, 0.4938,\n",
      "        0.2448, 0.2168, 0.4114, 0.5159, 0.2340]), 'labels': tensor([11, 11,  8, 11, 14, 11, 11,  1, 11, 14, 11,  7,  9, 14],\n",
      "       dtype=torch.int32)}\n",
      "480944\n",
      "{'image_id': 481386, 'boxes': tensor([[112, 476, 129, 524],\n",
      "        [ 94,  12, 152,  73],\n",
      "        [126, 402, 142, 450],\n",
      "        [158, 402, 177, 439],\n",
      "        [181, 321, 316, 406],\n",
      "        [126, 178, 326, 345],\n",
      "        [108, 409, 129, 456],\n",
      "        [104, 480, 118, 535],\n",
      "        [174, 489, 208, 557],\n",
      "        [126, 176, 288, 305],\n",
      "        [147,  27, 197,  69],\n",
      "        [127, 474, 140, 516],\n",
      "        [206, 527, 240, 580],\n",
      "        [394, 123, 427, 158],\n",
      "        [135, 459, 158, 500]], dtype=torch.int32), 'scores': tensor([0.2575, 0.8671, 0.2384, 0.1996, 0.1957, 0.1606, 0.6659, 0.3162, 0.4809,\n",
      "        0.2118, 0.5599, 0.1851, 0.3996, 0.9449, 0.2078]), 'objectness_scores': tensor([0.3367, 0.2690, 0.3163, 0.3119, 0.2039, 0.2236, 0.3927, 0.3337, 0.2925,\n",
      "        0.2006, 0.2442, 0.2974, 0.2992, 0.2203, 0.3370]), 'labels': tensor([ 8, 10,  8, 14,  5, 13,  8,  8,  8,  4, 15, 11,  8, 10, 10],\n",
      "       dtype=torch.int32)}\n",
      "481386\n",
      "{'image_id': 481390, 'boxes': tensor([[601, 463, 624, 480],\n",
      "        [434,  15, 448,  25],\n",
      "        [ 80, 460,  99, 474],\n",
      "        [307, 271, 334, 290],\n",
      "        [329, 289, 350, 310],\n",
      "        [ 96, 440, 110, 467],\n",
      "        [ 96, 356, 105, 364],\n",
      "        [ 82, 111,  99, 127],\n",
      "        [301,  43, 315,  72],\n",
      "        [580, 347, 605, 370],\n",
      "        [446, 244, 470, 260],\n",
      "        [309, 383, 330, 407],\n",
      "        [407, 393, 435, 410],\n",
      "        [270,  43, 276,  60],\n",
      "        [280, 405, 305, 421],\n",
      "        [510, 222, 528, 248],\n",
      "        [286, 255, 307, 280],\n",
      "        [409,  13, 419,  36]], dtype=torch.int32), 'scores': tensor([0.2861, 0.2177, 0.2642, 0.3729, 0.5631, 0.3909, 0.2152, 0.1857, 0.6228,\n",
      "        0.4206, 0.3178, 0.3297, 0.3709, 0.4113, 0.4388, 0.5816, 0.4096, 0.4051]), 'objectness_scores': tensor([0.5138, 0.3260, 0.2012, 0.2092, 0.2733, 0.2277, 0.2118, 0.2002, 0.3997,\n",
      "        0.2057, 0.2182, 0.2208, 0.2083, 0.2694, 0.2066, 0.2303, 0.2166, 0.3366]), 'labels': tensor([ 4, 11,  3, 11, 12, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "481390\n",
      "{'image_id': 481573, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "481573\n",
      "{'image_id': 482275, 'boxes': tensor([[422, 349, 444, 364],\n",
      "        [371, 441, 397, 469],\n",
      "        [418, 441, 432, 467],\n",
      "        [254, 186, 358, 454],\n",
      "        [422, 442, 450, 468],\n",
      "        [504, 432, 526, 463],\n",
      "        [421, 432, 451, 468],\n",
      "        [471, 346, 493, 361],\n",
      "        [159,  96, 166, 103],\n",
      "        [367, 421, 543, 468],\n",
      "        [215, 169, 243, 205],\n",
      "        [450, 349, 465, 359],\n",
      "        [582, 423, 625, 478],\n",
      "        [522, 424, 546, 461],\n",
      "        [419, 429, 442, 467],\n",
      "        [499, 427, 524, 447],\n",
      "        [470, 422, 490, 443],\n",
      "        [419, 354, 445, 388],\n",
      "        [515, 316, 615, 414],\n",
      "        [392, 349, 529, 388],\n",
      "        [496, 352, 522, 384],\n",
      "        [222, 445, 256, 479],\n",
      "        [511, 351, 527, 380],\n",
      "        [454, 436, 481, 466],\n",
      "        [496, 352, 515, 384],\n",
      "        [556, 419, 632, 479],\n",
      "        [553, 417, 596, 479],\n",
      "        [396, 435, 421, 468],\n",
      "        [ 93, 125, 310, 455],\n",
      "        [501, 428, 525, 462],\n",
      "        [379, 246, 526, 307],\n",
      "        [514, 315, 623, 480],\n",
      "        [507, 351, 527, 382],\n",
      "        [202, 160, 240, 258],\n",
      "        [482, 435, 508, 465],\n",
      "        [483, 429, 508, 465],\n",
      "        [468, 429, 486, 445],\n",
      "        [472, 353, 500, 385],\n",
      "        [522, 432, 539, 461],\n",
      "        [465, 425, 487, 450],\n",
      "        [440, 434, 457, 464],\n",
      "        [447, 355, 473, 386],\n",
      "        [393, 356, 421, 387],\n",
      "        [415, 430, 433, 450],\n",
      "        [505, 352, 527, 383],\n",
      "        [514, 352, 528, 383],\n",
      "        [524, 434, 547, 462],\n",
      "        [440, 434, 458, 467],\n",
      "        [623, 412, 640, 480],\n",
      "        [396, 443, 422, 468],\n",
      "        [278, 166, 313, 189],\n",
      "        [371, 430, 397, 469]], dtype=torch.int32), 'scores': tensor([0.2567, 0.4191, 0.2605, 0.7396, 0.3285, 0.2627, 0.9448, 0.2138, 0.2503,\n",
      "        0.8921, 0.3992, 0.3434, 0.3225, 0.1609, 0.1698, 0.1603, 0.1693, 0.9522,\n",
      "        0.3781, 0.8834, 0.5431, 0.6065, 0.2257, 0.8950, 0.2857, 0.5688, 0.1961,\n",
      "        0.5229, 0.9496, 0.5149, 0.2300, 0.8635, 0.1934, 0.3086, 0.5557, 0.5762,\n",
      "        0.1379, 0.8481, 0.1544, 0.1343, 0.1536, 0.5475, 0.5688, 0.1777, 0.4662,\n",
      "        0.1551, 0.7123, 0.1627, 0.2304, 0.9384, 0.2594, 0.4009]), 'objectness_scores': tensor([0.2632, 0.3045, 0.2305, 0.2587, 0.3269, 0.3514, 0.2788, 0.2890, 0.3180,\n",
      "        0.3762, 0.2366, 0.2483, 0.2653, 0.2727, 0.2036, 0.2435, 0.2342, 0.4397,\n",
      "        0.3179, 0.3500, 0.4422, 0.2514, 0.2138, 0.4055, 0.2665, 0.2130, 0.2145,\n",
      "        0.3970, 0.2682, 0.4173, 0.5316, 0.2524, 0.2001, 0.4327, 0.3964, 0.2068,\n",
      "        0.2137, 0.4311, 0.2483, 0.3603, 0.2276, 0.4222, 0.4511, 0.3753, 0.3999,\n",
      "        0.2345, 0.4314, 0.3684, 0.2084, 0.2755, 0.3225, 0.4092]), 'labels': tensor([11, 10, 11,  7, 15, 10, 10, 11, 11, 12,  7, 11, 10,  4, 10,  4,  7, 10,\n",
      "        10, 12, 12, 10, 11, 12, 11, 10,  6, 10,  7, 12,  9, 12, 11, 11, 10, 10,\n",
      "        11, 10, 11, 11, 14, 10, 10,  4, 12, 11, 10, 11, 14, 12, 11, 10],\n",
      "       dtype=torch.int32)}\n",
      "482275\n",
      "{'image_id': 482436, 'boxes': tensor([[315,  87, 340, 157],\n",
      "        [215, 120, 257, 165],\n",
      "        [231, 229, 430, 383],\n",
      "        [189, 135, 204, 145]], dtype=torch.int32), 'scores': tensor([0.4282, 0.6640, 0.2423, 0.2132]), 'objectness_scores': tensor([0.2089, 0.2080, 0.2442, 0.3840]), 'labels': tensor([11, 15, 10, 14], dtype=torch.int32)}\n",
      "482436\n",
      "{'image_id': 482917, 'boxes': tensor([[223,  65, 428, 171],\n",
      "        [378, 237, 406, 273],\n",
      "        [  1,  77, 272, 377],\n",
      "        [331,  97, 410, 130],\n",
      "        [258, 105, 316, 130],\n",
      "        [340,  75, 400,  88],\n",
      "        [  0,  61,  63, 181]], dtype=torch.int32), 'scores': tensor([0.3111, 0.7669, 0.8857, 0.2687, 0.6721, 0.3483, 0.7145]), 'objectness_scores': tensor([0.2300, 0.2136, 0.4765, 0.2610, 0.2769, 0.2083, 0.2659]), 'labels': tensor([14,  7,  3, 14, 14, 11,  7], dtype=torch.int32)}\n",
      "482917\n",
      "{'image_id': 483050, 'boxes': tensor([[294, 248, 411, 320],\n",
      "        [  0, 282, 132, 475],\n",
      "        [605, 148, 638, 281],\n",
      "        [340, 213, 451, 305],\n",
      "        [ 76, 273, 115, 292],\n",
      "        [225, 215, 342, 247],\n",
      "        [538, 271, 638, 356],\n",
      "        [175, 208, 492, 314],\n",
      "        [440, 208, 493, 292],\n",
      "        [551, 258, 600, 291],\n",
      "        [221, 217, 342, 313],\n",
      "        [  0, 150,  50, 298],\n",
      "        [348, 210, 392, 230],\n",
      "        [123,  93, 529, 289],\n",
      "        [177, 217, 230, 298],\n",
      "        [552, 258, 601, 281]], dtype=torch.int32), 'scores': tensor([0.9023, 0.4425, 0.3906, 0.8574, 0.5913, 0.9964, 0.3409, 0.9917, 0.4262,\n",
      "        0.3638, 0.9284, 0.3176, 0.2587, 0.6647, 0.3642, 0.2620]), 'objectness_scores': tensor([0.4499, 0.4861, 0.2709, 0.4091, 0.3776, 0.2087, 0.4691, 0.2619, 0.2915,\n",
      "        0.3842, 0.4527, 0.4044, 0.2424, 0.6399, 0.3938, 0.5062]), 'labels': tensor([13,  7,  7, 13, 11,  4,  7, 13,  7, 14,  3,  7, 11, 13,  7, 11],\n",
      "       dtype=torch.int32)}\n",
      "483050\n",
      "{'image_id': 483667, 'boxes': tensor([[118,   1, 412, 215],\n",
      "        [  1, 279, 422, 639],\n",
      "        [195, 394, 251, 640]], dtype=torch.int32), 'scores': tensor([0.6955, 0.9957, 0.9590]), 'objectness_scores': tensor([0.3607, 0.2167, 0.5148]), 'labels': tensor([7, 7, 7], dtype=torch.int32)}\n",
      "483667\n",
      "{'image_id': 483999, 'boxes': tensor([[336, 208, 354, 229],\n",
      "        [269, 202, 286, 218],\n",
      "        [379, 189, 391, 196],\n",
      "        [220, 246, 249, 261],\n",
      "        [339, 178, 352, 199],\n",
      "        [365, 120, 398, 156],\n",
      "        [206, 247, 220, 263],\n",
      "        [246, 242, 269, 284],\n",
      "        [325, 216, 345, 238],\n",
      "        [284, 223, 297, 241],\n",
      "        [103, 245, 119, 272],\n",
      "        [552, 173, 638, 255],\n",
      "        [169, 130, 200, 158],\n",
      "        [330, 187, 347, 216],\n",
      "        [321, 282, 349, 309],\n",
      "        [286, 158, 320, 233],\n",
      "        [161, 344, 213, 378],\n",
      "        [336, 246, 359, 288],\n",
      "        [ 29, 117,  42, 170],\n",
      "        [126, 201, 442, 423],\n",
      "        [136, 405, 220, 424],\n",
      "        [189, 377, 220, 406],\n",
      "        [450, 407, 458, 416],\n",
      "        [441, 227, 454, 260],\n",
      "        [250, 169, 262, 179],\n",
      "        [354, 256, 378, 273],\n",
      "        [205, 282, 242, 303],\n",
      "        [491, 331, 528, 356],\n",
      "        [293, 232, 316, 259],\n",
      "        [359, 289, 402, 310],\n",
      "        [330, 155, 404, 194],\n",
      "        [300, 387, 321, 402],\n",
      "        [340, 303, 370, 350],\n",
      "        [256, 273, 283, 298],\n",
      "        [356, 217, 383, 229],\n",
      "        [251, 211, 270, 246],\n",
      "        [413, 385, 450, 405],\n",
      "        [315, 388, 371, 427],\n",
      "        [207, 279, 240, 301],\n",
      "        [271, 297, 291, 311],\n",
      "        [164, 142, 185, 156],\n",
      "        [202, 349, 221, 397],\n",
      "        [241, 143, 286, 182]], dtype=torch.int32), 'scores': tensor([0.6189, 0.3266, 0.2008, 0.4612, 0.2289, 0.1443, 0.3741, 0.5545, 0.1972,\n",
      "        0.1795, 0.2370, 0.2758, 0.4454, 0.3133, 0.9113, 0.2537, 0.4006, 0.9153,\n",
      "        0.2942, 0.8298, 0.9055, 0.3774, 0.2386, 0.3687, 0.3113, 0.2971, 0.2807,\n",
      "        0.2339, 0.1499, 0.2337, 0.5230, 0.2803, 0.8515, 0.8849, 0.2458, 0.8834,\n",
      "        0.3019, 0.6186, 0.1437, 0.3567, 0.5151, 0.2275, 0.2382]), 'objectness_scores': tensor([0.2988, 0.2411, 0.3832, 0.2734, 0.2514, 0.2208, 0.2512, 0.3321, 0.2803,\n",
      "        0.2193, 0.2090, 0.3324, 0.2110, 0.2488, 0.3259, 0.4165, 0.3139, 0.2915,\n",
      "        0.2004, 0.2850, 0.4810, 0.2972, 0.2494, 0.2147, 0.3065, 0.2807, 0.2153,\n",
      "        0.3146, 0.3145, 0.2408, 0.3386, 0.2229, 0.3003, 0.3547, 0.2452, 0.3037,\n",
      "        0.3305, 0.2481, 0.2150, 0.2144, 0.2445, 0.2095, 0.2342]), 'labels': tensor([10, 11, 14, 11, 11,  7, 11, 13, 15, 11, 11,  7, 11, 14, 10, 11, 11, 10,\n",
      "        11, 10, 11, 10, 11, 11, 11, 11, 12, 11, 13, 10,  7, 11, 10, 10, 12, 10,\n",
      "        11, 10, 14, 11, 11, 11,  7], dtype=torch.int32)}\n",
      "483999\n",
      "{'image_id': 484351, 'boxes': tensor([[ 80,  11, 190, 134],\n",
      "        [596, 113, 631, 135],\n",
      "        [188,  10, 209,  52],\n",
      "        [  0,   0,  92, 130],\n",
      "        [ 96, 222, 384, 409],\n",
      "        [137, 363, 141, 378],\n",
      "        [132, 167, 252, 253],\n",
      "        [ 84, 154,  94, 167],\n",
      "        [360, 102, 366, 110],\n",
      "        [  1, 198, 127, 269],\n",
      "        [245, 267, 281, 279],\n",
      "        [ 99, 125, 125, 130],\n",
      "        [452, 194, 470, 255],\n",
      "        [271,  79, 278,  87],\n",
      "        [149,  57, 164, 105],\n",
      "        [225, 151, 288, 180]], dtype=torch.int32), 'scores': tensor([0.9911, 0.3579, 0.3223, 0.4336, 0.2510, 0.2193, 0.4652, 0.3295, 0.2505,\n",
      "        0.2737, 0.4134, 0.2289, 0.2557, 0.1868, 0.6019, 0.6152]), 'objectness_scores': tensor([0.4189, 0.2564, 0.3272, 0.2770, 0.2011, 0.2343, 0.2268, 0.2682, 0.2619,\n",
      "        0.2121, 0.3231, 0.2157, 0.3697, 0.2116, 0.4257, 0.2489]), 'labels': tensor([ 7, 14,  7,  7,  9, 11,  7, 11, 11,  8, 11, 14, 11, 14,  7, 14],\n",
      "       dtype=torch.int32)}\n",
      "484351\n",
      "{'image_id': 484404, 'boxes': tensor([[116, 239, 130, 274]], dtype=torch.int32), 'scores': tensor([0.1849]), 'objectness_scores': tensor([0.2167]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "484404\n",
      "{'image_id': 484978, 'boxes': tensor([[363, 282, 431, 310],\n",
      "        [446, 276, 489, 322],\n",
      "        [  3, 296, 636, 491],\n",
      "        [393, 145, 442, 213],\n",
      "        [458, 295, 488, 322],\n",
      "        [490, 271, 533, 308],\n",
      "        [389, 361, 427, 413],\n",
      "        [489, 270, 534, 339],\n",
      "        [ 91, 325, 388, 449],\n",
      "        [437, 392, 641, 485],\n",
      "        [ 84, 310, 121, 345],\n",
      "        [444, 318, 525, 395],\n",
      "        [523, 299, 560, 344],\n",
      "        [572, 137, 600, 207],\n",
      "        [274, 346, 393, 389],\n",
      "        [509, 340, 558, 393],\n",
      "        [404, 326, 462, 402],\n",
      "        [560, 289, 614, 346],\n",
      "        [536, 203, 623, 332],\n",
      "        [114, 277, 184, 336],\n",
      "        [235, 293, 282, 352],\n",
      "        [589, 355, 639, 397],\n",
      "        [200, 298, 321, 333],\n",
      "        [614, 296, 639, 355],\n",
      "        [407, 262, 446, 326]], dtype=torch.int32), 'scores': tensor([0.2680, 0.3238, 0.4720, 0.3778, 0.3087, 0.9747, 0.9880, 0.1247, 0.2013,\n",
      "        0.2737, 0.9345, 0.9962, 0.1954, 0.4737, 0.1998, 0.2371, 0.9732, 0.1817,\n",
      "        0.8575, 0.9703, 0.3442, 0.3506, 0.2037, 0.2345, 0.1571]), 'objectness_scores': tensor([0.3884, 0.2954, 0.3451, 0.3607, 0.2156, 0.2131, 0.4432, 0.2606, 0.3432,\n",
      "        0.4003, 0.4828, 0.4610, 0.4000, 0.2600, 0.3487, 0.4483, 0.4518, 0.3974,\n",
      "        0.4917, 0.4406, 0.3020, 0.2558, 0.3734, 0.2637, 0.4545]), 'labels': tensor([11, 10,  8, 11, 11,  3, 10,  8, 11,  9, 10, 10, 10, 11, 15, 14, 10, 10,\n",
      "        10, 10, 10, 11,  7, 11, 11], dtype=torch.int32)}\n",
      "484978\n",
      "{'image_id': 485237, 'boxes': tensor([[224,  90, 240, 105],\n",
      "        [ 60,  87,  76, 102],\n",
      "        [266,  85, 282, 101],\n",
      "        [  9,   5, 311, 113],\n",
      "        [229,  22, 597, 144],\n",
      "        [407,  22, 423,  87],\n",
      "        [104,  91, 121, 107]], dtype=torch.int32), 'scores': tensor([0.3955, 0.2553, 0.4329, 0.9868, 0.9820, 0.3848, 0.2654]), 'objectness_scores': tensor([0.2015, 0.2410, 0.2088, 0.5215, 0.5173, 0.3414, 0.2011]), 'labels': tensor([14, 14, 14,  0,  0, 11, 14], dtype=torch.int32)}\n",
      "485237\n",
      "{'image_id': 485424, 'boxes': tensor([[ 74,   1, 133,  83],\n",
      "        [135,  38, 237, 195],\n",
      "        [370, 387, 399, 395],\n",
      "        [316,  67, 362, 130],\n",
      "        [122, 372, 235, 469],\n",
      "        [ 21, 356,  53, 373],\n",
      "        [ 79, 148, 149, 206],\n",
      "        [ 50, 236, 118, 304],\n",
      "        [344, 364, 461, 478],\n",
      "        [  0, 413,  73, 479],\n",
      "        [ 80, 146, 150, 275],\n",
      "        [ 73,  22, 131,  82],\n",
      "        [ 86, 199, 146, 275],\n",
      "        [  1, 353,  55, 379],\n",
      "        [ 51, 236, 131, 317],\n",
      "        [136,   0, 271,  45],\n",
      "        [  0, 334, 104, 449],\n",
      "        [335, 227, 370, 259]], dtype=torch.int32), 'scores': tensor([0.2207, 0.5411, 0.4363, 0.9585, 0.2579, 0.6119, 0.8124, 0.4091, 0.1633,\n",
      "        0.3035, 0.4447, 0.3045, 0.7341, 0.6098, 0.4587, 0.5745, 0.3266, 0.9939]), 'objectness_scores': tensor([0.3320, 0.2078, 0.2121, 0.4865, 0.4662, 0.2471, 0.2960, 0.2402, 0.3133,\n",
      "        0.3032, 0.3864, 0.2218, 0.2966, 0.2097, 0.4361, 0.3248, 0.2424, 0.4775]), 'labels': tensor([11,  7, 11, 10, 13, 11, 10, 10, 13,  2, 10, 10, 10, 11, 10, 11, 16, 10],\n",
      "       dtype=torch.int32)}\n",
      "485424\n",
      "{'image_id': 485844, 'boxes': tensor([[171, 210, 270, 232],\n",
      "        [204,  42, 220,  59],\n",
      "        [ 27, 245, 109, 281],\n",
      "        [374, 192, 507, 247]], dtype=torch.int32), 'scores': tensor([0.2410, 0.1717, 0.2682, 0.2620]), 'objectness_scores': tensor([0.2108, 0.4466, 0.2064, 0.2926]), 'labels': tensor([11, 14,  8,  7], dtype=torch.int32)}\n",
      "485844\n",
      "{'image_id': 485972, 'boxes': tensor([[  3, 270, 425, 640],\n",
      "        [  0,   1, 422, 244]], dtype=torch.int32), 'scores': tensor([0.9993, 0.3201]), 'objectness_scores': tensor([0.4135, 0.3001]), 'labels': tensor([12, 11], dtype=torch.int32)}\n",
      "485972\n",
      "{'image_id': 486040, 'boxes': tensor([[372, 462, 398, 484],\n",
      "        [ 75, 357, 259, 450],\n",
      "        [  2, 193, 480, 639],\n",
      "        [307, 298, 432, 347],\n",
      "        [197, 200, 479, 635],\n",
      "        [271, 331, 366, 486],\n",
      "        [151,  73, 253, 353],\n",
      "        [361, 449, 414, 483],\n",
      "        [205, 197, 479, 417],\n",
      "        [357, 185, 395, 237],\n",
      "        [353, 172, 382, 196]], dtype=torch.int32), 'scores': tensor([0.1981, 0.9499, 0.4322, 0.1732, 0.3653, 0.2509, 0.3041, 0.4238, 0.7193,\n",
      "        0.2999, 0.2904]), 'objectness_scores': tensor([0.2397, 0.3920, 0.4231, 0.2224, 0.2069, 0.4328, 0.4597, 0.3436, 0.2448,\n",
      "        0.3279, 0.3667]), 'labels': tensor([ 4, 14, 14,  9,  7, 16,  7, 16,  7,  7, 14], dtype=torch.int32)}\n",
      "486040\n",
      "{'image_id': 486112, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "486112\n",
      "{'image_id': 486479, 'boxes': tensor([[ 66,  55, 302, 234]], dtype=torch.int32), 'scores': tensor([0.9625]), 'objectness_scores': tensor([0.5220]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "486479\n",
      "{'image_id': 487583, 'boxes': tensor([[239, 222, 426, 639],\n",
      "        [343, 166, 410, 242],\n",
      "        [254, 223, 376, 264],\n",
      "        [364,   7, 425,  73],\n",
      "        [  3,   1, 324,  42]], dtype=torch.int32), 'scores': tensor([0.2118, 0.9826, 0.8886, 0.4700, 0.6718]), 'objectness_scores': tensor([0.3186, 0.3687, 0.3090, 0.2159, 0.3265]), 'labels': tensor([ 7, 10, 12, 11, 11], dtype=torch.int32)}\n",
      "487583\n",
      "{'image_id': 488166, 'boxes': tensor([[241, 218, 275, 275],\n",
      "        [231, 418, 329, 588],\n",
      "        [  7, 542, 255, 617]], dtype=torch.int32), 'scores': tensor([0.3343, 0.5456, 0.6093]), 'objectness_scores': tensor([0.4236, 0.4155, 0.2101]), 'labels': tensor([11, 12, 12], dtype=torch.int32)}\n",
      "488166\n",
      "{'image_id': 488251, 'boxes': tensor([[272, 115, 390, 314],\n",
      "        [435, 308, 462, 335]], dtype=torch.int32), 'scores': tensor([0.7280, 0.4042]), 'objectness_scores': tensor([0.2025, 0.2777]), 'labels': tensor([7, 9], dtype=torch.int32)}\n",
      "488251\n",
      "{'image_id': 488592, 'boxes': tensor([[254, 411, 311, 431],\n",
      "        [127, 372, 175, 414],\n",
      "        [  1, 322, 124, 547],\n",
      "        [369, 415, 441, 494],\n",
      "        [445, 325, 481, 392],\n",
      "        [188, 378, 207, 410],\n",
      "        [220, 409, 226, 415],\n",
      "        [425, 205, 468, 251],\n",
      "        [339, 424, 359, 508],\n",
      "        [290, 479, 320, 504],\n",
      "        [ 49, 503, 101, 557],\n",
      "        [219, 384, 262, 398]], dtype=torch.int32), 'scores': tensor([0.2936, 0.2120, 0.3859, 0.3444, 0.2124, 0.3535, 0.2284, 0.4716, 0.3648,\n",
      "        0.1921, 0.5497, 0.2521]), 'objectness_scores': tensor([0.3275, 0.2039, 0.2079, 0.2394, 0.2011, 0.5509, 0.2360, 0.2110, 0.2025,\n",
      "        0.3864, 0.2083, 0.2161]), 'labels': tensor([11,  1,  7, 12,  8,  7, 11, 14,  8,  8,  6, 11], dtype=torch.int32)}\n",
      "488592\n",
      "{'image_id': 488673, 'boxes': tensor([[ 37, 399, 198, 538],\n",
      "        [214, 513, 324, 566],\n",
      "        [275, 426, 336, 458],\n",
      "        [298, 354, 320, 433],\n",
      "        [ 44, 540, 194, 612],\n",
      "        [400, 440, 480, 469],\n",
      "        [ 71, 203, 128, 316],\n",
      "        [343, 392, 383, 460],\n",
      "        [239, 443, 310, 580],\n",
      "        [311, 236, 338, 258]], dtype=torch.int32), 'scores': tensor([0.9859, 0.9018, 0.8972, 0.5879, 0.4142, 0.2218, 0.6832, 0.9485, 0.7145,\n",
      "        0.3483]), 'objectness_scores': tensor([0.4499, 0.2040, 0.2012, 0.5067, 0.2124, 0.2117, 0.2504, 0.2682, 0.3309,\n",
      "        0.3022]), 'labels': tensor([10, 10, 12, 11,  7, 12,  7, 10, 10, 14], dtype=torch.int32)}\n",
      "488673\n",
      "{'image_id': 489014, 'boxes': tensor([[ 83, 167, 101, 206]], dtype=torch.int32), 'scores': tensor([0.3829]), 'objectness_scores': tensor([0.4042]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "489014\n",
      "{'image_id': 489091, 'boxes': tensor([[ 89, 241, 109, 264],\n",
      "        [197, 289, 233, 313],\n",
      "        [ 58, 269, 335, 448],\n",
      "        [158,   1, 336, 313],\n",
      "        [275, 245, 292, 256],\n",
      "        [248, 276, 298, 291],\n",
      "        [ 61, 289,  95, 346],\n",
      "        [149, 257, 176, 275],\n",
      "        [281, 288, 335, 315],\n",
      "        [189, 249, 218, 270],\n",
      "        [200, 254, 335, 318],\n",
      "        [ 89, 242, 102, 261],\n",
      "        [262, 282, 283, 292],\n",
      "        [142, 260, 189, 289],\n",
      "        [134, 299, 235, 345],\n",
      "        [248, 279, 334, 316],\n",
      "        [ 65, 325, 102, 442],\n",
      "        [117, 120, 134, 160],\n",
      "        [101, 121, 116, 159],\n",
      "        [203, 334, 295, 378]], dtype=torch.int32), 'scores': tensor([0.2080, 0.4877, 0.9938, 0.3270, 0.1773, 0.2014, 0.1782, 0.4140, 0.2745,\n",
      "        0.2387, 0.8165, 0.2167, 0.2237, 0.2165, 0.9392, 0.4034, 0.2257, 0.3889,\n",
      "        0.3744, 0.4014]), 'objectness_scores': tensor([0.3508, 0.6098, 0.2113, 0.6426, 0.3515, 0.2150, 0.2198, 0.2632, 0.2402,\n",
      "        0.3394, 0.4744, 0.2016, 0.5260, 0.2943, 0.6825, 0.2138, 0.2188, 0.2574,\n",
      "        0.2462, 0.5024]), 'labels': tensor([11,  9, 15, 15, 14, 11, 14, 11, 11, 11, 15, 11, 11, 11, 15, 15, 11, 11,\n",
      "        11,  2], dtype=torch.int32)}\n",
      "489091\n",
      "{'image_id': 489842, 'boxes': tensor([[308, 332, 382, 419],\n",
      "        [292, 159, 377, 238],\n",
      "        [417, 279, 444, 300],\n",
      "        [456, 181, 466, 201],\n",
      "        [199,  75, 214, 107],\n",
      "        [219, 127, 250, 147],\n",
      "        [513, 126, 563, 171],\n",
      "        [228, 192, 256, 219],\n",
      "        [554, 526, 582, 559],\n",
      "        [277, 103, 290, 118],\n",
      "        [433, 338, 522, 400],\n",
      "        [257, 166, 436, 418],\n",
      "        [476, 279, 497, 334],\n",
      "        [348,  90, 359, 104],\n",
      "        [389, 174, 423, 212],\n",
      "        [ 66, 134, 108, 167],\n",
      "        [143,  75, 166, 123],\n",
      "        [330, 442, 362, 493],\n",
      "        [309, 373, 372, 419],\n",
      "        [333,  23, 376,  55],\n",
      "        [354, 552, 361, 565],\n",
      "        [576, 373, 640, 427],\n",
      "        [306, 215, 336, 243],\n",
      "        [144, 185, 177, 224],\n",
      "        [ 94, 499, 130, 545],\n",
      "        [383, 117, 426, 143]], dtype=torch.int32), 'scores': tensor([0.3154, 0.5161, 0.2942, 0.3584, 0.2028, 0.2722, 0.1769, 0.2427, 0.2239,\n",
      "        0.1535, 0.1708, 0.3561, 0.2775, 0.3228, 0.3838, 0.5564, 0.3678, 0.4219,\n",
      "        0.1382, 0.2306, 0.1420, 0.2095, 0.6883, 0.2848, 0.2588, 0.2158]), 'objectness_scores': tensor([0.3483, 0.2833, 0.2756, 0.5450, 0.5438, 0.2343, 0.4802, 0.2218, 0.2541,\n",
      "        0.4218, 0.4668, 0.2575, 0.2057, 0.2535, 0.5492, 0.2722, 0.5347, 0.5161,\n",
      "        0.2681, 0.3215, 0.2244, 0.3608, 0.2189, 0.2790, 0.2027, 0.3049]), 'labels': tensor([ 7,  7,  7,  2, 11, 11,  7,  7, 11, 16, 12,  2, 14,  7,  7, 11, 14,  7,\n",
      "        16, 16, 11,  3,  7,  7,  7, 16], dtype=torch.int32)}\n",
      "489842\n",
      "{'image_id': 489924, 'boxes': tensor([[250, 409, 449, 606],\n",
      "        [255, 469, 281, 498],\n",
      "        [235, 406, 334, 467],\n",
      "        [140, 162, 318, 276],\n",
      "        [127,   0, 311, 223]], dtype=torch.int32), 'scores': tensor([0.9658, 0.2792, 0.1746, 0.2228, 0.6224]), 'objectness_scores': tensor([0.6813, 0.2057, 0.2229, 0.4280, 0.3141]), 'labels': tensor([ 9, 11,  7, 12, 11], dtype=torch.int32)}\n",
      "489924\n",
      "{'image_id': 490171, 'boxes': tensor([[276, 231, 381, 308],\n",
      "        [ 59, 263, 280, 309]], dtype=torch.int32), 'scores': tensor([0.9284, 0.2811]), 'objectness_scores': tensor([0.5758, 0.2046]), 'labels': tensor([3, 8], dtype=torch.int32)}\n",
      "490171\n",
      "{'image_id': 490515, 'boxes': tensor([[250, 117, 291, 154],\n",
      "        [259, 127, 293, 148],\n",
      "        [190, 205, 226, 220]], dtype=torch.int32), 'scores': tensor([0.9854, 0.2032, 0.2739]), 'objectness_scores': tensor([0.5041, 0.6839, 0.4620]), 'labels': tensor([ 8, 16, 11], dtype=torch.int32)}\n",
      "490515\n",
      "{'image_id': 491008, 'boxes': tensor([[ 89, 162,  98, 179],\n",
      "        [264, 244, 288, 258],\n",
      "        [  0, 349, 217, 426],\n",
      "        [239, 370, 280, 392],\n",
      "        [222, 234, 301, 427]], dtype=torch.int32), 'scores': tensor([0.5373, 0.9025, 0.5095, 0.5043, 0.3322]), 'objectness_scores': tensor([0.2508, 0.4679, 0.2092, 0.3095, 0.2184]), 'labels': tensor([11,  7, 13, 11,  7], dtype=torch.int32)}\n",
      "491008\n",
      "{'image_id': 491130, 'boxes': tensor([[108, 286, 160, 345],\n",
      "        [ 67, 153,  90, 170],\n",
      "        [221, 408, 271, 471],\n",
      "        [231, 179, 289, 215],\n",
      "        [363, 124, 406, 173],\n",
      "        [229, 201, 286, 234]], dtype=torch.int32), 'scores': tensor([0.3746, 0.4032, 0.9434, 0.4168, 0.7774, 0.9646]), 'objectness_scores': tensor([0.2796, 0.2079, 0.2619, 0.3064, 0.4409, 0.4996]), 'labels': tensor([8, 7, 8, 8, 8, 8], dtype=torch.int32)}\n",
      "491130\n",
      "{'image_id': 491216, 'boxes': tensor([[160, 263, 193, 327],\n",
      "        [114, 313, 157, 381],\n",
      "        [240, 270, 294, 354],\n",
      "        [298,  64, 346,  90],\n",
      "        [193,  31, 293, 140],\n",
      "        [296, 108, 350, 132],\n",
      "        [105, 342, 188, 563],\n",
      "        [186, 273, 241, 368],\n",
      "        [295, 150, 354, 177],\n",
      "        [178, 423, 269, 507]], dtype=torch.int32), 'scores': tensor([0.7217, 0.3190, 0.2796, 0.2824, 0.6722, 0.1863, 0.1782, 0.3124, 0.2971,\n",
      "        0.9160]), 'objectness_scores': tensor([0.2939, 0.2066, 0.3737, 0.2023, 0.2686, 0.2627, 0.2537, 0.3005, 0.2398,\n",
      "        0.4548]), 'labels': tensor([11, 15,  8, 11,  7, 11,  6,  7, 11,  2], dtype=torch.int32)}\n",
      "491216\n",
      "{'image_id': 491366, 'boxes': tensor([[205, 217, 413, 345],\n",
      "        [  0, 273, 106, 374],\n",
      "        [416, 185, 456, 243],\n",
      "        [180, 179, 233, 213],\n",
      "        [166, 199, 258, 292],\n",
      "        [  0, 272, 206, 375]], dtype=torch.int32), 'scores': tensor([0.5740, 0.7835, 0.3106, 0.2003, 0.2920, 0.3514]), 'objectness_scores': tensor([0.3552, 0.2309, 0.2602, 0.2661, 0.2292, 0.3251]), 'labels': tensor([13, 13,  0, 14, 14,  7], dtype=torch.int32)}\n",
      "491366\n",
      "{'image_id': 491497, 'boxes': tensor([[168, 289, 317, 412],\n",
      "        [ 85,   3, 271, 487],\n",
      "        [  0, 326, 140, 501]], dtype=torch.int32), 'scores': tensor([0.5789, 0.3698, 0.2838]), 'objectness_scores': tensor([0.3260, 0.5191, 0.2237]), 'labels': tensor([13, 13, 13], dtype=torch.int32)}\n",
      "491497\n",
      "{'image_id': 491757, 'boxes': tensor([[511,   6, 640, 137],\n",
      "        [460, 295, 480, 325],\n",
      "        [318, 153, 529, 362],\n",
      "        [230,  20, 312, 126],\n",
      "        [350,  12, 542, 121],\n",
      "        [354,   0, 642, 104],\n",
      "        [402,  60, 571, 141],\n",
      "        [372,  10, 545,  50],\n",
      "        [348,   5, 640, 136],\n",
      "        [229,  20, 312,  79]], dtype=torch.int32), 'scores': tensor([0.5480, 0.6139, 0.9880, 0.2557, 0.5272, 0.4394, 0.4063, 0.3108, 0.1599,\n",
      "        0.1940]), 'objectness_scores': tensor([0.3061, 0.2084, 0.4984, 0.5808, 0.3489, 0.2640, 0.5435, 0.2106, 0.4447,\n",
      "        0.2179]), 'labels': tensor([ 3,  8,  2, 10, 13,  7, 11, 11, 13, 11], dtype=torch.int32)}\n",
      "491757\n",
      "{'image_id': 491867, 'boxes': tensor([[232, 289, 288, 600],\n",
      "        [118, 579, 314, 640],\n",
      "        [210, 169, 319, 197],\n",
      "        [ 52, 240, 400, 618],\n",
      "        [294, 376, 360, 437]], dtype=torch.int32), 'scores': tensor([0.7285, 0.2357, 0.4519, 0.9982, 0.2938]), 'objectness_scores': tensor([0.4271, 0.4207, 0.2008, 0.2520, 0.2133]), 'labels': tensor([ 7,  8,  7,  7, 12], dtype=torch.int32)}\n",
      "491867\n",
      "{'image_id': 492077, 'boxes': tensor([[409, 123, 415, 136],\n",
      "        [185, 286, 253, 348],\n",
      "        [377, 102, 417, 114],\n",
      "        [225, 134, 235, 148],\n",
      "        [440,  79, 459, 117],\n",
      "        [274,   0, 306,  33],\n",
      "        [186, 141, 202, 173]], dtype=torch.int32), 'scores': tensor([0.1739, 0.2469, 0.5660, 0.2324, 0.3600, 0.2968, 0.2046]), 'objectness_scores': tensor([0.2237, 0.2183, 0.2833, 0.2800, 0.2447, 0.2465, 0.2517]), 'labels': tensor([14,  1, 14, 14, 11,  8, 11], dtype=torch.int32)}\n",
      "492077\n",
      "{'image_id': 492110, 'boxes': tensor([[159, 365, 267, 425],\n",
      "        [386,  58, 418, 104],\n",
      "        [530, 183, 620, 221],\n",
      "        [  2, 323, 470, 426]], dtype=torch.int32), 'scores': tensor([0.9837, 0.6806, 0.8932, 0.4762]), 'objectness_scores': tensor([0.3204, 0.3992, 0.2934, 0.2171]), 'labels': tensor([10, 16, 11, 14], dtype=torch.int32)}\n",
      "492110\n",
      "{'image_id': 492284, 'boxes': tensor([[359, 158, 454, 283]], dtype=torch.int32), 'scores': tensor([0.2776]), 'objectness_scores': tensor([0.3460]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "492284\n",
      "{'image_id': 492362, 'boxes': tensor([[153, 498, 186, 555],\n",
      "        [277, 405, 302, 439],\n",
      "        [321, 417, 355, 443],\n",
      "        [ 83, 504, 316, 603],\n",
      "        [ 20, 379,  44, 407],\n",
      "        [  0, 183,  17, 217],\n",
      "        [ 40, 180,  56, 215],\n",
      "        [ 27, 181,  44, 216],\n",
      "        [ 37, 372,  56, 403],\n",
      "        [ 13, 180,  31, 218],\n",
      "        [208, 487, 252, 538]], dtype=torch.int32), 'scores': tensor([0.3991, 0.5092, 0.7669, 0.8511, 0.2535, 0.2097, 0.2203, 0.1731, 0.5394,\n",
      "        0.2339, 0.5691]), 'objectness_scores': tensor([0.2328, 0.2382, 0.2461, 0.5170, 0.2818, 0.3340, 0.3022, 0.3182, 0.2074,\n",
      "        0.3406, 0.2668]), 'labels': tensor([ 9,  7,  7,  9,  8, 11, 11, 11,  7, 11,  9], dtype=torch.int32)}\n",
      "492362\n",
      "{'image_id': 492758, 'boxes': tensor([[218, 238, 227, 250],\n",
      "        [429, 190, 523, 298],\n",
      "        [ 48, 195, 192, 321],\n",
      "        [242, 134, 285, 209],\n",
      "        [383, 305, 578, 382],\n",
      "        [  3, 128,  88, 259],\n",
      "        [252, 199, 388, 295],\n",
      "        [400, 130, 440, 215],\n",
      "        [386, 342, 642, 426],\n",
      "        [196, 276, 263, 333]], dtype=torch.int32), 'scores': tensor([0.2572, 0.7124, 0.9687, 0.9816, 0.2486, 0.3332, 0.2169, 0.3322, 0.3860,\n",
      "        0.9814]), 'objectness_scores': tensor([0.4558, 0.2209, 0.3089, 0.2227, 0.2828, 0.2618, 0.2140, 0.2203, 0.2425,\n",
      "        0.2691]), 'labels': tensor([11, 13, 13,  6, 15,  6, 13,  6, 13, 12], dtype=torch.int32)}\n",
      "492758\n",
      "{'image_id': 492878, 'boxes': tensor([[246, 274, 268, 298],\n",
      "        [341, 133, 496, 304],\n",
      "        [ 23, 160, 161, 375],\n",
      "        [ 54,  80, 181, 289],\n",
      "        [227, 149, 295, 247],\n",
      "        [ 11, 526, 118, 629],\n",
      "        [189, 243, 289, 394],\n",
      "        [177, 103, 228, 130],\n",
      "        [  9,  38, 634, 315],\n",
      "        [240,  82, 605, 262]], dtype=torch.int32), 'scores': tensor([0.1935, 0.2753, 0.2410, 0.5196, 0.4329, 0.4961, 0.3703, 0.1946, 0.7164,\n",
      "        0.8132]), 'objectness_scores': tensor([0.2250, 0.2880, 0.3899, 0.3632, 0.3013, 0.2508, 0.4503, 0.3102, 0.2118,\n",
      "        0.3172]), 'labels': tensor([11, 16, 10,  7, 10,  0, 16,  8, 15, 15], dtype=torch.int32)}\n",
      "492878\n",
      "{'image_id': 492905, 'boxes': tensor([[326,  92, 347, 129],\n",
      "        [ 65, 158, 121, 252],\n",
      "        [184,  85, 198, 118],\n",
      "        [181, 123, 280, 145],\n",
      "        [ 87, 109, 431, 259]], dtype=torch.int32), 'scores': tensor([0.3489, 0.1829, 0.3995, 0.5097, 0.7375]), 'objectness_scores': tensor([0.4072, 0.4273, 0.4744, 0.4840, 0.3625]), 'labels': tensor([ 7, 14, 11, 11, 14], dtype=torch.int32)}\n",
      "492905\n",
      "{'image_id': 492968, 'boxes': tensor([[121,  44, 171,  89],\n",
      "        [301, 283, 346, 328],\n",
      "        [108,  80, 243, 258],\n",
      "        [120, 247, 143, 279],\n",
      "        [119,  65, 160,  88],\n",
      "        [184, 220, 215, 253]], dtype=torch.int32), 'scores': tensor([0.9155, 0.7078, 0.9323, 0.2218, 0.2769, 0.3594]), 'objectness_scores': tensor([0.4933, 0.2136, 0.2321, 0.5517, 0.6064, 0.4673]), 'labels': tensor([ 8, 14,  8,  2, 11,  8], dtype=torch.int32)}\n",
      "492968\n",
      "{'image_id': 492992, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "492992\n",
      "{'image_id': 493286, 'boxes': tensor([[  4,  14, 637, 218],\n",
      "        [550, 150, 639, 194],\n",
      "        [357,  52, 423, 204],\n",
      "        [499, 169, 558, 185],\n",
      "        [594, 157, 640, 194],\n",
      "        [460,  80, 505, 210],\n",
      "        [  2, 138, 190, 207],\n",
      "        [522, 168, 568, 185],\n",
      "        [  0,  58, 204, 207]], dtype=torch.int32), 'scores': tensor([0.9753, 0.9798, 0.8118, 0.2258, 0.9875, 0.2668, 0.5096, 0.1509, 0.5636]), 'objectness_scores': tensor([0.4485, 0.2426, 0.4475, 0.2276, 0.3088, 0.3267, 0.3155, 0.2097, 0.2344]), 'labels': tensor([ 0,  0,  0,  0,  0,  8,  0, 11,  0], dtype=torch.int32)}\n",
      "493286\n",
      "{'image_id': 493772, 'boxes': tensor([[272, 262, 343, 291]], dtype=torch.int32), 'scores': tensor([0.4800]), 'objectness_scores': tensor([0.6247]), 'labels': tensor([6], dtype=torch.int32)}\n",
      "493772\n",
      "{'image_id': 494188, 'boxes': tensor([[431, 210, 461, 266],\n",
      "        [361, 221, 388, 275]], dtype=torch.int32), 'scores': tensor([0.4042, 0.5337]), 'objectness_scores': tensor([0.3123, 0.2940]), 'labels': tensor([7, 7], dtype=torch.int32)}\n",
      "494188\n",
      "{'image_id': 494427, 'boxes': tensor([[ 73, 319, 437, 425],\n",
      "        [  3,   6, 480, 635]], dtype=torch.int32), 'scores': tensor([0.9995, 0.9467]), 'objectness_scores': tensor([0.3230, 0.2417]), 'labels': tensor([14, 14], dtype=torch.int32)}\n",
      "494427\n",
      "{'image_id': 494634, 'boxes': tensor([[169,  78, 197, 110],\n",
      "        [  0, 111, 481, 475],\n",
      "        [603, 232, 617, 253]], dtype=torch.int32), 'scores': tensor([0.2289, 0.8413, 0.2513]), 'objectness_scores': tensor([0.2484, 0.4885, 0.2828]), 'labels': tensor([11,  2, 11], dtype=torch.int32)}\n",
      "494634\n",
      "{'image_id': 494869, 'boxes': tensor([[ 85, 218, 171, 244],\n",
      "        [184, 305, 286, 514],\n",
      "        [  0, 418, 151, 641],\n",
      "        [368, 178, 411, 255]], dtype=torch.int32), 'scores': tensor([0.1919, 0.7348, 0.9791, 0.4088]), 'objectness_scores': tensor([0.2092, 0.3349, 0.3249, 0.2447]), 'labels': tensor([14,  7,  3,  8], dtype=torch.int32)}\n",
      "494869\n",
      "{'image_id': 494913, 'boxes': tensor([[346, 113, 369, 143],\n",
      "        [153, 234, 192, 274],\n",
      "        [  2, 282, 284, 427],\n",
      "        [111, 280, 142, 306],\n",
      "        [389, 259, 516, 395],\n",
      "        [480, 236, 637, 429],\n",
      "        [ 76, 296, 140, 339],\n",
      "        [184, 189, 221, 228],\n",
      "        [ 74, 297, 189, 426],\n",
      "        [ 52, 115,  75, 147],\n",
      "        [  1, 310, 115, 428],\n",
      "        [ 84, 267, 115, 296],\n",
      "        [ 56, 272,  84, 301],\n",
      "        [146, 101, 168, 147],\n",
      "        [ 55, 201, 108, 226],\n",
      "        [459, 266, 475, 292],\n",
      "        [536, 317, 639, 419]], dtype=torch.int32), 'scores': tensor([0.3203, 0.4103, 0.9556, 0.2070, 0.4788, 0.8961, 0.2616, 0.2206, 0.9667,\n",
      "        0.2295, 0.8352, 0.1796, 0.2254, 0.6052, 0.3623, 0.1774, 0.8334]), 'objectness_scores': tensor([0.2702, 0.2673, 0.3396, 0.3871, 0.3444, 0.3561, 0.2027, 0.2539, 0.2744,\n",
      "        0.2478, 0.2473, 0.3636, 0.3524, 0.4650, 0.2251, 0.2013, 0.2588]), 'labels': tensor([11, 14, 13, 11,  8, 13,  8, 11, 13,  3, 13, 11, 11,  7, 11, 11, 13],\n",
      "       dtype=torch.int32)}\n",
      "494913\n",
      "{'image_id': 495054, 'boxes': tensor([[ 86, 133, 166, 209],\n",
      "        [301, 248, 359, 280],\n",
      "        [376, 218, 498, 232],\n",
      "        [ 27, 131, 605, 286],\n",
      "        [457, 274, 461, 281],\n",
      "        [357, 280, 361, 286],\n",
      "        [462, 275, 466, 281],\n",
      "        [169, 280, 174, 286],\n",
      "        [281, 280, 285, 287],\n",
      "        [198, 237, 253, 268]], dtype=torch.int32), 'scores': tensor([0.9670, 0.4811, 0.3190, 0.9601, 0.2353, 0.2601, 0.2250, 0.3158, 0.1927,\n",
      "        0.3778]), 'objectness_scores': tensor([0.5239, 0.3307, 0.2586, 0.5652, 0.2209, 0.4929, 0.3467, 0.4331, 0.4883,\n",
      "        0.3378]), 'labels': tensor([ 0, 11, 14,  0, 11, 11, 11, 11, 11,  9], dtype=torch.int32)}\n",
      "495054\n",
      "{'image_id': 495732, 'boxes': tensor([[102,   0, 204,  57],\n",
      "        [120, 356, 309, 490],\n",
      "        [  0, 307, 134, 612],\n",
      "        [215, 320, 348, 534],\n",
      "        [364, 397, 376, 411]], dtype=torch.int32), 'scores': tensor([0.4796, 0.5978, 0.4219, 0.4443, 0.3005]), 'objectness_scores': tensor([0.2440, 0.3505, 0.2422, 0.2293, 0.2468]), 'labels': tensor([10, 13,  7,  7, 14], dtype=torch.int32)}\n",
      "495732\n",
      "{'image_id': 496571, 'boxes': tensor([[258, 182, 305, 245],\n",
      "        [245,  98, 271, 117],\n",
      "        [184, 177, 204, 197],\n",
      "        [104, 261, 359, 352],\n",
      "        [186, 426, 237, 478],\n",
      "        [249,  93, 272, 108],\n",
      "        [173, 406, 193, 429],\n",
      "        [147, 146, 258, 231],\n",
      "        [417, 273, 425, 294],\n",
      "        [193, 101, 220, 173],\n",
      "        [137, 419, 162, 444],\n",
      "        [126, 398, 186, 459],\n",
      "        [129, 432, 152, 455],\n",
      "        [402, 244, 420, 293],\n",
      "        [360, 327, 420, 376],\n",
      "        [382, 242, 426, 295],\n",
      "        [174, 157, 202, 182],\n",
      "        [394, 250, 409, 292],\n",
      "        [215, 444, 233, 464],\n",
      "        [273, 359, 289, 491],\n",
      "        [159, 428, 179, 445],\n",
      "        [127, 368, 261, 500],\n",
      "        [195, 149, 261, 195],\n",
      "        [179, 405, 249, 434],\n",
      "        [161, 411, 177, 430],\n",
      "        [293, 359, 359, 420],\n",
      "        [168, 409, 260, 496],\n",
      "        [144, 444, 183, 480],\n",
      "        [140, 400, 162, 421],\n",
      "        [ -3, 117, 417, 434],\n",
      "        [385, 252, 399, 288],\n",
      "        [118, 202, 180, 266]], dtype=torch.int32), 'scores': tensor([0.9798, 0.5407, 0.4099, 0.1429, 0.3653, 0.2916, 0.2733, 0.2547, 0.1704,\n",
      "        0.4590, 0.2480, 0.3345, 0.3501, 0.2748, 0.8163, 0.3079, 0.4760, 0.2614,\n",
      "        0.2674, 0.8408, 0.2930, 0.2725, 0.1792, 0.2896, 0.2613, 0.9742, 0.5029,\n",
      "        0.3994, 0.1985, 0.4222, 0.2948, 0.9835]), 'objectness_scores': tensor([0.3483, 0.2571, 0.2549, 0.2856, 0.4850, 0.2544, 0.2673, 0.2038, 0.2053,\n",
      "        0.2294, 0.2606, 0.2176, 0.2404, 0.3747, 0.2935, 0.2148, 0.3978, 0.3863,\n",
      "        0.2273, 0.4168, 0.2534, 0.2293, 0.3656, 0.2303, 0.2387, 0.2697, 0.3380,\n",
      "        0.5361, 0.2375, 0.2973, 0.3588, 0.2941]), 'labels': tensor([10,  7,  3, 13, 12,  7, 11, 11, 11, 11, 10, 12, 12, 11, 10,  7, 11, 11,\n",
      "         4, 11, 11, 12,  7, 11, 11, 10, 11, 12, 11, 11, 11, 10],\n",
      "       dtype=torch.int32)}\n",
      "496571\n",
      "{'image_id': 496854, 'boxes': tensor([[436, 157, 570, 301],\n",
      "        [277, 168, 405, 206],\n",
      "        [122, 176, 163, 194],\n",
      "        [318, 312, 362, 358],\n",
      "        [340, 224, 368, 240],\n",
      "        [176,   0, 431, 188],\n",
      "        [472, 178, 640, 482]], dtype=torch.int32), 'scores': tensor([0.3803, 0.2380, 0.1916, 0.8424, 0.9420, 0.9983, 0.3220]), 'objectness_scores': tensor([0.2152, 0.2013, 0.2054, 0.2316, 0.4754, 0.3150, 0.2486]), 'labels': tensor([ 6,  7,  7, 12,  7,  6,  6], dtype=torch.int32)}\n",
      "496854\n",
      "{'image_id': 496954, 'boxes': tensor([[169, 190, 417, 419],\n",
      "        [169, 193, 348, 319],\n",
      "        [  3,   0, 262, 134],\n",
      "        [  0,   0, 631, 481],\n",
      "        [  0,   1, 395, 158],\n",
      "        [ 38, 153, 507, 480],\n",
      "        [  4,   0, 375, 132]], dtype=torch.int32), 'scores': tensor([0.9998, 0.9993, 0.9935, 0.9969, 0.9968, 0.9997, 0.9966]), 'objectness_scores': tensor([0.5977, 0.2123, 0.5297, 0.4384, 0.4018, 0.3696, 0.3289]), 'labels': tensor([12, 12, 12, 12, 12, 12, 12], dtype=torch.int32)}\n",
      "496954\n",
      "{'image_id': 497568, 'boxes': tensor([[ 80,  76, 147, 198],\n",
      "        [  0, 184,  10, 199],\n",
      "        [ 31, 296,  68, 356],\n",
      "        [114, 283, 211, 352],\n",
      "        [ 62, 282,  70, 290],\n",
      "        [ -1,  76, 632, 392]], dtype=torch.int32), 'scores': tensor([0.3480, 0.2246, 0.4379, 0.9814, 0.1701, 0.9777]), 'objectness_scores': tensor([0.3845, 0.2109, 0.5033, 0.3605, 0.2132, 0.4755]), 'labels': tensor([ 7,  0,  9,  0, 11,  0], dtype=torch.int32)}\n",
      "497568\n",
      "{'image_id': 497628, 'boxes': tensor([[399, 272, 429, 325],\n",
      "        [373, 438, 480, 631],\n",
      "        [140, 516, 340, 638],\n",
      "        [  1, 443, 112, 612],\n",
      "        [ 62, 204,  97, 238],\n",
      "        [125, 276, 377, 330],\n",
      "        [ 75, 233,  92, 282],\n",
      "        [ 31, 278, 106, 385],\n",
      "        [409, 173, 420, 215],\n",
      "        [395, 322, 445, 383],\n",
      "        [ 49, 112,  94, 191]], dtype=torch.int32), 'scores': tensor([0.1770, 0.3021, 0.4130, 0.5960, 0.2455, 0.5179, 0.4749, 0.6924, 0.4480,\n",
      "        0.2495, 0.1638]), 'objectness_scores': tensor([0.2759, 0.5014, 0.5271, 0.5727, 0.2430, 0.2456, 0.2539, 0.2796, 0.2286,\n",
      "        0.3959, 0.2807]), 'labels': tensor([ 2,  6, 13, 13,  3,  2,  7, 10, 11, 10, 10], dtype=torch.int32)}\n",
      "497628\n",
      "{'image_id': 497867, 'boxes': tensor([[169,  34, 341, 101],\n",
      "        [ 65,  63, 581, 329]], dtype=torch.int32), 'scores': tensor([0.5441, 0.9992]), 'objectness_scores': tensor([0.2496, 0.5808]), 'labels': tensor([14,  1], dtype=torch.int32)}\n",
      "497867\n",
      "{'image_id': 498286, 'boxes': tensor([[ -3, 344, 258, 477]], dtype=torch.int32), 'scores': tensor([0.1983]), 'objectness_scores': tensor([0.2013]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "498286\n",
      "{'image_id': 499313, 'boxes': tensor([[  2,   4, 632, 480],\n",
      "        [451,   0, 580,  54],\n",
      "        [399,   0, 503,  76],\n",
      "        [496,   0, 584,  53],\n",
      "        [ 37,  53, 624, 444],\n",
      "        [203,   0, 486,  28],\n",
      "        [519,   0, 641, 104],\n",
      "        [466,   5, 640, 177],\n",
      "        [559, 336, 638, 476]], dtype=torch.int32), 'scores': tensor([0.4092, 0.3434, 0.3859, 0.2816, 0.5333, 0.2256, 0.1682, 0.4166, 0.2612]), 'objectness_scores': tensor([0.4968, 0.2168, 0.5433, 0.2494, 0.5132, 0.2677, 0.2643, 0.2017, 0.3170]), 'labels': tensor([12, 10, 12,  2, 12, 11,  8, 11, 11], dtype=torch.int32)}\n",
      "499313\n",
      "{'image_id': 499775, 'boxes': tensor([[ 70, 186,  98, 199],\n",
      "        [193, 222, 357, 389],\n",
      "        [ 69, 186,  99, 228],\n",
      "        [ 69, 301,  94, 357]], dtype=torch.int32), 'scores': tensor([0.3412, 0.9940, 0.3733, 0.3951]), 'objectness_scores': tensor([0.2043, 0.5814, 0.2351, 0.2420]), 'labels': tensor([11,  1,  7, 11], dtype=torch.int32)}\n",
      "499775\n",
      "{'image_id': 500211, 'boxes': tensor([[320, 228, 395, 474],\n",
      "        [452, 109, 490, 146],\n",
      "        [452, 277, 484, 395],\n",
      "        [127, 278, 160, 393],\n",
      "        [391, 237, 477, 455],\n",
      "        [263, 287, 300, 390],\n",
      "        [561, 243, 607, 366],\n",
      "        [ 52, 288,  85, 355],\n",
      "        [186, 286, 206, 357],\n",
      "        [ 88, 298, 114, 387],\n",
      "        [316, 265, 342, 402],\n",
      "        [500, 260, 576, 459],\n",
      "        [559, 241, 606, 436],\n",
      "        [205, 275, 242, 400],\n",
      "        [  0, 295,  16, 380]], dtype=torch.int32), 'scores': tensor([0.5999, 0.1564, 0.4117, 0.4136, 0.2061, 0.2657, 0.3598, 0.4416, 0.5527,\n",
      "        0.3493, 0.3252, 0.4830, 0.4098, 0.3657, 0.3931]), 'objectness_scores': tensor([0.5283, 0.2910, 0.5607, 0.5432, 0.5194, 0.5528, 0.3911, 0.5328, 0.4134,\n",
      "        0.5118, 0.5368, 0.5261, 0.4064, 0.5238, 0.4295]), 'labels': tensor([ 7,  1,  7,  7, 14,  6, 14,  7, 11,  7,  7,  6,  7,  7, 11],\n",
      "       dtype=torch.int32)}\n",
      "500211\n",
      "{'image_id': 500270, 'boxes': tensor([[143, 293, 173, 309],\n",
      "        [ 85, 209, 105, 219],\n",
      "        [ 41, 181,  48, 185],\n",
      "        [107, 301, 198, 325]], dtype=torch.int32), 'scores': tensor([0.3444, 0.3696, 0.2168, 0.2374]), 'objectness_scores': tensor([0.2217, 0.2471, 0.2100, 0.6298]), 'labels': tensor([11, 11, 14,  9], dtype=torch.int32)}\n",
      "500270\n",
      "{'image_id': 500464, 'boxes': tensor([[  2, 263,  32, 278],\n",
      "        [349,   1, 429, 185],\n",
      "        [  0, 263,  45, 502],\n",
      "        [247, 332, 264, 374],\n",
      "        [228, 113, 260, 132],\n",
      "        [282, 313, 309, 380],\n",
      "        [  0, 260,  40, 284],\n",
      "        [164,  62, 196, 119],\n",
      "        [ 62, 225,  97, 257],\n",
      "        [261, 315, 278, 372],\n",
      "        [139,  49, 166,  79],\n",
      "        [  4, 226, 209, 355],\n",
      "        [139,  47, 170, 116]], dtype=torch.int32), 'scores': tensor([0.5178, 0.1877, 0.3220, 0.3742, 0.2630, 0.8055, 0.2167, 0.2538, 0.9466,\n",
      "        0.3182, 0.2615, 0.9987, 0.3198]), 'objectness_scores': tensor([0.2064, 0.2435, 0.2547, 0.2289, 0.2430, 0.2567, 0.2014, 0.2750, 0.3624,\n",
      "        0.2183, 0.2004, 0.4525, 0.2439]), 'labels': tensor([11, 14,  7, 11, 11,  7,  9, 11, 15, 11, 11, 15, 11], dtype=torch.int32)}\n",
      "500464\n",
      "{'image_id': 500716, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "500716\n",
      "{'image_id': 501523, 'boxes': tensor([[142, 299, 204, 363],\n",
      "        [280,   0, 344,  35],\n",
      "        [459, 321, 560, 457],\n",
      "        [215, 117, 484, 399],\n",
      "        [177,  79, 547, 397],\n",
      "        [429, 352, 594, 479],\n",
      "        [347,  22, 473, 116]], dtype=torch.int32), 'scores': tensor([0.4042, 0.4267, 0.2599, 0.6519, 0.9317, 0.5322, 0.3973]), 'objectness_scores': tensor([0.2266, 0.2272, 0.2164, 0.5001, 0.2184, 0.2559, 0.6214]), 'labels': tensor([ 9, 10,  8,  2, 15,  8,  9], dtype=torch.int32)}\n",
      "501523\n",
      "{'image_id': 502347, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "502347\n",
      "{'image_id': 502737, 'boxes': tensor([[ 18, 103, 178, 211],\n",
      "        [  8,  36, 184, 334],\n",
      "        [ 46, 356,  73, 393]], dtype=torch.int32), 'scores': tensor([0.9099, 0.8336, 0.2535]), 'objectness_scores': tensor([0.2004, 0.4698, 0.2488]), 'labels': tensor([10, 10, 11], dtype=torch.int32)}\n",
      "502737\n",
      "{'image_id': 503855, 'boxes': tensor([[ 64, 164,  84, 193],\n",
      "        [148, 119, 158, 125],\n",
      "        [520,  53, 544, 169],\n",
      "        [  0, 193,  26, 227],\n",
      "        [110, 132, 117, 139]], dtype=torch.int32), 'scores': tensor([0.2952, 0.1565, 0.3244, 0.2196, 0.2101]), 'objectness_scores': tensor([0.3865, 0.2474, 0.2021, 0.2733, 0.2797]), 'labels': tensor([ 7, 14,  7,  7,  4], dtype=torch.int32)}\n",
      "503855\n",
      "{'image_id': 504000, 'boxes': tensor([[411,  45, 468, 114],\n",
      "        [483,  89, 581, 122],\n",
      "        [476,  90, 514, 116],\n",
      "        [  0,  48, 105, 139],\n",
      "        [321, 134, 626, 218],\n",
      "        [573, 123, 580, 128],\n",
      "        [ 81,  42, 491, 199],\n",
      "        [ 70, 158, 150, 243],\n",
      "        [ 73, 158, 125, 242]], dtype=torch.int32), 'scores': tensor([0.9342, 0.3521, 0.4874, 0.6347, 0.6841, 0.1499, 0.9859, 0.3981, 0.7613]), 'objectness_scores': tensor([0.2927, 0.2038, 0.2136, 0.3954, 0.2538, 0.2369, 0.3766, 0.2413, 0.2462]), 'labels': tensor([ 0,  0,  6,  0,  0, 14,  0,  8, 14], dtype=torch.int32)}\n",
      "504000\n",
      "{'image_id': 504711, 'boxes': tensor([[  5,   1, 639, 481],\n",
      "        [112,   4, 170,  75]], dtype=torch.int32), 'scores': tensor([0.9994, 0.3625]), 'objectness_scores': tensor([0.3636, 0.2506]), 'labels': tensor([12, 12], dtype=torch.int32)}\n",
      "504711\n",
      "{'image_id': 507081, 'boxes': tensor([[ 72,  10, 270, 451],\n",
      "        [ 43, 367, 111, 544],\n",
      "        [317,  38, 636, 225]], dtype=torch.int32), 'scores': tensor([0.6673, 0.1433, 0.2050]), 'objectness_scores': tensor([0.2044, 0.3985, 0.2865]), 'labels': tensor([ 1,  7, 14], dtype=torch.int32)}\n",
      "507081\n",
      "{'image_id': 507575, 'boxes': tensor([[486, 163, 526, 258],\n",
      "        [525, 326, 640, 418],\n",
      "        [240, 394, 308, 438],\n",
      "        [431, 184, 463, 245],\n",
      "        [460, 179, 492, 246],\n",
      "        [ 19, 258, 587, 479],\n",
      "        [106, 260, 151, 295],\n",
      "        [426,  80, 511, 141],\n",
      "        [144, 300, 210, 337],\n",
      "        [ 97, 181, 279, 269]], dtype=torch.int32), 'scores': tensor([0.2369, 0.4380, 0.3590, 0.2665, 0.4741, 0.9904, 0.2836, 0.3637, 0.3602,\n",
      "        0.3335]), 'objectness_scores': tensor([0.2215, 0.2093, 0.2065, 0.2160, 0.2087, 0.2170, 0.2126, 0.2195, 0.3578,\n",
      "        0.3601]), 'labels': tensor([ 8,  8, 14, 11,  8, 14,  8,  9,  8, 12], dtype=torch.int32)}\n",
      "507575\n",
      "{'image_id': 507797, 'boxes': tensor([[163, 219, 169, 227],\n",
      "        [168, 346, 202, 358],\n",
      "        [532, 177, 552, 189]], dtype=torch.int32), 'scores': tensor([0.1748, 0.2545, 0.2973]), 'objectness_scores': tensor([0.2471, 0.2378, 0.2019]), 'labels': tensor([11, 11, 11], dtype=torch.int32)}\n",
      "507797\n",
      "{'image_id': 507893, 'boxes': tensor([[299, 399, 390, 582],\n",
      "        [ 31, 462, 308, 629],\n",
      "        [296, 392, 388, 417],\n",
      "        [  1, 246,  23, 301],\n",
      "        [294, 115, 340, 152],\n",
      "        [299, 398, 389, 465],\n",
      "        [324, 368, 350, 396],\n",
      "        [277, 289, 327, 305],\n",
      "        [  7,   3, 407, 633]], dtype=torch.int32), 'scores': tensor([0.2274, 0.7403, 0.4614, 0.2684, 0.5964, 0.8608, 0.2439, 0.2414, 0.9335]), 'objectness_scores': tensor([0.4415, 0.6603, 0.2204, 0.3766, 0.3233, 0.2532, 0.4494, 0.4322, 0.2412]), 'labels': tensor([15, 15,  9,  3, 15, 15, 11,  0, 15], dtype=torch.int32)}\n",
      "507893\n",
      "{'image_id': 508370, 'boxes': tensor([[205, 102, 213, 131],\n",
      "        [217, 513, 321, 590],\n",
      "        [121, 563, 167, 596],\n",
      "        [225, 104, 421, 288],\n",
      "        [199, 128, 220, 160]], dtype=torch.int32), 'scores': tensor([0.6227, 0.1699, 0.4145, 0.3867, 0.6965]), 'objectness_scores': tensor([0.2011, 0.3813, 0.2365, 0.2417, 0.2403]), 'labels': tensor([11,  9,  8,  9, 10], dtype=torch.int32)}\n",
      "508370\n",
      "{'image_id': 508730, 'boxes': tensor([[588, 237, 616, 280],\n",
      "        [511, 223, 551, 248]], dtype=torch.int32), 'scores': tensor([0.1687, 0.6677]), 'objectness_scores': tensor([0.2435, 0.2729]), 'labels': tensor([3, 2], dtype=torch.int32)}\n",
      "508730\n",
      "{'image_id': 509403, 'boxes': tensor([[371, 196, 461, 320],\n",
      "        [176, 224, 184, 233],\n",
      "        [531, 267, 552, 292],\n",
      "        [511, 212, 588, 346],\n",
      "        [182, 180, 208, 208],\n",
      "        [364, 357, 401, 372],\n",
      "        [200, 225, 208, 230]], dtype=torch.int32), 'scores': tensor([0.4458, 0.2211, 0.1799, 0.9747, 0.3652, 0.2202, 0.1410]), 'objectness_scores': tensor([0.2484, 0.3274, 0.3497, 0.4649, 0.2202, 0.2957, 0.2402]), 'labels': tensor([ 7, 14,  4,  3,  7,  4, 11], dtype=torch.int32)}\n",
      "509403\n",
      "{'image_id': 509451, 'boxes': tensor([[141, 343, 169, 374],\n",
      "        [130, 257, 150, 278],\n",
      "        [251, 224, 257, 230],\n",
      "        [155, 145, 190, 183],\n",
      "        [430, 128, 470, 271],\n",
      "        [345, 338, 375, 374],\n",
      "        [139,   0, 176,  18],\n",
      "        [146,  61, 192,  77],\n",
      "        [ 65,   0, 102,  17],\n",
      "        [298,  13, 389,  59],\n",
      "        [154, 145, 191, 205],\n",
      "        [270,  69, 312,  88],\n",
      "        [282, 172, 310, 294],\n",
      "        [331, 127, 352, 176],\n",
      "        [396,  36, 481, 121],\n",
      "        [ 88,  34, 116, 104]], dtype=torch.int32), 'scores': tensor([0.3901, 0.1857, 0.1567, 0.7354, 0.8124, 0.2928, 0.2086, 0.1464, 0.1634,\n",
      "        0.6349, 0.7410, 0.2728, 0.3864, 0.6372, 0.1989, 0.8144]), 'objectness_scores': tensor([0.2096, 0.2760, 0.2781, 0.2246, 0.5066, 0.2528, 0.2652, 0.3190, 0.2572,\n",
      "        0.2932, 0.4340, 0.2438, 0.3718, 0.2114, 0.3204, 0.3434]), 'labels': tensor([13, 11, 11,  7,  7, 11,  7, 11, 14,  7,  7, 11, 10, 11,  8,  7],\n",
      "       dtype=torch.int32)}\n",
      "509451\n",
      "{'image_id': 509824, 'boxes': tensor([[403, 339, 520, 425],\n",
      "        [ 92, 529, 572, 626],\n",
      "        [494, 146, 512, 172],\n",
      "        [ 19,  83,  78, 139],\n",
      "        [464, 304, 594, 423],\n",
      "        [ 18,  85,  78, 352],\n",
      "        [ 17, 289, 613, 562],\n",
      "        [ 64, 296, 206, 396],\n",
      "        [323, 300, 608, 537],\n",
      "        [ 21, 296, 324, 544],\n",
      "        [ 68, 350, 217, 438]], dtype=torch.int32), 'scores': tensor([0.7467, 0.3664, 0.4101, 0.3045, 0.9428, 0.2561, 0.9994, 0.4559, 0.9994,\n",
      "        0.9994, 0.3096]), 'objectness_scores': tensor([0.3560, 0.3551, 0.2659, 0.2846, 0.4032, 0.3077, 0.5197, 0.4201, 0.2385,\n",
      "        0.2123, 0.3984]), 'labels': tensor([13, 15, 11, 14, 13,  7, 13, 13, 13, 13,  6], dtype=torch.int32)}\n",
      "509824\n",
      "{'image_id': 510329, 'boxes': tensor([[ 67, 315, 286, 478],\n",
      "        [476, 340, 495, 352],\n",
      "        [456, 418, 474, 449],\n",
      "        [405, 418, 527, 449]], dtype=torch.int32), 'scores': tensor([0.3117, 0.2432, 0.2908, 0.2769]), 'objectness_scores': tensor([0.2565, 0.2787, 0.2115, 0.3392]), 'labels': tensor([ 5, 14,  2, 11], dtype=torch.int32)}\n",
      "510329\n",
      "{'image_id': 512476, 'boxes': tensor([[482, 186, 640, 356],\n",
      "        [396, 138, 477, 300],\n",
      "        [263, 105, 376, 212],\n",
      "        [140, 253, 396, 319],\n",
      "        [321, 302, 416, 332],\n",
      "        [  0,  -1, 232, 302],\n",
      "        [ 44, 200, 116, 319],\n",
      "        [ 99, 239, 206, 317],\n",
      "        [ 92, 309, 331, 392]], dtype=torch.int32), 'scores': tensor([0.1962, 0.2875, 0.3481, 0.2143, 0.1840, 0.3197, 0.2350, 0.3080, 0.2819]), 'objectness_scores': tensor([0.3007, 0.2426, 0.3206, 0.5403, 0.2356, 0.2370, 0.4062, 0.5275, 0.6199]), 'labels': tensor([ 9, 11,  7,  8, 12,  6,  9,  9, 10], dtype=torch.int32)}\n",
      "512476\n",
      "{'image_id': 512564, 'boxes': tensor([[ 60, 297,  75, 312],\n",
      "        [ 36, 288,  44, 308],\n",
      "        [ 48, 212,  58, 238],\n",
      "        [383, 275, 456, 346],\n",
      "        [  7, 172,  96, 381],\n",
      "        [496, 250, 506, 268],\n",
      "        [293, 396, 302, 419],\n",
      "        [ 60, 283,  75, 298],\n",
      "        [416, 211, 434, 230],\n",
      "        [534, 280, 543, 301]], dtype=torch.int32), 'scores': tensor([0.2037, 0.3708, 0.2957, 0.9973, 0.4684, 0.7001, 0.1966, 0.2478, 0.2468,\n",
      "        0.5242]), 'objectness_scores': tensor([0.2570, 0.2058, 0.2260, 0.4869, 0.2468, 0.2571, 0.2178, 0.2658, 0.2250,\n",
      "        0.2110]), 'labels': tensor([ 0, 11, 11,  1,  1,  7, 14,  8,  8, 14], dtype=torch.int32)}\n",
      "512564\n",
      "{'image_id': 512657, 'boxes': tensor([[311, 317, 626, 427]], dtype=torch.int32), 'scores': tensor([0.2808]), 'objectness_scores': tensor([0.2794]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "512657\n",
      "{'image_id': 512836, 'boxes': tensor([[107,  44, 305, 253],\n",
      "        [ 62, 276, 269, 415],\n",
      "        [ 64,  77,  99, 106],\n",
      "        [ 65, 279, 182, 415],\n",
      "        [283, 320, 396, 420],\n",
      "        [ 77, 266,  95, 289],\n",
      "        [142, 159, 287, 384],\n",
      "        [154, 459, 196, 525],\n",
      "        [274, 289, 449, 420],\n",
      "        [198, 464, 244, 529]], dtype=torch.int32), 'scores': tensor([0.9516, 0.9015, 0.2495, 0.9397, 0.9168, 0.2306, 0.6702, 0.6243, 0.9668,\n",
      "        0.6271]), 'objectness_scores': tensor([0.6571, 0.2025, 0.3684, 0.4742, 0.2301, 0.2633, 0.2209, 0.5825, 0.5231,\n",
      "        0.5786]), 'labels': tensor([6, 3, 3, 3, 3, 3, 6, 8, 3, 8], dtype=torch.int32)}\n",
      "512836\n",
      "{'image_id': 513283, 'boxes': tensor([[  0, 246, 151, 312],\n",
      "        [  0, 305, 626, 512],\n",
      "        [ -2, 218, 629, 521],\n",
      "        [251, 163, 378, 407],\n",
      "        [298,  66, 564, 338]], dtype=torch.int32), 'scores': tensor([0.4727, 0.3281, 0.3927, 0.7245, 0.2035]), 'objectness_scores': tensor([0.3091, 0.3014, 0.2244, 0.4870, 0.3147]), 'labels': tensor([11, 12,  4,  4, 16], dtype=torch.int32)}\n",
      "513283\n",
      "{'image_id': 513580, 'boxes': tensor([[128, 112, 504, 326],\n",
      "        [455, 156, 523, 257],\n",
      "        [189, 283, 212, 311]], dtype=torch.int32), 'scores': tensor([0.9889, 0.2780, 0.2502]), 'objectness_scores': tensor([0.5351, 0.3101, 0.3110]), 'labels': tensor([ 0,  6, 16], dtype=torch.int32)}\n",
      "513580\n",
      "{'image_id': 514376, 'boxes': tensor([[ 62,  34,  98,  64],\n",
      "        [157, 205, 180, 211],\n",
      "        [ 37, 225,  73, 298],\n",
      "        [ 38, 226,  68, 259],\n",
      "        [474, 150, 486, 175]], dtype=torch.int32), 'scores': tensor([0.1740, 0.4192, 0.6329, 0.3358, 0.3394]), 'objectness_scores': tensor([0.2197, 0.2173, 0.2203, 0.2149, 0.4376]), 'labels': tensor([11, 14, 14, 14, 14], dtype=torch.int32)}\n",
      "514376\n",
      "{'image_id': 514914, 'boxes': tensor([[150,   0, 280, 135],\n",
      "        [515, 134, 536, 154],\n",
      "        [395, 149, 415, 212],\n",
      "        [  2, 258, 369, 365],\n",
      "        [ 29, 245,  61, 279],\n",
      "        [  0,   2, 626, 369],\n",
      "        [236, 134, 255, 162],\n",
      "        [171, 175, 330, 273],\n",
      "        [ 10,  45, 119, 251],\n",
      "        [168, 176, 255, 222],\n",
      "        [276, 200, 316, 293],\n",
      "        [174, 150, 190, 177],\n",
      "        [253, 150, 266, 158],\n",
      "        [341, 123, 412, 159],\n",
      "        [203, 151, 325, 213],\n",
      "        [293,   2, 450, 279]], dtype=torch.int32), 'scores': tensor([0.2790, 0.1461, 0.3073, 0.7867, 0.2765, 0.9776, 0.2819, 0.9124, 0.8053,\n",
      "        0.3486, 0.5026, 0.4246, 0.2940, 0.1513, 0.9845, 0.4981]), 'objectness_scores': tensor([0.2684, 0.6201, 0.2435, 0.5004, 0.2068, 0.2369, 0.3975, 0.2068, 0.4277,\n",
      "        0.2033, 0.3572, 0.2713, 0.2385, 0.3061, 0.4637, 0.2429]), 'labels': tensor([ 7, 14, 11, 15,  6, 15, 11, 15,  7, 13,  7, 11, 11,  9, 15, 15],\n",
      "       dtype=torch.int32)}\n",
      "514914\n",
      "{'image_id': 515025, 'boxes': tensor([[431, 194, 523, 328],\n",
      "        [235, 193, 503, 399],\n",
      "        [ 33, 273,  70, 313]], dtype=torch.int32), 'scores': tensor([0.6606, 0.9777, 0.9847]), 'objectness_scores': tensor([0.2879, 0.4528, 0.2068]), 'labels': tensor([ 3,  2, 10], dtype=torch.int32)}\n",
      "515025\n",
      "{'image_id': 515077, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "515077\n",
      "{'image_id': 516143, 'boxes': tensor([[ 85, 181, 542, 386],\n",
      "        [347, 244, 376, 271],\n",
      "        [  0,   0, 124,  21],\n",
      "        [389,  89, 527, 157],\n",
      "        [367,  91, 497, 162]], dtype=torch.int32), 'scores': tensor([0.9997, 0.1979, 0.1578, 0.5861, 0.5427]), 'objectness_scores': tensor([0.6106, 0.3317, 0.2024, 0.3367, 0.2024]), 'labels': tensor([ 1, 11, 14,  1,  1], dtype=torch.int32)}\n",
      "516143\n",
      "{'image_id': 516601, 'boxes': tensor([[423, 222, 431, 230],\n",
      "        [486, 226, 490, 229],\n",
      "        [593, 218, 598, 222],\n",
      "        [578, 221, 582, 224],\n",
      "        [493, 220, 499, 225],\n",
      "        [516, 222, 524, 229],\n",
      "        [437, 264, 453, 292],\n",
      "        [ -1,  58, 633, 359]], dtype=torch.int32), 'scores': tensor([0.2516, 0.1790, 0.2714, 0.2791, 0.3627, 0.2329, 0.2077, 0.9958]), 'objectness_scores': tensor([0.3467, 0.2150, 0.2414, 0.2314, 0.2953, 0.2593, 0.3206, 0.2252]), 'labels': tensor([ 0, 11, 11, 11, 11, 14, 11,  8], dtype=torch.int32)}\n",
      "516601\n",
      "{'image_id': 516916, 'boxes': tensor([[348, 365, 443, 425],\n",
      "        [495, 207, 585, 297],\n",
      "        [ 54, 175, 632, 464],\n",
      "        [500, 379, 634, 478],\n",
      "        [224, 206, 379, 265]], dtype=torch.int32), 'scores': tensor([0.1315, 0.6245, 0.5844, 0.8742, 0.9992]), 'objectness_scores': tensor([0.2122, 0.3130, 0.2467, 0.3364, 0.2260]), 'labels': tensor([12, 14, 14, 14, 14], dtype=torch.int32)}\n",
      "516916\n",
      "{'image_id': 517056, 'boxes': tensor([[  4, 252, 632, 479],\n",
      "        [594, 164, 608, 183],\n",
      "        [556, 322, 621, 361],\n",
      "        [532, 167, 641, 269],\n",
      "        [219, 366, 280, 399],\n",
      "        [433, 349, 491, 377],\n",
      "        [155, 155, 210, 173],\n",
      "        [301, 338, 362, 370],\n",
      "        [578, 355, 640, 398],\n",
      "        [152, 224, 183, 247],\n",
      "        [464, 315, 515, 337],\n",
      "        [533, 395, 600, 430],\n",
      "        [ 14, 186,  90, 218],\n",
      "        [183, 407, 293, 438],\n",
      "        [ 84, 347, 530, 478],\n",
      "        [503, 333, 557, 358]], dtype=torch.int32), 'scores': tensor([0.9967, 0.2775, 0.2968, 0.5090, 0.4740, 0.7993, 0.2014, 0.1894, 0.3047,\n",
      "        0.4173, 0.3099, 0.9861, 0.2445, 0.6452, 0.9989, 0.3968]), 'objectness_scores': tensor([0.2099, 0.5063, 0.3022, 0.3139, 0.3184, 0.3512, 0.2822, 0.2695, 0.3337,\n",
      "        0.4923, 0.3659, 0.3768, 0.2899, 0.3357, 0.2429, 0.3709]), 'labels': tensor([12, 11, 12,  7, 12, 12,  7,  7, 14, 11, 11, 12,  0, 11, 12, 11],\n",
      "       dtype=torch.int32)}\n",
      "517056\n",
      "{'image_id': 517832, 'boxes': tensor([[280, 217, 645, 550],\n",
      "        [194, 301, 472, 572],\n",
      "        [370, 391, 395, 419],\n",
      "        [324, 346, 409, 380]], dtype=torch.int32), 'scores': tensor([0.8511, 0.9593, 0.3275, 0.2989]), 'objectness_scores': tensor([0.2113, 0.4809, 0.2735, 0.3779]), 'labels': tensor([ 3,  3, 14, 11], dtype=torch.int32)}\n",
      "517832\n",
      "{'image_id': 519208, 'boxes': tensor([[218,   1, 639, 406],\n",
      "        [387, 139, 391, 144],\n",
      "        [  0,   1, 354, 408],\n",
      "        [  7,   0, 638, 407]], dtype=torch.int32), 'scores': tensor([0.9904, 0.2801, 0.9991, 0.9956]), 'objectness_scores': tensor([0.3075, 0.2237, 0.5640, 0.4533]), 'labels': tensor([ 5, 11,  5,  5], dtype=torch.int32)}\n",
      "519208\n",
      "{'image_id': 519764, 'boxes': tensor([[  5, 157, 110, 310],\n",
      "        [  0,  81, 144, 326],\n",
      "        [110,  40, 148,  89],\n",
      "        [199, 117, 381, 254]], dtype=torch.int32), 'scores': tensor([0.2322, 0.1692, 0.2532, 0.9790]), 'objectness_scores': tensor([0.2715, 0.2272, 0.3206, 0.5233]), 'labels': tensor([7, 1, 7, 2], dtype=torch.int32)}\n",
      "519764\n",
      "{'image_id': 520009, 'boxes': tensor([[106, 283, 115, 307],\n",
      "        [187, 334, 194, 347],\n",
      "        [297,   0, 396, 253],\n",
      "        [267, 182, 302, 252],\n",
      "        [  0, 225,  22, 266],\n",
      "        [225, 380, 242, 411]], dtype=torch.int32), 'scores': tensor([0.1836, 0.1650, 0.3005, 0.2873, 0.3697, 0.3577]), 'objectness_scores': tensor([0.2006, 0.2136, 0.2412, 0.6186, 0.4392, 0.2676]), 'labels': tensor([14, 11,  7, 11, 11,  8], dtype=torch.int32)}\n",
      "520009\n",
      "{'image_id': 520264, 'boxes': tensor([[263, 335, 282, 376],\n",
      "        [ 23, 411, 139, 446],\n",
      "        [349, 224, 387, 242],\n",
      "        [370, 261, 400, 278],\n",
      "        [  1,  10, 219, 285],\n",
      "        [ 57, 449, 107, 480],\n",
      "        [242, 384, 299, 402],\n",
      "        [  1,  43, 106, 271],\n",
      "        [460, 325, 486, 369],\n",
      "        [416, 197, 458, 214]], dtype=torch.int32), 'scores': tensor([0.2042, 0.3868, 0.1629, 0.2647, 0.1880, 0.2511, 0.4109, 0.1535, 0.4660,\n",
      "        0.1704]), 'objectness_scores': tensor([0.3708, 0.2359, 0.2274, 0.4160, 0.2258, 0.3735, 0.2962, 0.2040, 0.4354,\n",
      "        0.2040]), 'labels': tensor([ 9,  9, 11, 11,  7, 11, 11,  8, 11, 11], dtype=torch.int32)}\n",
      "520264\n",
      "{'image_id': 520324, 'boxes': tensor([[158, 217, 352, 277],\n",
      "        [146, 217, 632, 356]], dtype=torch.int32), 'scores': tensor([0.9116, 0.9393]), 'objectness_scores': tensor([0.4065, 0.4984]), 'labels': tensor([0, 0], dtype=torch.int32)}\n",
      "520324\n",
      "{'image_id': 520531, 'boxes': tensor([[ 42, 391, 115, 424],\n",
      "        [ -1, 290, 628, 480],\n",
      "        [  1, 339, 184, 472],\n",
      "        [ 90, 290, 149, 316],\n",
      "        [  0,  86, 141, 323],\n",
      "        [175,   0, 232,  52],\n",
      "        [209,  99, 562, 464]], dtype=torch.int32), 'scores': tensor([0.2550, 0.8871, 0.4240, 0.2685, 0.2613, 0.2096, 0.9787]), 'objectness_scores': tensor([0.3046, 0.2052, 0.2129, 0.2205, 0.2667, 0.3841, 0.4512]), 'labels': tensor([ 8,  2,  7,  8, 13,  4,  2], dtype=torch.int32)}\n",
      "520531\n",
      "{'image_id': 520659, 'boxes': tensor([[110, 184, 245, 270],\n",
      "        [ -1,  56, 631, 385]], dtype=torch.int32), 'scores': tensor([0.4987, 0.6370]), 'objectness_scores': tensor([0.2008, 0.2289]), 'labels': tensor([6, 8], dtype=torch.int32)}\n",
      "520659\n",
      "{'image_id': 520832, 'boxes': tensor([[326, 207, 426, 225],\n",
      "        [319, 429, 359, 445],\n",
      "        [544, 123, 584, 213],\n",
      "        [340, 216, 376, 248],\n",
      "        [533, 120, 571, 214],\n",
      "        [241, 408, 265, 449]], dtype=torch.int32), 'scores': tensor([0.1706, 0.2580, 0.4858, 0.1877, 0.3261, 0.3665]), 'objectness_scores': tensor([0.2008, 0.2354, 0.2508, 0.2342, 0.2298, 0.2802]), 'labels': tensor([11, 11, 11,  7,  7,  2], dtype=torch.int32)}\n",
      "520832\n",
      "{'image_id': 520871, 'boxes': tensor([[ 54, 153, 281, 225],\n",
      "        [  5, 107, 632, 425],\n",
      "        [462,  11, 569, 133],\n",
      "        [  3, 191, 593, 417],\n",
      "        [589,  47, 639, 136],\n",
      "        [621, 273, 639, 353]], dtype=torch.int32), 'scores': tensor([0.3971, 0.3022, 0.8744, 0.4865, 0.1784, 0.2489]), 'objectness_scores': tensor([0.3791, 0.4220, 0.5284, 0.4190, 0.3440, 0.2454]), 'labels': tensor([12, 12, 10, 12,  7, 11], dtype=torch.int32)}\n",
      "520871\n",
      "{'image_id': 520910, 'boxes': tensor([[200, 432, 215, 466],\n",
      "        [190, 213, 206, 227],\n",
      "        [175, 273, 223, 282],\n",
      "        [107,  12, 330, 628],\n",
      "        [111, 176, 121, 271],\n",
      "        [174, 365, 309, 461],\n",
      "        [301, 349, 309, 361],\n",
      "        [249, 390, 259, 398],\n",
      "        [232, 389, 241, 397],\n",
      "        [115, 327, 174, 362],\n",
      "        [116, 301, 130, 309],\n",
      "        [186, 432, 201, 466]], dtype=torch.int32), 'scores': tensor([0.2731, 0.4554, 0.1746, 0.5030, 0.5724, 0.4894, 0.1474, 0.1773, 0.2040,\n",
      "        0.3068, 0.1937, 0.3817]), 'objectness_scores': tensor([0.2455, 0.3620, 0.2625, 0.2150, 0.2121, 0.4973, 0.2034, 0.2836, 0.2688,\n",
      "        0.2948, 0.2691, 0.2290]), 'labels': tensor([ 7,  7, 11,  7, 11, 15, 11, 14, 14, 15, 14,  7], dtype=torch.int32)}\n",
      "520910\n",
      "{'image_id': 521405, 'boxes': tensor([[  0,   4, 390, 426],\n",
      "        [ 69, 496, 195, 639]], dtype=torch.int32), 'scores': tensor([0.3830, 0.8638]), 'objectness_scores': tensor([0.2525, 0.2835]), 'labels': tensor([5, 7], dtype=torch.int32)}\n",
      "521405\n",
      "{'image_id': 521719, 'boxes': tensor([[  3,  -3, 413, 609]], dtype=torch.int32), 'scores': tensor([0.7926]), 'objectness_scores': tensor([0.2381]), 'labels': tensor([6], dtype=torch.int32)}\n",
      "521719\n",
      "{'image_id': 522007, 'boxes': tensor([[412,   1, 638, 221],\n",
      "        [422, 138, 554, 213],\n",
      "        [401, 334, 545, 420],\n",
      "        [202, 366, 215, 385],\n",
      "        [182, 130, 226, 344],\n",
      "        [241, 337, 257, 354],\n",
      "        [218, 364, 235, 383],\n",
      "        [192, 367, 203, 385],\n",
      "        [484, 260, 497, 281],\n",
      "        [230, 365, 248, 382],\n",
      "        [481, 278, 569, 359]], dtype=torch.int32), 'scores': tensor([0.3910, 0.2868, 0.6920, 0.2730, 0.6087, 0.4751, 0.2171, 0.3567, 0.2478,\n",
      "        0.3933, 0.3034]), 'objectness_scores': tensor([0.2297, 0.2108, 0.2723, 0.2193, 0.2138, 0.2012, 0.2052, 0.2002, 0.2022,\n",
      "        0.2139, 0.2017]), 'labels': tensor([15, 14, 15, 11,  7, 11, 11, 11, 11, 11, 12], dtype=torch.int32)}\n",
      "522007\n",
      "{'image_id': 523957, 'boxes': tensor([[178,  80, 215, 110],\n",
      "        [122, 267, 131, 273],\n",
      "        [185, 106, 212, 115],\n",
      "        [ 18, 331,  30, 349],\n",
      "        [344, 313, 377, 370],\n",
      "        [168, 323, 183, 350],\n",
      "        [ 43, 313,  51, 320],\n",
      "        [181, 323, 203, 359],\n",
      "        [215, 336, 266, 361],\n",
      "        [448, 240, 457, 244],\n",
      "        [ 53, 330,  66, 351]], dtype=torch.int32), 'scores': tensor([0.6275, 0.1979, 0.1471, 0.6085, 0.7738, 0.2170, 0.1234, 0.3258, 0.4621,\n",
      "        0.1710, 0.3629]), 'objectness_scores': tensor([0.3234, 0.2828, 0.2249, 0.7690, 0.6882, 0.7851, 0.2026, 0.7948, 0.5641,\n",
      "        0.2599, 0.7998]), 'labels': tensor([ 8, 11, 11, 11,  8, 11, 14, 11,  9, 11,  6], dtype=torch.int32)}\n",
      "523957\n",
      "{'image_id': 524456, 'boxes': tensor([[ 32,   1, 195,  41],\n",
      "        [140,  96, 296, 215],\n",
      "        [367, 271, 412, 296],\n",
      "        [  4,  38, 639, 479],\n",
      "        [304, 229, 453, 296],\n",
      "        [209, 117, 221, 146]], dtype=torch.int32), 'scores': tensor([0.4772, 0.8519, 0.2523, 0.9801, 0.2744, 0.2522]), 'objectness_scores': tensor([0.2986, 0.2320, 0.2063, 0.4996, 0.4831, 0.6349]), 'labels': tensor([16, 14, 11, 14,  9,  7], dtype=torch.int32)}\n",
      "524456\n",
      "{'image_id': 524850, 'boxes': tensor([[146, 131, 152, 142],\n",
      "        [319, 161, 331, 182],\n",
      "        [  1,  16, 321, 319],\n",
      "        [191,  45, 323, 129],\n",
      "        [  3,  16, 310, 140],\n",
      "        [  3,  14, 499, 315],\n",
      "        [315,  85, 499, 176],\n",
      "        [247,  16, 266,  34]], dtype=torch.int32), 'scores': tensor([0.4227, 0.3017, 0.9774, 0.9681, 0.8418, 0.9524, 0.9894, 0.3045]), 'objectness_scores': tensor([0.4314, 0.7026, 0.3907, 0.2125, 0.2235, 0.2181, 0.4183, 0.2230]), 'labels': tensor([11, 11,  0,  0,  0,  0,  1, 11], dtype=torch.int32)}\n",
      "524850\n",
      "{'image_id': 525083, 'boxes': tensor([[366, 216, 380, 228],\n",
      "        [387, 216, 403, 227],\n",
      "        [419, 345, 616, 428]], dtype=torch.int32), 'scores': tensor([0.3402, 0.2433, 0.2479]), 'objectness_scores': tensor([0.2084, 0.2114, 0.2654]), 'labels': tensor([11, 11,  8], dtype=torch.int32)}\n",
      "525083\n",
      "{'image_id': 525247, 'boxes': tensor([[265, 245, 633, 333],\n",
      "        [  3, 100, 380, 428],\n",
      "        [  2,  87, 634, 425]], dtype=torch.int32), 'scores': tensor([0.9966, 0.6314, 0.6722]), 'objectness_scores': tensor([0.2021, 0.4971, 0.3376]), 'labels': tensor([14,  2,  2], dtype=torch.int32)}\n",
      "525247\n",
      "{'image_id': 527029, 'boxes': tensor([[332, 499, 363, 543],\n",
      "        [256, 203, 447, 421],\n",
      "        [385, 193, 594, 348]], dtype=torch.int32), 'scores': tensor([0.3338, 0.6185, 0.2583]), 'objectness_scores': tensor([0.2062, 0.2489, 0.2153]), 'labels': tensor([ 7, 12, 12], dtype=torch.int32)}\n",
      "527029\n",
      "{'image_id': 527616, 'boxes': tensor([[  4,  10,  76, 169],\n",
      "        [ 38, 155, 212, 460],\n",
      "        [  4,   7, 211, 459],\n",
      "        [490,   5, 612, 286],\n",
      "        [ 68, 186, 185, 445],\n",
      "        [356, 131, 377, 166],\n",
      "        [299, 103, 326, 165]], dtype=torch.int32), 'scores': tensor([0.3458, 0.7658, 0.4032, 0.8429, 0.7081, 0.2001, 0.7177]), 'objectness_scores': tensor([0.2228, 0.2172, 0.3648, 0.2265, 0.2034, 0.2454, 0.3089]), 'labels': tensor([11,  7,  7,  8,  7,  7,  7], dtype=torch.int32)}\n",
      "527616\n",
      "{'image_id': 528399, 'boxes': tensor([[373, 387, 450, 428],\n",
      "        [177, 115, 366, 221],\n",
      "        [307,  76, 431, 206],\n",
      "        [571, 104, 639, 300],\n",
      "        [243, 261, 640, 426],\n",
      "        [361,  66, 410,  97],\n",
      "        [402, 167, 577, 243],\n",
      "        [511,  32, 595, 161],\n",
      "        [435,  29, 521, 167],\n",
      "        [438, 138, 570, 223],\n",
      "        [370, 212, 544, 314],\n",
      "        [ 34,  54, 308, 132],\n",
      "        [  0,  66, 632, 430]], dtype=torch.int32), 'scores': tensor([0.8598, 0.3593, 0.9582, 0.7796, 0.5013, 0.3179, 0.8142, 0.7698, 0.7114,\n",
      "        0.9274, 0.5500, 0.5873, 0.5304]), 'objectness_scores': tensor([0.2062, 0.2054, 0.4178, 0.3023, 0.2013, 0.2580, 0.2220, 0.3589, 0.3364,\n",
      "        0.2629, 0.2315, 0.2147, 0.2572]), 'labels': tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 12, 10], dtype=torch.int32)}\n",
      "528399\n",
      "{'image_id': 528980, 'boxes': tensor([[ 61, 544,  74, 556],\n",
      "        [280, 487, 329, 559],\n",
      "        [  1, 580,  15, 592],\n",
      "        [189, 570, 199, 604],\n",
      "        [189, 370, 224, 405],\n",
      "        [ 39, 552,  60, 594],\n",
      "        [184, 524, 200, 568],\n",
      "        [  1, 612,  20, 640],\n",
      "        [128, 627, 136, 637]], dtype=torch.int32), 'scores': tensor([0.2412, 0.4963, 0.2418, 0.3906, 0.2076, 0.6038, 0.2419, 0.1802, 0.1958]), 'objectness_scores': tensor([0.2291, 0.2105, 0.2188, 0.2221, 0.2619, 0.2519, 0.5072, 0.2707, 0.2237]), 'labels': tensor([11,  5, 14, 11, 13,  8,  8,  8, 14], dtype=torch.int32)}\n",
      "528980\n",
      "{'image_id': 529122, 'boxes': tensor([[264,  75, 295,  94],\n",
      "        [ 90,  47, 162,  86],\n",
      "        [405,  39, 501,  88],\n",
      "        [  1,  -1, 487, 282],\n",
      "        [425, 140, 496, 234]], dtype=torch.int32), 'scores': tensor([0.2034, 0.3297, 0.2764, 0.6929, 0.3291]), 'objectness_scores': tensor([0.2028, 0.2405, 0.2191, 0.2046, 0.2236]), 'labels': tensor([ 4,  7,  8, 12, 12], dtype=torch.int32)}\n",
      "529122\n",
      "{'image_id': 529148, 'boxes': tensor([[174, 282, 225, 311],\n",
      "        [237,   0, 258,  23],\n",
      "        [  2, 311, 211, 424]], dtype=torch.int32), 'scores': tensor([0.2166, 0.1702, 0.9616]), 'objectness_scores': tensor([0.2199, 0.2510, 0.2725]), 'labels': tensor([12, 14, 14], dtype=torch.int32)}\n",
      "529148\n",
      "{'image_id': 529528, 'boxes': tensor([[140,  46, 251, 130],\n",
      "        [424, 109, 457, 140],\n",
      "        [393, 115, 427, 146],\n",
      "        [ 39, 141, 257, 298],\n",
      "        [  0,  43,  72, 237],\n",
      "        [392,  96, 456, 179]], dtype=torch.int32), 'scores': tensor([0.1933, 0.1725, 0.1728, 0.9088, 0.4469, 0.4027]), 'objectness_scores': tensor([0.2780, 0.2548, 0.2814, 0.3577, 0.2323, 0.2046]), 'labels': tensor([ 3,  3, 10, 12, 10,  3], dtype=torch.int32)}\n",
      "529528\n",
      "{'image_id': 529568, 'boxes': tensor([[367,  69, 477, 198],\n",
      "        [114,   0, 306, 181],\n",
      "        [147, 370, 281, 389],\n",
      "        [379, 337, 416, 390],\n",
      "        [288, 384, 457, 482],\n",
      "        [298,  24, 478, 258]], dtype=torch.int32), 'scores': tensor([0.3842, 0.5288, 0.9120, 0.4217, 0.4129, 0.1723]), 'objectness_scores': tensor([0.2753, 0.3167, 0.3802, 0.2683, 0.4020, 0.3667]), 'labels': tensor([16,  6, 11,  8,  8, 16], dtype=torch.int32)}\n",
      "529568\n",
      "{'image_id': 530061, 'boxes': tensor([[  2, 246, 635, 454],\n",
      "        [ 90, 192, 620, 437]], dtype=torch.int32), 'scores': tensor([0.8219, 0.7735]), 'objectness_scores': tensor([0.3132, 0.2460]), 'labels': tensor([10, 10], dtype=torch.int32)}\n",
      "530061\n",
      "{'image_id': 530099, 'boxes': tensor([[160, 179, 428, 295]], dtype=torch.int32), 'scores': tensor([0.9585]), 'objectness_scores': tensor([0.4861]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "530099\n",
      "{'image_id': 530146, 'boxes': tensor([[396,   0, 497,  48],\n",
      "        [ 80, 404, 247, 613],\n",
      "        [  2,   5, 635, 635],\n",
      "        [232, 392, 315, 573],\n",
      "        [138, 323, 231, 414],\n",
      "        [ 10,  78, 636, 632],\n",
      "        [ 57, 271, 151, 363],\n",
      "        [137, 377, 239, 420],\n",
      "        [ 64, 333, 140, 517],\n",
      "        [313, 183, 578, 448],\n",
      "        [117, 278, 187, 361],\n",
      "        [  1,   0, 128, 127]], dtype=torch.int32), 'scores': tensor([0.3671, 0.5435, 0.2855, 0.2093, 0.3799, 0.2360, 0.8275, 0.1868, 0.2420,\n",
      "        0.4604, 0.1608, 0.1728]), 'objectness_scores': tensor([0.3217, 0.2588, 0.3509, 0.7146, 0.5105, 0.4897, 0.5783, 0.3138, 0.6169,\n",
      "        0.2014, 0.4267, 0.4826]), 'labels': tensor([10, 12, 12,  3, 12, 12, 11, 11,  7, 12,  4, 16], dtype=torch.int32)}\n",
      "530146\n",
      "{'image_id': 530162, 'boxes': tensor([[177, 320, 311, 426],\n",
      "        [ 16, 143,  51, 160],\n",
      "        [305, 233, 341, 285],\n",
      "        [224,   0, 303,  47],\n",
      "        [129,  23, 502, 276],\n",
      "        [500, 383, 547, 428],\n",
      "        [131, 179, 160, 191],\n",
      "        [ 40, 165, 109, 218],\n",
      "        [162, 167, 222, 219],\n",
      "        [491, 207, 553, 284],\n",
      "        [  0, 156,  26, 222],\n",
      "        [110, 180, 130, 203]], dtype=torch.int32), 'scores': tensor([0.4539, 0.5320, 0.4540, 0.3141, 0.9979, 0.7017, 0.4358, 0.1190, 0.5176,\n",
      "        0.2943, 0.2354, 0.3258]), 'objectness_scores': tensor([0.2026, 0.2278, 0.2204, 0.2173, 0.3045, 0.2099, 0.2446, 0.2596, 0.2308,\n",
      "        0.2172, 0.2134, 0.2459]), 'labels': tensor([ 8, 12,  7,  7,  6, 10, 11,  8,  7,  7,  7, 11], dtype=torch.int32)}\n",
      "530162\n",
      "{'image_id': 530624, 'boxes': tensor([[ 30,   1, 587, 271]], dtype=torch.int32), 'scores': tensor([0.9184]), 'objectness_scores': tensor([0.3083]), 'labels': tensor([3], dtype=torch.int32)}\n",
      "530624\n",
      "{'image_id': 530836, 'boxes': tensor([[ 81, 256, 113, 279],\n",
      "        [340, 280, 358, 315],\n",
      "        [472, 234, 507, 258],\n",
      "        [397, 292, 582, 427],\n",
      "        [416, 242, 441, 272]], dtype=torch.int32), 'scores': tensor([0.1845, 0.2941, 0.4970, 0.5235, 0.7258]), 'objectness_scores': tensor([0.2397, 0.2087, 0.2042, 0.2026, 0.2679]), 'labels': tensor([11, 11, 10, 12, 10], dtype=torch.int32)}\n",
      "530836\n",
      "{'image_id': 530854, 'boxes': tensor([[556,  43, 638,  83],\n",
      "        [131, 146, 166, 165],\n",
      "        [393,  68, 639, 207],\n",
      "        [376,  69, 639, 373],\n",
      "        [430, 327, 642, 424],\n",
      "        [200,  91, 450, 212],\n",
      "        [408,  63, 603, 131],\n",
      "        [261,  38, 517, 106],\n",
      "        [  0,  90, 181, 169],\n",
      "        [  3,  52, 635, 421],\n",
      "        [329, 159, 416, 212],\n",
      "        [ 16, 139, 162, 169],\n",
      "        [147, 144, 224, 168],\n",
      "        [202, 107, 339, 163],\n",
      "        [ 56, 133, 153, 169]], dtype=torch.int32), 'scores': tensor([0.3015, 0.1771, 0.5837, 0.9164, 0.6906, 0.7292, 0.6744, 0.7361, 0.9072,\n",
      "        0.9966, 0.9381, 0.6428, 0.2402, 0.8648, 0.3049]), 'objectness_scores': tensor([0.4383, 0.2609, 0.2502, 0.5260, 0.2587, 0.5409, 0.5479, 0.5486, 0.5496,\n",
      "        0.2473, 0.2131, 0.2017, 0.4314, 0.2545, 0.3954]), 'labels': tensor([11,  7,  7,  7,  7,  7,  7,  7,  7,  6,  7,  7, 11,  7,  7],\n",
      "       dtype=torch.int32)}\n",
      "530854\n",
      "{'image_id': 530975, 'boxes': tensor([[433, 315, 637, 480],\n",
      "        [118, 304, 399, 440],\n",
      "        [  0, 280, 632, 482],\n",
      "        [441, 375, 599, 464],\n",
      "        [288, 111, 396, 179]], dtype=torch.int32), 'scores': tensor([0.3906, 0.4783, 0.4196, 0.3592, 0.4434]), 'objectness_scores': tensor([0.2320, 0.2054, 0.2178, 0.2010, 0.2264]), 'labels': tensor([7, 3, 3, 7, 6], dtype=torch.int32)}\n",
      "530975\n",
      "{'image_id': 531036, 'boxes': tensor([[  0, 221, 160, 370],\n",
      "        [ 13, 301,  45, 337],\n",
      "        [ 37, 208,  91, 222],\n",
      "        [139, 244, 334, 399],\n",
      "        [107, 496, 133, 513]], dtype=torch.int32), 'scores': tensor([0.9965, 0.2995, 0.4394, 0.9962, 0.3293]), 'objectness_scores': tensor([0.4518, 0.2044, 0.2013, 0.2499, 0.2270]), 'labels': tensor([ 1,  9, 14,  1,  1], dtype=torch.int32)}\n",
      "531036\n",
      "{'image_id': 532129, 'boxes': tensor([[  3,  31, 625, 427],\n",
      "        [ 29,   0, 211,  25],\n",
      "        [  2,   0, 635, 426]], dtype=torch.int32), 'scores': tensor([0.3622, 0.4390, 0.4548]), 'objectness_scores': tensor([0.4189, 0.2520, 0.3117]), 'labels': tensor([12, 11, 12], dtype=torch.int32)}\n",
      "532129\n",
      "{'image_id': 532530, 'boxes': tensor([[  1, 229, 338, 424],\n",
      "        [354, 209, 507, 253],\n",
      "        [  0, 147, 336, 226],\n",
      "        [  0, 143, 354, 423]], dtype=torch.int32), 'scores': tensor([0.7078, 0.2590, 0.2762, 0.6219]), 'objectness_scores': tensor([0.2850, 0.2607, 0.2183, 0.2618]), 'labels': tensor([16,  8,  1,  1], dtype=torch.int32)}\n",
      "532530\n",
      "{'image_id': 532575, 'boxes': tensor([[ 48, 283, 177, 393],\n",
      "        [ 94, 389, 131, 427],\n",
      "        [  1, 377, 181, 426],\n",
      "        [136,  15, 313, 122],\n",
      "        [  0,  64, 479, 427]], dtype=torch.int32), 'scores': tensor([0.6419, 0.2121, 0.3620, 0.1958, 0.9802]), 'objectness_scores': tensor([0.3319, 0.3029, 0.2018, 0.2129, 0.4906]), 'labels': tensor([7, 9, 3, 9, 3], dtype=torch.int32)}\n",
      "532575\n",
      "{'image_id': 532690, 'boxes': tensor([[ 87, 176, 435, 470],\n",
      "        [  6, 106,  33, 150],\n",
      "        [ 55, 491, 103, 527],\n",
      "        [  0, 252, 181, 637],\n",
      "        [420, 444, 459, 464],\n",
      "        [220, 120, 339, 156]], dtype=torch.int32), 'scores': tensor([0.6400, 0.3166, 0.1978, 0.3031, 0.4238, 0.2719]), 'objectness_scores': tensor([0.2432, 0.2228, 0.2892, 0.3994, 0.3390, 0.2132]), 'labels': tensor([ 7,  8,  9, 13, 11,  7], dtype=torch.int32)}\n",
      "532690\n",
      "{'image_id': 532761, 'boxes': tensor([[ 11, 251, 112, 361],\n",
      "        [131, 231, 197, 281],\n",
      "        [161, 155, 203, 235],\n",
      "        [ 73, 238, 133, 315],\n",
      "        [510, 287, 638, 456],\n",
      "        [529, 278, 546, 296],\n",
      "        [117, 235, 188, 297],\n",
      "        [  0, 233, 222, 477],\n",
      "        [244, 248, 253, 262],\n",
      "        [  1, 353, 117, 399],\n",
      "        [178, 226, 216, 270],\n",
      "        [  0, 292, 116, 403],\n",
      "        [562,  85, 582, 137],\n",
      "        [ 88, 234, 223, 345],\n",
      "        [212, 335, 322, 480],\n",
      "        [  0, 237,  95, 296]], dtype=torch.int32), 'scores': tensor([0.9968, 0.8310, 0.9161, 0.3407, 0.4452, 0.1719, 0.8867, 0.9988, 0.1992,\n",
      "        0.2009, 0.3639, 0.9941, 0.5380, 0.9952, 0.4498, 0.2552]), 'objectness_scores': tensor([0.2246, 0.2612, 0.3384, 0.2155, 0.3846, 0.2960, 0.3968, 0.5384, 0.7209,\n",
      "        0.3165, 0.2775, 0.2095, 0.2065, 0.2606, 0.5441, 0.2015]), 'labels': tensor([13, 13,  6, 13, 13, 11, 13, 13, 14,  5, 12, 13, 11, 13,  9, 10],\n",
      "       dtype=torch.int32)}\n",
      "532761\n",
      "{'image_id': 532855, 'boxes': tensor([[113, 119, 128, 127],\n",
      "        [224, 134, 343, 224],\n",
      "        [289,  87, 334, 129],\n",
      "        [293,  88, 332, 120]], dtype=torch.int32), 'scores': tensor([0.2881, 0.8039, 0.2624, 0.1890]), 'objectness_scores': tensor([0.4008, 0.3402, 0.3134, 0.2028]), 'labels': tensor([11,  9,  7,  7], dtype=torch.int32)}\n",
      "532855\n",
      "{'image_id': 532901, 'boxes': tensor([[409, 162, 484, 252],\n",
      "        [461, 222, 495, 254],\n",
      "        [536,  -4, 597, 293],\n",
      "        [  1, 266, 596, 349],\n",
      "        [327,   8, 359,  94],\n",
      "        [420,  94, 430, 122],\n",
      "        [215, 114, 363, 240],\n",
      "        [149,  94, 159, 122],\n",
      "        [129, 175, 187, 248],\n",
      "        [  0, 197,  96, 294],\n",
      "        [193, 154, 237, 185],\n",
      "        [409, 161, 488, 252],\n",
      "        [224,  10, 257,  96],\n",
      "        [171, 178, 200, 214],\n",
      "        [181, 207, 224, 238],\n",
      "        [107, 220, 142, 255],\n",
      "        [407, 169, 471, 244],\n",
      "        [106, 219, 141, 291],\n",
      "        [112, 165, 183, 251]], dtype=torch.int32), 'scores': tensor([0.9655, 0.4898, 0.3457, 0.3671, 0.2143, 0.1626, 0.3856, 0.3444, 0.2549,\n",
      "        0.3347, 0.4665, 0.9862, 0.1857, 0.3982, 0.5405, 0.4258, 0.9068, 0.3281,\n",
      "        0.9287]), 'objectness_scores': tensor([0.2439, 0.3650, 0.2063, 0.2563, 0.2824, 0.6709, 0.2462, 0.4626, 0.3567,\n",
      "        0.3070, 0.3863, 0.3980, 0.3130, 0.3286, 0.2031, 0.3068, 0.2613, 0.2744,\n",
      "        0.3446]), 'labels': tensor([13,  6,  7,  7,  6,  0, 13, 11, 13, 12, 14, 13,  6,  8, 11,  6, 13,  3,\n",
      "        13], dtype=torch.int32)}\n",
      "532901\n",
      "{'image_id': 533206, 'boxes': tensor([[126, 215, 394, 337],\n",
      "        [411, 172, 553, 244],\n",
      "        [592,   1, 638, 176],\n",
      "        [  1,  19, 634, 422],\n",
      "        [358, 218, 396, 259],\n",
      "        [ 73, 186, 448, 375],\n",
      "        [123, 256, 185, 288],\n",
      "        [287,   0, 382, 117],\n",
      "        [332,   1, 435, 153],\n",
      "        [342, 257, 410, 350]], dtype=torch.int32), 'scores': tensor([0.4459, 0.9091, 0.2091, 0.5448, 0.5742, 0.5552, 0.4239, 0.7681, 0.8770,\n",
      "        0.1438]), 'objectness_scores': tensor([0.3404, 0.2441, 0.3164, 0.3750, 0.2126, 0.4379, 0.2163, 0.5260, 0.5262,\n",
      "        0.2057]), 'labels': tensor([16, 10, 11, 12, 12, 12, 11, 10, 10, 11], dtype=torch.int32)}\n",
      "533206\n",
      "{'image_id': 533536, 'boxes': tensor([[ 78, 280, 371, 479],\n",
      "        [ 53,  -1, 174, 204],\n",
      "        [  8, 180, 634, 482]], dtype=torch.int32), 'scores': tensor([0.9264, 0.2640, 0.8725]), 'objectness_scores': tensor([0.5433, 0.2380, 0.2287]), 'labels': tensor([ 2, 11,  2], dtype=torch.int32)}\n",
      "533536\n",
      "{'image_id': 534270, 'boxes': tensor([[306, 387, 331, 406],\n",
      "        [195, 134, 226, 164],\n",
      "        [169, 132, 252, 181],\n",
      "        [195, 396, 227, 410],\n",
      "        [235, 349, 321, 413],\n",
      "        [232, 170, 316, 201],\n",
      "        [157, 387, 176, 409]], dtype=torch.int32), 'scores': tensor([0.2439, 0.2061, 0.4230, 0.1749, 0.9823, 0.1971, 0.2108]), 'objectness_scores': tensor([0.3348, 0.2934, 0.6309, 0.4071, 0.5519, 0.5814, 0.3804]), 'labels': tensor([2, 8, 6, 1, 3, 6, 4], dtype=torch.int32)}\n",
      "534270\n",
      "{'image_id': 534673, 'boxes': tensor([[ 48,  79, 571, 401],\n",
      "        [ 92, 356, 132, 375]], dtype=torch.int32), 'scores': tensor([0.9995, 0.1856]), 'objectness_scores': tensor([0.5480, 0.2308]), 'labels': tensor([ 1, 14], dtype=torch.int32)}\n",
      "534673\n",
      "{'image_id': 535094, 'boxes': tensor([[310,  75, 634, 423]], dtype=torch.int32), 'scores': tensor([0.9977]), 'objectness_scores': tensor([0.5140]), 'labels': tensor([4], dtype=torch.int32)}\n",
      "535094\n",
      "{'image_id': 535253, 'boxes': tensor([[ 43, 282, 180, 452],\n",
      "        [301,  31, 446, 128],\n",
      "        [236, 130, 287, 254],\n",
      "        [ 18,  18, 126, 217],\n",
      "        [ 18,  21, 133, 303],\n",
      "        [432,  96, 459, 119],\n",
      "        [261,  82, 351, 140],\n",
      "        [ 21, 177, 105, 306],\n",
      "        [ 24, 204, 101, 306],\n",
      "        [169, 412, 284, 531],\n",
      "        [129, 218, 578, 555],\n",
      "        [176, 251, 312, 384],\n",
      "        [ 20,  21, 180, 303],\n",
      "        [266, 160, 433, 334],\n",
      "        [255,  76, 359, 141]], dtype=torch.int32), 'scores': tensor([0.8338, 0.5908, 0.3004, 0.1789, 0.4332, 0.4189, 0.6665, 0.3334, 0.2238,\n",
      "        0.5064, 0.3752, 0.3964, 0.3421, 0.3323, 0.3651]), 'objectness_scores': tensor([0.5662, 0.2286, 0.2139, 0.2645, 0.2561, 0.6980, 0.2204, 0.3443, 0.2158,\n",
      "        0.2669, 0.2055, 0.2686, 0.2223, 0.2547, 0.2156]), 'labels': tensor([10, 12, 10,  6,  9, 10, 11, 10,  7,  7, 16,  6, 16, 16, 12],\n",
      "       dtype=torch.int32)}\n",
      "535253\n",
      "{'image_id': 535306, 'boxes': tensor([[145, 117, 370, 232],\n",
      "        [222,   0, 281,  51],\n",
      "        [118,  67, 169, 107],\n",
      "        [138, 156, 164, 176],\n",
      "        [269, 100, 297, 138]], dtype=torch.int32), 'scores': tensor([0.7974, 0.2508, 0.5433, 0.1751, 0.2368]), 'objectness_scores': tensor([0.5720, 0.2126, 0.2490, 0.2373, 0.2543]), 'labels': tensor([ 8,  9,  7, 11,  8], dtype=torch.int32)}\n",
      "535306\n",
      "{'image_id': 535608, 'boxes': tensor([[304, 156, 429, 267],\n",
      "        [333, 265, 340, 274],\n",
      "        [183, 183, 189, 190],\n",
      "        [444, 181, 459, 199],\n",
      "        [ 78, 215,  83, 225],\n",
      "        [201, 172, 209, 187],\n",
      "        [ 59, 215,  67, 224],\n",
      "        [  2, 185, 498, 377]], dtype=torch.int32), 'scores': tensor([0.9791, 0.2061, 0.1850, 0.1348, 0.2027, 0.1962, 0.1554, 0.2211]), 'objectness_scores': tensor([0.4713, 0.2143, 0.2769, 0.2052, 0.2844, 0.2011, 0.2913, 0.2273]), 'labels': tensor([ 6, 14,  0, 11, 11, 11, 11, 13], dtype=torch.int32)}\n",
      "535608\n",
      "{'image_id': 536073, 'boxes': tensor([[ 43,   0,  97,  61],\n",
      "        [  0, 455, 327, 640],\n",
      "        [242,  18, 461, 459],\n",
      "        [ 61, 497, 241, 617],\n",
      "        [319, 385, 451, 556],\n",
      "        [ 61, 303, 152, 387]], dtype=torch.int32), 'scores': tensor([0.6878, 0.9735, 0.9456, 0.9887, 0.9642, 0.7255]), 'objectness_scores': tensor([0.4583, 0.5160, 0.6465, 0.5729, 0.4983, 0.2007]), 'labels': tensor([14, 11, 10, 11, 10, 12], dtype=torch.int32)}\n",
      "536073\n",
      "{'image_id': 537270, 'boxes': tensor([[538, 228, 618, 312],\n",
      "        [521,   1, 639, 118],\n",
      "        [356, 215, 409, 278],\n",
      "        [392, 413, 558, 457],\n",
      "        [ 91, 110, 211, 150]], dtype=torch.int32), 'scores': tensor([0.9881, 0.3051, 0.5740, 0.3623, 0.2951]), 'objectness_scores': tensor([0.3335, 0.2180, 0.3716, 0.2189, 0.2150]), 'labels': tensor([10, 14,  7, 11, 11], dtype=torch.int32)}\n",
      "537270\n",
      "{'image_id': 537506, 'boxes': tensor([[124, 100, 162, 135],\n",
      "        [386, 348, 403, 370],\n",
      "        [247, 293, 280, 311],\n",
      "        [256, 280, 287, 296],\n",
      "        [258,  96, 277, 120],\n",
      "        [322,  15, 438,  74],\n",
      "        [180,   0, 348,  88],\n",
      "        [ 75, 367, 110, 393],\n",
      "        [  0,   0, 171, 101],\n",
      "        [573,  12, 593,  31]], dtype=torch.int32), 'scores': tensor([0.2169, 0.1604, 0.6302, 0.1703, 0.3630, 0.1780, 0.9409, 0.1624, 0.9785,\n",
      "        0.1953]), 'objectness_scores': tensor([0.3209, 0.2988, 0.2543, 0.2114, 0.3212, 0.4017, 0.4499, 0.2079, 0.4697,\n",
      "        0.2173]), 'labels': tensor([14, 11,  3, 11, 14,  9,  6, 11,  6, 14], dtype=torch.int32)}\n",
      "537506\n",
      "{'image_id': 537991, 'boxes': tensor([[171,   0, 302, 125],\n",
      "        [244, 111, 276, 146],\n",
      "        [284,   2, 484, 414],\n",
      "        [ 10, 206, 126, 370],\n",
      "        [  0, 240, 365, 479]], dtype=torch.int32), 'scores': tensor([0.3967, 0.3756, 0.3738, 0.8038, 0.4664]), 'objectness_scores': tensor([0.3648, 0.2273, 0.2475, 0.2667, 0.3254]), 'labels': tensor([ 7, 11, 11,  7, 13], dtype=torch.int32)}\n",
      "537991\n",
      "{'image_id': 538458, 'boxes': tensor([[309, 160, 339, 176],\n",
      "        [462, 241, 515, 276],\n",
      "        [351,  34, 365,  46],\n",
      "        [552, 297, 609, 334],\n",
      "        [141, 192, 170, 212],\n",
      "        [558, 292, 614, 315],\n",
      "        [357, 154, 385, 182]], dtype=torch.int32), 'scores': tensor([0.2506, 0.7014, 0.2154, 0.4079, 0.1886, 0.3510, 0.5496]), 'objectness_scores': tensor([0.2117, 0.4367, 0.2055, 0.5181, 0.2325, 0.2316, 0.2305]), 'labels': tensor([ 9,  9, 11,  9,  7, 11,  9], dtype=torch.int32)}\n",
      "538458\n",
      "{'image_id': 539962, 'boxes': tensor([[ 23, 290, 630, 370],\n",
      "        [410, 288, 538, 387],\n",
      "        [  1, 200, 124, 244],\n",
      "        [  0, 199, 122, 289],\n",
      "        [591, 231, 639, 279]], dtype=torch.int32), 'scores': tensor([0.3332, 0.4016, 0.2178, 0.9423, 0.2050]), 'objectness_scores': tensor([0.2714, 0.2270, 0.2398, 0.2326, 0.2177]), 'labels': tensor([ 3, 10, 13,  6,  6], dtype=torch.int32)}\n",
      "539962\n",
      "{'image_id': 540280, 'boxes': tensor([[ 91, 203, 236, 599],\n",
      "        [ 97, 189, 174, 290],\n",
      "        [  0,  13, 426, 411],\n",
      "        [146, 351, 179, 641],\n",
      "        [ 95, 187, 230, 333],\n",
      "        [  3,  16, 423, 618],\n",
      "        [ 64, 395,  94, 602],\n",
      "        [265, 520, 301, 602],\n",
      "        [164, 400, 213, 434]], dtype=torch.int32), 'scores': tensor([0.6553, 0.2987, 0.9982, 0.4521, 0.3963, 0.9991, 0.4469, 0.2345, 0.4588]), 'objectness_scores': tensor([0.2165, 0.4230, 0.5086, 0.2270, 0.2246, 0.2610, 0.2419, 0.2960, 0.2688]), 'labels': tensor([ 7,  8,  6,  7,  7,  6,  7, 11, 11], dtype=torch.int32)}\n",
      "540280\n",
      "{'image_id': 540414, 'boxes': tensor([[312, 409, 350, 426],\n",
      "        [386, 167, 458, 190],\n",
      "        [288, 400, 353, 413],\n",
      "        [  1, 130, 105, 174],\n",
      "        [ 14, 145, 195, 258],\n",
      "        [282, 325, 328, 367],\n",
      "        [289, 392, 357, 411],\n",
      "        [185, 165, 272, 195],\n",
      "        [528, 125, 558, 156],\n",
      "        [286, 366, 359, 395],\n",
      "        [ 16, 147, 194, 197],\n",
      "        [419, 295, 441, 314],\n",
      "        [263, 432, 303, 448],\n",
      "        [544, 415, 580, 428],\n",
      "        [345, 335, 378, 377],\n",
      "        [521, 155, 554, 184]], dtype=torch.int32), 'scores': tensor([0.2602, 0.3222, 0.2508, 0.4809, 0.4936, 0.7872, 0.2385, 0.3050, 0.1833,\n",
      "        0.1527, 0.9545, 0.1904, 0.2190, 0.4259, 0.1902, 0.2217]), 'objectness_scores': tensor([0.2215, 0.3080, 0.2489, 0.2611, 0.2333, 0.2654, 0.2639, 0.2535, 0.2338,\n",
      "        0.2888, 0.3119, 0.2131, 0.2001, 0.3018, 0.3012, 0.2735]), 'labels': tensor([11, 11, 11,  9,  6, 12, 11, 14,  7, 11,  6,  7, 11, 11,  8,  9],\n",
      "       dtype=torch.int32)}\n",
      "540414\n",
      "{'image_id': 540466, 'boxes': tensor([[368,  90, 623, 275]], dtype=torch.int32), 'scores': tensor([0.9986]), 'objectness_scores': tensor([0.6304]), 'labels': tensor([6], dtype=torch.int32)}\n",
      "540466\n",
      "{'image_id': 540502, 'boxes': tensor([[368, 184, 388, 202],\n",
      "        [118, 252, 576, 425],\n",
      "        [326,  79, 390, 122],\n",
      "        [ 66,  34, 164, 113],\n",
      "        [289,  81, 333, 165],\n",
      "        [437,  77, 511, 166],\n",
      "        [ 23, 234,  49, 312],\n",
      "        [216, 214, 229, 254],\n",
      "        [393,  81, 439, 166]], dtype=torch.int32), 'scores': tensor([0.1860, 0.6531, 0.1755, 0.3480, 0.1274, 0.1664, 0.2840, 0.4063, 0.2082]), 'objectness_scores': tensor([0.2709, 0.2283, 0.2899, 0.2086, 0.2800, 0.2738, 0.2408, 0.2263, 0.2495]), 'labels': tensor([11, 15, 11,  7,  7,  8,  8, 11,  8], dtype=torch.int32)}\n",
      "540502\n",
      "{'image_id': 540928, 'boxes': tensor([[231,   0, 549, 292],\n",
      "        [  5, 287, 641, 454]], dtype=torch.int32), 'scores': tensor([0.8556, 0.3414]), 'objectness_scores': tensor([0.5673, 0.2905]), 'labels': tensor([2, 9], dtype=torch.int32)}\n",
      "540928\n",
      "{'image_id': 540962, 'boxes': tensor([[  2,   0, 495, 400],\n",
      "        [354, 279, 403, 326],\n",
      "        [333, 224, 479, 397],\n",
      "        [134, 191, 194, 263],\n",
      "        [260,   1, 303,  27],\n",
      "        [234, 264, 291, 340],\n",
      "        [273,  77, 304, 105],\n",
      "        [244, 211, 285, 250],\n",
      "        [390, 189, 459, 239],\n",
      "        [205,   0, 369,  27],\n",
      "        [397, 290, 443, 335],\n",
      "        [208, 288, 244, 307],\n",
      "        [236, 101, 393, 208],\n",
      "        [203, 210, 363, 322],\n",
      "        [225, 208, 319, 281],\n",
      "        [185, 170, 231, 232],\n",
      "        [303,  22, 365, 104],\n",
      "        [356, 237, 404, 284],\n",
      "        [386, 255, 440, 306],\n",
      "        [174, 260, 215, 289]], dtype=torch.int32), 'scores': tensor([0.9388, 0.6055, 0.9686, 0.2011, 0.1471, 0.2337, 0.1550, 0.1600, 0.4370,\n",
      "        0.1564, 0.5263, 0.4163, 0.2685, 0.3397, 0.2621, 0.2988, 0.8248, 0.3212,\n",
      "        0.7364, 0.2071]), 'objectness_scores': tensor([0.2092, 0.3871, 0.4946, 0.2194, 0.2273, 0.2310, 0.2145, 0.2568, 0.2458,\n",
      "        0.5495, 0.2804, 0.2687, 0.2114, 0.2876, 0.4406, 0.3465, 0.3305, 0.4580,\n",
      "        0.4619, 0.4193]), 'labels': tensor([13, 14, 13, 13, 11, 13,  0, 13,  7, 11,  7, 11, 15, 12, 10, 10,  2,  7,\n",
      "         7, 11], dtype=torch.int32)}\n",
      "540962\n",
      "{'image_id': 541634, 'boxes': tensor([[338, 316, 401, 361],\n",
      "        [274, 428, 371, 487],\n",
      "        [140,   7, 158,  51],\n",
      "        [174, 272, 479, 489],\n",
      "        [ 78,  36, 226, 326],\n",
      "        [190, 343, 269, 442],\n",
      "        [357, 392, 502, 487],\n",
      "        [310, 268, 370, 316],\n",
      "        [437, 210, 602, 338],\n",
      "        [143, 280, 482, 500],\n",
      "        [308, 319, 383, 380],\n",
      "        [423, 362, 481, 430],\n",
      "        [384, 333, 458, 413],\n",
      "        [269, 363, 323, 430],\n",
      "        [145, 431, 496, 584],\n",
      "        [  4,  12, 599, 605],\n",
      "        [  7,  83, 113, 271],\n",
      "        [392, 244, 606, 388],\n",
      "        [234, 415, 286, 447]], dtype=torch.int32), 'scores': tensor([0.2747, 0.2982, 0.3780, 0.3967, 0.1720, 0.4551, 0.3102, 0.4957, 0.4349,\n",
      "        0.3676, 0.4034, 0.3862, 0.1932, 0.2119, 0.2898, 0.8041, 0.2042, 0.7283,\n",
      "        0.1841]), 'objectness_scores': tensor([0.2023, 0.3220, 0.2613, 0.2506, 0.4272, 0.2947, 0.2049, 0.2047, 0.5678,\n",
      "        0.2448, 0.2634, 0.2639, 0.2863, 0.2996, 0.3114, 0.4000, 0.5083, 0.3947,\n",
      "        0.2100]), 'labels': tensor([12,  4,  7, 11,  9,  4, 11, 12, 10, 11, 12, 12,  4, 12, 11, 10, 12, 10,\n",
      "        10], dtype=torch.int32)}\n",
      "541634\n",
      "{'image_id': 541664, 'boxes': tensor([[408,  79, 485, 147],\n",
      "        [ 22,  80,  83, 175],\n",
      "        [ 52,  91, 142, 208],\n",
      "        [374,  23, 487, 146],\n",
      "        [226, 208, 379, 374],\n",
      "        [301, 208, 368, 323],\n",
      "        [228, 291, 308, 374],\n",
      "        [375,  22, 449,  89],\n",
      "        [289,  18, 389, 118],\n",
      "        [102, 206, 203, 361],\n",
      "        [  2,   0, 498, 375],\n",
      "        [122, 122, 441, 282]], dtype=torch.int32), 'scores': tensor([0.6113, 0.5453, 0.2863, 0.5876, 0.8398, 0.4560, 0.4931, 0.3592, 0.3324,\n",
      "        0.3271, 0.9378, 0.9962]), 'objectness_scores': tensor([0.3185, 0.2007, 0.2944, 0.3146, 0.2057, 0.2203, 0.2612, 0.2318, 0.3461,\n",
      "        0.2849, 0.3642, 0.4795]), 'labels': tensor([ 9,  8, 16,  9, 14, 16,  9,  9, 11, 14, 14, 14], dtype=torch.int32)}\n",
      "541664\n",
      "{'image_id': 541773, 'boxes': tensor([[503, 213, 520, 239],\n",
      "        [547, 111, 639, 216],\n",
      "        [252, 361, 303, 481],\n",
      "        [304, 244, 331, 310]], dtype=torch.int32), 'scores': tensor([0.3418, 0.2957, 0.5841, 0.4331]), 'objectness_scores': tensor([0.2307, 0.2069, 0.3065, 0.3081]), 'labels': tensor([11,  9, 10, 11], dtype=torch.int32)}\n",
      "541773\n",
      "{'image_id': 542856, 'boxes': tensor([[ -1, 171, 519, 382],\n",
      "        [387, 324, 428, 365],\n",
      "        [551,  71, 569, 130]], dtype=torch.int32), 'scores': tensor([0.9988, 0.2866, 0.2623]), 'objectness_scores': tensor([0.5087, 0.2163, 0.4292]), 'labels': tensor([ 1,  9, 11], dtype=torch.int32)}\n",
      "542856\n",
      "{'image_id': 543043, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "543043\n",
      "{'image_id': 543047, 'boxes': tensor([[ 14, 253, 125, 338],\n",
      "        [131, 256, 199, 292],\n",
      "        [416,  83, 453, 133],\n",
      "        [ 95,  98, 146, 231],\n",
      "        [148, 326, 413, 480]], dtype=torch.int32), 'scores': tensor([0.5256, 0.2016, 0.4029, 0.6201, 0.9082]), 'objectness_scores': tensor([0.2065, 0.2438, 0.3028, 0.2066, 0.3550]), 'labels': tensor([13, 11, 11, 11, 15], dtype=torch.int32)}\n",
      "543047\n",
      "{'image_id': 543581, 'boxes': tensor([[  0, 180, 136, 285],\n",
      "        [249, 124, 563, 363],\n",
      "        [534, 134, 613, 234],\n",
      "        [147, 183, 342, 382],\n",
      "        [419, 375, 444, 392],\n",
      "        [484, 310, 623, 402],\n",
      "        [383, 342, 416, 402],\n",
      "        [257, 134, 350, 226]], dtype=torch.int32), 'scores': tensor([0.2515, 0.9671, 0.7387, 0.9718, 0.2787, 0.8710, 0.4347, 0.9179]), 'objectness_scores': tensor([0.2270, 0.4600, 0.2252, 0.2309, 0.2088, 0.4078, 0.3036, 0.4145]), 'labels': tensor([14, 13,  6, 13, 11,  2, 10,  3], dtype=torch.int32)}\n",
      "543581\n",
      "{'image_id': 544565, 'boxes': tensor([[  0,   1,  94, 170],\n",
      "        [199, 544, 450, 604],\n",
      "        [111,  10, 573, 637],\n",
      "        [388, 218, 528, 364],\n",
      "        [138, 239, 275, 374],\n",
      "        [  5,   5, 639, 637]], dtype=torch.int32), 'scores': tensor([0.3154, 0.5908, 0.6591, 0.7456, 0.6703, 0.3271]), 'objectness_scores': tensor([0.2937, 0.2343, 0.4724, 0.4378, 0.4190, 0.3578]), 'labels': tensor([10, 12, 12, 12, 12, 12], dtype=torch.int32)}\n",
      "544565\n",
      "{'image_id': 545219, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "545219\n",
      "{'image_id': 545826, 'boxes': tensor([[310,   1, 498, 181],\n",
      "        [ 25,   8, 288, 331],\n",
      "        [ 51,   0, 228,  79],\n",
      "        [ 30,  80, 279, 331],\n",
      "        [258,   0, 422, 160]], dtype=torch.int32), 'scores': tensor([0.6476, 0.9310, 0.1730, 0.8949, 0.5328]), 'objectness_scores': tensor([0.3199, 0.3010, 0.2259, 0.3258, 0.2668]), 'labels': tensor([7, 2, 6, 2, 7], dtype=torch.int32)}\n",
      "545826\n",
      "{'image_id': 546219, 'boxes': tensor([[ 31, 303,  68, 340],\n",
      "        [247, 306, 265, 327],\n",
      "        [267, 303, 284, 316],\n",
      "        [198, 335, 219, 363],\n",
      "        [192, 320, 211, 351],\n",
      "        [276, 316, 292, 337],\n",
      "        [217, 344, 241, 367],\n",
      "        [226, 305, 245, 322],\n",
      "        [298, 343, 318, 368],\n",
      "        [216, 318, 237, 343],\n",
      "        [326, 305, 345, 322],\n",
      "        [241, 324, 259, 353],\n",
      "        [136, 251, 201, 285],\n",
      "        [324, 341, 352, 363],\n",
      "        [228, 330, 247, 354],\n",
      "        [315, 317, 336, 344],\n",
      "        [280, 305, 298, 318],\n",
      "        [349, 314, 364, 336],\n",
      "        [437, 295, 442, 299],\n",
      "        [168, 349, 363, 427]], dtype=torch.int32), 'scores': tensor([0.6177, 0.2787, 0.1643, 0.2658, 0.2259, 0.5196, 0.3407, 0.2660, 0.2368,\n",
      "        0.1975, 0.2725, 0.2129, 0.1607, 0.2296, 0.1932, 0.7599, 0.3884, 0.1933,\n",
      "        0.2518, 0.2356]), 'objectness_scores': tensor([0.3142, 0.2083, 0.2137, 0.2809, 0.2590, 0.2426, 0.2744, 0.2293, 0.2416,\n",
      "        0.2521, 0.2468, 0.2211, 0.2782, 0.2668, 0.2041, 0.2658, 0.2066, 0.2027,\n",
      "        0.2021, 0.2505]), 'labels': tensor([ 7, 11, 11, 11, 11, 12, 10, 14, 11, 11, 14, 11,  2, 14, 14, 10, 14,  4,\n",
      "        11, 12], dtype=torch.int32)}\n",
      "546219\n",
      "{'image_id': 546325, 'boxes': tensor([[  0, 281, 481, 626],\n",
      "        [ 15, 617, 104, 639],\n",
      "        [118,  21, 188,  74],\n",
      "        [ 36, 510, 113, 574],\n",
      "        [ 96, 293, 222, 377],\n",
      "        [ 81, 318, 209, 443],\n",
      "        [213, 282, 353, 395],\n",
      "        [102, 145, 148, 311],\n",
      "        [428, 307, 479, 465],\n",
      "        [  3, 526, 294, 638],\n",
      "        [171, 317, 357, 457],\n",
      "        [ 60,   0, 259,  62],\n",
      "        [344, 266, 478, 438],\n",
      "        [  1, 325, 115, 464],\n",
      "        [292, 138, 315, 170],\n",
      "        [109, 109, 372, 295]], dtype=torch.int32), 'scores': tensor([0.9979, 0.2714, 0.1888, 0.7963, 0.9697, 0.9776, 0.1714, 0.5573, 0.5818,\n",
      "        0.5416, 0.9888, 0.2397, 0.9089, 0.9490, 0.2090, 0.2941]), 'objectness_scores': tensor([0.5353, 0.2002, 0.3359, 0.4453, 0.2609, 0.3928, 0.2599, 0.2680, 0.2515,\n",
      "        0.3457, 0.4471, 0.6284, 0.2925, 0.3412, 0.2522, 0.3897]), 'labels': tensor([13,  7,  0, 12, 13, 13,  8,  7,  7, 13, 13,  8, 13, 13, 11,  8],\n",
      "       dtype=torch.int32)}\n",
      "546325\n",
      "{'image_id': 546626, 'boxes': tensor([[112, 161, 192, 192],\n",
      "        [  0,  94, 299, 398],\n",
      "        [110,  78, 212, 184]], dtype=torch.int32), 'scores': tensor([0.1870, 0.5920, 0.9972]), 'objectness_scores': tensor([0.2622, 0.2711, 0.4279]), 'labels': tensor([11, 10, 10], dtype=torch.int32)}\n",
      "546626\n",
      "{'image_id': 546717, 'boxes': tensor([[337, 239, 461, 370],\n",
      "        [238, 402, 459, 585],\n",
      "        [225, 265, 376, 394]], dtype=torch.int32), 'scores': tensor([0.2173, 0.9985, 0.2145]), 'objectness_scores': tensor([0.2010, 0.2543, 0.2511]), 'labels': tensor([ 7, 14,  7], dtype=torch.int32)}\n",
      "546717\n",
      "{'image_id': 546823, 'boxes': tensor([[482, 318, 498, 345],\n",
      "        [493, 373, 512, 413],\n",
      "        [ 30, 254,  87, 285],\n",
      "        [481, 340, 500, 403],\n",
      "        [ 17,  35,  38,  64],\n",
      "        [467, 238, 502, 248]], dtype=torch.int32), 'scores': tensor([0.2763, 0.2219, 0.5334, 0.3548, 0.2531, 0.2786]), 'objectness_scores': tensor([0.2948, 0.2544, 0.2214, 0.2252, 0.2441, 0.2056]), 'labels': tensor([ 4, 11,  6, 11,  7, 11], dtype=torch.int32)}\n",
      "546823\n",
      "{'image_id': 546829, 'boxes': tensor([[209, 147, 293, 287],\n",
      "        [152, 250, 227, 284]], dtype=torch.int32), 'scores': tensor([0.9859, 0.6301]), 'objectness_scores': tensor([0.5047, 0.2446]), 'labels': tensor([ 3, 11], dtype=torch.int32)}\n",
      "546829\n",
      "{'image_id': 546964, 'boxes': tensor([[374,  41, 415,  98],\n",
      "        [157, 168, 383, 293],\n",
      "        [ 91,  80,  96, 107],\n",
      "        [189, 185, 230, 222],\n",
      "        [326, 165, 398, 216],\n",
      "        [212,  39, 216,  62],\n",
      "        [160,  75, 165, 102],\n",
      "        [204,  41, 209,  67],\n",
      "        [ 85,  74,  89, 101],\n",
      "        [153,  81, 158, 107],\n",
      "        [381, 169, 456, 256],\n",
      "        [202,  26, 255, 175],\n",
      "        [ 16,   6,  94, 128],\n",
      "        [465, 271, 635, 386],\n",
      "        [203,  29, 255,  94],\n",
      "        [248,  42, 254,  68],\n",
      "        [ 46, 144, 212, 218],\n",
      "        [ 77,  80,  82, 107],\n",
      "        [304, 216, 409, 302],\n",
      "        [616, 103, 628, 127],\n",
      "        [496, 314, 639, 481],\n",
      "        [374,  40, 418, 172],\n",
      "        [166,  81, 172, 108]], dtype=torch.int32), 'scores': tensor([0.2070, 0.9965, 0.3594, 0.4756, 0.1832, 0.2923, 0.7225, 0.3077, 0.4735,\n",
      "        0.4997, 0.8120, 0.2239, 0.1402, 0.8622, 0.3760, 0.3146, 0.7586, 0.5008,\n",
      "        0.1240, 0.2996, 0.5173, 0.8357, 0.3146]), 'objectness_scores': tensor([0.2264, 0.4673, 0.3443, 0.2151, 0.2179, 0.2169, 0.2819, 0.2379, 0.3120,\n",
      "        0.3121, 0.2183, 0.2241, 0.2067, 0.3464, 0.2252, 0.3052, 0.2292, 0.3747,\n",
      "        0.2706, 0.2256, 0.4119, 0.2030, 0.3391]), 'labels': tensor([14, 13, 11, 12, 12, 11, 11, 11, 11, 11, 13, 16,  8, 13, 12, 11, 13, 11,\n",
      "        12, 11, 13, 10, 11], dtype=torch.int32)}\n",
      "546964\n",
      "{'image_id': 546976, 'boxes': tensor([[145, 255, 357, 375]], dtype=torch.int32), 'scores': tensor([0.3251]), 'objectness_scores': tensor([0.2188]), 'labels': tensor([9], dtype=torch.int32)}\n",
      "546976\n",
      "{'image_id': 547144, 'boxes': tensor([[569, 189, 640, 246],\n",
      "        [160, 282, 328, 344],\n",
      "        [452, 252, 595, 302],\n",
      "        [168,  12, 498,  75],\n",
      "        [516, 370, 636, 478],\n",
      "        [359, 130, 440, 283],\n",
      "        [468, 336, 587, 421],\n",
      "        [ 21, 219, 642, 477],\n",
      "        [290, 122, 389, 293]], dtype=torch.int32), 'scores': tensor([0.4238, 0.9952, 0.9992, 0.2687, 0.3414, 0.6065, 0.7948, 0.8142, 0.4964]), 'objectness_scores': tensor([0.2729, 0.4605, 0.5304, 0.2608, 0.2277, 0.4108, 0.3413, 0.2523, 0.3512]), 'labels': tensor([14, 14, 14, 14, 14, 14, 14, 14, 14], dtype=torch.int32)}\n",
      "547144\n",
      "{'image_id': 547336, 'boxes': tensor([[182, 188, 210, 245],\n",
      "        [100, 327, 195, 363],\n",
      "        [326,  85, 423, 132],\n",
      "        [163, 382, 204, 433]], dtype=torch.int32), 'scores': tensor([0.3290, 0.1401, 0.2564, 0.9867]), 'objectness_scores': tensor([0.3068, 0.2231, 0.2211, 0.3803]), 'labels': tensor([11, 11, 11, 10], dtype=torch.int32)}\n",
      "547336\n",
      "{'image_id': 547502, 'boxes': tensor([[191, 239, 290, 449],\n",
      "        [463, 205, 638, 477],\n",
      "        [274, 223, 348, 297],\n",
      "        [238, 254, 279, 295],\n",
      "        [346, 125, 442, 251]], dtype=torch.int32), 'scores': tensor([0.7121, 0.9561, 0.9194, 0.4509, 0.9938]), 'objectness_scores': tensor([0.4999, 0.4889, 0.4664, 0.2375, 0.5201]), 'labels': tensor([3, 3, 3, 7, 3], dtype=torch.int32)}\n",
      "547502\n",
      "{'image_id': 547816, 'boxes': tensor([[ 33, 437, 267, 561],\n",
      "        [248, 160, 365, 588],\n",
      "        [ 59, 427,  87, 443],\n",
      "        [  2,   4, 416, 636],\n",
      "        [386, 165, 410, 280],\n",
      "        [357, 321, 407, 552],\n",
      "        [182,   0, 241,  28],\n",
      "        [370, 510, 409, 543]], dtype=torch.int32), 'scores': tensor([0.9715, 0.8604, 0.8180, 0.8264, 0.7799, 0.3432, 0.5424, 0.2998]), 'objectness_scores': tensor([0.5859, 0.3531, 0.4043, 0.2161, 0.2281, 0.4654, 0.2416, 0.2227]), 'labels': tensor([15,  7, 11, 15, 11,  7, 11, 15], dtype=torch.int32)}\n",
      "547816\n",
      "{'image_id': 549220, 'boxes': tensor([[135,  96, 206, 309],\n",
      "        [  0,  94, 441, 473],\n",
      "        [391,  87, 396,  94]], dtype=torch.int32), 'scores': tensor([0.4808, 0.8950, 0.3230]), 'objectness_scores': tensor([0.2825, 0.4496, 0.3401]), 'labels': tensor([ 7,  3, 11], dtype=torch.int32)}\n",
      "549220\n",
      "{'image_id': 549674, 'boxes': tensor([[ 59, 347, 450, 457],\n",
      "        [103, 183, 256, 238],\n",
      "        [  0, 173, 633, 478]], dtype=torch.int32), 'scores': tensor([0.9991, 0.9965, 0.9920]), 'objectness_scores': tensor([0.4374, 0.4069, 0.2235]), 'labels': tensor([14, 14, 14], dtype=torch.int32)}\n",
      "549674\n",
      "{'image_id': 549930, 'boxes': tensor([[324, 178, 342, 183],\n",
      "        [457, 179, 487, 189],\n",
      "        [324, 184, 350, 192],\n",
      "        [ 57, 186,  83, 199],\n",
      "        [224, 187, 242, 194],\n",
      "        [ 58, 186,  79, 194],\n",
      "        [529, 180, 615, 243],\n",
      "        [510, 194, 531, 202],\n",
      "        [457, 180, 489, 202],\n",
      "        [ 19, 186,  36, 193],\n",
      "        [160, 352, 279, 470],\n",
      "        [250, 190, 271, 198],\n",
      "        [  3, 187,  23, 195],\n",
      "        [313, 189, 339, 198],\n",
      "        [616, 192, 638, 205],\n",
      "        [ 98, 191, 115, 198],\n",
      "        [269, 330, 344, 379],\n",
      "        [ 47,  31, 374, 171],\n",
      "        [326, 189, 527, 207],\n",
      "        [ 91, 187, 111, 194]], dtype=torch.int32), 'scores': tensor([0.3258, 0.3490, 0.1945, 0.5325, 0.2267, 0.2331, 0.6251, 0.3192, 0.2530,\n",
      "        0.2038, 0.4458, 0.4644, 0.2498, 0.4439, 0.3599, 0.1915, 0.2322, 0.9974,\n",
      "        0.2290, 0.2339]), 'objectness_scores': tensor([0.3775, 0.3639, 0.2511, 0.2129, 0.2940, 0.2919, 0.2576, 0.2421, 0.2114,\n",
      "        0.2267, 0.2204, 0.3595, 0.2227, 0.3105, 0.2435, 0.2028, 0.2435, 0.4373,\n",
      "        0.2793, 0.2887]), 'labels': tensor([11, 11, 14, 11, 11, 14,  8, 14,  6, 14,  9, 11, 14, 11, 11, 11,  7,  6,\n",
      "         0, 14], dtype=torch.int32)}\n",
      "549930\n",
      "{'image_id': 550322, 'boxes': tensor([[ 76, 159, 223, 393],\n",
      "        [ 67, 306, 268, 538],\n",
      "        [  1, 481, 208, 639],\n",
      "        [122, 340, 139, 360]], dtype=torch.int32), 'scores': tensor([0.9675, 0.4663, 0.4031, 0.1849]), 'objectness_scores': tensor([0.5599, 0.4400, 0.2991, 0.2268]), 'labels': tensor([16, 11,  7,  8], dtype=torch.int32)}\n",
      "550322\n",
      "{'image_id': 550349, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "550349\n",
      "{'image_id': 550691, 'boxes': tensor([[194,  54, 439, 407],\n",
      "        [126,  24, 192, 293]], dtype=torch.int32), 'scores': tensor([0.9977, 0.1775]), 'objectness_scores': tensor([0.6128, 0.2035]), 'labels': tensor([1, 6], dtype=torch.int32)}\n",
      "550691\n",
      "{'image_id': 551660, 'boxes': tensor([[ 17, 297,  30, 310],\n",
      "        [249, 447, 276, 471],\n",
      "        [  6,  11, 414, 633],\n",
      "        [ 75, 236,  94, 249],\n",
      "        [147,  16, 416, 634],\n",
      "        [ 51,   7, 153, 121]], dtype=torch.int32), 'scores': tensor([0.2125, 0.2388, 0.4352, 0.2582, 0.3620, 0.7781]), 'objectness_scores': tensor([0.2054, 0.2012, 0.3438, 0.2184, 0.3649, 0.5641]), 'labels': tensor([11,  7, 11, 11, 11, 10], dtype=torch.int32)}\n",
      "551660\n",
      "{'image_id': 551815, 'boxes': tensor([[102, 280, 640, 479],\n",
      "        [248, 122, 639, 461]], dtype=torch.int32), 'scores': tensor([0.9308, 0.9592]), 'objectness_scores': tensor([0.2740, 0.4209]), 'labels': tensor([2, 2], dtype=torch.int32)}\n",
      "551815\n",
      "{'image_id': 551822, 'boxes': tensor([[ 25, 192, 621, 441],\n",
      "        [216,  22, 325, 193],\n",
      "        [102,  90, 217, 185],\n",
      "        [ 91,  27, 218, 185],\n",
      "        [  5, 128, 637, 453]], dtype=torch.int32), 'scores': tensor([0.6616, 0.8113, 0.9019, 0.8502, 0.9093]), 'objectness_scores': tensor([0.4291, 0.4878, 0.2033, 0.4978, 0.4211]), 'labels': tensor([12, 10, 10, 10, 12], dtype=torch.int32)}\n",
      "551822\n",
      "{'image_id': 552775, 'boxes': tensor([[132, 342, 292, 424],\n",
      "        [292, 275, 352, 287],\n",
      "        [137, 150, 203, 229],\n",
      "        [136, 116, 374, 195],\n",
      "        [ 74, 217, 243, 298],\n",
      "        [ 81, 231, 220, 285],\n",
      "        [226, 243, 375, 315]], dtype=torch.int32), 'scores': tensor([0.6582, 0.7422, 0.4639, 0.8517, 0.8277, 0.6708, 0.4318]), 'objectness_scores': tensor([0.2377, 0.2791, 0.6214, 0.2358, 0.2974, 0.2303, 0.5840]), 'labels': tensor([12, 11, 10, 14, 12, 12, 15], dtype=torch.int32)}\n",
      "552775\n",
      "{'image_id': 553664, 'boxes': tensor([[289, 214, 302, 229],\n",
      "        [ 55, 228, 133, 259],\n",
      "        [293, 217, 303, 229],\n",
      "        [303, 217, 312, 229],\n",
      "        [289, 145, 312, 230],\n",
      "        [  3, 221, 636, 368]], dtype=torch.int32), 'scores': tensor([0.2871, 0.2312, 0.2288, 0.2012, 0.4672, 0.2955]), 'objectness_scores': tensor([0.3342, 0.2041, 0.2545, 0.2871, 0.2157, 0.3949]), 'labels': tensor([ 7, 16,  7, 11, 11, 13], dtype=torch.int32)}\n",
      "553664\n",
      "{'image_id': 554002, 'boxes': tensor([[257, 308, 354, 336],\n",
      "        [429,  81, 619, 357]], dtype=torch.int32), 'scores': tensor([0.2585, 0.9796]), 'objectness_scores': tensor([0.2142, 0.3997]), 'labels': tensor([7, 3], dtype=torch.int32)}\n",
      "554002\n",
      "{'image_id': 554291, 'boxes': tensor([[501, 285, 639, 415],\n",
      "        [472, 306, 516, 386],\n",
      "        [593, 300, 641, 371],\n",
      "        [  1, 224, 634, 428],\n",
      "        [208,  68, 487, 425]], dtype=torch.int32), 'scores': tensor([0.3243, 0.3436, 0.8193, 0.8018, 0.4583]), 'objectness_scores': tensor([0.2048, 0.4810, 0.3102, 0.4752, 0.4439]), 'labels': tensor([16, 11, 11,  2,  2], dtype=torch.int32)}\n",
      "554291\n",
      "{'image_id': 554579, 'boxes': tensor([[176, 118, 333, 390],\n",
      "        [207, 339, 406, 603],\n",
      "        [208, 119, 293, 246],\n",
      "        [123,  93, 241, 451],\n",
      "        [  8, 143, 196, 530]], dtype=torch.int32), 'scores': tensor([0.8438, 0.9812, 0.7261, 0.8060, 0.6635]), 'objectness_scores': tensor([0.2437, 0.3777, 0.2145, 0.2149, 0.2034]), 'labels': tensor([7, 3, 7, 7, 7], dtype=torch.int32)}\n",
      "554579\n",
      "{'image_id': 555005, 'boxes': tensor([[132,  78, 538, 182],\n",
      "        [528,  73, 638, 254],\n",
      "        [319, 205, 539, 286]], dtype=torch.int32), 'scores': tensor([0.3590, 0.6284, 0.2710]), 'objectness_scores': tensor([0.3228, 0.2728, 0.3624]), 'labels': tensor([ 3,  7, 16], dtype=torch.int32)}\n",
      "555005\n",
      "{'image_id': 555009, 'boxes': tensor([[214, 161, 295, 208],\n",
      "        [472, 115, 492, 131],\n",
      "        [169, 211, 351, 274],\n",
      "        [ 99, 268, 180, 337],\n",
      "        [  1, 186, 496, 371],\n",
      "        [219, 161, 230, 183],\n",
      "        [447, 226, 473, 250],\n",
      "        [235, 244, 377, 347],\n",
      "        [416, 195, 451, 239]], dtype=torch.int32), 'scores': tensor([0.3812, 0.2603, 0.2354, 0.5000, 0.7167, 0.3051, 0.3598, 0.1970, 0.1419]), 'objectness_scores': tensor([0.2445, 0.2411, 0.6886, 0.4091, 0.3557, 0.2389, 0.2997, 0.6435, 0.2565]), 'labels': tensor([11, 11, 14, 12, 14, 11, 14,  7,  8], dtype=torch.int32)}\n",
      "555009\n",
      "{'image_id': 555050, 'boxes': tensor([[103,  77, 120, 111],\n",
      "        [  3,  51,  36, 131],\n",
      "        [122,  78, 136, 113],\n",
      "        [ 54,  91,  70, 166],\n",
      "        [  4, 214,  17, 225],\n",
      "        [200, 104, 218, 137],\n",
      "        [146, 114, 184, 139],\n",
      "        [194,  88, 217, 137],\n",
      "        [436,  85, 459, 148],\n",
      "        [ 11, 168,  22, 186],\n",
      "        [220, 171, 278, 222],\n",
      "        [286,  78, 486, 104]], dtype=torch.int32), 'scores': tensor([0.2022, 0.4631, 0.2251, 0.2951, 0.2385, 0.2285, 0.2179, 0.1812, 0.4977,\n",
      "        0.1763, 0.9960, 0.3387]), 'objectness_scores': tensor([0.5234, 0.5880, 0.3574, 0.2120, 0.2786, 0.2364, 0.2114, 0.4982, 0.5607,\n",
      "        0.2377, 0.6136, 0.2344]), 'labels': tensor([11,  8, 11, 11,  1,  0,  7,  9,  8,  0,  4,  7], dtype=torch.int32)}\n",
      "555050\n",
      "{'image_id': 555972, 'boxes': tensor([[111,  77, 343, 321],\n",
      "        [110, 174, 327, 322]], dtype=torch.int32), 'scores': tensor([0.7385, 0.7449]), 'objectness_scores': tensor([0.3628, 0.2207]), 'labels': tensor([10, 10], dtype=torch.int32)}\n",
      "555972\n",
      "{'image_id': 557172, 'boxes': tensor([[ 65,   4, 116, 363],\n",
      "        [ 92, 382, 127, 460],\n",
      "        [245, 303, 278, 313],\n",
      "        [321, 325, 335, 335],\n",
      "        [356,  78, 380, 101],\n",
      "        [274, 294, 306, 342],\n",
      "        [352, 241, 389, 300],\n",
      "        [260, 351, 486, 478],\n",
      "        [528, 268, 546, 298],\n",
      "        [267,   0, 490, 322],\n",
      "        [251, 288, 289, 305],\n",
      "        [337, 296, 468, 330],\n",
      "        [108, 275, 264, 363],\n",
      "        [248, 288, 293, 313],\n",
      "        [373, 348, 398, 360],\n",
      "        [188, 262, 210, 278],\n",
      "        [361, 201, 383, 222],\n",
      "        [220, 263, 231, 278],\n",
      "        [343, 246, 357, 254],\n",
      "        [385, 239, 406, 290],\n",
      "        [235, 269, 243, 279],\n",
      "        [451,  32, 480, 283],\n",
      "        [328, 321, 373, 375],\n",
      "        [345, 176, 354, 191],\n",
      "        [ 97,  -4, 492, 348],\n",
      "        [438, 250, 450, 275],\n",
      "        [111, 277, 264, 327]], dtype=torch.int32), 'scores': tensor([0.3243, 0.4716, 0.2979, 0.4399, 0.2080, 0.4500, 0.1571, 0.9975, 0.3175,\n",
      "        0.5758, 0.2750, 0.3691, 0.9743, 0.2238, 0.3488, 0.5100, 0.2620, 0.2323,\n",
      "        0.1875, 0.2861, 0.2148, 0.5904, 0.3057, 0.1783, 0.9134, 0.4260, 0.2286]), 'objectness_scores': tensor([0.2969, 0.2557, 0.2082, 0.2246, 0.3052, 0.4457, 0.3719, 0.5852, 0.5336,\n",
      "        0.2444, 0.2625, 0.2567, 0.5078, 0.2668, 0.5368, 0.5058, 0.2473, 0.4657,\n",
      "        0.2172, 0.3881, 0.2054, 0.3017, 0.5633, 0.2016, 0.4327, 0.4316, 0.3106]), 'labels': tensor([ 7,  7, 14, 11, 11, 11,  3, 15, 11, 15, 11, 11, 15, 14, 11, 11, 11, 11,\n",
      "        14, 11, 11, 11, 15,  0, 15, 11, 14], dtype=torch.int32)}\n",
      "557172\n",
      "{'image_id': 557672, 'boxes': tensor([[189,  19, 617, 262]], dtype=torch.int32), 'scores': tensor([0.9786]), 'objectness_scores': tensor([0.5928]), 'labels': tensor([6], dtype=torch.int32)}\n",
      "557672\n",
      "{'image_id': 558114, 'boxes': tensor([[540,  59, 582,  96]], dtype=torch.int32), 'scores': tensor([0.3544]), 'objectness_scores': tensor([0.2109]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "558114\n",
      "{'image_id': 558213, 'boxes': tensor([[121, 322, 142, 328]], dtype=torch.int32), 'scores': tensor([0.1419]), 'objectness_scores': tensor([0.3393]), 'labels': tensor([10], dtype=torch.int32)}\n",
      "558213\n",
      "{'image_id': 558854, 'boxes': tensor([[  3,  39, 497, 374],\n",
      "        [357,  11, 496, 197],\n",
      "        [175,  50, 260,  88],\n",
      "        [ 37, 119, 121, 161],\n",
      "        [165,  65, 351, 175],\n",
      "        [373,  34, 466,  60],\n",
      "        [185,  39, 312,  95],\n",
      "        [428,   0, 498, 107],\n",
      "        [215, 201, 420, 353],\n",
      "        [ 27, 159, 214, 287]], dtype=torch.int32), 'scores': tensor([0.3349, 0.9900, 0.2462, 0.8550, 0.2632, 0.2936, 0.6225, 0.9485, 0.8033,\n",
      "        0.3900]), 'objectness_scores': tensor([0.3913, 0.4608, 0.3675, 0.2671, 0.4677, 0.2159, 0.3717, 0.3287, 0.3690,\n",
      "        0.3322]), 'labels': tensor([ 4, 10, 11, 12, 10, 11,  4, 10, 12, 12], dtype=torch.int32)}\n",
      "558854\n",
      "{'image_id': 559160, 'boxes': tensor([[231, 226, 341, 393]], dtype=torch.int32), 'scores': tensor([0.2511]), 'objectness_scores': tensor([0.2689]), 'labels': tensor([7], dtype=torch.int32)}\n",
      "559160\n",
      "{'image_id': 559513, 'boxes': tensor([[366, 264, 412, 314],\n",
      "        [ 35, 252, 175, 374],\n",
      "        [ 61,  68, 254, 222],\n",
      "        [405, 188, 499, 295],\n",
      "        [471, 205, 516, 274],\n",
      "        [494, 296, 595, 368],\n",
      "        [  4, 116, 636, 420],\n",
      "        [251, 103, 546, 221],\n",
      "        [  3, 194, 638, 404],\n",
      "        [344, 129, 485, 207],\n",
      "        [406, 187, 486, 258],\n",
      "        [300,  94, 364, 155],\n",
      "        [ 72,   0, 177,  95],\n",
      "        [412, 305, 523, 366],\n",
      "        [545, 198, 599, 262],\n",
      "        [163, 205, 219, 272],\n",
      "        [202, 167, 390, 412],\n",
      "        [460, 273, 571, 309],\n",
      "        [463, 235, 578, 310],\n",
      "        [405, 286, 524, 367],\n",
      "        [246,   0, 298,  84],\n",
      "        [358, 212, 405, 245]], dtype=torch.int32), 'scores': tensor([0.1904, 0.7933, 0.6152, 0.2344, 0.2639, 0.2544, 0.2184, 0.5611, 0.3218,\n",
      "        0.4640, 0.4215, 0.3132, 0.1641, 0.2422, 0.4050, 0.5336, 0.2687, 0.7050,\n",
      "        0.3147, 0.2281, 0.4013, 0.7270]), 'objectness_scores': tensor([0.2415, 0.3397, 0.3786, 0.4865, 0.3677, 0.4228, 0.3852, 0.2615, 0.3784,\n",
      "        0.2294, 0.2552, 0.4332, 0.3041, 0.2906, 0.2741, 0.3457, 0.3329, 0.4069,\n",
      "        0.3929, 0.4546, 0.2005, 0.2326]), 'labels': tensor([ 4, 12, 10, 12, 12, 11, 12, 10, 12, 12, 12, 12, 16, 11, 11, 12, 12, 11,\n",
      "         7, 11, 10, 11], dtype=torch.int32)}\n",
      "559513\n",
      "{'image_id': 559543, 'boxes': tensor([[ 89, 200, 130, 222],\n",
      "        [ 15, 237, 109, 332],\n",
      "        [128, 201, 194, 223],\n",
      "        [199, 109, 223, 186],\n",
      "        [229, 179, 286, 266],\n",
      "        [  5, 154,  78, 261],\n",
      "        [398, 153, 431, 177],\n",
      "        [ 64, 159, 224, 303],\n",
      "        [410, 234, 492, 269],\n",
      "        [332, 160, 500, 332],\n",
      "        [289, 201, 363, 287],\n",
      "        [  5, 155,  77, 208],\n",
      "        [348, 127, 373, 179],\n",
      "        [167,   3, 298, 194],\n",
      "        [293, 239, 363, 288]], dtype=torch.int32), 'scores': tensor([0.5755, 0.4013, 0.4351, 0.2646, 0.4459, 0.7511, 0.2560, 0.9711, 0.4965,\n",
      "        0.9563, 0.4156, 0.6917, 0.1891, 0.3426, 0.3116]), 'objectness_scores': tensor([0.2450, 0.2042, 0.2652, 0.2074, 0.2059, 0.2767, 0.2304, 0.3902, 0.2125,\n",
      "        0.3702, 0.2070, 0.2674, 0.2894, 0.2138, 0.2194]), 'labels': tensor([11,  8, 11,  7, 16,  7, 11, 13,  7, 13, 13, 10,  7,  7, 13],\n",
      "       dtype=torch.int32)}\n",
      "559543\n",
      "{'image_id': 559842, 'boxes': tensor([[295, 325, 327, 359],\n",
      "        [209, 184, 236, 212],\n",
      "        [ 35, 174,  65, 203],\n",
      "        [310, 172, 328, 186],\n",
      "        [190, 101, 209, 107],\n",
      "        [178, 141, 190, 161],\n",
      "        [345,  99, 373, 116],\n",
      "        [ 25, 204,  92, 277],\n",
      "        [399, 174, 486, 304],\n",
      "        [571, 112, 591, 118],\n",
      "        [188,  85, 210, 101],\n",
      "        [569,  97, 596, 113],\n",
      "        [280, 109, 301, 134],\n",
      "        [550, 176, 637, 305]], dtype=torch.int32), 'scores': tensor([0.3202, 0.2929, 0.1611, 0.1374, 0.1954, 0.2635, 0.2564, 0.2686, 0.4690,\n",
      "        0.2551, 0.1790, 0.2119, 0.1984, 0.5196]), 'objectness_scores': tensor([0.6199, 0.2762, 0.3126, 0.2130, 0.2884, 0.3333, 0.2884, 0.2073, 0.4528,\n",
      "        0.2543, 0.2724, 0.2929, 0.2956, 0.4785]), 'labels': tensor([ 6,  8,  3,  9, 11, 11, 11,  5,  7, 11, 11, 11,  6,  9],\n",
      "       dtype=torch.int32)}\n",
      "559842\n",
      "{'image_id': 560011, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "560011\n",
      "{'image_id': 560312, 'boxes': tensor([[ 34,  58, 222, 355]], dtype=torch.int32), 'scores': tensor([0.2217]), 'objectness_scores': tensor([0.3562]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "560312\n",
      "{'image_id': 560474, 'boxes': tensor([[498,  47, 518,  54],\n",
      "        [179,  61, 194,  68],\n",
      "        [485,   0, 638,  63],\n",
      "        [272,  38, 336,  75]], dtype=torch.int32), 'scores': tensor([0.3285, 0.1487, 0.5879, 0.4392]), 'objectness_scores': tensor([0.2099, 0.2150, 0.2250, 0.2658]), 'labels': tensor([11, 11,  7, 11], dtype=torch.int32)}\n",
      "560474\n",
      "{'image_id': 560880, 'boxes': tensor([[246, 286, 262, 295]], dtype=torch.int32), 'scores': tensor([0.2278]), 'objectness_scores': tensor([0.4174]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "560880\n",
      "{'image_id': 560911, 'boxes': tensor([[ -1, 141, 481, 466],\n",
      "        [227, 125, 250, 154]], dtype=torch.int32), 'scores': tensor([0.8831, 0.1785]), 'objectness_scores': tensor([0.4716, 0.4186]), 'labels': tensor([13, 11], dtype=torch.int32)}\n",
      "560911\n",
      "{'image_id': 561256, 'boxes': tensor([[533, 205, 598, 271],\n",
      "        [517, 310, 637, 351],\n",
      "        [105,  15, 160, 105],\n",
      "        [384, 169, 448, 186],\n",
      "        [388, 224, 419, 251],\n",
      "        [192,  74, 240, 139],\n",
      "        [322, 319, 636, 457],\n",
      "        [232, 195, 285, 284],\n",
      "        [325, 410, 346, 419],\n",
      "        [324, 422, 345, 441],\n",
      "        [475, 226, 482, 237],\n",
      "        [323,  58, 379, 128],\n",
      "        [322, 410, 344, 425],\n",
      "        [489, 357, 633, 455],\n",
      "        [531, 320, 542, 327],\n",
      "        [467, 275, 500, 296],\n",
      "        [331, 254, 549, 483],\n",
      "        [366, 120, 472, 199],\n",
      "        [509, 193, 523, 290],\n",
      "        [374, 135, 420, 182],\n",
      "        [576, 302, 587, 320],\n",
      "        [544,  32, 602, 108],\n",
      "        [542, 303, 555, 322],\n",
      "        [420, 207, 470, 248],\n",
      "        [434,  45, 486, 116],\n",
      "        [462, 258, 497, 289]], dtype=torch.int32), 'scores': tensor([0.6114, 0.9009, 0.4375, 0.3724, 0.3228, 0.5960, 0.4199, 0.6081, 0.4078,\n",
      "        0.5231, 0.2691, 0.4054, 0.4040, 0.5681, 0.3487, 0.3186, 0.4452, 0.2377,\n",
      "        0.5150, 0.2360, 0.3823, 0.3969, 0.5688, 0.1965, 0.3866, 0.4608]), 'objectness_scores': tensor([0.3015, 0.5635, 0.3375, 0.3255, 0.5655, 0.3446, 0.2736, 0.2115, 0.3136,\n",
      "        0.4796, 0.5143, 0.3705, 0.3481, 0.2295, 0.2048, 0.2828, 0.2705, 0.3234,\n",
      "        0.2095, 0.2130, 0.3086, 0.3912, 0.4927, 0.6100, 0.3953, 0.3959]), 'labels': tensor([ 7, 15, 16,  7,  2,  6,  7,  7, 11, 14, 11,  6, 11,  7, 11, 11,  7,  7,\n",
      "        11,  7, 11,  6, 11, 11,  6,  7], dtype=torch.int32)}\n",
      "561256\n",
      "{'image_id': 561465, 'boxes': tensor([[513,   0, 607, 118],\n",
      "        [ -1,   1, 532, 276],\n",
      "        [191, 245, 607, 610],\n",
      "        [  0, 269, 137, 612]], dtype=torch.int32), 'scores': tensor([0.4680, 0.9275, 0.4659, 0.7565]), 'objectness_scores': tensor([0.3088, 0.3467, 0.2977, 0.2293]), 'labels': tensor([ 2, 12, 12, 10], dtype=torch.int32)}\n",
      "561465\n",
      "{'image_id': 561889, 'boxes': tensor([[277, 250, 313, 271],\n",
      "        [287, 277, 331, 335],\n",
      "        [122,  16, 503, 448],\n",
      "        [448, 258, 479, 345],\n",
      "        [180,  22, 336, 176],\n",
      "        [330, 172, 417, 255],\n",
      "        [132,  89, 243, 259],\n",
      "        [358, 386, 381, 443],\n",
      "        [370, 335, 385, 392],\n",
      "        [378, 371, 429, 411],\n",
      "        [  5,   0, 637, 477],\n",
      "        [411, 231, 430, 293]], dtype=torch.int32), 'scores': tensor([0.3501, 0.3461, 0.2692, 0.2894, 0.3648, 0.6370, 0.4089, 0.5429, 0.5823,\n",
      "        0.6183, 0.5453, 0.1696]), 'objectness_scores': tensor([0.2557, 0.2939, 0.2043, 0.3307, 0.3486, 0.2564, 0.2424, 0.2593, 0.2116,\n",
      "        0.2707, 0.3234, 0.3021]), 'labels': tensor([11, 11, 11, 11, 12, 12, 12,  7,  7,  7, 12,  7], dtype=torch.int32)}\n",
      "561889\n",
      "{'image_id': 561958, 'boxes': tensor([[385, 219, 420, 247],\n",
      "        [404, 171, 422, 186],\n",
      "        [296, 228, 320, 247],\n",
      "        [341, 174, 358, 191],\n",
      "        [457, 162, 476, 177],\n",
      "        [366, 273, 375, 372],\n",
      "        [497, 187, 506, 195]], dtype=torch.int32), 'scores': tensor([0.4503, 0.2060, 0.2223, 0.1912, 0.3931, 0.5171, 0.2278]), 'objectness_scores': tensor([0.2154, 0.2087, 0.2373, 0.2000, 0.2073, 0.2292, 0.2187]), 'labels': tensor([ 8,  3,  8, 11, 11, 11, 11], dtype=torch.int32)}\n",
      "561958\n",
      "{'image_id': 562059, 'boxes': tensor([[  1,  72, 194, 306],\n",
      "        [260, 303, 274, 318],\n",
      "        [215, 243, 232, 260],\n",
      "        [335, 182, 352, 198],\n",
      "        [150, 317, 163, 330],\n",
      "        [254, 258, 268, 271],\n",
      "        [303, 196, 324, 213],\n",
      "        [174, 257, 191, 276],\n",
      "        [416, 170, 427, 183],\n",
      "        [372, 296, 389, 311],\n",
      "        [416, 248, 426, 258],\n",
      "        [166, 285, 181, 301],\n",
      "        [285, 305, 301, 321],\n",
      "        [159, 317, 176, 335],\n",
      "        [158, 258, 176, 280],\n",
      "        [318, 276, 335, 291],\n",
      "        [318, 225, 337, 242],\n",
      "        [370, 218, 385, 235],\n",
      "        [194, 229, 213, 244],\n",
      "        [364, 177, 378, 188],\n",
      "        [255, 265, 271, 281],\n",
      "        [353, 276, 368, 288],\n",
      "        [385, 181, 402, 199],\n",
      "        [  0, 414, 422, 618],\n",
      "        [  0,  48, 425, 616],\n",
      "        [331, 268, 347, 284],\n",
      "        [131, 169, 428, 418],\n",
      "        [  4,  -2, 424, 625],\n",
      "        [323, 357, 342, 372],\n",
      "        [288, 340, 306, 353],\n",
      "        [261, 294, 276, 307],\n",
      "        [186, 356, 206, 378]], dtype=torch.int32), 'scores': tensor([0.9942, 0.2397, 0.2896, 0.1945, 0.2355, 0.1804, 0.2601, 0.2743, 0.2522,\n",
      "        0.4367, 0.2624, 0.2324, 0.2087, 0.2386, 0.2397, 0.3649, 0.5542, 0.4914,\n",
      "        0.1808, 0.2947, 0.2787, 0.2350, 0.2549, 0.6136, 0.7622, 0.2761, 0.9807,\n",
      "        0.7498, 0.2457, 0.2197, 0.1740, 0.3511]), 'objectness_scores': tensor([0.5833, 0.3977, 0.4517, 0.3827, 0.3197, 0.3412, 0.4460, 0.4220, 0.3791,\n",
      "        0.4871, 0.3516, 0.4482, 0.4542, 0.4733, 0.3652, 0.4452, 0.4337, 0.3759,\n",
      "        0.4106, 0.2600, 0.4329, 0.4248, 0.4046, 0.3706, 0.2994, 0.4188, 0.3918,\n",
      "        0.3034, 0.3144, 0.3990, 0.3371, 0.4478]), 'labels': tensor([10, 11, 12, 14, 14, 11, 11, 12, 11, 12, 11, 11, 12, 12, 11, 12, 11, 12,\n",
      "         6, 11, 11,  6, 14,  7, 12, 11, 12, 12, 11, 11, 14, 11],\n",
      "       dtype=torch.int32)}\n",
      "562059\n",
      "{'image_id': 562207, 'boxes': tensor([[211,  67, 407, 406],\n",
      "        [110, 302, 122, 309],\n",
      "        [194, 229, 229, 293],\n",
      "        [212,  66, 406, 410]], dtype=torch.int32), 'scores': tensor([0.9989, 0.1985, 0.2510, 0.9989]), 'objectness_scores': tensor([0.7148, 0.4790, 0.2529, 0.3820]), 'labels': tensor([ 5, 14,  7,  5], dtype=torch.int32)}\n",
      "562207\n",
      "{'image_id': 562229, 'boxes': tensor([[255, 497, 421, 585],\n",
      "        [173, 249, 193, 279],\n",
      "        [320, 124, 382, 170],\n",
      "        [280, 332, 299, 344]], dtype=torch.int32), 'scores': tensor([0.3677, 0.5444, 0.1464, 0.2568]), 'objectness_scores': tensor([0.6520, 0.2113, 0.2680, 0.3192]), 'labels': tensor([ 8,  7,  8, 11], dtype=torch.int32)}\n",
      "562229\n",
      "{'image_id': 562243, 'boxes': tensor([[ 89, 279, 564, 637],\n",
      "        [250, 167, 411, 201],\n",
      "        [289, 344, 382, 642]], dtype=torch.int32), 'scores': tensor([0.9992, 0.3310, 0.9996]), 'objectness_scores': tensor([0.2006, 0.4214, 0.5204]), 'labels': tensor([ 7, 11,  7], dtype=torch.int32)}\n",
      "562243\n",
      "{'image_id': 562448, 'boxes': tensor([[ 24, 166, 514, 302]], dtype=torch.int32), 'scores': tensor([0.7419]), 'objectness_scores': tensor([0.6474]), 'labels': tensor([1], dtype=torch.int32)}\n",
      "562448\n",
      "{'image_id': 562818, 'boxes': tensor([[  0, 179, 636, 480]], dtype=torch.int32), 'scores': tensor([0.9967]), 'objectness_scores': tensor([0.2430]), 'labels': tensor([8], dtype=torch.int32)}\n",
      "562818\n",
      "{'image_id': 563267, 'boxes': tensor([[ 62, 306,  98, 327],\n",
      "        [241, 109, 262, 116],\n",
      "        [215, 247, 273, 271],\n",
      "        [451, 242, 467, 264],\n",
      "        [247, 266, 261, 272],\n",
      "        [184, 229, 501, 373]], dtype=torch.int32), 'scores': tensor([0.3365, 0.1340, 0.3026, 0.2748, 0.2058, 0.5079]), 'objectness_scores': tensor([0.4276, 0.2224, 0.2165, 0.3511, 0.3303, 0.2966]), 'labels': tensor([11, 11, 11, 14, 11,  7], dtype=torch.int32)}\n",
      "563267\n",
      "{'image_id': 563349, 'boxes': tensor([[200, 259, 220, 281],\n",
      "        [336, 379, 365, 408],\n",
      "        [224, 250, 245, 264],\n",
      "        [190, 261, 362, 401],\n",
      "        [334, 336, 363, 368],\n",
      "        [186, 252, 215, 283]], dtype=torch.int32), 'scores': tensor([0.4117, 0.9330, 0.2675, 0.9954, 0.1645, 0.4299]), 'objectness_scores': tensor([0.4797, 0.2657, 0.2981, 0.2185, 0.3112, 0.3548]), 'labels': tensor([11,  8,  8,  8, 11,  8], dtype=torch.int32)}\n",
      "563349\n",
      "{'image_id': 563604, 'boxes': tensor([[113, 391, 163, 470],\n",
      "        [  4, 390,  38, 415],\n",
      "        [355, 373, 406, 455],\n",
      "        [ 14, 383,  46, 413],\n",
      "        [523, 317, 602, 370],\n",
      "        [275, 418, 326, 434],\n",
      "        [ 25,  23, 391, 208],\n",
      "        [ 57, 371, 103, 444],\n",
      "        [312, 372, 344, 433]], dtype=torch.int32), 'scores': tensor([0.2557, 0.3157, 0.4686, 0.3319, 0.3263, 0.2146, 0.2639, 0.6435, 0.4242]), 'objectness_scores': tensor([0.6490, 0.2105, 0.5824, 0.2268, 0.3045, 0.2346, 0.3383, 0.6550, 0.2079]), 'labels': tensor([ 9, 11,  7, 11,  8, 11, 14,  7,  1], dtype=torch.int32)}\n",
      "563604\n",
      "{'image_id': 563648, 'boxes': tensor([[  0, 470,  18, 515],\n",
      "        [197, 458, 209, 494],\n",
      "        [ 80, 524, 110, 552],\n",
      "        [  8, 108,  37, 152],\n",
      "        [334, 493, 342, 499],\n",
      "        [147, 488, 165, 535],\n",
      "        [331, 522, 464, 570],\n",
      "        [143, 435, 169, 521],\n",
      "        [  0, 151,  21, 165],\n",
      "        [  0, 512,  33, 565],\n",
      "        [ 28, 377,  83, 488],\n",
      "        [330, 407, 383, 438],\n",
      "        [147, 432, 156, 442],\n",
      "        [ 93, 339, 122, 396],\n",
      "        [ 41, 555, 117, 579],\n",
      "        [ 26, 235,  86, 266],\n",
      "        [ 13, 122,  36, 151],\n",
      "        [102, 458, 126, 547],\n",
      "        [  0, 468,  34, 566],\n",
      "        [153, 486, 170, 502],\n",
      "        [ 82, 477, 125, 551],\n",
      "        [153, 439, 165, 447],\n",
      "        [217, 283, 288, 345],\n",
      "        [248, 284, 286, 316],\n",
      "        [138, 471, 160, 537],\n",
      "        [  1, 172,  62, 213],\n",
      "        [ 42, 186,  61, 202],\n",
      "        [103, 461, 124, 528],\n",
      "        [ 78, 489, 114, 518],\n",
      "        [148, 499, 164, 528],\n",
      "        [ 64, 265, 113, 303],\n",
      "        [  1, 378,  88, 564],\n",
      "        [101, 499, 126, 549],\n",
      "        [447, 292, 467, 318],\n",
      "        [237, 205, 261, 225]], dtype=torch.int32), 'scores': tensor([0.2110, 0.3950, 0.1455, 0.2527, 0.2230, 0.2044, 0.4108, 0.2500, 0.4896,\n",
      "        0.1673, 0.5225, 0.3441, 0.1707, 0.3236, 0.4038, 0.9371, 0.2151, 0.2092,\n",
      "        0.2683, 0.4107, 0.4722, 0.1437, 0.8126, 0.1956, 0.1950, 0.3856, 0.2164,\n",
      "        0.1757, 0.3426, 0.2680, 0.2535, 0.4541, 0.5145, 0.3583, 0.2714]), 'objectness_scores': tensor([0.2411, 0.3728, 0.2111, 0.2569, 0.2013, 0.2105, 0.2430, 0.2450, 0.2973,\n",
      "        0.2743, 0.3486, 0.2196, 0.2395, 0.2127, 0.2224, 0.3999, 0.2789, 0.2808,\n",
      "        0.2220, 0.2841, 0.3056, 0.2785, 0.5383, 0.2387, 0.2410, 0.3854, 0.2063,\n",
      "        0.2039, 0.2246, 0.2108, 0.4033, 0.4793, 0.2736, 0.2467, 0.3594]), 'labels': tensor([ 8, 11,  7, 11, 11, 11, 14,  3, 11, 11,  8,  8, 11, 11,  8,  6, 13,  2,\n",
      "        11, 11,  9, 11,  9, 11, 11,  7,  7,  7,  9,  7, 11,  7,  2, 11, 11],\n",
      "       dtype=torch.int32)}\n",
      "563648\n",
      "{'image_id': 564280, 'boxes': tensor([[204, 162, 226, 213],\n",
      "        [ 35,   0, 238, 328],\n",
      "        [ 88,  10, 599, 408],\n",
      "        [342,  47, 560, 215],\n",
      "        [192, 110, 274, 178],\n",
      "        [  0,   1,  83, 382]], dtype=torch.int32), 'scores': tensor([0.5348, 0.7688, 0.8033, 0.5845, 0.3553, 0.3898]), 'objectness_scores': tensor([0.2148, 0.3207, 0.5506, 0.3295, 0.3662, 0.2805]), 'labels': tensor([16,  3,  3,  3,  3,  7], dtype=torch.int32)}\n",
      "564280\n",
      "{'image_id': 565391, 'boxes': tensor([[ 11, 239, 116, 285],\n",
      "        [364, 398, 432, 481],\n",
      "        [155, 221, 274, 274],\n",
      "        [427, 224, 480, 283],\n",
      "        [187, 277, 346, 321]], dtype=torch.int32), 'scores': tensor([0.4070, 0.5744, 0.5996, 0.3889, 0.8305]), 'objectness_scores': tensor([0.3138, 0.2422, 0.3186, 0.2316, 0.5260]), 'labels': tensor([11, 15, 11, 11,  2], dtype=torch.int32)}\n",
      "565391\n",
      "{'image_id': 565776, 'boxes': tensor([[570, 185, 579, 190],\n",
      "        [221, 211, 281, 312],\n",
      "        [292, 184, 316, 205],\n",
      "        [ 14,   0, 138, 197],\n",
      "        [312, 132, 331, 176],\n",
      "        [337, 243, 355, 312],\n",
      "        [517, 174, 539, 230],\n",
      "        [542, 264, 616, 292],\n",
      "        [124, 257, 157, 418],\n",
      "        [161,  72, 240, 208],\n",
      "        [ 29, 272, 123, 418],\n",
      "        [ 76, 113, 123, 158],\n",
      "        [ 92, 170, 134, 233],\n",
      "        [286, 201, 350, 226],\n",
      "        [458, 264, 535, 292],\n",
      "        [ 77,  72, 104,  99],\n",
      "        [401, 193, 434, 209],\n",
      "        [ 28, 224, 109, 264],\n",
      "        [312, 132, 325, 171],\n",
      "        [365, 185, 380, 204],\n",
      "        [152, 229, 199, 403],\n",
      "        [343, 226, 638, 411],\n",
      "        [398, 216, 454, 229],\n",
      "        [197, 222, 220, 336],\n",
      "        [356, 256, 637, 417],\n",
      "        [ 98, 228, 180, 243]], dtype=torch.int32), 'scores': tensor([0.1969, 0.2540, 0.3306, 0.2371, 0.3966, 0.9755, 0.2167, 0.3623, 0.1849,\n",
      "        0.3857, 0.1891, 0.3213, 0.4365, 0.7644, 0.4084, 0.9051, 0.5260, 0.4182,\n",
      "        0.2204, 0.3671, 0.3874, 0.6365, 0.3327, 0.3233, 0.3483, 0.4389]), 'objectness_scores': tensor([0.2390, 0.2746, 0.3681, 0.2490, 0.2708, 0.2424, 0.3845, 0.2122, 0.2478,\n",
      "        0.2043, 0.2191, 0.2067, 0.3610, 0.2004, 0.2065, 0.3148, 0.2163, 0.2655,\n",
      "        0.2054, 0.2402, 0.2121, 0.2172, 0.2868, 0.2822, 0.2086, 0.2733]), 'labels': tensor([11,  7, 10, 13, 11,  7,  8, 14,  9,  8,  7, 10, 13, 14, 14, 10, 14,  6,\n",
      "        11,  7,  7, 15, 14, 11, 15, 14], dtype=torch.int32)}\n",
      "565776\n",
      "{'image_id': 565877, 'boxes': tensor([[  0, 198, 288, 531],\n",
      "        [118, 146, 224, 187],\n",
      "        [275, 188, 426, 502],\n",
      "        [100,  70, 238, 162],\n",
      "        [133, 491, 168, 536],\n",
      "        [266, 487, 275, 498]], dtype=torch.int32), 'scores': tensor([0.5455, 0.2652, 0.5867, 0.3370, 0.2688, 0.1628]), 'objectness_scores': tensor([0.2947, 0.2412, 0.2326, 0.3039, 0.5482, 0.2499]), 'labels': tensor([ 7,  7,  7,  7, 11, 11], dtype=torch.int32)}\n",
      "565877\n",
      "{'image_id': 565962, 'boxes': tensor([[151,  63, 478, 321]], dtype=torch.int32), 'scores': tensor([0.9681]), 'objectness_scores': tensor([0.5287]), 'labels': tensor([2], dtype=torch.int32)}\n",
      "565962\n",
      "{'image_id': 565989, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "565989\n",
      "{'image_id': 566282, 'boxes': tensor([[359, 304, 387, 339],\n",
      "        [ 47, 284,  85, 318],\n",
      "        [385, 312, 405, 342],\n",
      "        [376,  58, 419, 135],\n",
      "        [447, 151, 461, 162],\n",
      "        [620, 200, 637, 231],\n",
      "        [100, 324, 152, 374],\n",
      "        [164, 347, 196, 370]], dtype=torch.int32), 'scores': tensor([0.3464, 0.7518, 0.5670, 0.5162, 0.2779, 0.4928, 0.5030, 0.2983]), 'objectness_scores': tensor([0.2504, 0.2658, 0.2431, 0.5871, 0.5554, 0.3477, 0.6605, 0.2382]), 'labels': tensor([11, 11,  2,  7, 11, 14, 10, 11], dtype=torch.int32)}\n",
      "566282\n",
      "{'image_id': 566758, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "566758\n",
      "{'image_id': 567898, 'boxes': tensor([[315,  83, 337, 109],\n",
      "        [ 84, 226, 313, 454],\n",
      "        [  2,   2, 637, 451],\n",
      "        [459, 325, 501, 363]], dtype=torch.int32), 'scores': tensor([0.2122, 0.3651, 0.9618, 0.2594]), 'objectness_scores': tensor([0.2141, 0.3323, 0.2735, 0.2279]), 'labels': tensor([12,  4, 12, 11], dtype=torch.int32)}\n",
      "567898\n",
      "{'image_id': 568195, 'boxes': tensor([[192, 214, 341, 406],\n",
      "        [ 91, 392, 120, 419],\n",
      "        [187, 459, 327, 510],\n",
      "        [328, 431, 422, 471],\n",
      "        [231, 204, 281, 272],\n",
      "        [109, 439, 196, 479],\n",
      "        [  0, 338,   7, 370],\n",
      "        [264, 431, 274, 439],\n",
      "        [197, 417, 316, 498],\n",
      "        [252, 419, 262, 428],\n",
      "        [  0, 443, 422, 636],\n",
      "        [221, 418, 230, 425]], dtype=torch.int32), 'scores': tensor([0.2707, 0.3132, 0.6786, 0.6186, 0.1865, 0.3871, 0.3034, 0.2067, 0.9980,\n",
      "        0.1656, 0.7632, 0.2318]), 'objectness_scores': tensor([0.2494, 0.3581, 0.2191, 0.2264, 0.4375, 0.3001, 0.2345, 0.2055, 0.5580,\n",
      "        0.2007, 0.2757, 0.2132]), 'labels': tensor([ 7,  7, 12, 10,  7, 10, 11,  6, 12,  7, 12, 14], dtype=torch.int32)}\n",
      "568195\n",
      "{'image_id': 568290, 'boxes': tensor([[196, 136, 427, 299],\n",
      "        [159, 218, 187, 245]], dtype=torch.int32), 'scores': tensor([0.9980, 0.3068]), 'objectness_scores': tensor([0.6250, 0.2937]), 'labels': tensor([ 1, 14], dtype=torch.int32)}\n",
      "568290\n",
      "{'image_id': 568439, 'boxes': tensor([[218, 111, 373, 311],\n",
      "        [507, 210, 517, 238],\n",
      "        [392, 187, 424, 229],\n",
      "        [420, 189, 442, 264],\n",
      "        [463, 208, 475, 258]], dtype=torch.int32), 'scores': tensor([0.9988, 0.2264, 0.8465, 0.2305, 0.1607]), 'objectness_scores': tensor([0.4961, 0.3100, 0.2112, 0.3346, 0.2158]), 'labels': tensor([ 1, 14,  1, 14, 11], dtype=torch.int32)}\n",
      "568439\n",
      "{'image_id': 568584, 'boxes': tensor([[  0, 164, 286, 427],\n",
      "        [ 46,   0, 207, 168],\n",
      "        [259,   1, 377, 370]], dtype=torch.int32), 'scores': tensor([0.9355, 0.4369, 0.4499]), 'objectness_scores': tensor([0.4097, 0.2022, 0.2321]), 'labels': tensor([13,  6,  6], dtype=torch.int32)}\n",
      "568584\n",
      "{'image_id': 568690, 'boxes': tensor([[136, 187, 282, 323],\n",
      "        [442, 283, 473, 341],\n",
      "        [352,  71, 405, 148],\n",
      "        [336,   4, 480, 453],\n",
      "        [438,  94, 473, 163],\n",
      "        [367, 239, 391, 290],\n",
      "        [422,   8, 459,  76],\n",
      "        [414, 285, 473, 346],\n",
      "        [395, 149, 422, 214],\n",
      "        [455, 377, 472, 396],\n",
      "        [390, 315, 425, 365],\n",
      "        [339, 260, 363, 311]], dtype=torch.int32), 'scores': tensor([0.9767, 0.2655, 0.2476, 0.7147, 0.2271, 0.2633, 0.1869, 0.4712, 0.4402,\n",
      "        0.8614, 0.2183, 0.3460]), 'objectness_scores': tensor([0.4737, 0.2047, 0.2389, 0.2821, 0.2065, 0.3279, 0.2461, 0.4673, 0.2489,\n",
      "        0.2759, 0.3114, 0.3524]), 'labels': tensor([ 2,  7,  9,  7, 11, 14, 11,  6,  7, 11, 11,  7], dtype=torch.int32)}\n",
      "568690\n",
      "{'image_id': 568710, 'boxes': tensor([[ 75, 178, 115, 208],\n",
      "        [427, 131, 454, 138],\n",
      "        [147,  27, 195, 215],\n",
      "        [ 71, 205, 121, 288],\n",
      "        [  3, 306, 515, 425],\n",
      "        [507,  16, 542, 123],\n",
      "        [402, 183, 637, 382],\n",
      "        [330, 249, 338, 263]], dtype=torch.int32), 'scores': tensor([0.8622, 0.2042, 0.4738, 0.4294, 0.4833, 0.2261, 0.9965, 0.1703]), 'objectness_scores': tensor([0.4005, 0.3072, 0.4413, 0.2040, 0.3332, 0.2044, 0.3851, 0.2492]), 'labels': tensor([10, 14, 11,  7, 13,  7, 13, 14], dtype=torch.int32)}\n",
      "568710\n",
      "{'image_id': 568814, 'boxes': tensor([[518, 324, 541, 343]], dtype=torch.int32), 'scores': tensor([0.6006]), 'objectness_scores': tensor([0.6463]), 'labels': tensor([11], dtype=torch.int32)}\n",
      "568814\n",
      "{'image_id': 568981, 'boxes': tensor([[222, 181, 273, 216],\n",
      "        [582, 219, 640, 244],\n",
      "        [590,   7, 619,  38]], dtype=torch.int32), 'scores': tensor([0.4346, 0.6485, 0.3521]), 'objectness_scores': tensor([0.2969, 0.5914, 0.2409]), 'labels': tensor([11,  9,  9], dtype=torch.int32)}\n",
      "568981\n",
      "{'image_id': 569059, 'boxes': tensor([[243, 267, 437, 338],\n",
      "        [407, 213, 491, 254],\n",
      "        [ 78,  72, 169, 142],\n",
      "        [ 79,  71, 172, 235],\n",
      "        [ 81, 257, 161, 292],\n",
      "        [ 56, 140, 100, 241],\n",
      "        [262, 186, 289, 223],\n",
      "        [ 38, 181, 612, 472],\n",
      "        [435, 110, 475, 195]], dtype=torch.int32), 'scores': tensor([0.9947, 0.7425, 0.4615, 0.3311, 0.4177, 0.4075, 0.3973, 0.9812, 0.6129]), 'objectness_scores': tensor([0.3889, 0.2352, 0.2108, 0.2215, 0.2022, 0.2803, 0.2083, 0.2851, 0.2503]), 'labels': tensor([14, 14,  7,  7, 14,  7,  2, 14, 11], dtype=torch.int32)}\n",
      "569059\n",
      "{'image_id': 569917, 'boxes': tensor([[163,   1, 344, 170],\n",
      "        [  1,   6, 480, 638],\n",
      "        [134, 471, 192, 637],\n",
      "        [189, 143, 197, 155],\n",
      "        [453,  69, 479, 129],\n",
      "        [269,  58, 308, 107],\n",
      "        [190, 231, 251, 266],\n",
      "        [219, 443, 475, 642],\n",
      "        [215, 369, 417, 459],\n",
      "        [135, 317, 478, 536],\n",
      "        [229, 340, 299, 385],\n",
      "        [321, 307, 351, 361],\n",
      "        [277, 220, 338, 248]], dtype=torch.int32), 'scores': tensor([0.4889, 0.9832, 0.4490, 0.1767, 0.1861, 0.3189, 0.2684, 0.9384, 0.9956,\n",
      "        0.9989, 0.3707, 0.4422, 0.2444]), 'objectness_scores': tensor([0.5369, 0.2335, 0.3703, 0.2155, 0.2419, 0.2972, 0.2958, 0.2765, 0.3790,\n",
      "        0.2672, 0.5751, 0.2226, 0.2506]), 'labels': tensor([12, 15,  7, 11,  7, 15,  9, 15, 15, 15,  9,  7,  9], dtype=torch.int32)}\n",
      "569917\n",
      "{'image_id': 570456, 'boxes': tensor([[ 76, 212,  94, 232],\n",
      "        [ 45, 251,  95, 277],\n",
      "        [352, 344, 398, 393],\n",
      "        [376, 268, 407, 303],\n",
      "        [293, 292, 434, 431],\n",
      "        [433, 304, 511, 362],\n",
      "        [339, 297, 381, 343],\n",
      "        [269, 201, 311, 248],\n",
      "        [470, 235, 502, 261],\n",
      "        [319, 314, 355, 356],\n",
      "        [146, 374, 184, 420]], dtype=torch.int32), 'scores': tensor([0.2332, 0.3330, 0.6128, 0.2097, 0.9773, 0.4236, 0.9063, 0.2518, 0.6354,\n",
      "        0.6285, 0.8065]), 'objectness_scores': tensor([0.2289, 0.2870, 0.2349, 0.2272, 0.4192, 0.2811, 0.2002, 0.5256, 0.2565,\n",
      "        0.2266, 0.3349]), 'labels': tensor([ 7, 14, 11, 12, 13,  7, 13, 13, 13, 11, 10], dtype=torch.int32)}\n",
      "570456\n",
      "{'image_id': 570471, 'boxes': tensor([[156,   0, 244,  72],\n",
      "        [342, 228, 355, 240],\n",
      "        [ 51, 414, 147, 482],\n",
      "        [  0, 368, 107, 453],\n",
      "        [ 29,   0, 138,  46],\n",
      "        [  0, 328,  44, 381],\n",
      "        [ 22, 231,  75, 311],\n",
      "        [  1, 323,  80, 377],\n",
      "        [ 93,  75, 117, 106],\n",
      "        [ 50, 417, 154, 500],\n",
      "        [ 99, 184, 193, 247],\n",
      "        [ 52, 414, 146, 478]], dtype=torch.int32), 'scores': tensor([0.8671, 0.3361, 0.9174, 0.9942, 0.1862, 0.9714, 0.8851, 0.9977, 0.6484,\n",
      "        0.9841, 0.3278, 0.9804]), 'objectness_scores': tensor([0.2094, 0.4410, 0.2412, 0.4185, 0.2150, 0.2246, 0.3542, 0.2185, 0.4315,\n",
      "        0.2767, 0.3488, 0.2646]), 'labels': tensor([14, 11, 12, 12,  8, 12, 10, 12, 11, 12, 14, 12], dtype=torch.int32)}\n",
      "570471\n",
      "{'image_id': 570539, 'boxes': tensor([[177, 130, 266, 186],\n",
      "        [ 37, 148,  79, 191]], dtype=torch.int32), 'scores': tensor([0.3628, 0.2146]), 'objectness_scores': tensor([0.3593, 0.3979]), 'labels': tensor([ 7, 10], dtype=torch.int32)}\n",
      "570539\n",
      "{'image_id': 570664, 'boxes': tensor([[390,   2, 432,  61],\n",
      "        [178,  11, 363, 171],\n",
      "        [181,  44, 214,  75],\n",
      "        [ 61, 161, 290, 252],\n",
      "        [196, 224, 240, 269],\n",
      "        [125, 206, 176, 260],\n",
      "        [144, 311, 177, 333],\n",
      "        [126, 230, 177, 260],\n",
      "        [183, 195, 230, 228],\n",
      "        [ 62, 224, 116, 250],\n",
      "        [170, 135, 190, 165],\n",
      "        [ 75, 146, 102, 180],\n",
      "        [255, 249, 321, 333],\n",
      "        [281, 113, 455, 334],\n",
      "        [141, 110, 187, 130],\n",
      "        [412,   0, 501, 311],\n",
      "        [ 10,   0,  40,  39],\n",
      "        [140, 206, 163, 236],\n",
      "        [101, 145, 141, 170],\n",
      "        [136,   0, 221, 117],\n",
      "        [320,  50, 336,  65],\n",
      "        [443, 231, 491, 296],\n",
      "        [ 51, 208,  79, 234]], dtype=torch.int32), 'scores': tensor([0.3623, 0.9691, 0.1690, 0.7364, 0.3412, 0.6150, 0.4443, 0.3374, 0.6026,\n",
      "        0.2128, 0.3241, 0.5549, 0.8447, 0.9775, 0.2916, 0.7241, 0.9339, 0.2557,\n",
      "        0.5453, 0.3472, 0.5054, 0.8743, 0.4297]), 'objectness_scores': tensor([0.5444, 0.5233, 0.2982, 0.4457, 0.3090, 0.2608, 0.2563, 0.2944, 0.3221,\n",
      "        0.3759, 0.3774, 0.3424, 0.4833, 0.5153, 0.3567, 0.2307, 0.2199, 0.2264,\n",
      "        0.4287, 0.3605, 0.3634, 0.2066, 0.3377]), 'labels': tensor([14,  2, 11,  9,  9,  9, 11,  9,  9,  9, 11,  9,  2,  2,  9,  7,  7,  7,\n",
      "        11,  2, 11,  2,  7], dtype=torch.int32)}\n",
      "570664\n",
      "{'image_id': 570736, 'boxes': tensor([[306, 306, 344, 367],\n",
      "        [262,   0, 425, 285],\n",
      "        [383, 453, 420, 485],\n",
      "        [291,  50, 329, 117],\n",
      "        [ 81, 304, 106, 335],\n",
      "        [  7, 377, 164, 500],\n",
      "        [  0,  72, 158, 128],\n",
      "        [367,   8, 425,  46],\n",
      "        [384, 336, 401, 362],\n",
      "        [295, 314, 312, 330],\n",
      "        [332, 369, 425, 398],\n",
      "        [  2,   8, 424, 637],\n",
      "        [263, 129, 285, 147],\n",
      "        [ 80, 357, 102, 374],\n",
      "        [344, 255, 366, 270],\n",
      "        [  7, 376, 166, 584]], dtype=torch.int32), 'scores': tensor([0.3153, 0.4221, 0.3966, 0.2359, 0.2940, 0.9441, 0.3278, 0.2667, 0.2817,\n",
      "        0.5510, 0.7100, 0.9677, 0.3652, 0.2678, 0.6472, 0.9549]), 'objectness_scores': tensor([0.3535, 0.4417, 0.2743, 0.3024, 0.2115, 0.2013, 0.2400, 0.2341, 0.3818,\n",
      "        0.2422, 0.3803, 0.3034, 0.2053, 0.2661, 0.2632, 0.5252]), 'labels': tensor([11, 15, 11,  7, 11, 15,  6,  9, 11, 14, 11, 15, 11, 11, 14, 15],\n",
      "       dtype=torch.int32)}\n",
      "570736\n",
      "{'image_id': 570782, 'boxes': tensor([[169,  83, 270, 232],\n",
      "        [306, 201, 484, 251],\n",
      "        [430, 115, 471, 204],\n",
      "        [  0, 187, 570, 426]], dtype=torch.int32), 'scores': tensor([0.1880, 0.9953, 0.2621, 0.9831]), 'objectness_scores': tensor([0.2147, 0.2239, 0.3393, 0.2716]), 'labels': tensor([16, 14, 10, 14], dtype=torch.int32)}\n",
      "570782\n",
      "{'image_id': 571313, 'boxes': tensor([[  6, 348, 123, 394],\n",
      "        [247, 447, 315, 497],\n",
      "        [  0, 331, 189, 584],\n",
      "        [189, 402, 233, 501],\n",
      "        [336, 373, 383, 442],\n",
      "        [423, 239, 434, 259],\n",
      "        [131, 313, 245, 363],\n",
      "        [292, 425, 365, 469],\n",
      "        [  6, 563, 169, 640]], dtype=torch.int32), 'scores': tensor([0.2700, 0.8026, 0.2443, 0.2597, 0.2008, 0.1921, 0.1916, 0.4670, 0.1761]), 'objectness_scores': tensor([0.7103, 0.2234, 0.2563, 0.2468, 0.2885, 0.2428, 0.3670, 0.2156, 0.2348]), 'labels': tensor([14, 14,  1,  7,  7, 14, 12, 15, 10], dtype=torch.int32)}\n",
      "571313\n",
      "{'image_id': 571598, 'boxes': tensor([[154, 423, 171, 451],\n",
      "        [ 59, 316, 110, 479],\n",
      "        [  5, 291, 144, 479],\n",
      "        [512, 286, 564, 478]], dtype=torch.int32), 'scores': tensor([0.1507, 0.9732, 0.9996, 0.6841]), 'objectness_scores': tensor([0.2195, 0.2552, 0.2031, 0.2358]), 'labels': tensor([11,  7,  7,  7], dtype=torch.int32)}\n",
      "571598\n",
      "{'image_id': 571804, 'boxes': tensor([[439, 217, 462, 264],\n",
      "        [  2,  64,  72, 165]], dtype=torch.int32), 'scores': tensor([0.5182, 0.3606]), 'objectness_scores': tensor([0.2541, 0.2656]), 'labels': tensor([11,  7], dtype=torch.int32)}\n",
      "571804\n",
      "{'image_id': 571857, 'boxes': tensor([[182, 220, 194, 229],\n",
      "        [330, 184, 440, 216],\n",
      "        [125, 226, 134, 230],\n",
      "        [183, 228, 194, 232],\n",
      "        [344, 216, 499, 286],\n",
      "        [126, 278, 136, 284],\n",
      "        [188, 291, 200, 298],\n",
      "        [178, 292, 189, 299],\n",
      "        [ -1, 156, 493, 263],\n",
      "        [275, 187, 430, 230],\n",
      "        [116, 294, 126, 300],\n",
      "        [110, 171, 323, 287],\n",
      "        [  0, 189,  86, 226],\n",
      "        [271, 190, 310, 204],\n",
      "        [124, 220, 135, 228],\n",
      "        [130, 246, 136, 255],\n",
      "        [444, 191, 497, 207]], dtype=torch.int32), 'scores': tensor([0.2616, 0.5912, 0.2526, 0.1850, 0.7964, 0.1685, 0.1417, 0.1338, 0.9635,\n",
      "        0.9793, 0.1572, 0.3896, 0.4814, 0.2109, 0.2025, 0.1882, 0.5304]), 'objectness_scores': tensor([0.2740, 0.2110, 0.3074, 0.2750, 0.6244, 0.2298, 0.2748, 0.2740, 0.4129,\n",
      "        0.4796, 0.2239, 0.2428, 0.4449, 0.4092, 0.2639, 0.2913, 0.4694]), 'labels': tensor([11,  0, 11, 11,  6, 11, 11, 14,  0,  0, 11,  0,  0,  0, 11, 11,  0],\n",
      "       dtype=torch.int32)}\n",
      "571857\n",
      "{'image_id': 572388, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "572388\n",
      "{'image_id': 572408, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "572408\n",
      "{'image_id': 572462, 'boxes': tensor([[502, 401, 531, 426],\n",
      "        [265, 403, 281, 414],\n",
      "        [442, 380, 463, 401],\n",
      "        [403,   7, 602, 299],\n",
      "        [357, 436, 398, 467],\n",
      "        [371, 405, 398, 432]], dtype=torch.int32), 'scores': tensor([0.2255, 0.2268, 0.2086, 0.4628, 0.2029, 0.2774]), 'objectness_scores': tensor([0.2153, 0.2119, 0.2102, 0.2602, 0.3404, 0.2766]), 'labels': tensor([11, 11,  7,  8, 11,  7], dtype=torch.int32)}\n",
      "572462\n",
      "{'image_id': 572620, 'boxes': tensor([[483, 283, 496, 294],\n",
      "        [276, 279, 303, 298],\n",
      "        [310, 108, 339, 127],\n",
      "        [451, 196, 460, 201],\n",
      "        [495, 190, 505, 196],\n",
      "        [431, 259, 447, 275],\n",
      "        [163, 252, 171, 257],\n",
      "        [593, 368, 640, 402],\n",
      "        [ 23, 369,  56, 402],\n",
      "        [468, 315, 483, 325],\n",
      "        [113, 323, 150, 334],\n",
      "        [367, 131, 372, 138],\n",
      "        [ 93, 337, 121, 368],\n",
      "        [557, 155, 579, 168],\n",
      "        [127, 298, 135, 304],\n",
      "        [299, 207, 394, 278],\n",
      "        [526, 303, 551, 323],\n",
      "        [353, 225, 384, 241],\n",
      "        [495, 196, 509, 206],\n",
      "        [540, 322, 574, 339],\n",
      "        [248, 237, 262, 246],\n",
      "        [443, 196, 458, 211],\n",
      "        [411, 216, 417, 221],\n",
      "        [328, 270, 353, 289],\n",
      "        [250, 240, 256, 245],\n",
      "        [517, 306, 534, 323],\n",
      "        [140, 325, 150, 331],\n",
      "        [428, 265, 439, 279],\n",
      "        [558, 329, 602, 353],\n",
      "        [287, 293, 297, 299],\n",
      "        [445, 314, 466, 325],\n",
      "        [465, 197, 476, 204],\n",
      "        [447, 186, 466, 198],\n",
      "        [332, 233, 386, 290],\n",
      "        [ 53, 246,  67, 255],\n",
      "        [  6, 261,  18, 269],\n",
      "        [494, 189, 513, 204]], dtype=torch.int32), 'scores': tensor([0.1581, 0.5142, 0.1940, 0.2336, 0.3504, 0.3273, 0.3557, 0.6502, 0.4050,\n",
      "        0.1948, 0.5046, 0.2475, 0.2550, 0.3757, 0.3179, 0.9697, 0.3923, 0.2970,\n",
      "        0.1760, 0.2918, 0.2004, 0.2153, 0.2076, 0.2222, 0.2261, 0.2973, 0.2627,\n",
      "        0.2085, 0.4442, 0.2843, 0.1231, 0.7354, 0.1609, 0.9456, 0.3042, 0.3090,\n",
      "        0.2275]), 'objectness_scores': tensor([0.2178, 0.4882, 0.4477, 0.2317, 0.2473, 0.2882, 0.3213, 0.2922, 0.2734,\n",
      "        0.2605, 0.3230, 0.3634, 0.2313, 0.2460, 0.3789, 0.2007, 0.2308, 0.2791,\n",
      "        0.4329, 0.2137, 0.2227, 0.5322, 0.3803, 0.2802, 0.2898, 0.2124, 0.2063,\n",
      "        0.2703, 0.2291, 0.2104, 0.2408, 0.3922, 0.3896, 0.5269, 0.2933, 0.2784,\n",
      "        0.2268]), 'labels': tensor([13, 11,  6, 10, 11, 11, 11,  8, 11, 11, 11, 10,  9, 11, 11,  9, 11, 11,\n",
      "         6, 11, 11, 11, 10,  8, 11,  8, 11, 11,  9, 11,  2,  6,  4,  9, 11,  8,\n",
      "        10], dtype=torch.int32)}\n",
      "572620\n",
      "{'image_id': 572678, 'boxes': tensor([[475, 293, 530, 320],\n",
      "        [226, 190, 257, 225],\n",
      "        [292, 157, 315, 206],\n",
      "        [461, 298, 536, 327],\n",
      "        [380, 203, 389, 261],\n",
      "        [188, 196, 209, 228],\n",
      "        [161, 217, 320, 327],\n",
      "        [199, 235, 559, 423],\n",
      "        [ 37,  89, 201, 280],\n",
      "        [451, 240, 476, 291],\n",
      "        [279, 346, 383, 389],\n",
      "        [305, 297, 328, 347],\n",
      "        [339, 271, 377, 292],\n",
      "        [142, 195, 317, 285],\n",
      "        [  1, 200, 110, 312],\n",
      "        [392, 391, 431, 425],\n",
      "        [313, 231, 384, 284],\n",
      "        [208, 192, 230, 228]], dtype=torch.int32), 'scores': tensor([0.1437, 0.5544, 0.2594, 0.2656, 0.2080, 0.1861, 0.9263, 0.3890, 0.2524,\n",
      "        0.1753, 0.4555, 0.3131, 0.2063, 0.8757, 0.7044, 0.1645, 0.8325, 0.3086]), 'objectness_scores': tensor([0.3217, 0.2113, 0.2027, 0.2205, 0.4068, 0.2504, 0.3304, 0.3069, 0.2888,\n",
      "        0.2309, 0.3897, 0.2588, 0.3301, 0.3679, 0.2516, 0.2199, 0.2012, 0.2317]), 'labels': tensor([ 3, 13, 11, 11, 11,  3, 13, 15, 16, 11, 15, 10, 11, 13, 15, 11, 15, 11],\n",
      "       dtype=torch.int32)}\n",
      "572678\n",
      "{'image_id': 573094, 'boxes': tensor([[244, 128, 342, 278],\n",
      "        [ 67, 257,  77, 276],\n",
      "        [168,  40, 316,  91],\n",
      "        [181, 286, 297, 381],\n",
      "        [192, 304, 205, 328],\n",
      "        [ 47, 250, 168, 328],\n",
      "        [136, 121, 190, 284],\n",
      "        [218,  78, 256,  99],\n",
      "        [185, 238, 223, 290],\n",
      "        [265, 285, 375, 416]], dtype=torch.int32), 'scores': tensor([0.1458, 0.1336, 0.2349, 0.4877, 0.2165, 0.2657, 0.2230, 0.4346, 0.5538,\n",
      "        0.2259]), 'objectness_scores': tensor([0.5939, 0.2254, 0.8099, 0.5217, 0.2620, 0.3386, 0.3069, 0.3603, 0.2902,\n",
      "        0.2173]), 'labels': tensor([ 8, 11, 15,  9, 11, 13,  9, 11,  8,  6], dtype=torch.int32)}\n",
      "573094\n",
      "{'image_id': 574315, 'boxes': tensor([[183, 101, 430, 341],\n",
      "        [  0,   0, 222, 246],\n",
      "        [  4,  -2, 637, 479],\n",
      "        [145, 345, 510, 477]], dtype=torch.int32), 'scores': tensor([0.9842, 0.6565, 0.8058, 0.9987]), 'objectness_scores': tensor([0.5029, 0.2217, 0.4479, 0.5995]), 'labels': tensor([ 2,  2,  2, 14], dtype=torch.int32)}\n",
      "574315\n",
      "{'image_id': 575243, 'boxes': tensor([[182, 119, 189, 129],\n",
      "        [270,  44, 290, 151],\n",
      "        [244, 141, 369, 227],\n",
      "        [339,  41, 353,  58],\n",
      "        [609, 104, 623, 116],\n",
      "        [356,  69, 367,  85],\n",
      "        [439,  73, 512, 128],\n",
      "        [435,  78, 453,  93],\n",
      "        [326,  45, 341,  82]], dtype=torch.int32), 'scores': tensor([0.1748, 0.3226, 0.5115, 0.2417, 0.1973, 0.1855, 0.3696, 0.2642, 0.2807]), 'objectness_scores': tensor([0.2655, 0.2023, 0.6212, 0.2156, 0.2204, 0.2535, 0.3375, 0.2177, 0.3587]), 'labels': tensor([14, 11,  9, 11, 11, 11,  0, 11, 11], dtype=torch.int32)}\n",
      "575243\n",
      "{'image_id': 575357, 'boxes': tensor([[329, 185, 378, 233],\n",
      "        [249, 158, 617, 359]], dtype=torch.int32), 'scores': tensor([0.2814, 0.8348]), 'objectness_scores': tensor([0.3505, 0.5797]), 'labels': tensor([7, 3], dtype=torch.int32)}\n",
      "575357\n",
      "{'image_id': 575970, 'boxes': tensor([[258, 101, 280, 119],\n",
      "        [438, 201, 446, 215],\n",
      "        [271, 204, 351, 248],\n",
      "        [144, 226, 151, 234],\n",
      "        [ 63, 165,  86, 290],\n",
      "        [241, 105, 263, 119],\n",
      "        [349, 193, 362, 231],\n",
      "        [243, 261, 641, 442],\n",
      "        [365, 256, 472, 277]], dtype=torch.int32), 'scores': tensor([0.2734, 0.1869, 0.2741, 0.1556, 0.4422, 0.2083, 0.1513, 0.3864, 0.1624]), 'objectness_scores': tensor([0.2345, 0.2986, 0.2359, 0.2133, 0.2167, 0.2546, 0.2619, 0.2380, 0.3382]), 'labels': tensor([ 2, 14,  7,  3,  7, 11, 11, 10,  2], dtype=torch.int32)}\n",
      "575970\n",
      "{'image_id': 576566, 'boxes': tensor([[248, 380, 289, 436],\n",
      "        [137, 312, 197, 354],\n",
      "        [ 65, 525, 143, 548],\n",
      "        [129, 488, 209, 624]], dtype=torch.int32), 'scores': tensor([0.1701, 0.2879, 0.4611, 0.6024]), 'objectness_scores': tensor([0.2428, 0.2592, 0.2685, 0.4694]), 'labels': tensor([ 2,  0, 11,  9], dtype=torch.int32)}\n",
      "576566\n",
      "{'image_id': 577932, 'boxes': tensor([[ 85, 138,  99, 177],\n",
      "        [545,   0, 611,  67],\n",
      "        [ 81, 185, 100, 203],\n",
      "        [315, 167, 401, 248],\n",
      "        [559, 114, 609, 164],\n",
      "        [476,  28, 516,  85],\n",
      "        [314, 168, 400, 201],\n",
      "        [514,  11, 547,  56],\n",
      "        [605, 381, 632, 440]], dtype=torch.int32), 'scores': tensor([0.3120, 0.3906, 0.2579, 0.9290, 0.2883, 0.4567, 0.2242, 0.4510, 0.6831]), 'objectness_scores': tensor([0.2872, 0.2305, 0.2291, 0.2228, 0.2223, 0.2987, 0.2211, 0.2860, 0.2146]), 'labels': tensor([ 7,  7, 14,  6,  7, 16,  8,  7,  7], dtype=torch.int32)}\n",
      "577932\n",
      "{'image_id': 578489, 'boxes': tensor([[515, 142, 612, 332],\n",
      "        [121, 146, 413, 415]], dtype=torch.int32), 'scores': tensor([0.9493, 0.9598]), 'objectness_scores': tensor([0.3289, 0.3432]), 'labels': tensor([ 7, 13], dtype=torch.int32)}\n",
      "578489\n",
      "{'image_id': 578500, 'boxes': tensor([[356,  71, 424, 131],\n",
      "        [331,  56, 358,  97],\n",
      "        [496, 108, 639, 290],\n",
      "        [  0, 150,  76, 290],\n",
      "        [138,  67, 169, 114],\n",
      "        [400, 159, 438, 185],\n",
      "        [418,  22, 466, 113],\n",
      "        [319, 153, 337, 172],\n",
      "        [564, 181, 639, 217],\n",
      "        [458, 176, 525, 245],\n",
      "        [263, 183, 342, 249],\n",
      "        [311, 149, 468, 241],\n",
      "        [479, 104, 534, 180],\n",
      "        [  0,  86,  37, 121],\n",
      "        [355, 161, 380, 177],\n",
      "        [274, 140, 327, 198],\n",
      "        [299, 125, 321, 153]], dtype=torch.int32), 'scores': tensor([0.3472, 0.2442, 0.9968, 0.4343, 0.2052, 0.3762, 0.2433, 0.2176, 0.3120,\n",
      "        0.5767, 0.2413, 0.9962, 0.1708, 0.2655, 0.4292, 0.3757, 0.3220]), 'objectness_scores': tensor([0.3488, 0.2159, 0.3784, 0.2960, 0.2362, 0.2286, 0.2467, 0.2324, 0.2553,\n",
      "        0.2086, 0.2831, 0.4425, 0.2597, 0.2347, 0.2083, 0.2560, 0.2535]), 'labels': tensor([13,  7, 13, 13,  7,  6,  6, 11, 13, 13, 12, 13, 10, 13,  7, 10,  6],\n",
      "       dtype=torch.int32)}\n",
      "578500\n",
      "{'image_id': 578922, 'boxes': tensor([[316, 501, 426, 640],\n",
      "        [329, 293, 594, 488],\n",
      "        [440, 258, 466, 278],\n",
      "        [  0,   4, 526, 579],\n",
      "        [220, 482, 304, 621],\n",
      "        [465, 256, 492, 276],\n",
      "        [379, 293, 451, 399]], dtype=torch.int32), 'scores': tensor([0.9765, 0.4838, 0.3145, 0.2018, 0.3715, 0.4467, 0.4443]), 'objectness_scores': tensor([0.3777, 0.2046, 0.2698, 0.4049, 0.2252, 0.2842, 0.4105]), 'labels': tensor([10, 12, 12, 15, 16, 11, 10], dtype=torch.int32)}\n",
      "578922\n",
      "{'image_id': 579070, 'boxes': tensor([[365, 356, 412, 426],\n",
      "        [ 15,  36,  29,  56],\n",
      "        [253,  56, 274,  99],\n",
      "        [150, 201, 172, 226],\n",
      "        [167, 230, 190, 257],\n",
      "        [122, 334, 178, 386],\n",
      "        [ 59, 239,  95, 288],\n",
      "        [ 77, 220, 110, 270],\n",
      "        [380, 332, 410, 371],\n",
      "        [488, 345, 557, 425],\n",
      "        [  4, 263,  34, 286],\n",
      "        [212, 220, 290, 340],\n",
      "        [  4, 280,  34, 313],\n",
      "        [ 35, 266,  64, 299],\n",
      "        [193, 219, 215, 246],\n",
      "        [401, 316, 430, 351],\n",
      "        [145, 230, 168, 258],\n",
      "        [251, 197, 270, 218],\n",
      "        [457, 244, 502, 305],\n",
      "        [283, 232, 307, 289],\n",
      "        [329, 260, 354, 296],\n",
      "        [ -7, 217, 500, 424],\n",
      "        [103, 293, 273, 426],\n",
      "        [436, 331, 466, 369]], dtype=torch.int32), 'scores': tensor([0.8854, 0.4550, 0.6047, 0.9848, 0.9944, 0.6978, 0.8831, 0.2051, 0.9268,\n",
      "        0.7092, 0.3090, 0.9721, 0.9910, 0.9904, 0.7567, 0.9908, 0.9713, 0.3744,\n",
      "        0.9827, 0.3347, 0.9721, 0.5956, 0.3651, 0.9978]), 'objectness_scores': tensor([0.3275, 0.2662, 0.2403, 0.2952, 0.2957, 0.2770, 0.3205, 0.3130, 0.3583,\n",
      "        0.3565, 0.3458, 0.3175, 0.3034, 0.3144, 0.3048, 0.3687, 0.2977, 0.3764,\n",
      "        0.3446, 0.2771, 0.3334, 0.2126, 0.2133, 0.3336]), 'labels': tensor([10, 11, 10, 10, 10, 10, 10, 11, 10, 10,  8, 10, 10, 10, 10, 10, 10, 11,\n",
      "        10, 11, 10, 10, 10, 10], dtype=torch.int32)}\n",
      "579070\n",
      "{'image_id': 579158, 'boxes': tensor([[ 78, 261, 193, 348],\n",
      "        [  1,   5, 627, 419],\n",
      "        [144,   0, 219, 131]], dtype=torch.int32), 'scores': tensor([0.4875, 0.9856, 0.5154]), 'objectness_scores': tensor([0.2218, 0.4250, 0.4168]), 'labels': tensor([8, 0, 0], dtype=torch.int32)}\n",
      "579158\n",
      "{'image_id': 579321, 'boxes': tensor([[ 96,   0, 235, 179],\n",
      "        [176,   0, 337, 216],\n",
      "        [175, 136, 257, 216],\n",
      "        [320, 109, 370, 269],\n",
      "        [208,  62, 630, 333],\n",
      "        [ 98, 101, 207, 180]], dtype=torch.int32), 'scores': tensor([0.6235, 0.4792, 0.3901, 0.5173, 0.8250, 0.3340]), 'objectness_scores': tensor([0.3049, 0.3221, 0.2695, 0.2638, 0.5020, 0.2658]), 'labels': tensor([7, 7, 3, 7, 3, 7], dtype=torch.int32)}\n",
      "579321\n",
      "{'image_id': 579655, 'boxes': tensor([[  0,  63, 286, 341],\n",
      "        [280, 173, 330, 275]], dtype=torch.int32), 'scores': tensor([0.2403, 0.3028]), 'objectness_scores': tensor([0.2580, 0.5347]), 'labels': tensor([10, 11], dtype=torch.int32)}\n",
      "579655\n",
      "{'image_id': 579902, 'boxes': tensor([[200, 437, 232, 494],\n",
      "        [267, 164, 337, 239],\n",
      "        [315, 431, 355, 500]], dtype=torch.int32), 'scores': tensor([0.2778, 0.9176, 0.2979]), 'objectness_scores': tensor([0.2050, 0.6163, 0.2031]), 'labels': tensor([11,  8,  7], dtype=torch.int32)}\n",
      "579902\n",
      "{'image_id': 579970, 'boxes': tensor([[266, 148, 304, 182],\n",
      "        [156, 152, 257, 258],\n",
      "        [ 29,   2,  85, 262],\n",
      "        [171, 159, 209, 192],\n",
      "        [151, 104, 159, 121],\n",
      "        [150,  55, 162, 103],\n",
      "        [286, 189, 336, 241],\n",
      "        [185, 123, 209, 141],\n",
      "        [206, 152, 230, 193],\n",
      "        [137, 119, 184, 197],\n",
      "        [347, 154, 404, 238],\n",
      "        [159,  64, 166, 103],\n",
      "        [175, 169, 209, 193],\n",
      "        [184, 122, 208, 158],\n",
      "        [334,  95, 363, 136],\n",
      "        [242,  16, 337,  55],\n",
      "        [212, 152, 230, 188],\n",
      "        [123,   0, 164,  36],\n",
      "        [ 60, 282,  68, 306],\n",
      "        [137, 119, 185, 153],\n",
      "        [157, 107, 166, 121],\n",
      "        [ 45, 197,  77, 237],\n",
      "        [143, 199, 231, 274],\n",
      "        [ 38,  30,  51,  44]], dtype=torch.int32), 'scores': tensor([0.5464, 0.9462, 0.5353, 0.4956, 0.2402, 0.6224, 0.2633, 0.4720, 0.2941,\n",
      "        0.3807, 0.4164, 0.4644, 0.2178, 0.3316, 0.4113, 0.7321, 0.2759, 0.4238,\n",
      "        0.2083, 0.3237, 0.2103, 0.2254, 0.2916, 0.3286]), 'objectness_scores': tensor([0.2681, 0.5745, 0.5996, 0.3372, 0.2655, 0.2702, 0.4568, 0.2228, 0.4016,\n",
      "        0.4234, 0.4057, 0.2303, 0.2032, 0.4419, 0.2596, 0.4843, 0.2691, 0.5878,\n",
      "        0.2189, 0.2185, 0.2485, 0.2378, 0.3802, 0.2270]), 'labels': tensor([ 1, 13,  7, 11, 11, 11, 14, 11, 11,  6, 14, 11, 11, 11, 11, 15, 11,  7,\n",
      "        11, 11, 11, 11, 14, 11], dtype=torch.int32)}\n",
      "579970\n",
      "{'image_id': 580197, 'boxes': tensor([[551, 145, 618, 166],\n",
      "        [583, 220, 632, 244],\n",
      "        [173, 222, 233, 249],\n",
      "        [604, 474, 611, 479],\n",
      "        [182, 151, 248, 168],\n",
      "        [213, 269, 223, 285]], dtype=torch.int32), 'scores': tensor([0.1915, 0.2984, 0.4433, 0.1601, 0.2277, 0.2316]), 'objectness_scores': tensor([0.6083, 0.6775, 0.6649, 0.5965, 0.2792, 0.2835]), 'labels': tensor([11, 11,  7,  3, 11, 11], dtype=torch.int32)}\n",
      "580197\n",
      "{'image_id': 580294, 'boxes': tensor([[ 12, 187, 240, 288],\n",
      "        [189,   2, 338, 191],\n",
      "        [350, 267, 409, 294],\n",
      "        [428, 142, 484, 196],\n",
      "        [235,  98, 445, 234],\n",
      "        [ 81, 286, 363, 431]], dtype=torch.int32), 'scores': tensor([0.8036, 0.9589, 0.4796, 0.9870, 0.6047, 0.5196]), 'objectness_scores': tensor([0.4134, 0.2073, 0.2117, 0.2609, 0.2222, 0.2337]), 'labels': tensor([15,  7, 11, 15,  7, 12], dtype=torch.int32)}\n",
      "580294\n",
      "{'image_id': 580410, 'boxes': tensor([[ 22, 248,  84, 314],\n",
      "        [  1, 168,  54, 202],\n",
      "        [  1, 267,  56, 346],\n",
      "        [  0, 262, 132, 500],\n",
      "        [ 75, 350, 426, 638],\n",
      "        [ 46, 252, 122, 334],\n",
      "        [  1, 168,  54, 257]], dtype=torch.int32), 'scores': tensor([0.5950, 0.3256, 0.4757, 0.9203, 0.5896, 0.8242, 0.4101]), 'objectness_scores': tensor([0.2110, 0.2622, 0.2024, 0.3416, 0.3289, 0.2583, 0.2156]), 'labels': tensor([13,  8, 13, 13, 13, 13, 14], dtype=torch.int32)}\n",
      "580410\n",
      "{'image_id': 580418, 'boxes': tensor([[323,  87, 451, 142],\n",
      "        [417, 218, 587, 423]], dtype=torch.int32), 'scores': tensor([0.4970, 0.9985]), 'objectness_scores': tensor([0.2620, 0.5353]), 'labels': tensor([6, 4], dtype=torch.int32)}\n",
      "580418\n",
      "{'image_id': 581062, 'boxes': tensor([[155, 151, 169, 160],\n",
      "        [127, 155, 171, 170],\n",
      "        [132, 154, 142, 163]], dtype=torch.int32), 'scores': tensor([0.3035, 0.2942, 0.1410]), 'objectness_scores': tensor([0.4280, 0.7323, 0.3829]), 'labels': tensor([11, 11, 14], dtype=torch.int32)}\n",
      "581062\n",
      "{'image_id': 581100, 'boxes': tensor([], dtype=torch.int32), 'scores': tensor([]), 'objectness_scores': tensor([]), 'labels': tensor([], dtype=torch.int32)}\n",
      "581100\n",
      "{'image_id': 581357, 'boxes': tensor([[ 66, 267, 103, 322],\n",
      "        [ 20, 261,  35, 274],\n",
      "        [ 25, 337, 107, 359],\n",
      "        [ 49, 327, 123, 518],\n",
      "        [316, 114, 362, 152],\n",
      "        [ 61, 328, 102, 410],\n",
      "        [226, 304, 375, 373]], dtype=torch.int32), 'scores': tensor([0.5424, 0.2476, 0.3671, 0.2039, 0.3240, 0.2632, 0.8979]), 'objectness_scores': tensor([0.4811, 0.2059, 0.2342, 0.6461, 0.3030, 0.2066, 0.6050]), 'labels': tensor([ 7, 11,  7,  7, 12,  6,  9], dtype=torch.int32)}\n",
      "581357\n"
     ]
    }
   ],
   "source": [
    "assert len(preds) == len(shared_coco_val_dataset)\n",
    "for idx in range (len(preds)):\n",
    "    assert preds[idx]['image_id'] == shared_image_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(targets)):\n",
    "    assert targets[idx]['image_id'] == preds[idx]['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAADwCAIAAAD+Tyo8AAEAAElEQVR4Adz9CZilyVXfCd99vzf3ytqrq3dtraW1IxmELAn0gMczRgY8HgYzAmQPGAPjgRmMEQYbvsHGnwGDARswBixWY1uWLYyMhCRja20ktHS3eqs1syr3u+/z+5/zvnHfvJlV3Q0N3/N8UVlxT0ScOHHixIl9edMPfbqTSqWm0+lkMgk2PvlM1/3n7FSmmzaTMQPILziF4tR9smZyuRxOQvNZAlMe5LZH7w+61Up1PBn3eh2AVGpy0Dz41m/91kJ9/Yknnrh+ffPFL37p+omT733vf+71erlsITPpTqbp4WQ8Gk9Gk2kml2ssLjUWF69duTQa9iuV4u725uu+6NVvfesbr1+5AvH8pO/JkThZGxNnOnVOcGLEVioFM/h7kPvM2ZOUYoEWbEeYjiMKc/iZnDKcxHd4OhWFo8YZOOqfmkqqqXRIJQDmfyRC2vGP+It7K98QEvGTGuMDnDaMzFQ6IMxMOikfj2sSEr6bpLg8X1Fcp3DYDkEOZFJjp48z4gQIY/J0MNgkN7Jk5ZMam39Ujs52wISmwyMLMPTIJxX/BuQ4H/rNZSJvYCBnCXg4DQKPSlPYqOl0hF6h4+lUlkTHY1ePzCQ9zmbzRB+bAchmrApMhh7RC9RkI49sSvowMaUIqkGS/eEok87t7TWvXb/ZafdQeNCoTJPRKJ/Pk/RoNCIF6ANj5y7cqQRgPYjAM5QaLbp/MgifXl8KGjwt1ghnr4e3/JMGn0L2eIUrlUrd3hWiU9WJRy0lO3/u9X9+lOqdWa91u3cvLS3t7zdf/Yq7h0Nx2Nrfg+/BeDQckZfJaDrJ5XOl0mjQyE9TmeloWD3RWGsUhq39Sj5VSOdGQ5W3Z0rSROJmyD/UAAnFBnaThGM/+z2MNkNOxD2E/+wdzsxcvIifWSoRq0ED5vD/LJ1HGXafpB34CcgBCEHPBCBWjOZA7Hz2ggikKHqnaT4RHKcS/QbkAHhAPlskOv0BVZWgfB69ylKXxuPheKy6hWcxV8AH3RsNB/lcpP+e5oza8cmmCoXCeDRF51FUkHFCigo8Hg5FcKS6hr94sLRyC5Wac2ZNsKh69nKZLIAbrwYOZzMnARwtCjbnaBh1ZXg6PjZonV7X0YKnO9vtfqvVo/ZWKpm9vb1+v4tZXFirNLr1Wha5gP/4482LF+939shVn0o5pv1OkQ1yOBmrz4dOPpPd29uhH15ZXtreuNLttEArVKqgAdAD03TlcwXqsJPy/Lso3cY/AI4T7LS1lMnQuYgBMwBHkQlKegbMABwN9XSJFuMcBeIQ+43wD/lFDgQOfWzcnpA5Z7DwDuME/IhEHNEQZ3QsdEbZk8DTU/G4IV1ngwENoUkER0tljA75RRHpM41KFCXCOFSBwXJvSDmaJxThGg/B55jkDjMZYgWA3i3AyegZOt7phG6eZKm4plSwO0aA/BELn1yW7jGN5qXj2gupmEhENsrMoTxJ1aCobt2Kg9qRzkXVkJpMBUGl0fmYFD1zLjfoxBTTEc/O+TirIbSbDCgI1qXK0MtiGBUFOLlpUb5BZAFYK9RjMinqnmVTNjSpXIWCPNudXrFY3N7efve7//21nT0A2jO1OpPRlY1NJUAZZYveBEiCZqi32XwhVxgVisW10nq/266UK5Dtj8aVfO6g3fIKTPulNixujoxWpNDAzptSiOHAbRR0pAK7PzTnMN0ZhkO3InhsrOAZYt2qAlshBPQZEKnzzGMGQdMVwr08iZltMWc4hpzEjAlZBZsp4qysnVQyCaK4AniQO0MSc0FO36Mng9wH/QoMGBA5Pb9zNEFwH49yGI7JzH5tCHYLwUWpG3KSKzqFbFZdArMb6DNspJNA0wrZks0aVbvkM+wB5LPZ0Yy+OGfk6+mnJwqIMhdnkV/rclLQ966YMfZgMKDrZbQJQYwrHjUAnHK5nKP6eICybpXbncOBUvII7kMFx0336hxge8awMZms+Zt+4YQzbHB6/VkOQhSAfK6MCMaTbLvThD7snjq1/PFP/EEnU7h8+fKVK5dPnDjxogde8Pu///7BQLKYZIrEYuaAgXI+m6vVao1G4/rGU2RmebHRabWfd/99L37hi8at3qRQrkw13iCIyqsOOJsnOk5spyBCkfzEaoBBSJqMSdzzkvS/PezUkjbJHhvFKYfUZ0DcTMaxougxy7H37Pd4+rPwGIqTED6wRwuRQ2nFIXE0Q3bHYZ4V1QUYbKcc/EMsS04WxpE9KOAHZwACP8HHASgAOCdJH/w8CAB/waaKnuJhTHcdb1sFC6Qcx5yTCT0s80KpEmrvVSbDjDnNAFE1Tf0v+kT1oWcGadbQx4yZ2E3ic9LHj/pl/boNy23aTxL0VKgufTswWXbFhpp64Ec/fxNozsBvtaEZOcZZjBjVCMGEYqJxT5CFl+1HQBxFFZ6Kms0RGAUllJi1KLIMS5VKKZfNDEf9fC5XrhRy+dV6rZPL7uRzlVPrd4yG2Z6tmnndg87U2jxN6zOFTGHU66d2d/eaB/12c//ixbtWT55krqCxck5No8WyIcdU7aKXt7iNJAdelB1Bx5kkpocnlea4GIcIhugBmIsCtRAEEOB4hDiHfoh4MgwqSWeAGex5EiHvBJEKraunFaVobAQcQzhUdyI0Ke2MYUslqoohlTnMQDNi6RZDaEafwjTGtCBlXHrcKOItfpzVYxkO0RUajRwhjHdct6F5KJfzaRzCtJjZLNn3eZx6YFu4UmW+sXXQbDaHw369Xl1aXiiVitQOdRmaxB0qNWIpWePBEw8sAFBLWbeiijJJHA7HmXyOwSkzym67TSdHXPmOx9RcG72ncotLZwLXTtSd++3rwT8JEBkqmGTFBmE6HSb9HQF/5vgeHR8AxwGAAex8njqskjto7uG85+7nX93cOLNaqWTvAHPaO7jz1Kl+X03DoEd/KtYHTOeZEKcnpcwoPWmXsvnl2sJkMpwWC9nppLW7nep3+uNBPm74IE41pin03ImsyQ6azlJw4nPUOH4SM0nhWHz39ChHEW7lA75HcTvm8Vboz8IfguTRyRItmYpgU5+AI4847RDFEovUzD0DTiAIEFLx0EDTg4yIUg9xD9E/3IIEaqQKvkz8KzA2SWrH0k8ii4gZxwQEOL7ZU785C3nvBz4ZJ/ic/b71S199K1rUXobNqD1zbebAaK81AhpXe6Wl6gFjyH7u7EXRQcHJjxTdbHzWM3eYzDTsTPpPxtFs0v09SLHG6tzdk7UjB+Qzms2lcQammd+SfLfbhl2aKuB2u33m9B2nT9XwYc2JnSQauC//86+htmKYTLCINSBrY/5G/VGftWfaoY0rnVqt0uu0+r3mmfXVwcEuG07pQa+fjnp+FIPoadvJIv8Qh4dkwQMHro4FksiOoCizrBwb6ZDnbZKYCwrOWFYhmQA8DbeHEn7uHM5YzNUhAYZEwHGEgBx8wEnC7gwRbwOEFG+DEyhbukFQh2Ik6QTY8A+hBcdc0Jd/yYMeNJ62UEv2hKhEpWJtOslsbmxfvXptT4vEEwbPyGA46t13771v+6q//O73/Nuaek0VGdtOBsj5H3/3D5wH5zVwDMDGKipKNwsCvSQ2NbnTGZYKWoVF4UmFPpn5I07QWCliF4e6IAMg2+cMU6t4JE1Pqc5SBSA7YytR5sEUQFXDTbbs1RPb/iJqY2saIpz4h1S6rVGlUmm1DthAqjeqvsL2sY99pD2c7OzulKulUW7a7uylcqm1UyugsdGWGmUK02I2W4EMTRTck5m1NSr8eDLMT0aLuUxxf/8A/1KhPEppWZvMM8ghoXK5CvvD0YAMwLLGaMxSLEdaU9T6oYY6SeP5RaJ4Rut71iq7oCY2QUjiOzxrua1YkI5KTPu5ahzBofjxAFb7qgWPAbrgLStqAQqTdovhUxIb/ytW1B71Bn1FMwM10TGybGQY8bg4jBsL80StZCN8hREEDQi7EEJ2aOlo8RFRTnOf7BTZ2qB3PDZ+TAJGG5mIt5HlC2qUBf7OGHa3r5WLyNBCixWokl9GT2iUa5z5EkZzKF/YOvwXI9oISrwiHu9snAeLL8uTxja69DozTyte6CtE+VVqUSjuke+HG+dedqSBgR1yBB5ZwPkb737/X3zr64Gz2QXLaXo0zey3uwfN9tbOTnPQmYyLz3/+81/3ui/6F//i54vZ4q+/67f/xc/9/KXHt1Pp1uLi4upyo1zOo8ETBqq+w5ye2j6nLedaD0aKSm44KdrWUamQZ4+Z1VyqLith00G+vd8lZLFRabBPk0q3m+1hq5PrD6IeKQgbgJIhJnzHnsoDMLb1YPIGlol/mVq7h8TMnzlgyIfKAHhgx0CqtKx6WCw1JtMK6ttYKFLf9vZvvveDH0YZNjY2WA94/guf94ef+iQy6/ba+YwGDGBiiEhTRLWkHbqxuQVdagQqcfrkiVe/8sHN69ck9UGahgo06gPG08XbSseY+9OxPKGjtNm1VuZlVHulBHb0AgZBJrP4ayKgrf0BPqWiVt0wIAcbgNqOTUYAsDE4MQy7HHBb6VhEEBxIhgIzocI2LFnMTVxf8TfX2E5WDFlqReAsAuZy2v8Ex43DUMgV1QHgCf9GRBahtkEaJU2LEGLZSugxLPmMh6wm/6BMVqEmIDa3ypGHHw0NPgEAMwl7RFKJ0okarPkGkSiYTqeF3uWLpcFgtLd7cHNr+2C/SW+CRn7ms3/0R5/5tBM/sX7ix37sx6DIASfOY2xtbS0uNtZWFpkhRwcjVH5KGRw/seDJs/zc6TBN1LGNYiZHO4j8C9lcf4yGsxyr1h8RkwP8S6VCrt1VxXNtCDohJMYDMlYbZQs2E3UF7gz21FvoGMmxcWmLLDYWqMIA4MAPZ7BUx2jFx91CvlAqZ5utneEwU63Wd3efYPp+x8UXfeTjn2/tHsAwE2CjOaTvpdOG++Xl5ZWV9M2NLto/HnXHow6ndt568vTNve1Br1MuFsEnR65Y2KSLUx1KVH4RWzGrUfYi38RPEgEp43RZJ1BmYDLIIxLmsTyiLaXZqTXrVBkHEOo9BjXFCVGNySZwoBCAMKLxhJwymEjS4ioXFgSgnFKdsImOMAC81gOQIjYhngjyRFS4WYahdKjGrKXSyIwHrDtopGP+RsakGlSlL3wZ4uIpklafieIwtrPqOM5VCHLACTjaXFBwguOZfRo0qp//8atSZzmZJtNkEdNyUu5KUgsVGE/49+wEBIDFpeV/9o9+6h/8/e95/AuP/dv/8P6f/7l/8eCDL19YWPyR/+dHfuu3/y0IV69ePn367Nvf/na6lt/5nf/0Dd/w9h/4we9fP3EiX8h/7/d+z+c//9mlBWgskHR/wuqPVpUZm1HZSA/xwxie9JEYmkyq8IDzFbZHw6SRtV4tcVsFZtAGAsi5K9c34nwd+mWLCVS8sAOA03PlPh7q0erlSPlCkPuzAxuiG4AlshyOzOVKtBKmH6rPHKw6c/p8Jf/5bHpQr8JcrtfezaeGBVqqTI55L2WPWNO5VIZxtJqlaZaOZ9hRjzHscpCDTqPX7FbyFU5iZcY6Sklarkhu42SOgY2snQ2DndN5Oyo5kE0Iru+IQ/6KNo8fuS13DoOFAcZmYB8rhGSI9HU+NJPpD1qekOHKctUng8AeNwTh9ApMlGQs+TMyFb7bihiroyoVMHoMINAAGngcScoWikDjI6iGDofgU2cZ70SRRUAFgQHIRuMApSjh8GfVuG/n55ymKElgyM1aDhEQS+GPcBjECsIDA1h4MZPmY8J3ore2PVO3wic0kHVgjlIINXlqcOEI1Jj/++/+0D//mR975PMP7+zsUr82rl//srd8+V133fPu97z7N//Nbzkm3cnP/uxP/72/9843velNP/mTP/lPfvwnPvqxj144d+63fuM3X/ySF9/Y3F1YWIBgp9tVH0tDiVAm06ymTpxYyNJw42OlI8lqmjelVaUaE84xD/6o5PrLoP4cFbl48aJzjO1FAnXgTkdnpJPG0az7jiRLqHsCbO433ek+wUbhkkQCTK9JG8HukXWnaWxUZDhIf8WXv4ap66teejdz3FKp/OYvfaXLcf+gRTZomaCMgVVlOJdbX1LORgPmksNT66c3n7pCErkUQw6dxzKZaoYJrtPBJrqz4T5zcAhN+icx3X8OzT2xJWYTS0gOAMPKObahqZWlhGhPYY8JPJ60vAqd0unRGpG7KTvXhoyEvbeMeI5+iKF8z8wkJy83HtFtGxJH9Y3k3BCEwGP6UbkTRKYaC7Sqdlh1wDpKmtMyaGouxzGgNvgxfR/aiBeisMrhQ+SkTApFhuIyniKAIyMCiHjSwSYUNaW3FBqIaHPcf/rMMGA6AAUnOOePEzl6U+WCcht8pKxU4ogOYJOoiMQqIRwjqiBrTENC3/Yd3/O+33nPhz/0oYODJtpI9fqlX/5lcD738Ofr9ZoNhNUGUbVQS2iw+/PmN7/5nnvvRa7Qr8o0GEAeHLQIZakKpZwMR2iMUjcJ4I+SU2TVUrnLsJyKzbYV61jdXj7HIo5Yo8ihT5Gkxmrrc2WdoHKeIRIpDXhLCxqSGWV+BcROQZ4rbAfwyaaY4wUcjyh3fzhwNGxXEWz8kQFjD9gtFdUU7exuoSVLS6s9jm2kpvV6hRakN+iePrnE4JCJYbFwEZ0D36kBYCB18c6VbCo7YFW6OygVKt12U+ekGZLkOiBQ4aksnLsuFlVDArcGi1uMy8VtEJJohGoQRsQYTRSMjo03Lf5hy6M7NWw3oCB3YMNVBaYMOE9LjqaTLAUGh1j4e1mQCk0SNoY8unEnK/wOYNPr0p6hDPwVNBeVwD0VQoENc5ZBS1YcEVSvN2J+xFTAv3lzA3/TuRy+jHvY0BgOW4gRf88EgFMmIqIFnhDD7l0YjnLa6SYbdHlLzzQC0tqK60ewxVBG+bIsJG08omE5cUHAdkBEbmsczdCjcg8RAwAB4BkZoy+ubBbgQW4zNb3j4l2swP3UP/vpXm/Qbnf7gwFHBrO5go9NiiXJB3on1tkFrVDcd919EeF84zf+9Z2dLQr6la94cNDvstvdqFdTu4MidZBxJ0lRvSlgtmHVBuiQJhUbUjpJkklzLoJAZo3WVKt1oL7T+cIhK1xEyyW3eQ7nx4bEZMnyhy3xUVFtDUnxLZ9wbOHWboqsTBwkuFQNDQHekcF/ZbnBSU9DRoippeUaq54bm5d/9bd/n/NVN7ZvcELr3vvvvXTpksbYqel4IFUmX5YTWXTg6H27tQ9RdVLj0erS8h0Xz+/v7kkEtt0FfbQWZBMuLhlgoiR93D8EBaf7BDsgWNw4t0nsw3kXY2bAdx48XWSIoTGmXMvlWrVaW1xYpn3GE0V2ZDtdC3pUgR2AGJMibETB+AJDCwWM6XQO8FcEM8gDT8ChnWODppN1ALsz1iqx5Ggm+J8/fxEPDgsyukPClWIFIozraCIBSI5mkbV9OMcPJ0qp7mM6ZnHVWQILd76oih2MiUF9bIbl21gs7hkFiQqgq7SjqJh8BQX2gN1OxjoKE5+/WQdOLPMJmHNEcCaClJM5BKQBwnA4+Mavf9v/849/+iu/8m0/+zM/Q5OGeMuVSr1eR0rgVKsVImLY8eCPKKz8PfSHD73hS/7cv/7lX3njG774HX/9HR98/++yNrmyWE7t7lfzRaqT8ul5tIEDAqSl6HZ6rWaTu3fcsRMCK46M13Jpel2N2+xCEpeimKuQXK7gJx4Mz7CxFIdFKbEDZBpvP7LGw2i1U6Fx5gEmGXZoDCv4WkRXOPlZ6VnbIjyOaaMEUuScVtUaC1oU3d3bfGqzc3f99Gcf/fRuc+dFr/jiL1z55M2bN8TuMJoTSmkGA3owriuxjrW5eRMdYpGF01x3Xjz70tc82B406Y4y/Zzrk3V+JDsb2XoGxWtUmQMQ1TcL+WNaSeJJEk6aUBoT5draQfJSKlLcDdbt0AOUBx8O4tAQM82RdNk9jHqgiFjZRgRBxhBEkwjL5lQxgDGecWx8RDD2Acbgj48z4HSwwcRAZ3tr18bwk3KxdOrUmfWVU2tr6wyCWGgFDQMOmE4Tm7YEgtRqNhEYNGncZAOlnf2b7k9tp7xAwEnKVh2ivPgPND3p4BtSuQ2CMRtiHAKOJ2gRkkEOJ22o4CR72NLXSD2s6KYc+Nv9X//K2/7z+z/y0Y987KMf/zgop0+fpgIzDUQkyJPsAeyzk3lwgGQ++9nPvv3t3/CzP/PzX/s1f5mW9u98z3e95IEXVqqFHGORJzaY7kqG5NyOKJCWHTXS0YZOBxr7xVKlWhUPGDyhz0CVCqwqyPrCeJLzSzqPX2rBCtU6GDGvSj9bBXUft6FlNJVV98EpIJ7qmvcsKMOEVHoY+Qiw+N3egP4TBWB5mcECs9Zev7O6tr5SLnZ2t/KT8UqpNmkPFvP1g8leNltOUx+1LTYuMNROF1GL8TBdLS9ks1uFAklkWcPq9xBCKZtu9NrDcpYdYBkkJMUxLYcJVM/5l+gi1RFHs7k6LuPRizAgOxBsVm9mcEKbnCxByrDnlVRs5EIGaK66vd7S8ir1crd5c3F1DQ2oVssMjahaxFLnp3O2HDrrU23wpNCoAGQBgDJKTZgnq2sFhj6As5GeFMkabub6zBcIdbR0TgigJY0SskmmezomMP4oB3FddIztWTvs9DuZfGbKgEyS0VxA1M2A3+tofxiz4D+xncuWIUUxkQUAajU1HHtve5OazqnDdrs5GGpOBBY4xVKdkzxs1JMoQ0TG7VCiZCf9FgMt4g6GI9o4WAVEFMyqQo7Ev4aillMN/+m9cJhT1VE+3N/FKAoWQd77YSuq/AkXhG2Y496YxVBdG0RUqdSrXvLApSs7zFnuve9uLVhksyfXz6qAtcY3Xl8/QYUqFYqnT59jXMUVwjOn1xj49Vr7f+Ptb2NErY66VMradMPTGU6HqhW2mW7Jii2UhqrO2v80n9lpHYzzxUa1xmpIKV3K5IapdrMyrZD3Jme0WDycpjrbeyx96Eoyew38wUsoSw6bOF1lSbQjk4RjP/1Gypr0MhhV4HcuFk60Ex0gOURgaprD7nUnr/+iF+F/57lFVOfkavGeu9buvnMV9W03m0hLbTnTsmmGU1lM5uv1dLtRQrcZjGfSFU5i7W1eK2UnRRa1x6q3GIoGgtSciDXbVgG+FcMRWvxzK7RkjsAJTsc/GssEK6Iwg007SElg3OmpGRE1KziLprVoNyMzZswqABtljcZaBcAl0UWNocVmgRI5o45c84oWlUBRlbaoppWW64hDEGO2rZmLihhtgz4RSZruVJvze3twW7IhIpjAGK/hMM+ZGegDQA3bAWDaeYTO5qD7Q9NrcrX4gt3dnWvXrt28udlqtaz7UpPKRHF9fR2B9PrqydlipJLTmVWKOrRDCiQKVxAhCfCPmpCdo0FzPs8EkyYV8WjcZgKccuJD0qUnQJKMX2gA1Z0wGkSLYXs86GaKuWI5v1DlJiubmNS7NF1UqaAlZQw8gE8WvPjcnmMMT4oBHPxVcbhQ3OvTZqPcpWmGnaTJqDfJk2hvnEmxF62J9IUzJ8B2TTBWxbAR8qJ3/t1TyVGu2J580kay7p/0BEYDzN9ommY4WrvN7i5TOLWmXAYGE4G1Wu0LF07gc+JEHaZpsO+55yzjZIqQK/sUIespveHA1285k0SkVz34kmGf+RguNpMzrd2bNE0imM3BKgb9p7FgiciLLZvLO4ewgTFPB5+dTUQiBFJO3El40BxsJaco6B8w/QxceU1I4jtB+TApyaaqRaoHejNS9UxP6NBQCSDQDFO1zmFUQz50KcoU6qXOAVFQiQIOCK5AAMW8zvg5k26708sRJmEviUA1Bk1U47rqoay5AmDwDwYnx4/Ax4c8klmpY0qnenZ2tiF1cMCfnf4fUYjKBVgsz9ItE5cS5y4a1Xtzc7Pb2UUN8EQrKE1VIARIhIQh1IkY4GUqmsEEBHyS8G0QkB5ihzVyANrSUn2aOYX0BtNs86DNRgmeVBT2PqhuuXzm5InlxaWFSqnMyZxKifwiXI2H/fyCSx7ZQgGZhHRFxDTfAWzY49wVXbyG2mqJe2weZZj6MknsD9hDRYYc6aLqkHgFFaKOezRiYoDlhG6aVTVzmHzlY0DVTggZqNAABK7cJ7anhcKiURFm+MOHiQA5pzxozCghIzWtVPM//0s/SUv85KWnyGd9cYFm+JHHnyTpXFrjOt1jUBROmakQUbJ+85qEQmM5HbG+d2KN2t5j0wYdBt/y5JOHqK/TLaioFCUs4D+JgYKLBSJJakk4SR9k8oUiwhulSxDOJDIIODHNTpOgxYVFpkODoQaWmMlg0h10iUsQhQRaBEPI8hWYUQHiScdhB+GVSjz0JRYhLEMp3MsJyEzSKSYsd95vcD/VQ7ERuNdzInH/OopsP0Rx58bmFTBxkrQz6REX6ovELVbK66dPLQ9XaZoxtOM09JlcL8v5wfG42Wnvt5qs6p2/445rl8dMoo2UGj6IIzcEeKgSHBL+rEScE89F0k76OzznI7azjLw5+YiMlCiVs7ZQx787yFy5cm3Q21a9zWRpB1nEqVbKp9eXl5YWKCPdCqCJ0bxhNJwM/Pa8590FAhEIBtuBwAZjF9CQGL0U6sslXVoDjlVOWIPAq5AvsrKYyg967RE1m5NY3rkTn2iHTFY9KiYkgA7g9JNMwd92B4Q2a/GsBL0cAftkITbQj0EqMGlT7/AZs1QOG1qU7R889JnL94+rv//hP2II/cVf/MXXN5uf/OQnkUu3zYENnfgjGz6ErtcXzp49u7VxldaI5oprE2dPn/rar/6qrZubTMByfpZb6XlZkw8ZMoCd5ESefwLj0QPBJLUkTArupHTpSB1GlQOOA9bGqZKvrq2xAs9AmiUgSpPulRpfbzQIQoNJTgrCqEcbMzLUqpgCgTM5F7IacWC8HgJ4NagePpgBewRBQSpoxhkGVOrW7wUhBZ7xofnxuCEWAD6ct0/6uCfMb23doP0lC5Q4aTGgICPwtrKiVIzNMRsQ9khLv9lsLSyutujweIxCJ7SpV6wBZsYDBrKHSi3k3ZlMcuhJ44+nwwE5oOHvoQGHXFtVjFJhok6SCPzGTSZz+zQ6VC6nxn3YlZVlThOOJ2W/CegLQlzX4UgGm4SgOaYDLn9E4SwFO8LhsPdYzTpKTlHl8tlKtcQtpF5Gjb7WKnMamw1Hae7iDVkKZicZpt1Yox4JZsqqspkoKNY/xI1PSDXAlIHjB9uDigU/4he8I4ADn4xmcYAGZ9mMnW1gtaq0UCzUM7lKetxfWj65u9dJTQujcW6hscJ8llIkbwykOIhQrSwuLa23D/bpwPscnrQ2O1ssU8UZ/5A1KGMUS0uvvkSEvmnZwdN1O6HtEW/JHygknXOwk8ITtCTZOTRHAMsBK37xphoYN51yM8u1Tgbg0cef+qVf+iWkiq6z3s4CD8MNJqis69A1GaBtHrbcgJFJpahtZJAx8a9mqomTrGIy5iTVbbUDTACwqxStQqRJsVwU67AQnEmiYFBTB4IoHLC5okLmqJUqLLZjJr49QaI5dqyKvCk1ZpDNshZDhTNnz7PpeunSkw8//PDa8kK9vkQhamClqbUaL+o5Z5A8Xc8UXjiB+TV71oTF/pHP0dBjESgHdI3kXCywR4/CePDyU9e4uI+02LqkiyVuNsWQuTDot1iMH7EYyeIqfGrYoQEg8gTHjZNymCAAbAciDD3ip5VppIKOa77AVLpYUEIc28tmBhyr6LVGeSYRiAtlnuYee+oqJCDtxghacWrWfsh4SmTpkG/s8JbbXZJwXPyhh48Ro196YNb0KAkIssDIoENRpqV7Lqw1SpOXvUDHNurFcTU/fNVL74Pt7kELBJ7LUZwJCxtsNKYzwybNU4FOqJRulLMnVxfbe1tlamiBCaNfpNQilmRpR/5Ie+jPHBoXc7Kb4/CZOKEgtp8BNUsLS6JmxOjSpgIT/XCTHCni6TPnmQoxTQSHRzipwEQhGwcH+77xSCuAViFe/KHAeAZJ4sQ4QIkArCyw365ZKLGo6tg+915ZXHJmTDgmIONJLJpuQVNJW8eOT2hryKtn2W1G87cQ1MwfTKMqi6GDDxcQG8Stt4Gg7o6xVJvP1637PdDGZ66wvn6KhVzYZszCugYaTFpIDzpziQYfS+KY2uv+ydAk7NSCD0BqwpqZFlCQOqHIkKu56CRbBmyB93sqOBoeut/GQp1qTvvD6X2fAlj1poZLQmwgEx2CXnzYIh6PdxzADgZR5Vi1zOfRcnVXRUan6YNWK89ZY97loJscj4v5SrpQpnuvM1NeP3GayIF10nSjI5qHiwp/fNAbBzw0wL6dgJNCwQ4GNDf4HAZyroKs16GdwJTZzZvbb3nDKxHTK158N+MmKU1/5eLFl7MFx5IAWqblKh7pyOZpqBgL0FD1dMF/yJRjPOqVi4XW1ibLeCxoMccnOoYyQH0ZrCE7MWAbwpZfZ8f8UKyZ69lBQXQeLRTPUSoe5PhWWVSWLiiQk6E4mT9Vylw3TbOQwyEKtotBoAfgBBUKjT55QZAxYGTux+4g6wRZrWfYoQq/s50k7qngU6bXs9E4FKjzTgcfAGo49ZzBrfsD44khrrNNilAGxocj6FDzwg15AWADG3+M6YP2eNBb/tgsJLoXB346TGamVqsz12XLiVbIFuqImllfz352a4MRBxF4tEkbQtwJVaWPti1hwJO2pJ615dI4lgIi0U1KbXP60DKjhdDi8MKFCxsbN663b8De6urqqVPrtXqZXHaYFWu6rLEBlQBWaF7JIML0GkFawRCaTBT/4MPo0eRDQzdCHDQK43SqPegV+v1yqZZn4s1MqlTlpZv0aNLIFnPLNc92UGBoidytzDitce8xZqqe2SupM+d2YC54OsAyuOUwKj/Yoh4uL9Z/5T2/y/74zrVtKi1LkTvdVvPRz9cr1d5Y7S51GzQUy8kC7Pdb6BU0ubKWZ4U5V6ImM19hZwklc+2BMVc4UgT2uDBrf16jkf2saQyco6MaKx1nNAw4ztgWJFEixfK0sNnDJgENkOwqH4vppXyxy31ONtwHAx7jo1mHyUKxxCaKLj3TEA+H1y49hTbv7mwRxMwRVWeqP+xzZkYTMLVfed3NQMcYQcMtYsQWsm30AJeqXsCArIpQDdEoVr8L9K/qMFT/Nd8iK7yMgs1baMNJZtie7jXbrnkkhJnYvWURsdrrCeGs1LSWTkFAFmoAJI4/HYQbd0ZEGCmUdG6J+k2Lq+yg47yDnM+22O8tl1nUpZ52+62FekOiSjM0k15RcCwWaSI6GZfzBZy0Bk7TU3FWHUYgGA9125wUvTIYq7dac0KxCDV/OR0G6I/Z/SZMg2SMHWnjrC4NXPH6dFysFCg13phYaJSr5XyreZCd5MY9du9HnIckg6x+KWd6bpYkoOraBVdR/aJfka81ggDGiRjgBO0B05t2E4meWGowLxrsdE5V1rrj1oDWJD1ivFkYdKqlOkexLu/dyOnu9nEG0sd5k8bxiotygu+iOJ5iTM4rOddgaU5RNpaQGX5Q8NygSqWrn/7M5UtXDj78YW4FT1/72tcOe4M//MOP0vN4g66Ss2wDUN7UcA5v7OzssMzOPtPSQvmr/9L/QP/RaqU5HUAWIELnRBQ0mvTl9EKMmbnNL7FuE3qbIC+PED0ARHHYuIrOQqEH+KPl8AgQFJFaQc+DU1nmlBlnIQa6J0TDAWy3Qakn0aIA3R0tG0SoEuB4ncHGQIFEMdQEeytMjEMT+ipJaSyVXVEoEeI21lcULe5gA0C9hJTqnB3MgAeI4NPpNdF25xMfR8BZt10oolOyGJIjJZJeXl12DpUGw2T7wSdX4IYtZ3sqU42oxoyoQWYMQrtgjYZmCk4B6SkPh81tgg4j/kld8Asn8EBfgO3GcwQMdeckCTxtkh7R0WhGuX434K4dJQY19FVT4XF+rMsGGoeyrDicZFkbnrIlrBONcVN5OJ1bdDAMXo7HZxXOWQ+2A5TlXJa8Xoz50oJqMNtDavt1uCU1zhc40VxaXDhTq66Tq2ymkSqO28x98pzrsGsM7K2xEDced7qdfLFSLK/t7+wc7I2XF6vMGPZ2W6z3tFpb2zs3FmorrjQ0gWgVugVBS/F4/gPbLoakTA8LJnKFTM2FunIR6hQCWqBvgFhy9tBW9BsiOGFPHFpcFIXtUJzQYc2KoYcer69WGYxaBdZyDnWPJp+scfSHwqWpQskdgCBy5o9a4eoFMhubtJVUQCSBk44XUiRnu8ZE4DhMlv1Z8L3KWeWKrIGdvBVZjkmX6EeJpwp5IrcuyAzOYJrb25YbNUAAXu2xH3v8EwGHSMBkEHPi9AozKR61WFniRTj2uuVP2sDEom+nGsOYBrU6ZqUeOEQPBP8MABemsRzVVWA8KQ4AGIBnC5117M4nQeLYspyEQU565qfpUi4/zlPu3O+wFp27AFM1iHzUgtLWrgMvzaR0v63f7ee2dvaPzTYt37H+eZtDHg1iVOYtI5mAoaQeOzwXhX02mhcpjUaAMKWr9lyfWl2o5qbDtcUaxVYpsuMyXKxrfdVVGU/ooHaZUTZHV9Q+QJNq9SIOzquUinr8GuVbXl5lEQuxuigBkLASYl0isYg1x1KQI/4OYzMUmkO7vdMjzpVKiBKSoF7VqvXgT47oq+ASIbgqQIEKjE3eWWomU0z+5UPL12XHQnfuNfPtandNlZljG2bATwLkAB8bKus0BYHsWzJsFmQVF5nYgUGG4fTI6TJthGmhNRCzCmYDGRcLmVDfYEJiDkyJSEQha56pxoKYhzhObAw1GXPm3Hky6wYncmB5CufnPvcwl3vIIKtrVFpumxJEiTH53+vtODMUIrySEA0N/6Hv6ToQw57+n6KNeJ06hQIv5AInHJJHLwu0FCCgESqeE1U3MAda8HdPNq+4KT/SlxhYz+YEKOcbxuPMJFflqCyDcrYVeE2OEx5a26QX1lpIIJcENGo9ztAAHOdNIUYtEKFBoElMPN3fbRSOnHsm4QFPnLTBX/YlDwI//+4TnNRZWl3Z3t05vf56SnQ40JIMmBQ2ZLERE3q53d0dDk6zxj/o9pgqM3Nm/5t1LmbCrh90vQiaN7GI7kknuboNPCfZ22Amg4hFKm7j70RkW/mRXyAQyEhhSfc3XAJ0sLSANlzUvAgEcsdoAoTAs1U5WnrdL6MQyBRZyw2lNx5FN+8O/6HozEmZ50IZfNAggqph64Klz5Z1YEAdCLNh/O1ALa0WdVSTK5URNDPpYkG9omeHemOtmuZ5GjkZk2HtEidm2O25HIjisawuZ7hqQ9YoPigrI6xzMzaapM6dO0dNbrU6+IOPbdHFOUXPixZGhlobnWAhaU8Im6AgpeD5pwTAs2eHWgxvSIxWiNQRIGUaygIfpI3zVmw4EUKdc3dic1ifQw3DLMcTWewYcY6OWso6zJCNFdZjJgyttUadzRfzbMCxUby6LC05auDsqCc+t1q84a01hZpYsR3AxzlzH7cjtIzGb2QSJ+pLVgnlBsalK5+gIEvlMmPy3b0b+wd7au6znLzqcR6WtQ/uo1FviwUO1hF1srDIi/gcUeJQ23ixvsgyQqvLCd52saBHMCCFDKHMkoCwNWg/Pl9BgqBhiOLArWzHPzZUpZBoWQNlSAJTgYkFb9Qoj44fzjhKpAo4qcCqUZMJhwrpdRnz0jxxWA9k2mKTmEgF+gjTDbHc4ESxkA9pYeCLfpfuV1U1N2XSGznt1j4Ha4lFfwplAIRMdNgARlPbzQ4JRQlYzceJQezOA0E4HQGAA6/EjWppPITGyQEnHkWhEaNYNVSghSmo6Z+ki4sLSyxnqFXSaIlikvazokGF51qjXaOQthCGRREZcKgCQAeEP1XjSWDDBZIlB3SFyrkVorc+hBqCPB1wluS2dvwohzM0GzFR97U+r01WipBpa7qwULHWa0LDqsLNF3Q8nBHsrT4+RsN4NBl8oHWsf7UWjStuJcPgD69Q4EoRVcsHI+OxBpNkjXb5Z3/h4e2dnWu81bm7c89991br9c987rM3b94sZjQC9IbZAWzGllyU4bAhSsfeNo/avekNr19eqvUHPDSrVRBTIE1LqMDIGifbK8fyP+fpgsZ+thqhKIna62TxDP7eA4cKTLONHoAGk3A4tKe/nAK5Y+hBRBo4DTdyRRaoGVuKZtrXq6RATtmjY7uBpgOu6Epehohsx+icIJdYqAVUOF2Iwa1PdcEGd8e194uBMhQAsIEXllVGMJYwWhBkv8nQfYTMXFfhyo5VfpIkOszQfNAigNnvtvD0cnQbJ/SbrTY4NzZvKi6ziWjnWbe+GaYU8toF5HgOoXOG6J4i/gbPhT/HTufWsqzRk6dODgEoI3LkPrAEENIGDk4HsAPbjiwMM0gsjaZrn5wyKrG3zPijVC5ysoQBtu42qJFl1MIMlD4teVQnJEgFs4OTCY8I5BnRo574sHDo/vAAEGyy6rB1PPL3bHG0EyV2PSPbyILVqWxufLM5baxcmO7wrPWgPSwtVtd32p9rj8ujaZ4WyfRK1zI4yMW7YQvrq9PedHdrj7sf01Hv6miTdelOZ2fr+vVygVMBMkgC+ggXTrD9+NexWYhZOzbwWXhCJ5RNEIXHVxLWJMAMWcbT+17XckJdpz0WuksFBibfaD8rWJr92gIyciQJjD3+qm0kl7OT9SBP0e25rBGbRkONuzbbxIhflqCMqvWaFwenOIkFe6TFEJrrQZBylcUmFvVODPejhp4sYBwBf62m2RzYmYEmSgEFRn/YtpShAlHXS3uiD3RU8GfTWzSpBtbBiqDdWkNPoKzBvN6NVTtC2thE+TM2sIexrEUp44Q9HLBNltwXBEOc1eFb8emYs1CGy8qqnlFm8KxFY5qHQnbUZYiLn0YuUGb9UftQ7MANbiEEFv5nRA8NKaMCS4YCZ9O0lMcYOzxzjD/X+DUMUJfAUESDSQbnLJovlWrjwWipXLneaTfyqQurjWx3t5Gmhhc0rdd+IIe7izxIwzbIuNNeKdSuMLzUA0OjSqG0t7/DjYiFpcV8SvqHQBnHmeqQT3QFWGeDg6DBwYlBiYM+RG0M6/REj4tAUkuYOecsxBrEgGpoXmUtfU6oDniyr8ZsfzjoMxEgR6gpzQsUmOxRaa1zLrJUUa5w7rAEZr1SaXc6bCJzU5ZvV1K6nhzqzT0fnPA/VheepZLTrhHK3AF/rQaN++BwronVK60809txzHRSmAxZGMnxtiBPUKImdLQcHKRjh5YOQVGz8Z2mSugOeWCzMWvla3tymh1rLkoPjjqJ87DUpydS1UTZHBolNiTYg4abUaYu4bPBm2Wil0uP+qTFDH00HVCHW+0m8wWEUOYanhUNoczhO91WtVa5ceMaO/29bhsfLcXAhQqNNsC2XZWu6TjJ036wRqql3OieMGN26Vpcxl7s5IBdW2IRIJ7Fus296f2MGkFuiOhxWZ2gS8hmSqn8cJrqT9OdNC+yDZgycJdmASG3WzxToVLhPUkmH+OpGj7TQGfAYTW4ghCgdeMuHHwohUwhN2q1uArNHhG3kNQJTSkuyiWrAbQPjZnh6jDLJLd1c59oRw05CZ7OujuD9oTQ2wOsdx6L4B28iUUWekz3iHnghedIot8/+YoH7+FoQHfQefOXvoYjL3v7feigl+AA+LSZIt/Z2nztGx4gCmcJKY92q99ut1rNXmrSRiiICWNKoBE4AEXtwiJRAEi5fSyTz61nSIikoQxjqrra6HcXfTL66JUT1dMIllE0kmFFAC55zVARLRdeCk4QBBqFYqFMSXMaEYM/gsJm7sqhY/wJJe+aTkVbRGwZaCuYIPdUQ2+UOXikIbad47W2Hh2SUY2MzaGMWF48R26DBdC31yY8Bk4MfFppsBWkSmJBGp05NWxSYaDB6mmU07hoqM6c3yIIHEoPtmNGnstfWJI2PGMTZyGKwBCX3MEhLSVqJWpqvTybz5SoMsjQLJXmkhOtvA6BseSjgTRnn61FUZ8i6XEQmjYVgDvxC8eSV5semySv3lfEIbNfimfmSEAjHtc7zugV2NjAFNUSLcQ+e3aJ9WfUe2FpGedop33+3GnKbJFHdzgyritLOtROVGLhv3uudGLl5NaNHSaPHG/inCpHlTj3zmFSDARgDEDqaUqJVHFCAabcDs7j2HyO/Twtt30GoTtnVvDwqXqisYD1CRyAzmfYVuE4NBln8MQVPLLA6i1OaiZ5B6AGwiJxn3jyEvlDkPxBwVQHYso7hiQslagnJAqdM9QgQreMHKjAwHJy1QWXGTQJUjT82HQHxIJUUiJg0Ta4vwcFm24R2J0gkDo2+OormSeSRZbI9Zqq8oshCJsWmfWOu+66iyIkLp5YCwtLzav7NT09xREAnkdmyICyHa9vJEDRik37A/ASP8R3Mg8JWNw+XSUOOQrxPBYL0n60gywSZHKyHj3gHQHInfsBBBhZs8yhOgxFhpgcVMLJLqGW9WwQbWsXjDSkJrQXPNlxhLJ7RP7GygwlTnTm41A8+J/3v1VzKSU9bMg/Y54f+bF/cx2zudFqdngF4s4773rooYfsi8FSXDSVOklJIzW0jeFiN9Pn6wE7W7scED1/+sxrXvWqxVq11T4Y9A/ACfgoOjLCx2R1TB0+zMtz77ISigrM6pI6SXLU0XYLGs0oWl0lqsmRfRpZW1jStfjRY49RezG0xPzhT6aYDHuVsC5UsmTwDOwVWxXCqgQ+1s2zKsRkGaMTUQAsRTtCyCfsWSQteXrHK0FF0zHrkCPVluiIZdlR7IJ9cQIAfzfyxei4hYy74FajdCa32j6knwGfBHlzQulobG8MM3y4ceMGTMYvr6ltYhgyenJSXNQyJOsgrM4lr/g4/aQd0oWuMxCAJFqAwQnV1vFlB6+AdwRwZLwBYE3qS8YYs+uRTnpjWsZbthuwRERsBxzGZi9gf8QSDyNzznQo+zzDwTFSl4+Og1sPRGoemSGlhqZHza16YHThKDI+iRHWofBe//gemGaebFvO4U0qopY/m+qOSt1RZZpZevL6RqOeeeUX3fvob78PWdBbtAfkBz0rugaXy3z1iJt1Jx575NHRIDtsd2vFA569z6fH+9dvVPnYtxZp1E0hI2BkSuV/JgVzKAPPtQNmyDU2owl4k2JrKMFuBLpMV6klDDglw3QmDCbxB9ZBaKazPBqsPGnNEyFAx0NN/lDg/ROqR7Q5RyRWCakSkXj5sUpCXIy5fKisyqPdJTNqI0w1RDPWMOEnCtgIyAJHjYvXE9ne80hk2js2zZYDQ4dsdxCYc+vEzkjr2yyVkpwJQLMJAOrqzY1NCxITxCOP7CQZtwz4i1pL006UMWeE5y1ftUC/7Y8a5D3wPFrshj4gNkbpGeyAuY6xHNkDgB1gZGuDW5HCB8u6Yijdntg8fd15Ggz2mwcZBpFFP/WtB8zIMuNmDabV9hl9EtTO6i26VCrMHIsxoxHHcynfik6xdPziFtNyyskzq5VFtSzKarHQGI9uprOs3zRqjQUqIGFLK8vtgxbKqlV0bWRxi4X7OuSDejvu7Hdq1UqGswPdNucN08Vpmes61mghTVd0AJID5ihLLGIfoUXOuew8506TT9QhwAlOemBGjNZu0wNzFFwnamwAHDWR4DCERneL5ZK+QQeknivNhowPgFF6Kp28bTxCdOBgvEJyHID6QufNI2cqb3TL1qSKrJCYAd8BtyEyc0oLVSjQp70FcINf/Eeo/HEKR7j6j6ECS7JxJFoAwwSHVkfL2mB6yiBTLnBL+TKkutR9kvEF4SSt+LoNymZSFZjxBbcqTW08LUvptlZE5LY4IVDJRewHv3kgZOkQoOyDSWSWz6zisIqsHhht04j6WOOyJQjAYWzGzF29EdXnWTfGJSLBmhhXBjhIqUlHtEoncfOf3YR26/h9UaTmqQZG3cnC57HczKEFHH0H9DjDdShjQWHUMs44UoqYc+uLvYMG559PLNxXqVeG7c0veuV96Omou0rJUcbgk09mwmgeHRQ6XyvciQ/ngVnG2tvf1rNEOS4bR6tiTDUJxQubKM4ntgPOGjChDv8Z2J4cedGY2QzqTd7JCy6YBOByOBfYOMtBkwyazv5SnKlJOaPaiyqDiUC0zaNqP+EhNUWUULU9i4wAOIwHsmVc28LspkIKgKEJKge+G8+7E3QYf4DkADDgQNtYjiQGVy4x+ugIiCRp3YTptaKosQaB0YUiOn2lGJ8cZjCAQGjRkIMW3mu6Pkm+GHtgU7EZf1izxZtuLIKQ6PFzYGfPOQm2mI+bkuAZANgIZQ+Mv+xnoA+OHNFh9dHoUOPwMXHBpIoyJHQUAM0wFeIA30zKl0tLKyt5CrrA5wg0qaGV5qUKqgy1OjtSF8SSBct5bA7kep3jczaZqkNIsugwJ6iP8oGP6d8xIXSax/iSLT6jEsvIFZEhJep47kRloXSRxwpzxXy323z8yce+8i2v5snCammJUqdtBg2AwqYHg3Jv3HzB89f391sNPbakD6bt7nb1ChxL7KbfMMZIFQ1AOdDdbi9a1yGuBGHNvAPH8vmce5IiukwWYAw70IdbF4jbZJADVCzACl/6zxo1IF/H02FDb5WITk323pjqSu4weGIccOLkzjNI9DhIRyW8i6Yyg+bnnECQFgZj8eWZME4NW7GQnoazMh7JAWyqs+MAexSygNH7oai6fKXoDJAcIcXn2u3lOpyUrFdgYBgmv8iBV2j5ajT5YvCldAk7zijAwxwIzuOQ8QtM3iL8GO+jUeSjTEoGFsFGH1qvY63pGAp4xZjzodTe5bXV5eUUj9Bq84+WhOFVJrWfGqqLYhnL3sFgtglpGsPc6trxc1pizdM291Huj0ULnsntqOAJkE7VsZVr60nkY+r1W+/+zIf+4KPdYff6jU2OYLziwZf/5ns+uLF5LZ2pgUkHQumiBxQqTo5t1JZPPPrIJ2idOJrJ586+9Itf+6K7Lj715OO8jwAOBmQw0QOUHqdUSzrk/T8hnizOSBGTTIor1wbjNRlEpXLnkZIIEUzPTNGNjk7H2d0vHX/jbU0eRcnXdEKQd1K42MCHGmCG0THngdXB8p2r8Yg5YY1T3NNMMcP0r68rCzZmhiD5wo4zxadS6ow2NT5W3aGKWC6VT1VmmrZuvzsujPsd3TqmPgy1usweI4eZGcDLSF3o72jnVa9sldNKhGzw58kpI+YZbBsMR1JyXXWJ8aU5yABL+NYZ836l7oTq43L0nhSMFi09IzTKxUKGWzg83cb2yc0bG3y4g2VHNdMDPuDeKLeq2zduVqsLqel1ipFnRbgaTFyIYyiKCKAjiUZ25k2rRuFbSdnaMBEkJJ2HEChD9u0XyxlVDbTeVJoBFWwLEzpO7Y+zbDTtk5VcqpwelxjTcxi0z9erSZp3YBgsSfp0nUQRk8BJgw+GWNjB32HsfJrPYok0c6wJ3zDEy743y0IOHNvlYqIBch1Y4gT3Fk1ElEEjkLDC0DrhdzuQ0euxwagU3KNgIZQ6hmF549HPP3bH3XddevxauVZeWzr52T/6DQTX7x9Q/ajAqCxO9Eml2x7Um4ONy5u8wFnIpM6eWsnzmFaKd9LYQtdRVV/BIiGvxkRkBSWk+P8TAI1S12PaAD/who0TwG33UZBtzpJlmOeccoETF5rrRpfmQUZcPiR22OQ3b0mRVOelfLQLdo9HT7SSpkbcqm2SDYkyVoI1m6OIGQhhB4MkSQUTfEDA6aNPkYk1yeFUwZZXLINRGVs2hWcmim5FafnSshyeDCh40Q4O3anFLz98ZvklKjjgR1Se5U8YK6uSJeImCSbhBMotQS0qQWumyIcwnRpCO+Qby02x/I9gQ5nHi6MlKSRhTjTdMkoc9/BvdNLgsOetXcnFjyQWgwtV30TGGGtTuTh8cu70BU50V0pVlHZvZ79RW6Idpl+g6tJF0JBThBQqzTZfl6hlC4u8mdTrcP1lTK/WZwDGTgPn8vRsKrrpNgBRsLM5HU78szcq5oSkrVPi7rpWmFWBbIzgXCETnDRQXDmhvvKOFU1VtaypLKc+rMq5yggdT6RhYqQ6zf5sJiYnQRKaPQlGBfYlFmojH+OiYisgVj3mWZBiZGvUZhXVnfAQ2MMHI2R6vFtMkVikEL5ypg0lh7EpR/LrWVZYXBXhxGssQwm2EVmB5YtqJELbS9LW4mgz39Mlugg+SxMGTcQjXUrjVnXYCQsnbl49itnEU8ZZrcK2T7ox+QGMCsVzpP4yEd1hcCAo1GdvXNoeL0lEhfisqMUCf6aRblG+akc9LxCMjuhYqVTKzN251DZeXqovLrP83OCz5twZ5bYKNRbWKWYvbObDjQZv2k3WVxdYz+IdLD6CPtIrwh1eHoM4mJQ9Bl5JzjurTvf4ba1nmp+nx0uWUBJWZ6U/MyKjlTuppumzxiOE4A2rKm+rQZybbNTrW9vbGdsNSo+ZBQjTKwAZ9FjYtkinSuX0QQgEnWWchLIbBIAAXSwEae/OEnUEumh5Wtm47U4UBcDhCJMfjM2Bj/bAfAtEubDBrTIWw3wNzekEUhHACqvO2+T5ZuUTTzyBp2cBlskmLY7XXsTFGgiLAIckGyjeGgi1l1TiJiv6lY+ZANyaDGPiqJjA8ToswBoqxBYoACDC4HSCSAvAbff5Y9hzRHJ8HOxYKnNpBxykGeBnAtyGjrNCOUETAyCC6cGXv/WN7UH3zeU3XLpyeTBof8VfeIsOoxRKvmqF5nkFZq2SKSIdMSMuvmbW67R5uDBfmHAJsdXc58YzNEGGLPjqc+z0ks0angnjzzEOCuT5DQKBMY6pwZifyqBaeRAqa6KgWYfzwsJC/frGBkJCCCB4twkpcJwgjFrEWfdLfYSa/VmdVdMQNxya/2tWrDfvbMjKtCoqCGsy2KJVIZiquQgcJor7O5NuO8KxtuN7DwxnwrfJC108nGPwwYY4tlNg2QLeKFOGWjTWtv6sQzvwSa4RFGgMsNljYj/xWVdgiyA2aBptr9izAB+QdTgAODHw5nbS31B1sFQLDTj4DzkwnqWJMgBX/kd049CsY2i5rOYC4JA3hxfnfN0ZxHps6DP39OI/ik/VIgiDjEgL23G2967+q1/55ZWTa9Revg/82le/5t3veU+FC/0TbZyC4wNpCpX1WAqbjZbLly8XC7yRn23UqnpAf7E+GXczqTLIgSwJ4cS+9YMcnv6f3Nb4Kjaz4mCoSeoeJrUAwx7HQS9piZAAGk+m2FVBWXG64nKLmRcq2FPiCD3X4InEQIIgTMiRp4XTDUGQMhQB2hAXQWG5p9usYxEqYydqiKtzNLhs/x9nIOtAUpJRSvbjBzyO9sCcWVdEG0InKzDznySpBHGlzkyCwTNXD/d2D3ibAx3RPJ3jnXbKsj/ocuBsd9fal1hhnMLT2l5NA5rzEE3XzTdwlQRIO+kEkaUDJwJBCYC5kCqwXI7pNvIDIDykqLhxo5D0fIawk3XkQBbPHK8qH0sCUR7rHyIfG3rUE8U46olPkdmQGWBnjkICzhcXOp1p5/L2I49eOmi3Lpy796A5eOrSJh+m9CE0FRhMVBzn4mJvmKld3thjnpSe9NaWFu699/7F+kqn1WVBMNAHmfaCiNSQQrF6LD9/2p4aE6PPcWaVa9iyZTnBZvAAJndwTiNPF4n60h4JQQNuu5hiw2YQ8HTbpYczaULeoeYGH2qy9RtKrt/zxgJ9jDpAmwOzzh/pQ6DgqVC7nL77Q9MBml/8PU7S5hKr/I8MoTmkQCmQl5Blh/Ek01p11gPD+Y2NDW6wcH6UVEgLUtpJ6jR19MUrRtTgO1NPb7uU4FDRDT1Zez2+49yeFrE5D2OlaRectArAUJrDMjB5qLaHOuyCmkvCp83g+B+hVqRx83B7JiwUsvzSNkeLE3NRPHjOE+ezbPgkr6NEjI6G4qQCAgaAckJLOP3X7aVXF1eyuQbTrrUTd1QqX9jY2GPHiyEkOBzyZ/KhNo+pXK7WbHFIuFIuZnj6vTfgOEetXFoc9bl3FtEnihvUl4Se2X3+Y1n+E3mSdFRE5DqmZHVSI2eFxtU4kjxDSxstoLjwTyhKgnxQdI/tEiPIOi5tx1KlaLUAoB//SbxgmnQlBg34bM7C3MJG2gwGRZwgmlqIOfFgExMY2zkEBgAZIqJK5+gVOFHIXjGM/jEV2KkR0QGYd/6HA61QMsjSMeB0mtPvJEQqjCDEtr3Fi5Ov/QVO8Hy2JrDpTDqpJMEkfDviKKFyEDd+t0aVjLxq3hrnmYQ4ESMWWcQCyk0yOuWPSVIhGyGr+CddekXyOJPWE3rHmGQPnKQzGdshJFTHVj1Jj7/haLq0wH5gt5LppHpb1fSomG4VMm1e4S1kqux+UHE5CUZfyuve6WqBh3tXsweVtRz3SIepEZ/L6vf4QnWxssD2ng57wBC4qAW1FwOczvBpD5p/7+uUa7hCM/g9hnt8bTWJIC/ysGYbNeNH4qDSR/zkUeRRSLodjjRyQWykx5P4OuR+c2elXGE/lIOuY+5nDceLy7oqzIyPTWOmhJwkP3PuIndfOXrTWKmTIy3mmKHIXJ7ot63PaduGbpIhKvXLDpYzJqa0Clyb1+BU5091w4l8tnnDqIdn9DKmit/6ZwhDLRj3xxPtmGbs/UrreLVdYPM+GEhr51KahKGpIKcaUWLo2c1YiMSmjpfKr1B90pY5OEE0GQzaWY3v81WVXtuap1KtvrJ5Y5uFzGK50O/qO9J8EHBxZfXhLzzKeZxafWlvb4eTs6o+2sXFVn9OGVpjRVZVvq5R8GHFO+FEBMYlhm0jA/NSu+f+OJUDx7GsKEpshGaGB9cHPAdEIRbyHAju8EZgZlIYT7TCKhxjxjDVJzk1nBYmbwd0KhYYF8uItrLo9OPUTZJxkooWbT4qAf8THXZt2gcdJ4pbXkdM4MBDqANHUOSBmI715xZ+8E+SUuomWkK9pCk8fJ649NgXf+nrz5w587wHnqf6lku/9OUv+fKv+LLeYJ9RZIaStxfhWIPhfEquWBi0+KJ5h++k0a70+i2mT7u7+/t7OzqMGB8zhKzfdJ/LIP5zPoHVJJBES8JJnKeFiehxJWUzOMk4dY+MY7j8bCjq36AGjI2/VypigIzNnBkfGiNHw4YCTus/cUUm4PgtJHx19NgH59HoN5oSg0lCUPaYnjSpk7SxKZUgiBqhIuOA7mElYSIfKrBrj1oIca5S9Vw4TQjiwxACCgA4Ieupwz84wI5DjtrtfWCvYYGIo3kuaFGUjKTEnziTU8r9/4fGJHC8ruZ4EsXLKZSWCwBnEBw+AWZt8FgJBYS50DwfQ0yYgGYtqMiqnBMzonvvv+9D//XDzXbr5s4WZmGpQYH9l/f/XrrI6R17eoG2jrdIucrAOYdCfqlxcXfrpu1m0jEMn3f33adPnirmeXJRG8VQphoDoPcUPz3Y3EGOwE+Cx2NA0GgpPSCKcliPQ5xbEZxr4Fy88MPaOJoKk43GoklCl5ylunRWttmT5wE/W4AllFjkJanHYsxKiiV2ADdIDAOMDTIVA0BnqfG0PgEf1rwJ8uYATPgnVAhmQnacCP4SAMYGSo6DbR560i2JHzmo8CCrCqsaqoj5T8bsXVg8yTsezpuTgh/kQBBd7vXrl4HztoCCjyMgK6LAs5wqEOqwMeQV3biJSylw9McEnO0Qeeac5XXWqc5CQ4RnAHimAqJn0233DD5JHGCP6KG8SrkQvCSWWBaJQpl5gslXSf/YJhCHQmbKM2USBiWLrWGaUb7x8P5jj18fjrP/8T+9t1avvO71r//kJ//wC489ks6vgMrYjREKGk8FZuyDel68K39z4zrPrPTbrYVq+e477+L22dWrVzW85iNndnHHlZhsEzGV1tCdFD3/DmA/rQn4julEjsaaK5WA4NEJdYM/uigdtRv5DvS6+l4Z3LL/BZpVG50eZfiAP1pMkBv03lVfdc4M1KBJLGzSwnjSUXr4GwQuQdjjlL7PwloZ0964rBmL8q3qqIF2CopnONOJOslA1pKy2p7hlbQ4LZvmew+ct2tfFCxR3MAhi6YpPo9pPTDUyDX5wklesMMMnPxyDkTNrr4IFZUURFgOsBeCVIG1GqxBn9Vhz6qyTPYZ8eHPH07/c6cj/Ult2HAS8ABgduTzrEj71JLoGCMZgEPUQnJaINMIX/0IO3KWslpIhqGJIbEoSdrGWVRT5RSrkdEG2PHmGdRso+yxsykeeBKIZmI0F7KA5aV1HiEoFRY4LLyz1a5WlhcX1gq56xyvoglnBoXSaceUjxty5oCTk5UKKt7vKbbrOleUMP1eEx/UHWUFMDGpD/BlGs8jtiQS6eUhweHpxn1naDbfiwOfxe/htBQRH3ohAJgEUKWyQSZpYfBUDbZBJtm5ubPN0Fn8x+NPcJwIdPBn98XQVakccJtQN6bNXotVYfSWsRmxYsYJeo2K/fQLFvSlLFZ82Ibpjb0N7C1I/iYc6YsG9OIj0CEUgzNjux6kAnugAZBTCg4YBEXku1B8fS+d5nGsxaUGz9njDzJxqcCtgy79s5AD6T9bQNmI1Rg2SNzczyU7c/Rvnz/dqAZDEomLRwwhMrVekcEZg6w5RSdygo8DDAPnfNx5qyE3t1QZ1XEBiTUbHxZSkIoynvTanWtXLjESvsK30K9eXlpc7HY6+RovVzCGVFUHi1VXihQVmQxWuBlcZvV5ZalSym/f2Lx27QoIXD+iVpAvbBaxUAsMepDMi+gksobzVgY0NX1moihWeEfxhXgLMytv01TooL70Qmgkx8eAYZWqglHds+Gny4S97qsb10v2bqPjgAyaZ0q8JZhxGDtpnCMwAzJTCv54TY4kvHo4PmXhLUAyuobedr8XOvi77QBuLWmpE44G2bYiwxrVbAfI0/VYWpCzFgEn6ZIRDyUvPKmEp/jJ6tg2j2Cfv3AWn8AzFfhgLx5Ca+2KlsN7V2w4E2rc/eIjluzPcW5ZLop7xJBo0m/mNDIunCTCs4W9B7ZYzpj3w+RgtsrgGY+T1lDFmOJXug8MxJVCvXjuAyyRcz21QFxRZEvCYb6MKrQjBnU64icPtgfcP+YjwuIaIOXHSIlzVNiMdb0Z3tne/B/+4htBev4LLuY5U5nmqdGNr/7qryjW7K0gq/aQ4sMwQwqPRxon9e7dd4HJkLQ/aC/Uqwe00p1Wv9uhbpBDqxETRmUYF4Fzgo0z4uYZ/MzhO5Gj8Z6WJPwQyzhRz0be0Uv7sqaORjm3uuJn59OQCT5UYOqDw0yIiYvoUHSEhu0Nk1UHrQkR5BXbba+fRNEilDEH55gQETQFmCGuVWB1g8CYOERXUkgWpzMfMs5A3CqwJrveLTq5YV9fY6SNVmJUb68POgitZsujO30yiA/8dLs6qIMnrTiNGisgBCVTpFZDzPVEtdeHyiz7h5X/p5V+4Pu5AJw3KMHVc0HvGBpJysCeons6nLt8ZQvIRWmyk24leZojQfEckw55sEbwaFCipTmUz35GN/J73ELg+QGGy9xWL7CUTOKtdKqDGrU7++PmuFIrdztbkG1v8hIqzwPxYXKNu5gDU4ep3gtFXocadXud/f1dDqUU775rcbHO9kO9WqECowHYGMoeFVH3dWS3K5nBo/w/Vz5kDAO1UAxOGd6oh8BeewHgmTrlPrBNp8w0Ac+I/1inoeOkvLJRnb3GBhtFV5B9/0CoVkD8ehL+2CAsQTmUPgD8OFmCHNmdVjvx8zosIh6qo9TW/EdOUMyQOtQw+JM1TOwfHcPGSXF4NkGDVThxHE6NEp3nKYnlCakpsM4ZaqzBA89qr3JEZ+RV6HjlNPznxvJsPje0rB13UpAl78+WLLFy506vEM0ju/iczpRFjuMMCR3nrT2AY/1Rg2P9x71arpS9scvDbguQXFtupMa9erlw88TCP/yJnztx8uwnPvVH3Ix94IEXLjXWfvM3fq3WqLONqTmgrlJSkdEzviWbuu+FL/7CI48qgH2jbrNUXb7veS/c390adFuwhB7QloOvKH64j1M0TN/oMHz1DOZc/6I9iyPMGvtIit8gJSEdn60owNAjUnEsVVG8cBLqMOzxES++NiZuJqNSmXPR7Wp1lYVzLoQyC0CJq3wBvl6n9npfrSqpNT88iMaTxLwQR1esbUnqCFmmJlvq6scYn9KX59hDZM2AlMkE++f6WlKxO+Kdbaqu3nvg1R1Kj08kMeFMZSsjLpoyVeUTU2MukUPQdtSzRWRma/jWlavRVy+dt5vDeOmTDCRk7JEZypTTo6z64y2DvLAZbNtzda5pLEmzLKmVSf7xzrzeUelzs3vU5zjA8o2NzRSvgGc1rfAxIzcpC5W6WrT6id0u+kkyA/axRJ4abG/J8zgpvTicKjV7OF6h7H6Z3qrohaw/h/u2Auc6LfmIkOPM9UixU4MIDTfIOwkh4RRHKTIIp2OUFRfjGYQasBe6264MwJwkTPoDkzL/uaBtHEGCdTr4jhStNGItUVTxpCRt/iBd0rFbixxZIQF2VpP+AfYpaHAGgKIKcBK4VQXmxOvN7f2Pf+oznEu/444LLFalRyxdjBnq8fF4Ho+d8mTHlNMZfBi3Xa+WuD7IW42oLjybkgCr9We3qJhL6WvAFFH0Xow+gNlrH5AX7wHII7osdUaaxzU0LuUk28fCXjDHBj1zz7m06PH8eCDtC0vm0AFBraGNpgFgmy6avOBvGVGvRXeFU1mWAcsrDiHzpUZ0YrLuR2k7cSUgHdQf5ynUIuszK7S/INJP8mgrKsGfWmRw3XjzZ8lFdKCBEV3jDTTwg4Ej94ni2w+hjuyAIzsCTYnOFUuzpZDMd65vkOaIE5kxgvSXZosc0Sh7yUqXxbbjKK6fFTXKkWIT3aqG/ATHxmFoeoB7y3OGEqM+R78Qj5K7NUE9B5AwvqRPruypQbWC1GuyrGI2TnOlUtg2ULyQQaZjCTpJ8Pj8xQObJKZg1GTey92ZVKvb5khNrljhBRyQqKKo7dryiWGPA7EjlleuXdmajnt85bnf3a9U62xkoHU6TIlG0sTq9YU03zBbrBZbOsvEjoj2CX0QyD0H0gETHwz6hOwo9YO23qN2Fhx4WpkG/OMz8mx8k6Qc5ioSi8zQYNZQJY/W1rCkTOWS+toxDybJ1t6rSw011bODvyqvegPGn8ojpKJpixYiEZbdIeZcFKpNFbCLwWAw3UBg3OIq8QkA1ubp/+hRszw4Z71KnCl6RvUF2rybjbRJBebdsLzlADEcCPJ0tDmn10Aw3R+ALBOXW62WEYiQUIppP5lFOPmCLqWAAz6GOQVLkgxJbtoCGEF4kn2QwTGy4gJ/N6QjwM/e8mtMysP+AIge8B1QfCjMt4Qig1HQYWPosiB1OOQY1xxa0ukwFdUrLZF93QKAY2Tyj7eR8PdhIzwyLYwYIn4yQQZOSWeA4wWI4BEBGkscZ7zlPhrSHw3YPThxcj2dp3cdX722OeocLNYrjz/x6Vc9+PJcqby5dfO1r3lFrcLOwe7X/OX/kf0HncJQN6/S4nwkGo7EKsXSPRfv8I+PciRrYbHW7vZu3Ngo84SwXWCgYpA1lIOypz5k8oduKUHOBTeX/aMMB5/b48OSk3Lb9SOpJU4nJIeO+hzYz3tyQoUgNBKFZdgAzwO+1FapgIM/hoxgg4ChMritWjGNFhe99vrLG6TFS3+011a3sUHnQQQqK02lxCJ56OOAOu9FBWYExCIodYEg41M64JNnEMiFG5GN1/M1qjbkOIrFixU9GeSwUwgwdPDBCYChgBjkM5Di0ypUY9r3peXzhHolh7QEopZO65HijaTVC7uxpMU4LQIhQSF962HmkwiyKFaN1UY4QSGqT4/CnGrsxPdo9GN9RCXEMth5jsmG+kX2lQX8AZAm3KuoPH1bewSVnhndB/CZqvXDTCanOT7o6JHnbF5gilM69BtEecj31g4q27GBo/So1Rs02x2eNEd3W3t7426zv9zwmsYlKQqJeR29iyaKnD+FEEbqrcUPzmKN9SE/XvCgPk/295pEpALTh4CvSSND7sTIGeWgDqDonfhjXEG4x7I35+nIiEjJJ9rsOTScjhmIB3wrIKGHII/LzBbOYY/MYZM1bIKSxcGIkTrMoQc8yRQUVNJm3EexuGgkY2rhxwxFQx00hU0cU2txQWKkyITECHCQ01et1Nfi46kze6RxJz7qpMR05UGUgeHT6KriYSDj/m4L2dAIAnADjL/7AJCKO6GJgRl8QCEFzpPyhA4+XE9hCYCF6LvvuQgyGYQUFChEkH1Igr+ExvzekiIUar6dSRD4bhsPHFzRJQ/52KwyAoSmyAETYMa3xXxaiygazCYabhGJs6/AuDSdlPsEf0d2O6SF0ziNeIOEI5hvxKBg+9CMysnTAHCDExkFcs8EUNv5bAxj3yube5PLm/ls8dTJ0+dPrU96zVqZLwQXf/Kf/VR3OGp1eo8+9oUXPP/ei+fPvetXf6tQ4TSSP4EY9cAMKyj1e+65p9lsX7+2yf7KqN+7/3l3v+qVL1tZWr557RJ6AFe02WTVlcZ6Y2+PxauJQGrhwK3YD6EAIN8K7Zn4B1IhdVdNNI8gDBzSysCtd5cCrKdFm3f29sgRxqtQSI5YQuNSgS8R21qH66VSUf3yoSMdk85dSd3kSUZ8jw0fOnuNvyFFLaJe0NMDK6ZahKjq4hN7SnRwIiqxQCwwsuAnhHqUgEYQsYInucPgdATKi4pMD0xzw5vYW1s38cc4PhFBgAItGlJixxp/DCxgGy9kylocq5aWEDj8zoxhyukAtgBDAiAth2cRDkOGHlEUshknEZyHY8xcSmgmMZeqC1B0CIQCyYchtPAtCfpALWkZe5aWJkTg0i3nfALmiTg/bjNAnaWcgKL5VcLHQbTqiJ88EP6x/nxifjCcHDS7uexkfW1Cy5tON5iP7+xtU+d6k/Tu/ibHgJutfrM9LJYXJvpuHvlhDY4uBBcDP94B5MJokadyq3xJaXFhb3vLtYGvK1HAbqBLROoJHIqCmQAcy1vS8ygmPk4ziRZglYCl4rZjHsUPZFFHDGyDA8AEHh1lR7RoD9PDM7kgiPHI9u4uQdxcsIzowAPGI4IQMRDXXnzck5X76EgXqJ6KKjxk9eq/RtSac5Ej6i+VLj+xlgROICgKlhcAfETREnIgyqChuT9RHA07ZDBIJggk+Dgdd8IbOizbEur1usvLS08++aSTCnHJPzD9MIbjOR4XHEMTPe0JqxOFgTgdzeFpb+TET3+EkTML9xEEEfCMhaiMq1M9ziiuI8fYTm0OF0837u+w2DvOEOpBALqu45InFTGpIKqrnrjE3/40wDKIhR9dkXWaAXDnra4HzqE5Mja6EeAkgLYknQHuj1DBQr22wGYun2bsdLiaPCyk8tVGHb45I8nQrNvnntmkVl9kewInf2RQRcQ8TYqmrYFsqTo44DWdUb7d29vf7/eXGG2m+VgwD0OboOPSlXKgoRwwCDw4QI5UYLEc5kLnnI485/lsncm0gDGmvt4fqu+CZ+Y6eFKffTuAcQSpEISnQs14XHKJT6TL86xEtUKvw/unKqyYlKImU7RoJEqVYebrna4VohZJIq1wxULMdsZYLGGCtolOQilxuiQBApNwhDPw5Y1O0gcYAxlsrduYYVbFoIP5BXTwcBsiSAAbItRk58QUzBFIfE4Jyf5M/UQ/NreCCXciiQZAcZL4MY3Zr0It5dujzSIYwSPcKlzfXuAHglZSVF3VYTYJKCZ+CLKEhGNAji/FgqEdhTh7EgOtcb+owrcsIzO1j0QAVQKMihcqloDQWEXR8QPtkmlLwiXZG07yLJhYFA4IaKoWF39u0qsVhhdP1VlmYQmm27nJHuB4Wu4edO+/757r16+eXn/xxsZ1oiwupV/4wB31nG41wZg0yHsSK9rccqZ1MrNYf16r2cxM72LR66knvqBN3/guofe9FDyTAoZeaAp5wp5lWPmJZo3K22FDo+EeJO2ACZSMzrQhGSMsJrl8IyR2r2zlH8wg5yjWhB3r9try6qVLV1iI5fn53e3ter3KC8MjrpjytcDJgMfb+eZVpVQeos8lG1RrzZjJH6JmwGmH2Kxuew3XYIv2S5PdaSVtBypstEzSupgA5jQ9mPS7XW6SlkfDHp9Qa7UOMmltYuWmaT5HvHfQ7o3GdPu8NKb7B1yvZgoZN3MOeEbQB2ofMqFW8WlEPjDJxrJW0bnkgNoQINlG7SM/fF6S6KgKowAlx11aXTHUjTG+a8WnCdeWVxjDM+unj23zBkerRYsM05QdOJw/WVpYpF1fWlu9dOWpIh8KHjJsGZWr1f2DFqNv7oGTIgrJf5JwkLJI66tYKkELkm2wvo/oVUFxLINIFRgehRGb4CSrtKp404JYP88oBh3RnUoRtbh0jBIRsA1vnIY48VTNDUJMe/aLpzbQHcE0lXERLvzH1gVLzprSUB2VACY32dbzn96O4ra4sgYlZkFa51D77GnbL6tHhIJJQo4Pu/iMmh2OUuHDwIxoAGQLEKFT30AAxhMYYlQq2vR2p3d1YyOnN5DyB80qa1msPVK0fA73Fa989WOPPXbi1Em07eFHH37pgy9vt7ZhBiJeIRHiaKBRcSlzgu9gX7+2M+jxmcLpfq594exFvW6Xt3MMaI8Z6DhvXlrw8ycxZGEmqWdDiIgB3WG4IkcUBE6yQ6hkbsZlBUgQy3J0SuVSncuU+LADDBqZckwQAj8QdOMRTZOVaOwd/UJcNRmj7SU1ooGa0/ToAQ7Rne3gr0o6G2RFnCdCBR6JMhceKRK+pJJERjE4Ku9rzuSXIJi0mpOqVLQQjSfM4++iw0Zr56kn3EniSdhRjvokoj4NSFz4uT3S0+KAAJWIiP+arXpr+fIkknRy+80Ovl6WIRiMbr+FdKiKTs7Fhz+f5RG+dEjVkoaHM0P4V+sNDsqoM6U51ev7qqyy7NlaEKBgflpo1VJNqXTQ6oz5blNO70WuLC1Mh7zKX86Xc//hd37n37/nvRwNfOqpp/LF3IMPPvhzP/+LfVucgA5ESBdqblarJ5nGP/n4U41ana0Hvvn+1rescT6h2dRH7hyfKBgYw8fJRDIy3SIoOG8DhKRvg3ObIKKH0CSMJ9Kg5YI3WiWYEZNmKBRy4GyzosOG09oqSzjCcQQANziJpcoYG3xIBcP3h71mBkz3Bx+AsuCsFTYwCUGBPtNbc0eAjombdlCNBWjBhiAw8lTnQ5AB9hQZw7IoC46vYBe1QzFv7oromIP0Sdc7Fzzoe7nSsL6+ThZcDnzG3Wa/fQqdujwa9Yq8MRIxz5SAk7aRmUs69j6+NTmKnPQhbsL5TLXFCyCk60CgA+AZD0BAONZ/LjSQzdXPLxNBhuYv9qZEVvgPbZKJzz0RSAfBqzfg0mwjKS85bx2mAw2PMdOC3oNk2GT9bmpgQ2tI07tADR3j2gLDoTEvuPcHPMw0HfDMDSP8TKlcqjYqI43m0z3msrVlHpTJFPKNxeVcoTTtN4wdWgK1BVJY1G48Xjm/xghwd3uP8Xur1eS+aLtzUC6r5abU3Rhu9AFxrpjS8KC8tDowpCybKCEe5/7wr4VGXknYxh2HUc11CzIILSRBojPYPlNYqy7gQ02me7EOWSN8FYrVZ/jnYAM9MOJlD1e+rObF1ZVUiUu9RyakwZ+mOwbgY+fBZ+tPzrCn7sTp/KkbDkMTBGD9wAErDeb0PtZjue1o2Eg48iFXkUJQe1WB8fecJvOL/1FDihQr/jBAZm2ASCR9L4adJE+CoRcEJQH2Ajv63gqy6vdafAGM6PQaoDE+IxZoGE9lDg6eDiSdHiVETCIk4UCQRDFzFEhVCDaEDrECzYAfYgUfcJ4WDgQBHB87N97f5gepYTsGhDCd/a4a5nSqUKrkCyW+xGJNc7pt151gXIvdiqRqgKnkOXavKYcGYz6WthHvQPMZX/TXt8soAFpQcPJ8IchuIOmNjIgBqY1TQJXRKr2Vw9PmFmXai26wikmdSeHbO3oJsN3Z6fX3B8Mm/QaPKy0sVkbjNg/iMe5K1l4ikSj56vaOufZIoiJ7C+OhxCU8wLeKcitCiMnJJyMKTqfoWuGNUASups0G0gTFczaVThhGUoNFJ5I6WOo5scksaBivA84tNkFCj20ADP6kCAC+j0glHB0zZXps2mcRCSUu/jQnegzlsJQ8CZa4CRGa2hraDv3pC77WNuKfNKJgOg8g2GIRUXHNCfPWmvArQzfLOQWH6TxAIwpOGCsWeL2wcrC/DT4VHhFwS9x0cpagJ+Fuh4NPcAafWbRYXEmf28BQsDwdj6LQuJ4fxfDQYAvB1cwKwYvCNUf1zyQAcgCgnGt+7hHEgXE98DDscSbPdZ9svlhfWqAl5OidWv98brmxJBzrBkXL6zC3hVotHwFyKI4Kqn4bRWSuxnKzGejTK5IQGkPVrVRretacDsV0d9jvDtt8UnC8vLJw+tT6ubNnT589xa3AcrW0urx45tR6/pTm6nBM+aFnwKSOWT11vtPpju48i5uxVFoD0t7GZotxPDgkR8fljFE3GKvz0ZZ4sBdVA5evpHKciToVgpIlYb3ccejx2PFIWFj0orBh28OB0Us4RCawgYi8Hnqo5S/qh5ESi3BkRBWN6PwzIo5DNnWOitoBYVUnPTwOjMW2EzQxXg2CTRKkSERPl8UkUreywENx/QEjdYwUIiYe2BOYzFycFecn6nvRD1/tDEwSBTgZU86YFIBN18QMLFklhfc052EvX33KWcUJ8yEW8MLCEre/kQm58yM+hqB1BIwnfRv4KIL7JG2PnqTm+YUZNwn6s+xE+BAK0jG8pBMYCo7pQCB1rP9cqDuxmYBWlU7cCTtMwDDN7IlVPZ5z1YfrpjTNNj0adrhYr5abUxUAJKbV7XS63VOPDUDH2NMXQMZ0uNhsyaJ5Pm+hAoPjOjTme9bp7O7Bgbr30Wi/kGMRi49KDj7Tmwx7r3/tq+Dh7Jl1qtwjX3jkNa9+xZQvtWnUHBmKDYMDm8KiCDkAoC8dDHh7kSpOG6IRF0S8w4cxKgloZApPz6YjeC4cJmjO3ErnboUv6seauLRCYETBvvkEb66dpotSQZzq9uIGC3GjzRpjV/zCg2QOMlWOhhV8YKLg6fQ9onxods2EdAMADiKFDcQIEWyohTPt+GMc2WHwMSGVKJQabmic/SNtZr+ytayloXWQXiAFQaeWZAOyzgkAX9RgPEEjTUKMO9AftIhQT1o0LeNY9M8wPBy2mTHR3LDTz24ZKc7RDwkFIMmM83OroOB/KwBmQokrXU/d+s8QxZMDM/g4gH/wDLC6ndhfEWI4zO2TcYmV24SGz1YtbSTlZon1/XGqw1Jvp7U/HvZYLuC+UTq9WFoiGuu/2DSz7FUQHRqsX1GXiMumLNt3e80DBsDoxLnTZ6hCILAgQR9oqRk+hzHyxXanzxCdEuJIPfsZXMcvlAuXrzz1a7/6r9fWT3zmM39ElJe/6uX/4d//u619KQT0sR2AOBHvON9A+Q72mlxI4imPcrHwwAtefOb0mavXHhFXdhILVSAK+BgUy0XwDG0iQucZIt8GDTrJ0KSTXHitwBMAJh1IVuDBVJeW2i1NgxEC9w7QXYy1SjoDx76CE4FbNzip1XYQ2jVB0gOTUOgTUbGQna07gsmTn6JgpMAh1Jmk3Saacw+CcOJQISgA5FnuEipNkIiI1tMZL1koU8DgAmDQHHQJ+YiI98BMy+MhGAKBbR6K1w0qK1/uqfm8I6SGP8adAcCZhI+GhujPIUCKZOE5J5grdFtIBLp0b1bAGuJiis0+b92O9TG/XLW2nGXEO+Vr2sNJucE7y1KdXJFb9QNavjTz00G2nVk5Wa3XCzd3t7v93ukL91zf3HvyictPbvWXJuV1Pq43HVdrDRrUYpZ9oup+a7dRLDVO0FBwrp6vq47q5SUWY3lkt99Pcy4jU1ho97NsDS8tnR8PP5Ef0/MztUIEqsksWnDen+nzXjd9+vT65k4/nc0XGpzc2m/RuWc5AqFndDgeL43TcB4l1B86THRMLErV7aQKuox9XgcOnXsCmfGp6oCMdY/8eqk4juy4kOZKS2dxkyYuykKugo72uq3GAi+5tRjvjPr0QWmeGJnyqIVeuqfgebq+zLWN1v7BZNxg4kM2mBnwPAEjFFBIl6uIbCNr0MwKlLaGon3IFhu5OZ7Osact2bJSCwjxHPt4fe4zpLOtdkeXbrtDOi8+z8v9bBbT+AAvSSBIyA1SyLDMI3iwTEI2T1FOPMsuEN+RAJkTOHRJNOXwrCy6FASBrk8GkyoBjOqo1viIH44T8blxqiJ3m3WeYLS922Q/AlMscQWlwg75PffcxeVirYlk8pyCL+Q1bKyUG3wziw9Udrq0aOVqocDzL1oqTfyptL2NUfqRcabcoZw4c1IDsYQBcJwkAIxhH2aIzk8HXJiepgoUFUqYTw/YtydHaunsehbjQVpEZuWTjE39lGNbvGDtyAQT6ZGNXk39xCiGoSR2JDbTpZgT+WOcO4uCTzrX6PjAiX4JTVUaOT7BOc62WJ6f5OlYs5VKjsljpcz8jPXKg/6Qty/YdGVE11hcosAuX9/4wuOPTYuVU9P108UTT+1eR+PK6ckXdq8U1mqT7YONjWtbWxuFYvbcuXO8VHZw0DzYb9115wU6AhY89CmP6bhsrYZmYqnUmTOnb968sbCyWCwVqPC0+Mxeb25dUxNmpxOokTxuy0oJsq5mJ7297XS/xVGAhVq1sVTnPnhxOoA7KjCZRxG9T0OPadFbTQkU4+WUtN3fgyJpxWge5MiH0Kw3u01oQL4V4N0LHJIpYFSfVNTMxAMFNT9mYJ4gcoTBExjbnUkbXIIwEHF/93FnsPn2ezCa51IGplN6c93aOZih5wNmkQpJAiJ91TtqZpxrKNBURKpHW6dqyLsqYm/CJ69lYrUTklH2SxdxBWZiZiUhXgw7wodPDBywEM2rBqTIjAwEOEnlWa4TTBD+EoWvgxr/TodQTBJO+gR/gJCXOXwP8ljBxhODk1jBcw5whOBp7byGBZaUefugO7LjmmghFlcFD+CMBTsQnANy+RJNuF5dMFR1L1IL5FquSuC62VVkhUQnTUDJZFe4nlvSsT4NjLVukhoMF5ut5c1mx45PT3r9DjcS0IFOt7W6eoLHH9QZ5iCbYqeWVhj6DIwb7APUqvpqWb+nQ5J6BXasT/yOB42FysU7z506tcbKDtuA40n/3PlTy6vcSaA2ogam0KqYjKx0fxj+771wbtDl5nCx222Nugc3rl5uDzSyQBAsEWEAYJiOiG0sYAxZMPtQSbi/yyiB4x6yA4JHw+llGfwdSHo6PCNxGPLGhXrrQ1lnVZ4ciUoYyDIhtEolAToneLpxp+m8StA9QcOHsnV898d2gCBfgBSAzjAot40FBi1ENywATlJTZTWCHY2ZacOSYjsFt63DYYAzpDnlaRGuISBnSoStBhGJFd17RTz6ugRqK3q25EZSXiOcGtWRuJggtOWl1Zs3tZOETPAkL2n6O21SaGsNJ3qpOYeyE41xPPueC4fFSKLscGICQoAdcH/SAnBb2IfxcTqHEX0bTcwyKxL6s+YLOZA4RWay05MJDvh+PjAJiZqnS7McI0Sq5Um7p/g4bHKFe84QZpdUkIKKih0afBazJXssjDOzPMqSo9snmLid5j4lxOE9vmLDUSotN2RSJ5YXG1T0dK7U7J/MVrJUllH6jupSYzRpTUYq13yGt2MYAnE2jsN/i4scvXjsYHGRW/uddpPNyhpfsM4zIBmwXfGJT3zsDW/44kqjpoN1a2uPf+Gxe++9Oy1tnPL4i7/ciMYIeTLmGDQPQXPijtGgzkuPp/WFxeXVtcGmjuxJKKyfSz6aD8N4Lz4LHcvLlZWcRUDsH8nJcx2E5qHBGSVh7igoKp6IWgJBxXbUkCtwqLfwBoxqAqCsYOKP7dUP4owpgr+TxXaTJBv7SddluA8ckyIowN5r4VSziG5pyM1FAlwmCCnEmAUwW9fWK0Q08clUTEPJY3qo2wcat/KBGFWiNG+oTPPjbKffdXwSjUXK75QeGn+qndp+eWhtFBtPMMWvXcbyOowPzdbmJgs16pdw0oQxkAKNwf7q0rIVqMYsKiaTpMHzFnEthSghnG7Am2MPn6NB+Lh/oEss90z6IzjLkxOQbaFwrl1ucoATYeCcYcSQ03GXw4GxGCX6df/AQO5Gp8W9POKofmiSgpikNMO9G/LUyIo0bUivvNGqa6UKbK6eE1qu12h4d/f3culK6mC6t7fLIPegtcsYt1ar4yxU6612izVpVMI3M5nx8djVygK1uFHkkaOyvimwuFDnu1XUTnoDkvlb3/kdL3zJAx//+McpvK/96q/58Ic//NRTl62R1VEfMUaXMKECj8qLKzxAe/067ydxBW/abu2fu/PulZNRt0NGUAWKOSkFomPwiX89UD4Yl64j4Ix8LUjOuICFaaoZRHk0dM4H51GD0kKBCky7QyhVlOFJqKj4OH1kznkVbJzkiHzBCbBnECDAhAZDqB5PijMLDjBEMOz0WKQ0WwVsvbEPpdCJXjghUaF5jdS4SzIolDRhAcAEAJhXqcQK4wWrhyLBVRJeV1dr7ybEImKKVVEkTAzqLZGJ5Q2DWGL6Rndg8wKcPtyguu7u7Fu91cY1ozkQ2DIbddXGceGBczuE2jkxJQfOUWP+EduEuhwcTXESsRzGdhwHgieA85n0h44rjQgSYAKXMKI/8keKzBRE1JKKRBOhx0WsqBaM7akH20Iii1hJ3nLjnQ6ygi0jpyU+XQ2nxeU8uvNj6sIJdafO6gLqRZ9GZUZ9SvU6nfBBq3mpx3qyVkoYk+9dukTrfe7uu0cbG+W+6hLTeernmbOn+EpVp9NjA+jCyrJWEXNpTkszYuekPkuIaA2btu12l+8btVsctu+XihWKkAUbHpCFjHi3xpiqSydMNeaDYLl8GfYYWU2ZQo6m+VKVlW0kLYZNFvAaFIJnZMiXGS9RAmcGf3e4pIHVPyWMNbJyMxsHOYgSH4/rdtIfWBHo2o4zZApvKvCKrdXDJ9WPETX+XiiUPTQx7JrgY+tDqsP4QBk0bDOi7tQAghdzV2I5Gv5OE6BQUNOGk9LsDBnXaUQHybx+MT5FFs+KyysoE31Di0SxHQMbeGA1lSGv9AE39ZFpjo7NaLvLcTwWNobksBlvo3BC8Ms3ccVQEEtBZNMOvZNZzksiHJZOinxKbDpm8QXbV3oYrXDC9PrGFWXQ3uaiJlszooSShoSUlBkgfo+15zwVRzIRMibEAnAJuGfwBzv4SE9MHOSMqOZPsCRM3XI0F06A44SE4UkEG5yADJw0uQtn7/Qe2Hy9VRbY1a1uNZBa+8lZ5cE9Grf6bY4vM2ql+DkKSe44uLHYWNqY7HCDhGEqR510dIpn5bhdgPJNMqw5s4XE2Su+ZGcLp6XFhepCjeNZ0t0R5TJhO5eaSyc6rFUaqysnsxnOx7Fty/xcsUrFWrd3mTpj65caTUnx+KzTZLhQXRp2DibD7rA/YO5VpzsfdPKseEevQKvDQWmw4Q0pNDu6DBAMeYrhAKioZt4WnHQ7TAm5oOPo+lVQXIo4XehR3Bn5ZAx1cLgZlSBn8OETG9XEpubAOXrgnvQ2kMIHyRPqZL1muo0nGoztCYCAP/v4Hj1iw5gEDcNcBlJUOd4NpMaSnsprYJtJaraiTp55FWQoH6cAfQyUMQDjtHpUajm2VqQYRNsiRa/fxhuEwIxH554zAEbDbowhYXlrYvjyZkkSGzlo2SKT29vbP7m+ynweBj1pxKXD4WtrwlZOdRAAfKaQ7uP2LHWD8HSf4H+UQ8fBJshtkIMnwkxSSMLgGPVElqm6GgOpmVKLL1Ajaovlc2NgOZN8RWRMeg47J55WYNhiTXO9HOVEAtECAPyZGdUYM8GrlsjVujHgoVVEe6irCA6fQpZXmFknZ+uCR9VTZwoLOTrJSebGfvuOCtfjVtrdbq1QT1dr/QFPQFM5+Wg7FMa68ZDjTVON3SgMOl42hMkjOOkUT5aR7HRlZbVULNd45I2v4Ywnp06dHgxbZF6NSVZrJDBMD8xftVioVGp3nj7BIY5SMd9pNTOjzv6Nq7sHOxAn/xSqynWqx/4ZIOjyhZUHIjPpROJ26XhQgG/vJPqcNJMRPW4SYS7UnSCQYe9XQxSkFCKSihufCJB3DBLEE3yHTaejE1f4uIpDAQOSA+5JFBUr56zs1BeeHgoSO4M4J2M1cHh6PGumTES2XaAg7Swz0g2pqD21qqugaImRF8ziD4UT6sZzwal3GOfEO6iA4tDESI5gDOYpHPCBVcB8tqJYJYgjQNPpSpwztfs0x4SyLuDElQtmBTR/aGNsPEUXVOw3+w3+ASDMYWyTgJCTobPIMRRCBVhr5T7mdCSkjQCdK3GOtGRpRBb+5BEZE7bDEHE2AjDnj1Olzg/dnYcFvse0HPLXlIjlP8E830q6owk3a5Ex24KUuSU3KWTS5QpDZTIxXj9RZ3+407pB30ezPGp3mNhxTRQmDpr7kBi0m5vbGzsl+hHTHjUNbCgPsCmzTqbVH3Tf+he/ZGVl6eyFGoXHIlpnmLvz/j/nJUqxBUODgs6hNE3O6+TGnW6bj7z308NpKVUaNbhUyEIXp6k5HAKOOhnuRceLYLFQlE1gjOcXG0N75j4maPeTLR01ozFSwHGvhI3cHI/tlBiMmsiAJRypLxdoU71uk/U8VJrv5BbZYO8csBTAq/cl3vRrdWh6uoMhwWtrq+goxToc25nzfIHNlV5nyCZf2Zt6KZEdRNYUl6RRaL3RQ15oGWksgek9WVwuTXgGmuWLzEK1wrQIsjDG/yxTETO+8kcDINHQYdocGAA0ZK5i0bEtRtp64yb4ExUEnHYgTuWLk4KTjxd3LDTbBKTsRRAzZCZmswlqLZrEoSoCSgW2F7ltWuSjzy96wQt2dm8wpbIxiIZyLHSXKrViodRs7nNkkJKlkPUaYDxaFgAvlgMbscOOpgYkZ/xodMctdRDgEturF3EsonCMNVkBZoZH76VP69H20eWPeoUsO8N0c7wiowpDb4iBNAf1bTQgXxHQoAaCKnFR5DdyqpZh5Cd9CHrinof8DU3+hqYgHhaKLgmQKiXhhQHct3unSumwoS3EQzxCw864eXiap8ChayxTEaEjNDmjJp8M02pS5JRqPpep5nz7SkqAjxOkUDNVncT6/d/7maWlhSeeeIKHznn1amd3+5GH3weOswdlAE+dlO644w4+A833k/QR28mglK/cf9+LOgfXQSNRdezq5YjL4FB5DgaCJotD5YQPCAQ5WgBCLAccbc4zOJ2yO52CUZVHMsid5istRz7kixJhRB3QbGSrISuCYn1rr9OlK9bpF5YZMrazgkJNJyzwg0ClwoAMe8o6MrfxtvRJykXy0mnkzNEu8Bmeg0P1ggflyIrPuXIBRNWYIHUwMwOOy5/qFHw9px5db6ZYZDzJFCaggYARM3ZMzFysXcf3xr2FtUaBuKRCfjkO4ALBhmFIwTw0CaJ1w9BbU2z4owIQBC1p3Od4W7XoT2pIS2l6uogqcuNjkDNmyhZSIkDcHvYk9KhPiBKAJI5epQwBSSBTnA1Fkv6VxQYqgqpJO0yromrJMpMxpIVrDFpiRjsGxha2+7id9XK3u4oE6aMLZorV0miYvnp5q1Ss97rTa1d37r2HA1pLo8Elp0AypIsealSuVm1Qry0Puju8PptncZLDOIPUyvLJ7Zsb8ElBM6SCHci7SguODZwAOnsOBB/3xP5jGydIppMUQnIkhD9Oa4aBdAkDdeQ0Ems2GB2r8AbcmESKRKnXapu7OywoUO40kpoQ6nPNOpfG+97odFQWVjRuIVQxgLSkWJFC4dcd9Lx5EycqOjsjQxyuf8plTSpJMLS2rdnomIcFQY96K+ZN/zyhKIp5gsBQWY2G5REeHBOnHiiXyGVoebC94lEuzqqmTMazJaVZPcsZN27cwJMM4iSP4kqP2mmGzGPa9mGdbbtIBftRosZIZJEKCqAkjZ9gy23lA17wjGCFzYx74g6Ah+GUjyw6H+XMunrZCNUKNypolw+xAEJch0XB/B3AnsOZQwixAHInz5zmBxOKAQByYfWVIE/P7Wa3gxwdB2niSYnwxzauYmlBDElp/GNUyYO2JTAUAAYUDT20aqwBOfWcCk9u9TypLYbzGCVVrljKc5KODgedpsDYsqdTciaTqUOwUMz3+l1G3bxRXtP3Y5liZ/b2dz3Pni582qwSthlMUoFJUNU4Kj0rFRParEX06GZHBa88HDLHN3BJFBgObCDgZIqW9EywBLFJTn67vaZJSY0OI16EiagJxdBtNqo1pMWIBU+GmgyjaQClP8oCAqQmC/DSwYaBYr7CS9AA6qf5gT8NFVk/IBoPi4lfb2uBKfkM630qX9ilEyUOmgjhIBklpSixoXS0sce4nYQP1T1SCZhi0p2cPVSSqA0LYIYQ8WBdNP6UDAzRNXjpsITG8vvjjz/CvEmVViujygSHwXn4vcAuZb3OTtLurt7xdKZE5LDBxw3eAIds4wGKeCZt1DeONP/r0Z2NiJriUhIMvd2DVGgvVTMCsui7+GMecIbQiM7hpEIU93anR8HHo+uS2uFYkcvVyPGCDdAoVaQfpE2Fo4hN7pS7vyMNdWXFEFyBWMEipaRRDdSZAeUVoau5EJhjrxYFGKYGPPK8vFTZ291oNbcWGiW+lUMFPn/+BESgSSmKftwilPmSWbnKsjYHZ2kFOFS8strY2dVjWiw/80eTAmyf/2G9Oypj8WlyhA7G4EhHg38AHGfOvn0orDpZTwTnHL47XSxgMsBnbsLbV+PxHk46FlYMVTdsxOgVA1FXy1z80Pq7vvqoLYC+1Ub4H1Xt6KgLxyXv4uJJbRHRo2hSoLF6bLUOwEFHnZm4xHXaWSxZORKE8SCHCXLj9F0BsAnF3z2xZ1M5+REiIuAw9vXoakUtSmTH56gYVynAjKWbYaWKdVN2kjjJFydkA2l7To3Q7e2bzJPZgkQ4XsJKD6mob1D7C7HbNLeEOo4i6L8z+Exti6JuyeN5br0qOwkQMJKJJRTozjnxd5yA6aTm4gZPp8PZ8VkPk6RIzxeSTwLe0npizF9ZBlUoDTxrMGZQFAxVh6sQ/GOJWO64eUb52NTF2W2z/6yFbWz0iU0kxo20sjvtDZTyjX/+z7FDwIPP9EuUHDd+3/Clr4O8lWjUmatajkYH7RatNfWUVxcP9naGI45t6tiQS0HlreFM1PhBAUaO7YFNeseKOCwqeP4im8bkkPuwgxRjj6gmO37wt2IgOQnL6xtDDEaD5IiIjDu4H8LRbUTDZg+e0o7JlJ2kg90myyN6u4AzSYxOcl1IcU97b3uP2uvGBylu8xoenZU/q8J+AQbx8uYRVyN0k8yMuh4kw1dVrGnkzX3RlDrRg5hOa3FL+YVbDICCrBkFUGQQYuP+o4G6SgxObCJRFipqLRFFdKRLChBB2lnQAPBkoEZ1ZpuCCKw60ZwBcKi23jgNPjBJWUuuKVK9vkASDLM5LoSgjF+RTRrRjwsEf3NG7qQzCc9VYw8KEZ1Vd6rGE0w1shUW2gwygYBkqznRNIRwDPgYj+vOOdg9sZP0Q3QHAhFHi1ah3TfEx0l1wolBXm7cybMbvgiMsPDHZiqCTwRTQRmvco/FP2syHjV3dFAGBPkbslfU4ZiVad3mlaGb7vXogviZ5AZCGGiq02q10Ta0lmHSZz/7WZKAiNtODbtQq3Gxu9Ni3xrO+mMeScoV77rzHqKrF9HgTotndtpPyuRT4GR+gckaAjc7Ukf3dLRjbZCP9Q+eybJxz2OjkB1TR70gC5/IBEM9RARVa2z4LCo+VCB0toaattlna5IRMkY9T2e1yMwwyrLG2IflOlKW9rjd7URffmBYik/Wvl1Iojlb9dUmHqRM84jEmgI9JEVIimDDWF5DWUlGe/BmVKllbGWBns0WkyCiNpyrSGwDaLNwxMYxnuYvT6NBcUlPIjpqkWbnKH2A4Ex7il7E1OuyfTmVxRqOxFvSkjzpKvtpfcMRJ9VYX6pFZ8XsvDGCWJaROds6TvJGnGAL9RkbIhpd+zU6IqWWC9KA4hanewK7jztDqPuDlkw2RHHP4AyxAHL/7b/9t1Al0CGkhsGH5V+C3YlNkeCJTycdVWCIUjzYqoFcH+NiIcYaLkZfYBKFmlzO2X6ySRxVC/idUY+2ATRKniNcBLFdQNXtjbupSZd7wXt7B9evbVOrX/D8Fy0vnWw2P+7ZMNGAzlxXqbR7k+qp5WFvlxZhoVFvHuz2e5NCvt7vtgh1JuGT6ZatZEXaQxAmKS93Bk8A4pot4Kg5LOqj4YqbpH8UwxEkM5MkAEqJzJC2A84DzNPKIn08mSQzsNWJdZz2Rorkl+J8MZtyMsgF26qNdmvpCOwkO5MOzjqqvGzRy4bQOsOo0xta5VPVloEYG7jsX5E0iUCKXlqTZ4MVPepO1ay7bhCE8VyQEQAKkRFviamxHoNgNUTDSaEwLJvyQm00mFULJA4jw7c4nAd4gSAwAQBMAQr6iF2agRhO98QJpwybcSIT5EcTBrc0IiPWXEiOuIk/0DShNxOIuBPko0YMHBuQQHUO3QN86qrU2ZO2NBCFbSwl4twaVIpRxiMk9zkaY84/95GPfsL0Aa3glDOgVpWIRl/mNRMY0eDvPe243/Xz8VxH1SIHVwh4FZc7REPtfIhp65ZdEYG10WYG2Fn0IO4RgkiBQ9/OiTL30fe7uQ5KuuCoOHLlSiPPVct0IZ+1b6ChNCZZHZj2ZoVp3fbWdXYT+E74Hk/b0sWyzZmbcuWVTWqObdDqwzkzRhRdB0h06B3NoNz8T1piikHej4oLn+NKWG2qkD1mMtoM28qDPIsEXNp7awAUquRgM1IIqFHjlWa2wafcd2WaV+5z1q2QGfd75SIfLspwqUs4mWmn36k2qiV77pzOhzkL964hni/U2e5Ol2oUk1ZyVAAMvKmJGmFLwEwC+D6DqqN2nyRDcPKq0gxMGJ2zhKHqRPb5WBYVg84jr+82WJEMtIzG5YFJB7ahATM4ET+zFUqqmC9RlWGDB11TOp6ZLhZoEHKsqkvKBCEBAJoAE9awqzE/xgYKM2lxE83F6LuaSl08M37qH+ztc1J+c+NKc//+xaXG7u42p7kYWrNgks2yrrecyfFsW2F1/fzNnc/wRiWzfp5dYcyggkXrIMX8mKetR36QkxPU1U7voN6oIOq8755YGanOG5OKzR0AM84VeunOET2BOoMJ44Jht8d8TWvtXvfUViFiGTKNnx4Ss4064uIpycc0NeS23Fsj5r5yw65Hj4nw63VbrSxEMeJT3vxP5X7rPb8TMU2jK0nLV0ZTEfWQ2HLFLS5bkNIEOl5bTqR3oBbDWUHHPVTAVtyyRIS3srpqzgGUihnQFJju8wFpXYem3ioV6i9kmAwPWHumd1Gt5xgGPXMJHWW1GeJ6QZoZEerraqQEMlMOxJaLFfpqbqJyw4HrN7s7G9xm1PkRfYNPwwcVgCrwkBv+imX8OHB7G5aPRTjq7z7k7ig+Qe4rnBhBngY7AJPki7gIATFSNwBwJnHIdb1S4kDwqN9N6+vVuiOp73xPx+2DHUJptrT0mdIxVK6dTCc8iRRpXm6a48If1IhF2SJo9ci8QWMlhlLwh2gmUzXEGE9aZU0FZyXaViuQJhTwdDpUEYI5PAGyzkAjbfaGePiWntbOg9BhQ8D0RfMXIvISnVOGAgbYzfJSPQYjVXH1K5XZsExdvHhBTUOxyJoILKAGsAM+WaYHxp/nyuEZ+LFHHuNrHil9k1FPxJApGkg2F2naNAagjxiNqtXycNQ7PT0BkxwYIyKceJahGQDn5/bOgBPKN5kpD03antYslrW3EkQQhaqnzMzH3WY7Mx7kdi5TLOOrvl4TEhmvsSXNZ2RQI6sA6pxFN8otFUI+lD66yZoRB6NVa2nwQLCaL1qcf1tdQcoYAomOjc5RABUGg6zG4NRLvzkqpfZEMhlORjLJokcSXNTFujb3DSeTv/AVb4EZKODDhJlBmqt4q9/l4YjtNre+myV2p7OpWqWopxD0Uky0g0XqFD/dAnM63vF3xiAFgJ0E3Jm0A07S8zZRHB9WAYJ9TNy46noQmGQZRcRJvmC4z46w1WQnAjW0H5msryzm0xqmIkN8iMLoEZyVxjLLeDKafPE5Bn1LBZMtadoCAnFxYnuKNd7WUvXiuqiadm3J6k1JlZDjexTwMcAsRlIKGEKdE/yB7dPO/CqeUG2ADLfoEZ5OBHxhmmq5fuLvRjHNoGT4AGKDCSAaGvf1UBiehqY5JvVuTy94Uo50+6RGEKvQ3NO6eXOT2nvixIlPf/LjByyI8MHjfBk9IX/FLG+8cEaaHKpPto5J1ZiFBeo+3bilq8LyRMEDzZfijTVZ+DgMgHHkyD/mNiCELMhHVGfRQ5BTCHSEZEZ9toQw+4ucxpZQSI5occzc7p5uS6MNyIIKYNJR+zrq6t0cr2wAIHgQ8vJyQhnwzHOLl/Et9cMeEE9iehLcPiJRRI/A0FGU0vO/u3sTHxYeMLs7LD9wUprR9njzJqup6n6RPsNyAAY8lN9DH/8k6TpN6ZEZSOnJaOZaOsiLlkxazf1Tp0+87GUvo+UBGYNOYYOjnsRESVQVQlwMAJLLszS3iWXJzWqvY7rYScTTddudFA1RqLdeMQDIKTZ8ki+CIjRT7v/1f/krNFVEp+qCJslbXE1fzUlV9EqCsERH1UEGNKfvBIftplZN9SepIhpi8Tf2yJZWUiT9zogjHdCAplOAJgiZgomX2i8nYzjlhYm1nvwW34xemZxpad3xyRQwOBghxIaBnbCFFmFaCM1WuteTCoGP8ujJ4jyv6ugILQShhhzYKKYCo6tsN164cOcjjz7W7A5sM4KPlZJFNEBHUlBz/iBFZ9HpHpg+5MSbcxLJWckqKzF3zrZ5ij1XHs8BQQo1G3TBsfHcmY8FJ5TNgxiugOtjYouk9AgC2+2YUvB0CcubdMDBAOe+5Zv/mgqeTJoqRKnx/sNCncqDGlHr3Fgd0zAXT2TabHW6vTYLFjiZrnT4dIIdygfNe0gAgmrlmkfBBgEDWexCtBzK/ERpal/YFI4HF2DLen3OBXeJVSstnlw9M+h+gkvFwoyOZPJoFFEnve6Ew85s6BOdrYsRT8FnyvXKUntwgxwxlqRnIAgtYis45A4GTBCRsPB3ceA5Zwia83FnwHcgOAk9GsVD51JxJzaGWLCEuKixva7uc5Bx9/fkDEtMMvblNRzQmAWDxr0dYrN8gTw1rzRStpPB4TbLnb5CJAMdmjSk5wRzJEiyGnrpF5XAH3VHpI5AWp6o2xxZdH/NtDyPisEglosoYOryozeMNAZUxrzd+gQh8hUzwmfcgO0CkdsMSTDKBQwpOoxN/USd8Fdp2gYbFRjh4MRGx7j0gkF0BTVomfvvv39376B56SpqRq+k2arawQLTCZcBOJ41tJr5eJGxNnRVl2Q0+zWbWb4bkpZPrCFOJQozf9UnB2Jfj4IryDAguA9OmAcOxpGxpa3OixcJxI0zBpCRP0jilg5J9HP/4d2/jVuLElYzOemCIfP7Pa1CY8iwyw4Y7lkb0Va77dpR3hQnVGiWe/Z9PGdICagZ1m1AJrn8gakRnb3SDhGMlRerASTFBxbobaR7/HEEnAJjZ4mS4+Q6Uu51B9vbu+yRejsCcYRJYcAwBuEVKtpOaB00Uc56pQrDPANQZsZnQiffAIaLaioLODHQcTPnjL2f5jdJ4Sgq/ICQtF1DFMuCVExW6oEP2NatV6Z57S45hWFnFTQJ0yoe0SkLNBgbGK0lCCf1mYbR2cAHo1i2jYHQJW7LdQgSG2YAtFhM1YdbfKS/cgbjaAqx0qewSBTe4IdEMcNp/ACAjs1IMXjckuhaxzJjictyJ7NuABDcie3M8IEFTwIbE0JZxdBCEfRsAEyyLIPYi5q6Hwob2OwyehRSYRR99uzZGzu77Q4LKEqXRUzO3jP/YG2UWoPotIlmpUN0shXSMmbkIn39S5jAEgQDLMD+HvrMowncZwR+6KOfe0Z4T4eUe/TJK2SJ7X4M9ZB8ceWddnVlue6lCIUk062ev32lxxNgnpUncqpNRbaFZJQ/T9QLiWs0EqL1J07H0Ka6k6hWBUXXWh0FjxODP0rMaAA9pocnYq0GYyx09ViYKHCtm2G7HbFEe4je7rbWVtfZIFVjrI+S8jwAY7Zus0kdYEeBjl21F60jHQ2iClJ9TJCMO53b4BmAJGbwNGBGwXIhvQ8IxAqeTgFsR/CgJCYwnuyL7e/vF0ua0JIXeKa2mNxsbinZqPO0kbIAhImh7JyUV2knDiZtKnQw1Dc8wQTNfXAqyjTrmqg+2Fpwfmn+NdWwpt2R3QZhQo8uDBt104CCBSbLH8XogQT6XRFSXmxwqLsWXr6SPwxEqduo0THddn7IMoAb/EF2ezDsUmpy0geoxqr48BkMOigAqsKzEEzr1JZYK0ZFveuui9v7e488+gRcU/kpeiXNErwWaX2uDn1dhGWypoFIXFhJfhzGJjTA7nT5uKdCDeGlz7vgoYFzJUoytgpN6QB7FMTy4Y99/vWvvN+d2CEIuG+r8Z4odgA4XAwR8ogQsF224OfanBHgJL3dClMxIWm2h9jNu7GnKm3b9N4heHw+uM1yPGXFCVsaL/pOJj7ib9oM6cEQCXgaelIhn+dYswRsySN0fKpV+NAiBAunxMZhqaGO0exOwzBmOwN6Y51wOHt6Dfowpj6Zc5s2TMCn2c+lxv2DpubSMMF5kEo5P0mdZ59f0lPboOzADMsaNN6+iEXOiSv5JgyeRw3hRz3NR/4ueiflaEl4LmIyKAk7GjIkC5WaFmPJMjyj9xgqjZjX1Fbc0sfRZVKN+WdPBTJ4ynAdk1BFsf5EETjmbFU4M9V2udWaWY1S6tJk7SFhSFFTaO+KTM+QWjxII10xiL7T51KVeKnFGVPe9WlFkpWQwdG5LRMsOsQHN8kRBh+fDRi6vofqEvXsGD4W3KhXdGYICoaz9BAhFYLQHCqineRjEtfiAQmTTHSiQ7nOsF7VPXlqnU74yUuXmTShY1yfQJc42QYFe8MAtpGtXudh2YEopCURWT6dAWw6B7EVG/fHFYCA73h/7Rv/+s/9zE/edfe9D77iVb/+rl/yeEJ26cX0AwU6KieFHQyhfKDVcYKnA+ORnZXQp0U006HKuYhynaubJmflxFONAvKipT6L6sfLsrb0B84dS6sg4Ek3SOOH7YXEU5VURpxggobBCdo4z86sqpATRzW9+lHiAGTDq2KHyXYHS8Ozvb096OztckJ9VzW8UDhz5tyjn/5DXthxIhQhaLRH2Jz707qaja9oGfZ2dqu10njECX4bnWsjyjlhlU2TTO002YE7ypKS5OgdikezzXzKic/ZflVdSPMlKpWVcX+1FsJB0ZG4gESZ4dRABYOnFSk+3kWyHYLEyAi7nat3rnB1ij0Y/WWmPMd75syZlZUV1BdBoeRM9jpt5sk0esTgo3DoNcpI9c5zs5tb2GwaE5FyYTuHB7uLhSrHTNEi62ZomaPDEqROS6iS4uvqLBvwhUh2sLLs3Y70OAMZMa0GDY7j/GnKTRNBFugQ2YYmg2BOxm1wGT5ABPHSvKIPlUKlyzCC577HmsTSOtDkMqAgCIpinZv6PEhq+HCLDmAkn4Rx+nZ2SwMNzGi0DRpsc/rqxMoqOra+uoIWPfHYwxyFZ7uKkwz5Qu7gYO959961u7X58Y9/isdcEBqPNCFTMsJMm9avmi+nM2169PGEjSTNJyFFZkmR/tSyqamjFRgMqQrG9z5Sg86YmoREGRpwXJ0tFF81+Ia3/41//tM//sgjn+UPUsFk09xFp4HQVVctMNCd6Ch7ioelpL229q6ORb2a9av5LDMpFohpsXnvMV/IVqoFttzZPCEr4x6vvg7KK1WidAct+Mp9zV99GxKh/PDCAGMQVqXKARcztnhryqmcNNv7njBpY7w/pCSub2+TcwAE6sb7bbZnwTehqBH1uNhUOfeEposPAARIwg6UmdhAbX9vjzVG1rklXibfpomUOwhoDM7qIo0LV3O0nsHEkAVGvo5Nw8L3qyGrk0RMBdV1Y6mK6Uf9GCNHDeqQqhs8I+jwD/6g4ecIDh9GmbnAwYDj9izgFpCjISgkj0IjK2w2RWjC6otLzdbB9etaa11cXOasL1lGbtzR0piC3RubDyME/pgfKqO2XEeeoGbnIKSLHA4hwA1cEAsDwDmMDK+gs/oBw5xJtwYW+joyYiMdLx18FEHtTjT1IHdQC3KggYB/Sso81d8C6CQoDz/Yvtegrw9iOT5ZQLfIIxx6KIpHBSaKvxGLJwZkDIlCjRaR6HiCiY8o2NHRcoG9X3UAly5d2t7ehk9Igg9l+IHg+fPnn3ziqe2dfc7nMagu1opMyTY3btJl0PdC3hhmdVONmjJoJkrUhjN4QHDOMARwyZBRi4hIU6nv/35y8dM/9yvf9Ne+9g8+9vnXvPz+hYXF/+t7f4Bnlanh/+Qf/fBn/+jTJEIbD31PglzAKjb5wsAM/sopRamFIBaP+N4BTXOaj5bw2ez9/RbPwHLAplrmlQtaT/Wt0Mz1Bt1pfzo+8LVlBhqqGxDa3duGIrB3XPghI/xZCPAseYbxwR9TblSxnTkvA2BMweZYpEebRkTO1hXsPa1hL1p1VBLRZE8FttBYIFfslPDdeuokmex3ulU+Ts855zHTJA3MaJb4A43+gP0AKjAZViloeY2vMe09+dTjF8+clZZEtQnKgqjR2tOnNltDqwKwKk26sOr5OmofG+SeVoTzNZYg/APNgDNH2dHIhWs/h8m4tk7fwi0OKjCqSVlQpcUtXyGwbVgkzHUrq70qBYIorr4mGUNOqdg6lp53kzZI7PzSWWPLQAR8DACGRzywUUcMpDhDbk5tueCEZ4wBtAo2slAJmojwt94JJyab46RFsVAWIWeJJACyk3GtWuOOJzxTkTk7oa44NebUOo0RDBMXTFLBn7kDmRUrZvD0UBBY+0Q98LHOW5kikFae+/uI6ObW5uc//3nOZnnjBQ5RyCyJIsZz58/Sl5w4sXr27JlMMaO7Me3eAdvEGs5gyE40MzfnzCI5kpm5TSDupLLBi+qYWrE8a3qwl/q+7+t8+7e//a99LThSrVTq2//29/zyL/3CH336oVOnzv3YP/3Zr/6qr6T9EwUyZoTJqNdesg9ACDxjs3HNDVngPguZvIOSK9S5BV7lPfNps6VRWKFUYBREj6WdfuaF733v78IuBspuoIKTSABelLwIWSxE+dHqhRnCIih2TmwrAZfO7hHTxh69tnpCnEhWWdXoXayzBsbYhm6W4gyGtrlSLTIkprw/9rGPve9974Mv2lkdBeLIEBVVJ+bZeRaH0KHFYBdgaWmxUqqSLrF4k4ZFrJWVZYbfFDO6DgVLGsY11CyXbK4F71alxW2cEYCjxgdIJOdB4DvswJwNTvABDpiBLD4ghCAAcoGPqa8eeaLGnjqlYXNPowwt6V26/NSVK1fA8VkIBzcYgXoqFCdZo29EwllbxWUAgnxwSpIsBtg+vScKJoaIpAgCSuAVI5/Te9TDSQ/6dAlopKUlTIsRxSItZ1tpWScZI7AUJEMqzhihOO2AR6cw4GVp+k+aDw2RgK0D4ZiKlqwgRZaVujpwyNMZoCRqYeENJQZgaRPhAIBMFDAxoDb398HhIiF3/UmXnNrYLccGJ3VMJ2fTaY4PEHF1dRV8jpzx6bz1E6u8voSTF6OoEngiBamq2nG8VXxuU4Xljo01jnI4b8jKV6+tOgrTYnvhitQXve5Lzl+4aLHTpTJDDKYmNrm11hB/6q1TQxTkCG4NmapDTlkEYf7K4ZNpqVzgxeW11UXG109duqYv87HHrhmkHiqBGMtwvMmqwYBVN+kcksKwCAxF8gOjsuMGOFeUM8gXHI/S32+pGG34TXQAWESsS6fOM7pgGIyhe6FyYvDh/CMcePPjFHBiSmXt70H2wVe8/P7nP+/JJx9HiZeWF7/srW+1hlP11mbKygP7vnyeGnnRrvMKPJV20GszqLt27dqdZ8+zEegVGIap6ig6FZiptkvKc2clF3WhwT8JEDfGPFQh4dmDksh4BuSj/h4UcJwCkkRKlCKagTQYevBJawTV293RyIKJup2diFuuwu7BfrPT5KYHn6fhqAtxqe0Is7W9hUCo3siQaC5eVOH61k2vUXiSoijayE1TCL0xxG4b8TSMIju0BrAxxzlR8HEbClDDOPNEWWisMUOjjlGLrAA1/0L5c8wwocnmAuUxmTCmwEaNr/auwQDr7aCBz3wPf6gx1AcgCsYBiGOYN6LfSAkc2FD1teLXpErH13SCmp6Ais/ECoLqo/S9S6jxFH5tOFxmy4LkWEPHf2EB3dNUBYb5yI/mXPBkOixyZtypKasZ8WD11p00ENpFVY1VG0cMMuJBqiiqyKrUtGHf9I1/Ve1yJv+yB19hA3Uha53fWgaXJxTIbKADAk7GqEzUCyPOmeugKNJkmZnzZDQ3PHYIsvpwpAopFlBY02FKhcwQHGIK5JgUG1vKE30X2wdm2C3SixwsVTF3sWaeylhBcHedvQM5UjlRPnzoWr2iZit6VQMDxyQNEaJjTHwC8CFR96fas++3tbv7yCMPv/glL3rhi1/40Kcfold56srlXquJ3FEJ6FBvMTCMBvOWKFcp+DQhoewZcDK4XueJNpU652PtoJwXAA0UPQ96KwkgaJO1N5zuJbSjxnl2f2BJI2FwumewHd/RAuyhiXgC3ZMy9hpFFK/A9LcnT55cXV1mtsbYkowgH87wkkFyzZYdAIPtnZ0DLkojDXki1RzP1qlrUg1Q85yrVovdnr5CSFFCGVE7P0RRFWPlyW5NkyGGTjpDLa3QooChYSFF1SUgmfDoEV5xTSOh3Z1Pc9YVlohLyUNZvO1u9dta0IImDMAhGQFGYV7+4IM0LrTF8IOTiBCh3FkRN8KySA1pwCe212lbs5CPPoOmtQ9uZVCl1Y9x35nonKxFj/gDRmJEhD5aR9ONpjGX4tQfu0m8klerlJkl8OUvFJOP+5BFTwviweDD6g4MW86lGJ965Ar2IbO5k+IvNqj75xxuLAhYO/GJOCj1mccDGACabDh0Q3LBny0edow4xsYsMc9Bskl6d2t3yIyy26Z3JnfUXq5/q5e3cUpudUUvPyIIDAKlEmIQOqt58qdHlNG34kCgB6s1yvgLwYzFU0/LwjD5hyHnJgiFjQ38cVIwrIJSWpM+guYxBc464paPPG2MZBLM8ZzsmQvn4JLVy4//4cdpZe+7776Nq9eZvXjZ0M5AkAqJs1zRyJPtXWaJKsIJXcGUaSEMU7mGOicnbUAlfFroc2AaS9/zQFnETNy4BDkGgCIMcBJQ+nEldIVzzCQ8hwO+cSKCHgSAxFB0xEhEMoJs0XX6K5bMTZVVARA7+DhZsm4Pm5Uax8VzC4urLE8QneWf1bXlfm+/0+lrMprWdhSjHzLIOxY7LTW4REfI0CcVL77dnR38cXJOhuqESIFJgif1wYQlZo/4YwObD2NsjXWB3VAt8UHshsDXT0vLK4ussdGXcnd3aUW7Fexr0Qxp2tnR6jEDhMWFhQceeIBMEQsDjrOBOF1P8EEsCaMhJZ6wR200fNVk7qlEczRb3yZzMIOWMy+1uiFxsW5CHeaDlY1qg4VztKxaKZ86tY4n423G8w3un+4fkBZkMc6A2wjLUpT1htc+EGC7pSelBR9PBIIcHnls8wO/9z6avm9++9d97JOff8XLnnfq9Jkf+MH/D/UJ1O/7vu++dvkyxWH5UM4oD3pLKHjeE5nVcjdCY5O02xtwCY/BaHPQ5mzDcNStLa3w1lSXLogZgJ7XZB03lfuu//NvOiFoYbx0DVCtw9DqBVtuHa/SJAruyQZiAkDmBX24TMaFga8uB47GLDahGJI1FU5H7EUWjvnIkfiWPvEFHimok2U8xTDy3IU7Wu39e+6/72Uvf/m/+/e/fXfqXsqeF5FMZ9Qciy09biY28KRNBYYfVjfoCpgCQRverHeSltPH07bBqa1JP4tV6J/7l78tPp8L8y3f8nVHyVB16YVoOq2mDBi50J6g2a3NljeO8DwctnzoQUa448f5lt1dPhtKJ6Eulx7voLnX6WzxLYtSiU/SsY9yQLtWqRRZibR2INo89waCIRKLDlxFoazx2d8/QOBUTGSF88knLgUmVZrBaEddhpKi9OFERZZhLrrHIBQXc2o6hlMnV9fW7iuViwgb/jvtwRNPPPXE45c4ZgZjxLp+/fqLXvQimleqGcnhQwoA6uLNUGoqx3gOTInibbVRbQfIjsY38eAfThjTIi76F/ghI6VSjXaHEGzaFK4f2q1DxhcTJAxZuKLJowI3W3tUe0aLThDbibvtjJEuxn0ASEIvmUSqJT5ZHDKuNr/xm1S4dI8ve5lOaFzbuPb2b/w68J2sdvE12sND/8kGJQ7zctugCYDskCj9FgrQ67Ml2GN4z4Ytmk5944bo4sLSJF/k42SUE4sYLFRqFXvt5AVo2WCDUxBqbpWfTOZGs0tJM3Elw7BOzklfSWZ0jQ0focENA3OYYNqtJxzgxmb34hB56NImW4QgimurotiKSL21s6x6fcOOZFCE6DEzontPnakjUw5RF2vtvc7ZE2fXKouFHm/V0QJwxbTPJw1h2xpvvVdIN8OKG4yReTYIyRAAO6JXr14llYhPUzuSBo1PuOg4EfdgrQn05kkbdCyUmRGjZtyJfP+3r/9LeFDYtNlQII+UWaHUIMjY11K5qkSa3c4ebdTp02de8tKXf/CD76UDQ2tZAiTrP/5T/xyhKGEjwj6tPrPH53JH7UI5Mxj3OHhCMfeHXLdmzKAxBYLujvSiGAnBHIrNRK8zGD72yOMbG5wWvbmzvUe7duLEyQsXLqT5XkYu1+r5RGO8mF7sjaa7+wMeTmZLh2/fMLambeeSYYYP8N64yvYNPPOR53yxMDnggxU8y9thblJgB84MaZI0QkBQGN6BdoFIza0KYwHyWWKqCnXr9OlTzJ9aB3sVPuqbX2baxUd0S/nMPXdeOHd6HXVEVshtubFy9akv7FYqwPhAk1QwjC0sl4dqET708krG6q1vw2h/llj6qChbIqxM0i3xXTt1mCz55PlGTFEvkVf18LiW6Rf8q47TXJUTPnwJoFIY9FsQ5BE178ooFeJ6Eg4ItnqrjHKSTyMVlF02qkIoK6psvXPt3BUMn7VafTDSs1ADei1F5vgIJcd1eWWQJFjw5hwJwwZNWNEcjb3UhvLD8izzGPp2ToSPcuXW1jZXiaqFCprKSCg97hCwWJmWi73V86fL+5UvXLrCfVBR5ZjO2sl1mIQPyq876NOGUTdwNhZWmCjRiU6yGi2wugkaiaFwimg9sDKkY8nkKlWO3sQir2omzajp8q/cQBPlJnsUNjbVlXUmbJykSxCGpDF/5W1/6aXcJUplWBghey94wfOuv+61J1ZX+Cjx8+67m6pCW+Opu+wyKfb0In7QCWiSFgrHJBDmwIEHENwA42dsUwxWMUwzzN+9ZSdyp9L6iZ/8xe//vu9EJ2hfuF9BKMfH6OW83jLVp+mpVhsPvOgln/jkf2fT6x1/4//44Ad/x5OGmi+kiQ21Y6QXAZFTq7tSUQ0rqDDGrXBNs/FPGlGzphNP2KA4cDJu1BnMmlp0/K1p44CUulPkSXOgE0c8USQFTANwqoFeN5vltGmTakaNZz2M+iW5MSbX9Eq5xjhAKlCGIOw57MJ0TtAQShxpIweOnWhuyU1RDfijlpoo1ufXnSAvP6BWOgXB8M2GxCQGyNDI0pxZkoaVBbkCwEnlUdJmU6+coAdhYxTZolA0gIpiNgBHLgzFF2IkRjxptgOOR5en0UG4IhbVbVckEYCkI0RoVnfAzJVpNjidaLteNnEnCaoqmwEaidqAgjJmaMAnt2m9db6GomR6QmRtr0YveDNjpzZSrQllHEnz2mD1t1rkaPeN4cLm1dGNJt/obvCRhQrHSegI2XCn3CmhSrVeralXASYbnkOcCNoMg3n6Re7Wq8tFeZRz3ZoEU1nqtLSsTz2khlItAdAHIm7f2MRGOYKhAoPJ65bEctIMhfOZUqGUrqYKjzz82MsefCWUoY85ffrk3ffdyTUjjmCvra346Q6ioxbYVH6WLUCDT1GjUNXOUQis16kZwpNQkClHXPgAuz8RPBY2xj0dH9g9cQLQYJEuYtGEigZuqDM0lARTrGaT2+F8Gj63u3vj/R94r/SGtq+x8F/e9x6YsJqp9w5UZWm2qboiLHnDMj9aCWZmxGMVXnst1zTsZN8yJOadB6I54HxaptRwoyo0H1tbN9ayJ2APwxlktYYTTWVb+weIHWDY6xZZ1ODoMu19GhdTjRZEaPSp3dgUKUMtGmGd5TJ5khCGdDHkndSxkR6tqiLGhuFIlRtn7Pny1IDGcuzzaXzE3okOdoqCiNPTUA5E5FFcPGnPsXFCEoAhMxN9TyvYpCgE/uK880soaieWTKQAoLlxGFquwbMgqMC3TfhJk6IGHz8QMHR/OAEiKhYETKOFrbUStRg+8rLUZc2QwXFSPDDIUJdnUqiuGJSTpgqg1dRCI8MERKCMUKdtLscmUsyXdkbdgLjT2uIJQrKADmdZNKg1Cgs1dgWf2LzJWcFOimX34kJtmb6Z1czUqJtrLC6ZBLWLINbMAFEdYIIgjHuSHjhbN27SXlJCLEvQd9Kcc/1NmDZPo9WXPvA2D82r7TwxoCIWhiFwni9/F4qTShVnp8XgUISBraJRmWksUlubWxx/1uFpPqIx7iov+czuFjf2d8pFTlxRZ3V5GE0lLppa9gcJnIRlge1tHgiwgyci7moH80iTKNjkCH8b1ghBTEgtYMX/NFGWiyAL5afT5zzAybd/07f/xm/+K87K/YO//xPv/8Dv3HnnPaxSvOtX/+VnP/cpjk/98N//p2//5q9+y5u+Es9v/453/tzP//j/9D/+z42FRQ4Q/5vffpeSUKIUIgAJSJomACkKKiYWVG81vsEDqbjAwQ9GmGqm+NOTzjTbQGziUFHVVDcaiIVYiIVaTcbJ7NbGFnWAtoYDPegu1ZjGiJrFQjc4nFelKFVejCZRO+uBoeCG5JAVMAygYQBWEbzKgS6dWVys88EX+ljq/97eDhMGpl3kTfs5VFg6KI4jcOzLlsqhUynlGZRZo8aukgZ5tGLYVCVCScKkEdny8T/zt0Iy3VaxxmUEUiIixUvGnY4qoFofNRw+R+JXdVbtqHCUOz0LpeSMzMxytZcGEKTSUlOihGJEBSTkowEHx4ks03y/i8ExR8aozH0W28SQShwqZJihELVzjcsJbMHT9lOxMzlqmuo8h15IhZEJa+zoPftJ+fJed9re3t5i/jEctJkxlPKNQpHrvKUM++p9HWZS7dNNK2k2LGJjeu2WamlsfKCLz8BuV6Ndyoy2KCUd5nJoBy8y0UtxzzxVhF+xRUinu08+vbAhy4DS3maZFKvqgdEsRhGq/xK8Jgn7u3vtg+YaJwdpqyYTNIN9ziceewTNY4rRg7vxiLUTcoky6dvCPM6gJjyqlsaVeBNNq6gEYTxfBqjCCC2eCADLKNItDUOKv/CVb/vd972bEc7y0hrL8AjkJ/7pP2zUF77j2//OX//fvy6dahK5UV/84Af/y9u+6q/+ox/9wa/7X77p997/n5988rHVlZV3vOM7U3/7ncdSlxBMMwRYq5H0IUoI9eiEBoPi0Y0r+5Mhh8C5yNLrdEFjLQEc5ENx0W6SU3/2CA1AxmgMowaO+zON5muvCApRoXgUHgvekPJEiQ4AcRhQudr3x4HxsSgSLzjr6yfW19eovVBmPkRFoapTMTkowr6renXOgo3UlKgqWZsCWe/GAdxAnDKB59hj9qvse3kpHxEOnuYdiW6GjRJGUzlriyli8S4z0nQbQ2ZIJZro4QgdMtlxOobE7qqaJ3pgPFF20gOydCNFkY+VHTY4JKGTvtZjq23QkTZmqNPT9Rof8Wy2+fiADnvX+JpTo1IvF3lXRVE4jc/3wHoM5Vr7zTYtb8tGlBQY9aqXZ4DN4ffB3kGrvrbQ55Qx3TLH3nvD3c3HFk/wPFEm98jn9eZ9ci7qQ1yfrJMGhYSBI5JnCLa6dJKsqk6Yce4JLGbroWhpyGkB+E8o7yXSjJMv1UeOgDGGsGFEq8nik0SANogyswKuCmbS7YPtnZ2t0xfO7Oxs093wXsrJU2fo4xE7C+s24KcGpjiJCX0isl7rvAFDzbnyIHzcOJMOoysOULT4exA2+kd8LxzYEm+uA4b9VV/1P3/ko//1kw99gkVLbiYjls89/LliqcrhPCoDQKvdBZ8xD5kmBvl+/vMfWF07qfEeS/SFImsWyIBFP4VKFxkiqfGn6A3ftiVMRVAY8xEdFxEAJmKVOwqaRSNL/pguQBYSYpyZMDNzCgtMbIRAK2OfAeZsDBtUfGgNbcFfzZnLgRpOcTOm09lUM4z8XIZK0uscuaUxtiVrL1OvwPhAhMfWGR9yloO+V9VS3xgbsapVsA1Cckk1tkZeGSc7rMxhG0llnLQcpvvxzCZtcQCy6YnBoqCtankLJqduu3Dw58kOYPHJeEZNkBkGVRSwXtq0uCp5JKY2CP3GIbdR8wwSh3YLm/9GyogYguJbRoJtHjpoQZtFCPgK4j+pM0rCn0UE7qv0pxpTU6/YEhpldvsdVYexPFl76vJ5EbSblYtcll3ckqY6KQ1y+/roE7Wj37xJhs6tnVxZqI35/mbremH9jJ4qeOgTn4R1LzxsTjgWqjVlRmsWkYEZcuiMtvZ03wWY5oNqrbP0tr3F1V1DQ1Ds7xiybTxwIsyFAl5MT8nVrVGAY/bLsWkSNIDmWFIufeXyky986YtIUU/HMuwuVgfDaWt3R825LU64hmFD2ft5J+58qjSoQNbykCKwVyrUi3RdfeVvjSuhni/FMWNZi+o2Hjhh4tSpsxTK73/w9ygdJjokXa8v8u5Au70NCv2TLqhMUxyuQI+JwzAf2fzQD/0gDRQvRdx/3/O/U6pq5cptAddJyc3qqmo02kyBq5uyK1KwLXHBALbny23IMNoFThgRQQJIg1DwARAU+cVmMYd8T3KpcoVpF90vWRu3O01kDibbOYx4aXC5zUA7zvS+WquoUGzmDE0MQsOGE4hjSMttPCkReGRURhQWdUnNm0WcuQmnGuVfKmnnhoGSR2Q1lOgmV9JXBcG2ROIWysJc8kQhb4gmdqo41CZiOAUZYwIEGGrAIm1yQxTkCzYYsSmu3WFgEQl5U45ki44Ff6KA6RGdFN/qkzzpbMStFZMlB5LR8RSiVPDJa/DMkRjaZb0S5wT5YflGzWmuxKYuE5l2q7970GWRYzBUh2zrvyyJsP9QmGZKDF1RMO6wZ3mIlYE4aNrfpo3LMovkDOTKydX712oHB5PH0PBcrclJrMX6okrJahccY5QB2ngbACsNGzJhA2PK5ZpJFQz8OGzMqi9v1bC1VEcOUkRJDmToyFXMc3Y3MsgRYdDu4c7YLRDW4dVSUo6sbfAlbzYTi/mr17jJqR3REi8w6mE6Fu4Kux1eZihxd5jygEcuYLEuDh1YEoeqzILJiClcut1qxzU2UmsOn7KA7a0PmKSLsVI2yDJuPsoYmVCwlRbN4j/8R3/vb37Ld73ui76UfphhJwg0qny+mHON4GB7h9Y8aFFvIN1q9j73uc+9+IEHP/qxP2BR/U1v/LLUd36va58SJnlXQxpXKQf5R24u4fQP/9BPEP6nbh65enwSu8lrfeOUtpo1LD/GsEnG382tY4KO8/q2v/kNlBc9JJ8gBlCeaaM0mqWC+HhSBUHUpI2TkvDioN0jiFjCsR7YkfHEOGwTJ+kwmoAPs3v6N5oS+kGI4MkAn8JSv2MIrgBe4slyp87hZD0HIug+MIDB0g2HsYHdqe/IUidQL5LlziqFjEZOJouVGt8dHXYm6QFfJBl0OVnEqyDgFKqqQqovLG6i/MTG1ppeu9dhP4ltHV5npV096HCtp6dzSt0mR7TY6OcNbZZoM7k6w1D2WljdUfPjPKnyShTYGge7XHBGUqMZ1geDJWJ1NCwe8zJHriwfjn0ljAi6TJl82GlNajRTfGOXtHj2Q3NXKbNyY5uNDLrYqMxXnnjiar83ogHpNjv1hXqtvnLy1MUnPv8pvmO1u7/HuINuRK/uaDs7zQscpC4GzDiAzWUAJEsheQcC3LL1Vc7xmSfLJlRsNcA4MWRRzHi9ImsSggiIIA3hqP+z//Kffvd3vvPKtaubV6/jeYkDbqNuc9yhNIdp1nglhE433bUNglRp+Av/6qfe8Y3f9uY3vwUGfuFf/eIPE0w/CEkqqqSnzkDvhZAECfg0C1qmHN/13f87oyIyRCSLAqL6PSTGJa1HHnlkZ2fvYK95sN+mgYYYw/jt9h6qyUXKhYX6+toqL8twGLNWqTI68wwyVGZEreRREV1yojlVJ8zSFwkhTIgQNBoU6Yf393e2tm+wbca2E6MJllIZF7CxwAvyvtyF4KgF7BGcObPmPHoq2OQXsoykHPbQX//19/INQTp8GnDWS6wqot9UY9BlUEnPrxWjMu5OVr2Z31Hf6Lphj66K8QDcaiHIFcwiBHxGXnRogQhTA1r6VL1BFDyhoCA9JEMOJH18sFWP4EnNqfYqhMg5CUKox1C0FT4/wAuSVphs0ErZQAuY1Mf1UhpVYr+cG/CQSfM6fpON/N64gZzZz013Dqatg3Sfb9bBUaGr7zBLu6CkYQFVQR0xN5a7zI7pt06ePHHn+cXrV65Urxe3Noc7vb1777yD15V3uqNCY0lDKzB5o9MzoEyZcQAbmcJZ8PfQQ7aJIsxPUC6Qg3FJgU8tCbAEZQY0Gy5GhZQky5CY433c8Dx15vSY86v6ulKFdSyUiU0KJMskiwqsDl6LBmxQ62QMlDFJYLV2IpC15CIXjTE9s9pgu8OFL+xh4As4iQlBd77jHV9TrFSbreb3vPP/YPTFp1ve+b3fzae3t69dvXFj8+u/+etL5bVRqvrGv/D1u3vp/Z29573kjffcuZIZNX/oh36ITbXF5foko1Yvpq/+xJ3uk3QGfwfW109dvHj3f//IhwNj8A8+5Sf2UuOnLl8+d0aX5u64cIaqeIrrNqurHPclOvVwb3cb6VGUOMkvK4KeWca0GGIhB0JRbqhhCN1XY19qNM6dPXeamrO7s3/9+sZWbufq1evsEYHD5gQ0eSOQTf05bt0Jq0LTyFNKhWBxAtCCQN+ugWpsT6GpSdKwSWLnCJIDwY787daCtsC4utDjhQB6OohKkYJMkgBVB6en6P7AAGQf27PvCPhjkIN+GPaKSSEQikEssIcBxk+NHV2N+rFo0Aemc+iaQ+1lYME8GD1iPtLX0WteTF25tsFrMV3GaCzgcM+iWM0xRmbMmivQ80gskCU/6jlopBmKF3S/IjPMrSwtNGr1br2xc73JsKVcyA57w07rIHdqdWmxWquWpsMeN1dYdTAyRHVDb0D+NcUwospLVLcth/p6qBDUW0WTE3eGnCuCSQobkojAsyoxWUEiGiEfri1x8ipvCHNL+8LFO/S9h+GwXmuwZHpi7ST7jRjmZ2pkbYkCOoVMdITTkp1Z9DbuCIx56hQkAEHYrgSOFuU+zixOxwegpFRYtBbWSxv+eLC3Xc2mV+oLo1Sx2Rk3u72t/VS7V9jfOshk+zuNLiJijZxt1QqVe0GtjCfqCbkT21MhKMABAWBz8/rmjQ352LQKNGop/Sfb0dQBJqf4LC0vvPzlLz95ds0KRXNgBilIsV4upStlHtYnNvqHjfSoRcxvvSbjQ5sINTypk0gMn5Mn1ziswrQWItxSKZXW1k+uoWTc2nv/+z8AzuLSChW7x2ciaiVuiYVMeRaggAE2PbLfOI+e9Dg/e7ZFwVIE4Vu8KG6AyQs5VU9il++gQFCoigEtACDqrmlMUPSNMnaIZX4zaaOfxJKRLKUVjhBVSzmt4BjqWwWTDtj1T1dsYG8fpzwiIK1mgscrU7zmy0Pp6UF7cunGLg0l8mcxjzEOk0FUup/uF0vRIpMqLiWnztxEwXqwRuCpBUZTvHpdq+cz+YV6gYM27d32Tr89uGO9vrDWqHFPvlWpL0mbMUEEAXBy7gTGOCaH0fD0/g9PQZawtV/Kq/9RwZJFSBSPHtLyWE4/BAEgOOxLl65g0/AwXKnWaqdOnkZMbFpSGznSpbmDbVew+DnqRU2mV1S3IctbKuIs4i3q+SFOQWI8FZJwBrAd0+3g6YBPMbQ0oREuBlFMWXtjjL7LgdrmVrGytFBd29/heaKnKCSEkuHMst4izvRoNoes4VSdlNHH0m9IHYfD8sV867d+27f+n/z+x//07x559PPf/3d/+Pv+3ncT9A/e+SMf/PAHzp+78Lf+ZuHHf+Ifv+tf/4pOXuRyb3nLn79w4Y7/7e3f9K53/cL161dHFJC9r8GiE2kwXqe/YpEQgnyplfaXb1/UcnUt4gxyVTY5eOEgNW0sLmBLLNqjo+9goqjXkeAoy319Do42aEbPfepTf/TxTzyEkLkDBEvUfxoH8Wwm4t9gl7D7h5wS0Xt7/BmcUqYstEmgVOS4KPw3RFkuLhMFTAjSS2PDlXeMThw7IAOTBDYEMUmAZss93d8TxYaeUUBbcRGX/iOiYP7Kh63SIEA0M8vLByRofXLUM8EXmFzR0blojiYM+6zp02XyHclLl27wbRw2O2u1pVqZZ564OseGSoo1RsYTpIchKmSh4IZPt/DGG00EXT0jjpKe4NTcaKuvHfuDcXu/vU8bsrRcv7nVYgyjg3Nk1wgp2xKf5ZxDiUZfwyoXCk5yE8Fea3RaQ0ax7BlEZwIfBzyKoURJGHmL4tSP2IiJES7tPbdkYJ6n3ckexyS4SryxsQE6Z7KsseAcue6dlHX/RowlqyU+HEklLSdvikK46q2rAgBMoAeBT89X4Nz9k7YH8TijFuB4Uimb47N/PW2L9NcbrAVOy9NCI9to6tp67sRpzkvwSGaF9d5un+8cRcoEP9BU/q15A060IXFq3/u9P/UTP7ywsPylb3jzw498LsLnuFY212o33/kD382y1z/50Z/+yEf+K0egWWG+eOeFt73tr/y7d//ajZvXuUPGNqGODrGCwp4bIxQznjtAKgO5ZtzIFgWVWq2/So7NDk74aThNV4xgOfjMvSK41VtWnAFPp+nnmQR+2Zd92R0X7/rQhz60d7DLZ5x4Tv3E2opLJmTNs+ESJoikPXUQ3NAdYai6pFUp2yedmMLk1XMeNfVKWde87b2O6OC9BMgUVZI8ajxdEpKMTQ8dxj8gOxs4AbwCW5DqLXXTY1lsWTbEZQiDpFTl2gN9FhcZYgACWZo9+ei4Up4vNx80D/ZaHVrQ08t1lud5toIVKb7C2aILHevwb3+s64rOCTZ5Mh60ZcAIvMqxh4y+zqFWI5fnQocmyDw1lR5s7nduck9hcWWvyYbiOHqvxCNjO98OwBykJX4anHhZj6VtjPoiABoOrchYbJOY8aE9VVTIeYII0Z0g1BTX0WPeQXDiDtDd0eLwjW8u6J+74wLPDFLYLMG94AUv4H4CmseZPO2LjHVhkJEeEw/LfzTXcqqkQHXFxglZjNdeAHQUT1JE3M6M4zjstnM4s6UrM4UYTQa0oalKYzLsV2pVJL3YKE76u4v1zMUzd3/h2vVxelCps5NmEzVuAurLM0WoxcRnzaV7Oj/AAEr0Pe/5mr/8dX/w3z/8rl/9RTm9UKyD+IOP/Fc6vccee4zb1q973Wt9/elLvuSNn/nMQ9c2LtNt6kyVtqvIZo53iMgsp7clNNt+Q2IAjGgwnBBjJKxXFhp1arW8GnUYYHmfXSQWs3xIWSpXM1WEV+BBJp+mvvCFz+dLRb//oQ989nOfWVw8S6ac7Th3UTZhI+SLEiQXqIEVhfTBhK/8evsiBFqe4wxrHzTctNSLK3oYjKIgIQ0WUMDjDMqDtzOD7QYfhIDtrCZtZ80poRQCou0AMUwDBwU0BfbhmWps17aAaZhA1XTP+89MXkMbpaDrZc2Nmzc5+HzhjpPrNb13MBlR7bM0AywdjPu6As3xcdigepk9q8C8tsKg7fTp87VqY9DfJ5cs9+7tNHX+joXEdPXKzX79iV2OHvMYLI2rZvYYzwC2w8GGunuSGWD88YgBk6A5wSFHc0QCtSQATHQKkhrhADRxBptzWlK7Tuf69c3zF+9gsw71Qvq8UQY+MG0D01gkKCmM7QVG4x8KmJAWmhHScr0hOsZxCMJYjEP6lwwF2dFIlHZO9d6lIW4ni5yL3uzs3thiEnHu5Nl2f8hsc5hqLTXWRtPeOD3q9EZ8oo2zHWRHq25moA8NSzdSJmcjouwF8fVf/8F/9qOve90bX/LiB3/t138pRER/Op02Tj4+YG+85ra2blK3Tp8+y4b5Bz/yARIqcL2IbwXb3gzawuiYCo9OI0CvP4gFaZAcrS9fTUYjddCCo3wjhnWadLD+D3KhUgPF0Fi1EhoVnE6bEyncdKMheNOb3nTPvXfzXsrQ3sQITDqATXLwE6elcqG0sFFhLw4PIokIx+aWHt1Lwe39fZ4o2YEal55pTeRpJ0ZYCzqKjA9NDzZowkwANAGWHXlCzYOwabKohFHV9fGzNoLMaJQkXP7TxFjt1ZYyxolHWF5qWV3S4zvzdLHtrp74oQFdXS7w4gn6w0Ny0njWszP5IV9dU99HB4OC8QdLYs0bDj6yyQnlxYWVUrneH3QYXNOwXr66NeCCJG+GpovtvUnqiZ0zawudUYptJvFK7KRxn2A7lyC4j0lGXRKA5t5m7GRHJDVHcDsKNmSHoUOBUbSeIp7JpD0V5mHIiEvhhIKMBFHTO++8mw6HrphhFy0xSiY94+w+ldgMcSGLQXYY/JF7YAYY48ghUYhjPFFHAH8OAJlFCIZwHhcxsGFPKoPdreVSkZMxXLxlx6Azyo0LC6nqSqeVY3DAEhJdIK+6UqFU8bpN6LghiRg85pdz1KkPfIBH+X71136R4x+O7DaZIcLp06epP8gaoSIBdtZ/+mf+8dLi8mte9Xo2EekqeMGeKTBqzoVpjsHAKhn0AQhSdRgA0VG3cbo8QUOqUOboG30xoSQKGvKhYvNHk8vdWqLgwxY9V2rZQ3r1q18JS2BijmYGTNJ1BghFsKAhSQA8Me6JYF22TsGIqRQcYJjgy2ywShT6CZChnETzIsMmCDToYDvgMDaycsWAJQwUMAk0VQSnCYAJDAAbWqSxwT/EJRY4tNpFvheXzuzutZh0aBtvpdHrbreYg0yZEdeL9aVsuc7ZZv74Fiz3exmVx38cCuOJYP1x7rLLNyV065hTlhzpyFUadT5rki1lmTyPMiVmljf2+gfd6YCVe12eAFEMa4wIc/QngjF5rnxrO5p/fKeZ4SB+VFk2qp1j0KQnasttBYJHAkRGimWnJciWSLGig41UQZTIEJQaG77m42VAdP35UIRwDs6iRp1u8amnnuD7t3DIA3z0uvl6bf3M2euXn+Tx0OlgUskXW3ttRrAcs1WylrCScUCH76MhtAvabUNUi+BZwBNuzFM8UMa2QarehgabessIk9CHH374wQcfrJcrPJRRYMCpkRWPmBYPWvssxfRG7EsXakXExfnRTpFRHlmdTGvsIKY4kKRr1VnuWakLYlmBIpa8dLkDUFXOBlGWf3jhKlfq3e/+lm/720jqd9/3n5xP5gt02zBKj86zvbxiKGpWu8guyf3ar//iO775O7Y2N65fv0J3wiaOWj43KiKS08QEgx9xrQlgq1a9MaeNkHqlLA6ZCvOBbKbDmpPqPSa92Ey3wtMz3B8BgS6ksWiP4I3HS8unqTBvfPNbP/KRj7BpXK8UOHXAYU2uoXD0JcuEjem2vXpNhVFc2mU+ksAMiG8CjnnfuFes1lBNvcbAwTke2bAHOmCVhgNWiUXqO83t/mTQqDX69gFqJva0PFx34cggNL3dMFt5RKQUrvmb7lmAy1C+PvZh4s8/xCTthYQWZU0/pQwMBz06hxTJHZ0DviywcemBPRGONtolYCYqSgpZUoI0JkTJl9fhv93azo66XNioMM8apuqFqj4BWOCNFB6F1SPn5Xy6NRpokYI7mFk2jOif+9QYGnqKiFUGrobS/hbLHJ9oF7UMkS/nRrSaO+1uo5gfDJvsX3OPmTc76qXVXrMlyc4ZU+tomEEQzqRR3o8z4MwkdRxC8APTYScLHHyAaWW9/OiBtQqHTknRuWVaWVheuvLkYzztI2VmbeHwBbQkkUDfgaTtTGKD73AA/IovautdLoAn4fqn0bvFghlKlvbBoisvnjQ2OYM1BMSfYJ3U8OJPshDBnnoImDl/5Ed+NHVAc+dB//ff+VsAkP47f/fbSdp5+L53fqcSS6V+4Ae/C4Ch9Y/+f3+QUAxOjDEgBPd024PIFICYi4ev7i9PrR3kyT71h8aLN7dYzmLpiLzj4xxa66fHmhGLVHzS51uQtHGb168iMUaR9Jl00bziBTUMsTwiMEkQw48901yCD2NUBnoOHhQHAU/Iuqhhgz0kj+scei6icj9eDZXirYwxEkXzzCYZm49lJ6tspm09G18NH/EIBlhRvubwUR4qMByy4MqqFR/tBJPMqhP0BsbE67C6cYJliymVhi3KWMbVwHO0/oSJi8aNG01MlfOjoh4JsHUE7uhtc1SR5aClxqEKrFypEF3QGm7BkMvO7cC08xGcARAFKzNs4KNo7pOk6WjBhxR9gLdpr0yea9RHuijNsG1B2xif+DgvtHGrBvocw1Ys41i/sXE42AAOe7hGGWaSnniEdIFRQTSJ9pIHInGijh6KTXRU2TXMyESWpyEuYMgy7mcDkql4o+ERTA72enO8ZJKkplD+RwU/CxG1mf8sy2CIgchILBxYwoZh33oBwLiPw6xqO7r7OwVsLrWScZhiMPLoIw9fOH+RkyHceKDLcj6iCmxaLQ7TI15gRiw9Tvy127AHL1RRTfmMf4LQY49LihwopMEBoHsniFU3rxIkihM0Kb1trlK90QSc7h8oONuaJzwb48wEIjidjp+RTlDyGk72dNhTh6JoYDhRydkLrlv4/pxoaXBKd2MRVRA0K3DL0j07t3rCgTsLGTV8tOjwT1rI2RMFoL1iQKJ80R+KESomXbGu07OQzSopL5NN79AOM4XEO6qcMy6ly4z1qL8ctwbY4m2JXIpXBGcVGDKeSc+Y6aFAmHPb5cgw2pk2ZIeVFU2IjYIc2jqTpuFDTp2gt8VGT7UlUPbQYLv8QOBFietXrt5zzz0cHqA6ZcvVs2fOo47aqBxq9E5TTd6ZBxg/keVkxY8LxrwdDrajJhGEz6MifDx+mub1SwZ7wJym5ml/gjgHBlmyT9WlkLxDdiLYgXNkodyZ4Mw/ZDzC9Ums1oYUIgXnv7a01XzIL/oTMxBySZgY48TgGbenCIyZpR5B3qjR4gFQ+ghyZkAJDg6eJ+N6RrA5qkkfQn+ydfPm448/zroDV7NRJF/HFpo4UvWFFM5sTqcUz5w5y77jQw99gs+tV6o1RowVJvNWCq6+wBhSpDUkNgtCwNq7skky8xFGy/hDihqLkClxEAAwHhEbBFGxvgsBPVsTohMR4h7dKbozicBeumSl3XxdsCJ3rJpqgknbFre5hq92EFKMEGm/yA4tUbvTp7vmlBQImk7GxeSiMP3RiRTrhhleIlJtqnNqlZu1bEPR6XJUFhHxvAmB3DHRDRSEzeSIzVEeG8sUuAFXSY/zfOHNs+G2WJEWyZCwA9hQdwOar1clYz0t7HRc+NDBSRRs5ONOR3CbTNIJUGw0wE899RSqQ1vLwWW+5L1+6jQrcmobmTORb+08O6WoMNzh/HhDDk1PAtv9k3bSk8dpmRlqyqeXFivsXvD8GkTAhxNNzzjQUCyqLR74+8MzSp4XFAx505DhtGpmLRqg7nYodXUw2jbwvGu2Zuxp3UW5tvrgLDnPRAEgv5aSKCghy3NAsCBZFmJFhlwgZdfEjKZK3isz0U3qtjhsPar5yAp0eGSL6sS7KuSdUTT33C5depImbGX1JNTAJC8ERd0xQ+5MCc1jfHT3XfcgNB6wU7djL84bV6JM7rDh2SjoQhiGvpdS9l0ZbILUTNiBR/yBkTM9EnFJ1Os5OBjxoFNxM54D87cHiAgP4ATA4FkHEIsWnLiV1N16NSjYngtyw5/T8eSQLQA4gTj0SYMs0OJzWJ24+GAcsApMDJTflMG6cSREqBA4ez3NH7Ta9FvlpQZPZ/AVBrZOO9OWLmBxbXOaWitXzq4tVPOZbqcZVWCoI2BnyG0kBYC/s5WwZxl2TC/9CYs4UBC+mhaXEz6ibHSwjIh8vBjcH2fSSNnMUIuuXrlCh8DpWQYkHNpfXlo9efLU5tXLqiW2ZEYqc8UYUnTAUpTqQJLkkp7OvCMAo0M6/cEjRvTDqQxHf7lee+7cudTlXe8c9GAKs26aRzsM7NGxI3YtAbTLFc48XV9nDPKyMi0REoIXZGFXG8c0rk4qRMQp2Fo32PMKbIVtkrSZv/n/v+z9B5ymyVUYenfOabon7+zObE5arZAECJRAKCFyMMHgdLm+n8EBZ5tgwBjb2NiAL2AwGEy0CSaIiyUEstIKBCggbc6zk3Pn3NPd93/Oed9n3p1dggHf+33fzzU99dZTderUqVPnVA7F41b6bUqiQQiRSiZbcCn/dmgLOH6IQ9sIbYxF4Ic+8eBDDz1k6sXGg4vnL6yvrtx8882f8VlvBY4DGB+y0e4Vu+CM9pqJMbd07z0vMW3hrRM3UVd2Ci1qG/zUO5JNqYWPk48DbaOj2B4FJCKb6BP06vLwl65PhohLnd0g/GM6Is226aTnhf6tUN3WoMdY3ixqdOujEpL5+GEQ2VIN9bZv1Q1qNb/ICzpz+7R4cuNKLIUuX1m1pRRlEYuVSiaVECpNLpzE3zEeN1MRv5k9E9DGJIqnUbtjgB1Xl2w50r0xtLtp29fGWluBg6Q08lOmPmWm8sOTD9uh6Apq7ApqhbY0N4ArYoFFxI54DbaK5bOMT1TKJxY4BOJIg46cGflkYPfYxOQNh288d+pEdQ6iFEVLqiqVwtak2zj4N+6Mce2z0x+zpIvR5s90h8we60yKy61xlhwAZxjY3FoxQWUa6jmiZilZUSW2J7FqwAQzeCAt+OyMhTZHLVT5UCsHSgWZWY6Pkhy/EdDOSEN2ebJDaVuVX3bqIp/h0BaHxlGVsOuPEoacFBkZV+phoJ2emnnmqWc57Ab0sJ5BKj6ATOELRVJAIKsWT/8Yy+CJ2WxLUMeO3WzjlIIj6SFwaRJ3IGdMXZlxJa26M1p4A2zNm9aGyOJPMZnNgNGkm48I5C3WFb4WtYX2j2mL2ZDR6cAfnwgLT1b8BaT+ABrkSgtqx1P4Kc0opgICojStiEQefQCuOTnVfVAfd24m2a33HwNARnq6Y/9G5NRYNtYLwq2I60qcQNrtwpko/dm5uZtvvAFj1ByO4A76lys6W10b7hA+efnS6JBq1B0daGvnTfzGVJbKLoAqD6gbmD/SIWIypgWYaZXShV2mEwkfIqLM8ELG9KCIgmaQComryB0G5J9X2caet2Dn8+mHoRAW5Z3Ir/MvgAYsFidyvx6hcdeMtNwaVVLLjl50XPO4ZRcxqjhcnXod8kq6yVQR0tADOFaPYvgkzWic4zO2jLc4BJK7gcfndlD0IRtsnTAvJCAhC7rdwF7jdBMYjtLD8mrw+KR+RPDQwYPUkiY6wWQY7OCRLAvlGW1wGrEgod4Ygl3uz3Wjj2Mn2Pi+9703T/t1Fn4rp+7cd/IUNvlja7TcxsN44Cp+4oHfDcUtSNG3H3nL5knBZ+OMAxx63A3ZfxwHktv8vAYePikvLww1YjJWi/FCpSo//gr6GoJrLrnWAiN7fWuNZsapqZyKq50fJqMUaOQ3V9QE+VRzyK8y5472twYaedrJ4qJjMLGFxiFiQmNZcMuhRvy0U7bHQtTWyupU/8j4xHhcZhlF3RYjOuEP3QMqVg+geSE4XrRRf8dpDOMWSee2FYJIsAhc609WkIWIMtxZyiEojWnq7ya0YDptg3TnECz36QWODQ4/8sgjlg11I2qMcPPNt+qH9nRZMdvSRqvdKl02JBIqVPFpGEZEqJ3LMTHHfL59cPH+bfQvcdifOsBfbP3f3llZW5XxlbXl8xfP2Qxz6x1HXdd8dXcVKrpNrMmunbuuoNHZ0xuKDo92zbUJBiU6OFEX00uHDePuegeypWL5fGxobH153dQhPLbSGboP9jolMBhHxqxAbq9jhcIr+mUyCzH68+prIWr2hq8ggbHLEeMI8OZKzSd32fBTohYLV866gokSwoe8xDSEr90dAMBd7CqONQXEc8ZZ4oMHBoZH3AM+s//QvsM3bfcMjEzue/ChR+bdW2CE3DdIGCyU+HOPQ+Y7Dgk6KtzX64Lx8f37b7z99vuM5gjw4OBojm+jJ29IiGnY5YQuplslX1rymoRHQ1ZVCzKnFYqbtJX72LjnOU2Mvfzlr5gc29vXPWj7ls2Dpj28jWI2OBeBI0qUc64yRhZotLXZOA4cf8q4HOTEH4aCrvwmC6MO1ePdtYPKlgpPrdo3gf3wmSVVOBvb7lO2TYLemFZSpnK6c1XdTcBljdaFtIcMpcrtGRvy0KoXikeH+uKt7DgqFkeKV22M7hmIiy+6tkcmx8w+2Uuo9TUuREAKo4MvvRTLHPdu/67FYZo9ODG87NrfxTkSfWVl8bJxcO/Krq3QMYawfbJ7vH9oTGO3ZkjcqG7bEWTJRXTJsjfBP4Eq29V1rFjPs1O0IkobTzmqQWw8AZQhK23n836JFtbGtR3ZTBkJaJAjq1TA9NL4hG7twvwVIzTVVouXUf+EKUTlIL+SUGVkSFglsqJwsxnwMJcxeQPYzKENSQZl7sRc71odG9sLxsRpzShqasgpQxafR3R+VI6ghYe2QyshDq0TNxCVtOaFwyd/0gNV4RHEgd6ChAqZFdTYkYfMReNznUMshmc5yn0dTPMJVbk7wbj1Zj3qhzAnOg0crAKgWZfEwWBECg2hz7YFqeUWq8iWcQa7tMNnzzxlFTd7la15FrHkmgAy3AxesZHBhqTwQMXBEw0cps/gUcdxV5FxpAkFbvtck7rOTAltklPvVEJsRFa6FZ1b+qhIACQVjj/CRgNSM8ehKRyITFRRIxOVKlOjYPqTsmogJZJ6NlodhEUs1a7JrXbzS2hiN2bcAKxjEgK56qqsTdtadLxrJqzqoCAR8dGl++NRC/5/mf/Fgf/Fgf8v4sCddx41WI7a8d99z09UDcqtCqHYbD5VnYRPks3h1+Gb/LpW55V/zdM0UcoTpJ4Cd1aEsZMpVj7TSIWnuoqJuiQ/0476Sa2v4bU334Lk137d18VqsCut3Wh7dfOXfvHnfuW//vzB/dObG6s52Ah6oGRXomxGY1aeTR0sR4waS8WmdtcaFEAm7goFRG6ZvrJ6JDmQdcnjmVOzd9x+42233TK9d0atZy4aDpXrxPiMF7tM83rl5Lbb79Sc631pWb23rV1CDLRskLrfcvHff/03Xve6V2mRGKkzyJCKdanY2JjE8zNM+vEf+y9/6a98hafdkk+tfHEH9Vnll62ZTw/5SAd00fIPxCpS3OkbrbxYeptN3HIkoFdHrvmDFYQGdrAubUNQhGlLkaQN1O1mkC05MDzZfPQvNMtwiqXZkWsAQp979vH3v//91onA6C7++rve/9lvfZ3d1jqeiAQAuV73rbfe6pZPSWcjA8e1zhS3uKvLyw888ICJiU//9E+Xlojwg9d62Qbybd/+L9L9Z2x9/d/8a0VHrmR5USSmABRlXHXgvG9us5VT3FCaivvd7/+9L/+iz8ElnnpwOMMtCoKJt0+3o/iUI4SaBcAxfNAV89/Awb4rk1XBOo1vV8/QuGHW7pEDe196x91PPPLUqfOX+yfGr8zO9xqzdPd4RdD9onOXzkFriTp48de+9it++D/8fPGu4UT1cnyGNrd7FWDoA/vr/vpX//sf+OkiqOzQng4wEdMjhv3lD6wczec//sd/4zu+43ubFDnAULDozjC2aFgMzEdYvE7oQTYZ1rPYf/CQfqwrr3wDt0IXsdJktJYy8yjVDUypKqSBe8gNr2kqFH9xFu92uksu44ldC6EkxoPunuEFa6bUMLggHdkjeaZSCwm7lXZrkjd6leVZyZE2CVEGnh//+CdQolBN/DgMYEKOY9jTG+6n8UBqzF5G5cVQyRwA11fYxcxi3TXfDhcy6qtx+Ox0d8CGE6rrQusThfRQLvRdgal9CK4sqxGjqjULEjk1vgQe1Qk3g39scUWRX/aRG47t2/e4NeSoHPLQfA3STX5LGrD4sszUliytRhEQZdEe3fCBk0qoAeFk+BTlDSu+9Z98QyvrMa3pHfEWJdwopyqMVMwXyhRjaP3Sl97/oQ/9tibDp8wWZnZMh+zs/Nvv/vfZMLS8m4Q4GLkDwyE4ct6u+7ITXm1VdWplEDdUn/rM27H8n28vR8Qdz1Bggyovaj14MJHNLY5t5139RpDrMJtpKfKc7K4UC6xicTOt8QmayhdcgdrsBD2IGh3wBMAn1D6pL7sTV7nZgio0ondodQSlKEquXY8GEQneqvglGdutY6UjVkiBnTp5Uksdeo2enm6v301MT7s+esRiYzTect78tYQYN9Rw/hBPAqwnVnISwgplQGmJIwcfaBk9CO97aVSHR8ddsW0dWND03gNdS2cUP33ONMzjheQp+KC7rSGJID/sPR8YgrzKFYYkT7saMu2KAvbqiqeOV+PA88Ur6m+nNeKKFWvQWzoddkFNBIyLeOKyixcxcvS8P+yqvzafM0cvEvE6Lyle51Of2IL4ajpKFQuSZ+kn/CDLzQFGUHFSi8QNA3/tqp1zp06d0s3qjAJbCRuHVq1qT9GVhliCCrhsPjoqBtWOBENb+AWJy+A4gG/8pm/51//qn/Ms0eITtULeHFSUgLz1ttvvuOtuSqvg/ur/8XW//VsfVCJgLFGZ3ShOFMK0FTVsIcawMY2DG6kMHzklVNUl4S9iyZhEhZYJMXPfcsy32/4bEU166TioB2oZPpQ3UjDJ6SxZtOeT48MbO15I6x0aVPXbPLnVN9S3uhX6zNSFxEVkJpEtcCDY2dGufOmfe+t/+7X32cL+hs96lSeBrRi894EPnz976S/9pS/4lbf/96UFD14OfNVXf96P/egviPK613/KoUP7Ze5d73oA0W9682tdB4Hgd/3GAy7kf9MbXw34Ew8+/pHf+wTgv/N3v+bJJ7ypd/HhRx7/nM95owMrLiHnX6RwlKlPxBS5luBkiRB4Maxbu+gA685VRxoOHDr4+OULFFgZeONPXJlpUHHziU2jyWJsFQQn9gXzNlszKAUGBjAARRtLjhtXx0b70IbjZsv27z/QdfyM6XcwWiHAZrJ1gbRDI+1dqOKmSSzZ6ytipIs8KXLIBQwQCgoa4urzOCXHM+6y2dnxuMHE5PjcXLxLwpOtReZoTDuNxuPFHZF0O4SbSSFve/0Bv8DgD+DMRClnSFvuQvMp42az1TWBMXCG4VAFqicbeJ7c/MET0aNHb/74xz++th7d70rZ84q2T1LSJoq8iyXUvh1uhjuSaxeZjW82ArjLQRDMIlb9GGS0DbdQvRg0b605rxUvG3MrMr0n0a2E7Z058Dlv+wKe+j5u8zx08Ea3vmjYLfxLq1WbtXkXqSf+zlQqtQQOC5EMz2JUrvqavlITRaEHPdlCbFPgGJ3hU07CxVyU6fFoipKFQTI++iCBo8Mj9JaIOcTvLUWz8pal+vuH11cW+vtiTitnZlt1XKTrRo6GCW/7nM/47//9QxcvXnnrZ7/uYx995MSFS1OT41/6BW/8iZ96+6OPP3v77Ud//6OP3nzLkaefOiExuC6cv/yB9//eXXffSpPp7WNPPPPYY8/cc/dtr3/dp9hY84EPfhiqr/krf64UGPxjjz39zDPPfe7nvfHhhx//xCceuf/+e++554526td+zf/Hyle+maMCkivj0ujUDcXRVgs+HmFTBp5jwVxlacK+uNzYHOH26LCucM4AA6sqGVs9mwQPg/s+9bKYqClXW+Mcai45ZW/e0i1cKNMBhjBOIY+O+hQR5msUpwtPSqzhxNmmMlaK0iKdoGxaqtBCgjZgBj8aAecB9u6b4VCNCl1cXLCXGM5A29EC1CefF5rMdMh0Zj4sMdkvhCyfxN0W2I4aUNbwCkOQijzEV3Z0QwUV09j8IRfEKCM4ReGGNpLWo9nZpjky7kIK6AEI1X00IKaJMPAp8rjBl7hLtD6FFq8g1wLXZhKeQvmLmHErv4HZyaa/9r/9jZ/8yR994vST3/8f/sP73vOeO++6a2x8/OFPfMLciQrxU17zmo9++OMHDu6XqS/+ki9++KFHDx0+QAp0fH717b98+vSpJBLCqEESud9rpvEpySn6USLXFWTGhIMsVa0NAFXcA902g1BdS0pBbVVxLta1UcZntdbwaJkRFpyM4427nme3RkFssaVngOSsDQ+NY3oyskVe8MGlyEXjG9/06kcffcrjzhI9duzw617/yr/wZW/7vLe81g0P0nrq8WfuuO2o8rrl5iPAIj2eTx1H8ZNPHD98eP+NNx564on4fPyJZ288cui97/udPVMTn/op92uE1RK2EKoin3r2pH7w0aNHHn38uKtxH3sMnijpzFXUCNww68B5jMGAYai715/7cq2pPvHEY65bNk5Uec3s2bdv+ojpt02jHRdTba7FEFLXOJY/3cTtqYrNweEBl0jr4sTDmnnIixDs37vv0IGDmkHFSRW1ijxpDjkz3vOI++rS6oRnUzQwpuc1Llvu/VtG3sUrcy72N/pd94DbzqZFRXMSV2MJVxvlwv0Rtw7aKG2TDeCtXXdQTq2ue9Umdp6Yl1pbWY4V2+gUdI9OTuw7sH9PvGRvY82m1sm2Bde4LizOnzlzCnzVEXr9VA9/1Cb+uNVoORTw0BBEUkai7mWsRFm11CnT2yAcdMeiveftrH2aBevTYuWidy13s8thcIWeToP5DLEjMSRJUbJ94h4wsmgtNHbSxx0utgZEPi1+21XPlO6VegMWS/StblezbR274zazFcSQv+c1LKVvbRo+92mU+Kolc7JnQ+HHsyPQ5i3nhnw+FWp8uiV/eeXQIWePI1hD51YQlMb1tLVRNMaBPV/xZV/1Sz/7c88++pQuEsodjPqpn/rpd//mez7tta87cOQ2z0sjYG5h9uMffxCeBx740K233bK4tPb006cefvCJr/zKv7i85F5qC/WW6mMawmwmiSSdMRHjprCBCNn1XEIegAspNXXiodZl1+4uzV6JWv7ywuqV+biCXQa9d7BlUsrRe936Haes4jEVT0DLtGvV4z263e6hjcHejf7BbjOagzD39u+ayxsacZPyhrvgd1Z2J8f2bXUNre32Ly/vjA/sccm3lscjwn3asGgOuiyn9/Z47TrHM3v3TknqwU88hkcK4L/+wn9TN3AcOXJQYZjOUXt4QlI379KlWVFKvAJN1CLx+Eu5y/6Cz3/jE088+9GPPfzyT7q3fKrS5Kao5ZMCU43WtXaggoiLpBmfwPBLbwcZTJFH66if+smECAD+1WLwZJQfybDBAR5BeE0KdbAYqIg4Hw4R4Sd21FgXa27+HCQSNdRSQJoT496aQgDMANbwIAEeBVukJknlbNlFTyHnVY7KNaqIycbaCvw6AFonGmteyGhLBgmxq9i9kS2WIEQjpuq1Qq0SJDaFqsiQkZwcfl6D1gZuVY5BbWomu9OgnJGErJXdhBaG6+xKF0x7jrHVDhQewBwR2jZKQTbVlSJmTRctKiMcGOD6xHMmI5UICWoxDUr+KiYYFBMDpyxXim5vbSfV9bbP+4KPfuT3HnvkYZkN/D09v/e7v3PT0ZujdhnoP336ZM3xqiwgkfKjjz7yutd/+oH90zfcsB92e2oO33B43bTl8tzE+CgMI8OTTj1KSHIWdM2COXGtW47U5YXlYHtIsv5IUKsV8Yk2FWvkr1ttH9ygvPKsES7BiwpcZox2sby7ey2mthzR8erahu3NrhRUIdLx8UHXWS5MT++x20p9sGdi4uLludGRMfh0VKwpGIOM5AzMSJ8F+azDJPCz/+UdX/wlb3rZy+7RuT1z5vwdd9z6yCNPHbvZVph7f+kX34XjTzz+7Gd+5queO366uI/0W2658emnT9xxx7FTJ8+i7I7bjz362NPsU6fOHTt2w9t/9d3ORlapy14ZRJw6ffauO295+JEn77zztrZ3/EZ+08CPHuzg4AEzY1NB3LGoHYt+Xc+Rm24cnRi/eG5ubKjVlS1pUDy0saIYB4keazXKMC+mglCrZewRY93sNuv2eEgtVqc0sI7VDMVOdMMQGrXmSqsYw7SkJOXGHF4MwNTR2tWG4CK70w5eZ+3Ds3KBMG7tNm8JaT/cHkl7/XT1DKthoAXDVEQVBw6HBMf4OwgXPTqaMbUXdUf6RCdN/wavGJ5lpM5wp83RuK8BtFwJU8gbn4pYnoWHm6PJURt5qGIaHmHan0kuUYvjRFcP7t9Ph9bXVoSGHCM4a2TwiozNky0J2xYrobIbbADlXl+e/vqr7Iirc1YwWmKdKAUa12fGrptJOF0wopa3GRZyZ9rQIOjChTNK/K1vfbPXqrD353/hF9QvHiWfHB+/+667n3rqKbMSV2aXQF48v7S0fkGhmO9QFpRQyx9Fb0AU9UgUk4KIHOleJh0eoA8h1G2we9qEnMbCRjpdnpxbQ2vkQgNAiomX8VSXmyZDgXVQqK4LAOj2zopjxz1Ls4v7ZvaODA7HbOfSoophfHhgw11k665hEcP+w+B2z5rNXTm/70M+3/Hf3vfnv+rzL126/N73fOgtb3ndS++/Gz2/8a4HBAF48snjn/mGV33wgx/hxmKyffsdN7/yk18K76//+vtJ1me/7fX3v/QuWXznO9//spfd/dVf9QXGwPJNg6rGKjymuL7wC970yZ/80tOnzsg/VAycTAFgjHTLh+2TWJuEVBsZBjsaQpZ0eg2DTz331MhQnx3iZqzzz8QdkAFlubS4RPDhsR0x5vfSVDLKbHhocGJ8jNDPTO9RosAMpJFxdWtcgtrJ4cGB9aFBeg5t1/p83EqhGGw/p7fKaHPLQJrsIbhoLrtohgdCCYYj5Z6DrgqlnjoI0au2imByKdYWKMaOu5TUPIRM7RNDFqzQkDhVlnPj+AIUG/PwrOv8Kjct8U0SWpaEiob6Tjcc5Rd2488Rfes0Fdy4Ed/guRYz1a/1mTNSDUxWNBFSGK4lEf38mAg0mF9eWgAQcwMxDI5eWBLQ6sXIDx/pFpLGBsNdnwCUF0nwCV6Q5KiIT9L13d/1r/4/X/c3X/u6z/zgBz6gfKGiuk5WgIkU9WLzdJSqLx/Wsbtrz9mzZ48cOUxpp6cn77nnLtO+ly9dcaHcY49cgPPipcXt7li5pcDt+Wy9n6BxZWMJ2thYGTyJJloS3BarZBgECYmCR2FQ1133H9nzbhet8zlx1IUGx8ZJt/XGaMiQbaivf1R9vttrgXlla8mlQ1tr6+P6a1ubc1cuHLnpFiLj2a0YQW4ZK+9qqKHeWFrp3s7W//u/76cxRUXzH3/k5xAh7Bd/8Z3Jas4oGDb5OX36vCsCuRH3/d/3k0HjtZq+6xd+8dcDOs0DH/yIvwIomO/6tz9SQa4a+LH/9AvcBgLvec9vQV74C4y/omL7xJcKJf06P2aSVJaCsIygHz5yw6OPONx/TQgAK2MZERHrR8bHOOpu5GB8FrnoLtmAkJLSJT1VJipv08W7cROyGLRrcIh0D1gMpLldF+c9QcDT3TH0sQhjlylS2WUiLyk0lQue6GGXAh++4SD8hvTi6nyl3Ab9Islucb7gzdkYycPmM3AmnlBoA30TCfb6xpJh+LPDxIpbmBZVgbB8xGlBVhBWVIzGIYngTxtVIQlcL2YqbtqRr3REQpBzV4zCjKUyS3sV1lk3daXhU/zxVYmyFVbGbRBGv7QMtG6yEWo1xUzt1tU+/Z/qbjhR0qSIPT/2H3/kH33DN9pUI13+Kg7lq+19+StfrimOVUBP+83M2BAKORn4pV/6pS/5ki952cteRr3f+973zkwf2Lt/n6HV1PQ+Sa+vXfWKIEmz8lcKTEhqHWi3L+jBNDeKqVAQU2TovrWIRk0CgDHaN5pXOLoLKm3zCNw0nLG0FHNDuTOqbyv2hFBuLCA5LoJXm5u7RbZtrYcO7Ltw6QrkEsqKjFC1Wrj4bFItB5ZxpN0qD+7bbjv66te88l2//gHuMp2x4O30rPy8EKCNti1bmRDgF8KX9Msk7ijykrCzp0/bFaQTYvwK4JZbbrErWg90tDcmUvAamK09cW20Frav94paP8nirwll4lyxddqsxaFdM3GR09SmJ+JkUNdVXe286sMA1R4wmjfgMm5kT+9RG7qSf8O+lzhSRtni7tLn5brJryRQroecaqmhu6bAprSM4My8KT4joY///jNNrOsc//4Hfvw6nz/Z53d/z78RERvYqGKHUKWpIuMsT6HlX8wvd2OD4d/6rBXM9iaEaETSgAHAWeUVCPOYaxwgyzXemj9zcV7BA+CgGMRUFM1O4YfneSb6Kd06Skqwxj5FicfMqyi/7Vu/ydkQ/dZ//u3/TEna8/OTP/oT5F6sRx999Olnn+Fz6vSJd77zHRcvXNbk/sAP/ICW4Omnn/2FX/hFaLe2V/ftO7Cyun7Lsdso/y23HJP6c6dOLi7HRoBaQUx6kE/fdsbHYnWAZpK64eFRdnQETp01eZb5ikzEGQUj5GCFY0SWjHSbNLs4H4VB1OBx3bMVJ9cuDHQNbPZ4tNC7jV0Dw73WkVbXV2dmpj2yIb+v/ORPWV6Ni2Yxi+TZmyEKHgZJNkU6TJPEVRknAWnxNN5m+2I/9dRzhrtBWkpnRem0w79dB1eUztBOd4WG/XwF5hOeKWdKqD6VEJ7yg/+5Z497AUi9Z96K+nmUQIW6vro45radXOpg4yZIsdS+o1MTkJQYcUSnJSexNFbR7bEFxGSh+y67YqnZswMbl5xhNAaOLIc4ddO9mDtB0p5prwdEC2y2TjMft6y4c3C3VeOCBxN2RxNEIpHNHz1FErexrrLVnYvJiAT+1E+7w62FmWJMvHmv1P6Hn/6ZX/7fv+Yrx4YnEEBqE1XgaWHLG3NlQeYkEjCtEVmMAmrKJ4YUPT3/4O9/A8w4ICLDJ0jJWjxx1tc1uxJqwJoAcblRUg5KkkFRMaVpVfTtz2AFw1cUxTe9Z49PoWJFdWxhIVW3fATRYdlBcfk0dsWKCb/eXlelKwsdKjKNQkEqUTsxATtvhoee4jQpLYhU6M0qU102pxHvvvceTZkdkRcvXj558uxLX/ryz/zMz3QzxO7Oux555FEsBKxBttNuZWWZ2qzlzdtmRffO7IctJvTTkAdkM7bb8JAuPvR2bRvUxmgoqjEj/JCx6LOHLpjEjipv2ON7cX9lmYyXPe3eXb2JHc2upsLgfXdrra9/aHgkWpmBrv6pmXEbKlc2nD8fuzJ/URPu7ezQfHVivCoQZbpKDnvictPnmUg8DZH1+7ywP/gDoVVu4egwPv8gJH+Qf5RxdoOhIQGKtjTBFmV9Lcta/DmMgfUz3UhQePBUAUuupIEmm6gCiblFki6YWIHNdEn0kwMesM65XrRSBxaVJk7F9Duycd/YKZKzzGNCQrPpD1tMwyot/swflAvYineVehX5yKj5KlWtPpip1WCUpC316WDfccddL33pK9716/+NiPCPW+y3QrHLiP4Pv/mbf/j7v1++VozL4p3QVR3/4gwYsXJuK0jqNG0ErXLEWPSwMTYz6KvVS68gn0VqBHQYOH01mBNtUy+0vHlyNSmCDwVeW1dMnRFDCVKBAUirklMisF+XRMXCMf4MSAiZSkWDVgAK0Su3hpAjQyPKVOacnTp06JB5E2qsWlheXvTpmUjD4894/RuOHT3K8777Xnr69DkjYV0i7fCxY7ecOPXcK17+8gsXA+3LPukl1p4jLzH1RnBiZ77nUaXlxGAdbOIrH3lvQegzgYzzqmG2N2OVI1o0/pbDKJ4unt2nVfPJ51XDoY1tC2wj6pxBZ3Yj6pD5KQNhU/dTox4jvO+TXjY09sTFS/OIsPfBZWM0I4bMoufE5LrXM+LFWmNxIMl9wmMDhKZeSvHiVcyXRakE+9qTmWrE8mGXqZKrAtBbuOaZhakL6TcUOfZCakvlTJ+Dn2fKojaVlkO1G3E2MBo4lSkM5NzUkllBIoslurqz52YXryzN9A0jaMBk1ciw5wtdR6wOYyLRmMjcEuToVUw4bLem74u8gPFPq6nljDZgZ32TZLgqzw3sfYvLq+ueg4yaMo9RasYHozqPWOoRir0Td6xZB1UWdDjaUu/PqWW3N0dGh4y0dweV64BNC7u925pY+131G2LWMU6TbfXkuWUXvfeORAmlGgfJ/V0D45OugFt1fd/spSvTk/aJHuDfuzuwur1uZ/uhg0cMzF7y0vsI7s33vtS+oj6nSwf6NRoGlg7c62gtL67u3Tft0SbS5er7nMHeLrVBvrF2FY1xged2NFbRWQ3PkC/M50rJUspSbhV3aEya8GrJRmhs+kWHiNT4ZLCDd5RuLJooQ+u3UVHmpLKeZr/eqYPEIFfWNh2otoxpOEsb1Ykuklc5KjWHQ7sdvq6UojUjee10Te04xR283dlYjCWcQL69bToGN6BdXlzpHus7cnDv9PRe6c/NXzDJPDd/yXnj4ZF+1+uphS00GEIfPHTIIryul+rX5sobjjy2tLy6dWmzd8Dc6Prq6poRb0/3MJxOrXZtLkWWiO6ug8HbNM3EidfctkajZ8eggSliRJkwaltZiiMt/cp9e3hgsH+3e2F+vnvQ5f44r1cpcMu54pFBOxWHdSQ9PmprgCWqpa5h60hEZWFx1f6Hm/cenjp04+rWrt1jm6u7S5dPWS/a8TRdn0PmuhsWSKOoujf1JVda9VkWSRRPEScY8dcZQQ1YxK8CT09B1wHXZyJsVdXlU/gxOkhI4Sg83A3C8i+cPMtYQVWzHrjhoItKpKmunZnZRw4IH0gOHWCQtF0mhA7lOjD+SqshjwPVKgUAIUO5TKdujYpV5zwq9ZJOYGRbnRlEQut/URXfaQpVYe60m1DxGhgJ8SfOJfeJMF4h/MG/9Tek89M/+R9/93d/+2d//pf/+bd/E3q75uc//SMfvv3OO23qePbZZ9To84sLUHkG4fTps/fccduFi5eHR0cOHNqv++AFKc84HD9+fHpmXMdeQiodgoUPUow8Uqjs1akCenp15xz9j7cKTWoDgLZMkc2mgcXwxq4gqK7zKf9CDknEDf3NmdjYB2L4s6YLzaeazfn5Oaup0/smocJ/hj+cFUVrSUqVF8qjoct+NYRXLi82noKa5HIWMrrQ8FS64+OjU1PTjz3+CXExgT/+eAjKJJbduIPDI9LSljoRpe0cHOg+duxYrG6sLDkOBLN2NW+qTpzWHdv3YKuX5E67VYxywl9ylWLZlXfNu/vApJidPuMi3eO+kdEpd51KN5hzVb0WIiE7EWXHQR1j2l1NdL86eWhQRJMFHvHYO753z9ik10hPnbm03tM1vG9GzbV9+oyywbqBGCBF2Y3nLsPnKTBfpgiNOpAMpk95okNQUVN2ALQ9K1b5VKSCoT712UIbvAgTXdEObA1CQeAFFSr+0Q7msOeZZ5565as+edFFXlqh/iFTEVhuR49CBQBSXK0ZXuma9sedCNHpavBUEhYGIFdgWioRSybAXCeggAu+opcCc0tCWhxlKgs8CzjsXL5SdcsDGABluCWReOisgXRX1z/5J//gr/55O8G++i98zckTJ8Q1Yaunp4Ix9Wnn/W233XbPPfc+9sQT9xy5BxcIx63Hbnr2xImFxUWSOjQ6trm9c/TmyZl4OXn6yuWTK9qTzVgWjicRcm1DV1+iyPOJjOBjmoakFnHtgkCkcDZiGodPpvLInymfsvlDUnY5yu1ZRhxWWZi6239gb9fTz6LESvjFixtKTU7hL0hg9Hx+bgVCGMpuHONjk3EByGD/qAfj0qh/ofJuUO1a0xvi0EsyGabL5viUzEKuTwsVT8D2PN+8b//yyqKB2HS+aWxqxZ4Z8w4HD+6/Mqvi2NYsgmTEMhD1bCIHCqNLEf+jokFfX1drQ3hR2DBk38x0r1cjVje61jYHPSO6GdNOQ6MjV3e8UZgdm1xJ0vvVJ1NNa+/b06E522KlOxV4uH94evKgLVb2aJw4c25tc2tobNRaqR4lAB3hPpswUwBHPGJaM1X0Mv6oYnEQaUw0QS2N9UXgwla0xonxE1bbJNM7FLWzjLlxoQwWcBSeistdn00UAJVuAXAzykMD4GxaC0/czNJ7YP9BXFanak10Cc2EBKNx3H7K1ZWe9ZjqYCp6ogmiSUNpL6ERStxJheq/Sg5YRsqcxggiqAhRC31smSIMJUSdbeSc7kiugtjcxSEI67Pl6XKWHKtHD/Qd7/hH//hb/69fe/t/+vH/aLIRpI78qNdGHEVeWhwdm/Col22DOsMnTp264dDh4cH+k6dPXpq9YmPchUsX49X24ZH9+w9Ozxy4/Q6DaiuWFDeqp8hF9nu0RUODw9QxOrrGToLb91qHnmY3GqH+CFOLYCOroDlKLfC085Sj1FDsMk1OOUC2WNP+4WlMrmMshDIcOnSQz0vuu0dhXZmb1QRRWh0fzKeNDA4fPXpTlnKrccYlJcLH42kcIBkOqVfSig2SSl2QlO1mo73k06d6cGbfvqnJaZzk1ruWqFI2L420u+++U/ZFwQ8HYza3PZii2nRiNPbGw2nFYW55RVpJEivac3QK0gB0Sn9Dj/0/B2ZmhhY8BzQ/3NXrdO/y+lq/keiup9KdYHAUNja2MkbddoUur29a8vAIrmVBSCKAxu32eHFqdbfnxKUrngF79rnTRPrQoRts7aC6Cspw1+U7pX2xgbjGwFVUiGvzP3+z1mhxqxQbRALVb2OD7nT7bHIV/qn5oVrt3mzwI/h3TZPBl7lOFCJ2MpGth2w6cXFpXlxglkLtf1QwF5dmSyXgB0bcdbYVbYGBZARV1rhV/9DG4xfD0eVujFLnDyxjhBVfyYSk9nliWpDiylafZwyq41rtcJtlxQfyBgw8YxqEEPZ4fTcmBrq6/vJffsc3/4Mv+qIvQ/9T+Q6wKkg5ugTAPoSV9Q39ZEiOnzihYYFEEBF2vkfzRQrNgnrmzYllnbfDh44M9N2tZ2rboOpJWiKysX3rakikwYHC3vAaq8Oo2XdFApyyVoabASkv5W5snkxMg2RxlH/6hSV6Ma1SZJeJCqJrxwTSmTOnzSH72LdvRlGYuQAASaUbcttKt7Wu26Rbjq1YDg8Dg+6nHEXZWGLs31MapRWVSwmZKFGmyloGicpIdp7VF+YLLEC++z2/+Za3vGVpeeG3f/uDsKkoKTw+L68t6zzbe24Ll5GFbrCEaJYBDw4abNjriuCmCz2hR5DEsCuniIkYXTCMa/cX5lYHt7vGhsftzaC3o0G0AwqwxFNmWlJbtfyLCRJNfdy6ZQHKqFb5xgbv2Z2dJ86e6z1/4cYDB1eWVrc3Nhe7Lq3Ozu66mws90RewiTS4YVJArOxhCqJNUejR4fcrvGSXXeSKUOS6xYNbUaYdVsQK01r7aX+GV8Rtz79jfQWxr8Pps4wonaE8KwoHxVtZnD9tNfjYUVN2mKbKPHz4hvMnnihex1hCGQ4PDbgazERXjmEqepCSmPG6kVcOaMsfWN0cwoHO2AjXkUGQIf4dfcWKxS6Ecco9OxrNVDA8iZ2YhqRWQmp3nTutHZ/xkYmu97//2R/6nl/+5V/+5m/+lgceeAA2k41WtiAlpHumZoKYnR3jtBtuPOKY2n/6qR//6q/8qpe95KVnz5/TfVj3DNrutnvPVlcWLU7u33dQ50ISly9fpMKRidQuTJccPSlsskfn/DUbRUqFGiJtXcnC9RN/rbJNVJULwVCxy3CX6fzEljhsy6y7L9addSFm5pOQt7vkUOqgMQ7F4w+SJ60bHqmuHeRRt7ewK8fYf57zniRMS2jCM1vmVS/d50qn6kh0Q6fR0Wi9TUSZK3ToemVlzYzgiVOnjx8/oaV/85vf/PTTT5ttPnrbzW69Nv66487bPMum0YbXnDOGY1q16lJwpzDa+NSQnPDWaGu1d7n4iYw0DpFE7myzil0FU6PbI71LCyvjfbHjznrJYM+gd1borf630zYWjLxxtKl/2+emu+317q6N3e217avr3g3e7t3q295YWHniqePuBzR/LSGc8FS48zC7QyFjwR2LRymc6+w4dJdGGfhFcTm4W44ozpZpYCDiruIsz/iMm+bDQCICRwEYhqX385QWTI2BCzXIAm4nde238Y/1cCvszz137LZbNSuF342zD30klkEFkQYM5c+hLvS4oLgNrzl8ZqzIpiJXNjLNU6zAkIddAKDdH/CGCDBREbW1vfyLAKj4K+iigbsqvoLJ1FtNDR81jkZRRKKwsDDvFcLv+JffbT+Yl8GsUgIw3ZJj+Iitp/ShD/3WK1/xSbQXwGs/9dM8d/7g4w9+5qs+46Mf+6ib190+0N874bXVrc3F3//ob73s/lcZGLs3Gw2aIxPUkETNk5cZy1KMvG32YeJkm35cTCCBCZ+2Iz7rzt7yTX+eZZI54Sz48sQB/k0QB8Ymb12QsILPOgjDI9Xr0cCQvdA3K7TWafGHMtNktjc1K02eKhz/69Psb4MzupuROlnasfArFZ+wyZJaoKdnRR8EbxllqhG2Gsd84hOfsJf+hhvjVLDHX0z4fdLLXiH1j3zko0TFejJpmZjaMzw6ujy3spzH1O2FsvW5coo2xg0Flcf5uTkOuZa6VKo7A9KyhWNGPXtG+g9NLW+tug91xB0m3uC00OPcWDS2wW3HBYcdle3vHtvtcq3OKh321lFX79KOl+odYtrs3R5dW57dHug7mQONrZ2NFbvyeze7NkJQ8aR6SFAtUy0ThFxFGbtMMQ6NHELLCOJg80u71TaWZwsoAQpJ46/pqFBFUkEyz+gONjBN9Bc6RCnPSvTSpQvw8Ekiey0k4D5sQvWxywEgKviY1Yxaw2cZn4z1ep6ltAXPxgj7VAstYA6emUQj4kGF6JX9+EiTPi1WcKOrHRK/haFS9xnd+6sOm2lWdRd7ur7ru/7tyuyd97zCbIre4A/90A/p0clOl32AH/vII088e+XK3Lvf9/7jJ541E/MbD7xnbHzEexvf/d3fDSGZd0Lg9KkTjq3ccMMhvHzqqadf8YqX2/Zkosh88/z8rBTlQhUud5Vl8ipu5TdW25I5jc1RUYry4kN58lF67BeazHXLmztSTKO7ru+wuDjvLRoTvyAMQRnvBmE+SmAGWPpmjNDTHUrOqAH0OtMRKfZ3bRQDU3xbIiSdq2tzfABQYN1qS/N4aO5SN1h+oV0+t0o83LkFuUms3/3d373//vvf+MY32oP14Q9/2CYq1QR6zGZP7RkfGxnVf1GtWBOG08qT3V2VnbonQCoMH1sGOIpsNneRgei13atDEyOTNxzQ8+heXOvbiWFKL8WLy8DjbJasaWFSSHaHt3b6zDh2x27Tq4N9ppTXICMb2ybCTGRcvXj67JZZi36zJY4E9w4si2gC2lUzLSFbtoXFjAZyt3c3o9WJi1sDeaxOA/ImrW3rIc3BQMIYofiba1BBRcuj0XOSGSbYSWzaXUdFVWVc7Cg3PG5rDhxxx4UpNK12rLBKl3xp7aLTNxBnU/FIPxJNvV48H9w++cypjaU1ArG8ujqxZ09f38T0oVtcLLx/75S2yzQAeM2h67C7+jYsU6BciqgKFjrOgpph534X19ZXzEB5I8BqNAdh2mzXZSnV8lcNS2RZqJ2RliJNcMAfK7s5lUdOYn+6ZeGdrXWnX50T8SDdVWevRxWWLKyurExOjZtbsoYBj3tCxwcmV5aXsWhsfCp9JmYmJ7QV68srn/G612scXNDBX/fvkQc/cevNNxsvzV++omU+MLX3gQfeT7z2TeybXbx8+szxmX1TBw7NnD97weGKu++4a3bx3JkzT9904y1LS+OLC8t6gPDYsEeyv3HtW7j/XzCj2q1Wst//bRw/FR/jYf1ZmR/6Nph+8nnYgtNt82xXlz/G9JO/5/LPJ6HOoW7XWgSGf2OGu/7Zt/n48cbjj+P4iW8D9fMtyL1dXXf+cSI1MKuNKx2Lz/+ML++pmK9bbxHdtftt4bmyOMeuFpiIhjqS9TIR3mEaTw7KWSGlwNktJe4q+2txA1sGc1CeBjkw7qgO0lF42K2Y+QOAKc9ys0WBR1WnNlVNDo0cUN3SJesH+kimSbKtDXCVmB0L/CdnDoiiZ2VUwxTZUpia3HPVEoSzI3oyasV4EmnXBK8xcCUatU92rdttf1RggiBHAJyQSNosKB8bvHzyVDPEkfQ0UYk49mWpqHhEWvJ+HPOKqhR5s/FvZCgEWQcMhWxdBs2s2JUWlbYMY4OnRgxmczDulJHyy1/+yttuvOX0udMf/cSH5+ZnbWZYWVt30+Pi4rIdLHPz8/sPbGi/m2fZdLk0dsT030x+59/7O//4e//P70KSJNj1ujc3gxKmglz2XG6fbZ8AwCmQiIk6wcA1H3lD8Eh/9S2Dly5tNDRwQlOLJy7O5GR2SMb3f9+Pfd1f/4vwaArCv22AcUZKNW/+fGEQFF2Itmc7UvziGGL+zff8yN/82r9sqzBKNKc8bzxymwWnmZn9bva28Da/MOsW0Njo0rfzrFnd02dNWDio5Go7M3/kxGF9jPUE18kTx49bdd9Y+p7v/4Hv+Oa/73Ciuhla7YkCNbmsXdKiDHcPEMK77757bv6K6QYF5DIV+UUSmXQlPVG88chRLbx+BjE7c/GUWliuB/us+nTvbNgSGAufwwPD+FBNFPmM6YJ88aMvb6EZHh1zIlLpSWt2YZFsXB0agd9w/d1v+MCbP/MNv/He97ztLW8lPKnAlpOjlcdoraJWMDhed03FZ5rG4YubSUHnDmCfYrQcpZxRJlFUhEVofoWDKbAK5S5T/twtoIQsq+LqKCkwHDGeOXzkkKXA1Y0VHU5KlUIY8zSD8apyHEyw38w5bNhqrgs3KYn8w2BOxU1XRjWzVy65tNAqi2u05eJq7A8JEwy49hckIKAokQQMuK9EuSSMCYIUA3+nVUxFSijho/cOHkJBAIDZJ4BY12gMDzkVET1GwIJ0rYGZTQm02S2kroKooofCjNwcn9Q4f/qnf7rTM95ZnTE/ubH2yOOPECCHTNfWN587efqe++/UPpOkQwdvgE2Rw6/4o9S7uv7G1/7trr/zj7/2//ibP/jD3yeUkW7xrdgLxqfssLl5fuVXfOXP/fzPfcWXffnP/vzP8VHFhRyvrcUuECO62AvTb/i6thgbDN3wpVOTcghkhQ9dguQ7/tm//uZv+fvf8e3/puv7fqzBXwQ0NmxMKXDjWQ7+7eqlNXhpS13X7GysQgEwZDCHrL9Dv8yTUYPJiT32maoEEewZDZWmLUB7Duz7pE96xae96rVKzNKhcsABquv8/frV9YueJz9zRqIxhLFeoAdnj5Rlva3YG8MfR8jM1MQeN8zuNV/d03v/yz/lwYc+fuTYWcRRTQAAl55JREFUrWrn6c1NpyAmJ/eI++gjj+87dIM+k4k0nyvbdrPEhpY1bYvKQy9ax69v2NYwmTbXSgq8w7C7PuwlKPzV2trk7aDGes/WxtbacvfqkvWyYULStdkjJEpzfGaSPTwyMUiQuLKDqUHiRCjx1aUkl7Hbo+Fj5CE/2YxcISXzVratwzGqCRMzJUFbib1tZOB5Z7znIWxwNqmAadwcxbsGDF5C8Mwzz7z29a8xcSk0Kt1hV7ROj40MamtdGatIDLpNCFgaKE1Tioyj0Rt5QMzOOJc8043F+YVLcxfHJ4adHdKqa+5i/inIDAWO7nzkOIxE0ZB5y+CU/tLJCrWBRk+VCQp1qWMIENxEAHki6IHFIHBwxH4DtRp+1E0BFIDGUlFqdmVuTo4qov1VxE59qsJysEaooderP/3VkFxd35Xf2269y1ZQG3muXL1kH5qVYR0D0kaBb7rxmBrBPF8AO7qcChzJM7FrEo1hpMWufAnhX0HUIMP1FGQ5WJBQcbMxUq3T+JYvx+xqVnlTXWLGdyW0FzCyZWp8YlQ1yoidM0DBN3yIRHE5DTfPcocj9aQ+G0/+WnV4irZA2CogIVFvsuGhycYyKhZusySyb+331KnT/O+443Y8X7BCvORFoW2jG7qkHlaegJG6sHTFkRB1n/yajDDGhDNGl05ubu+6hAYDVUZwwkbapvbshUH9uLiy9qpPfy3JUVsxsM3OLx12v9ShG4yfnjt12ny4Vx3f/Ma3qIUfe+wRbfjI2OjwFEFV363Joyjsyp17D+1TGZmYcDGIytE48OLclTOXLixR4YE++7TmV1Z6d3uHB2NMspJLg55+UA2VAutGqnFaKld8J8adfBTNZ/Ir+pDxGYIeBjwTF5OUcORUZ1SYaXiWo7Cx0c2HEJS78ecJT7WD3MDKFAA8Jpv0eUxE86kGBDwfvDIZYmYVU0+dPLOysjrYN3j+0nnRpcIATibHpQqjw0Pe67r99luPHLmRfxz+GOibhD2UtJWjIrixpVK0BVQ7O5B6fTO0wRg+7zRXoZPRkA873eIS4F1u2+VIcGmRlcZQy7wLd81KY7TJcS+HagiGtbNniUglinI9BdHRhiqhdfKGGI4Nuc2r11PJs4uLZ89duNxzWaKaR6ourkUb+TV5gy0+7eaDpBF6JfwVX/bV7/qNd7z1LZ/j3rzBgcHpeLgk9iqOjoz+6n/7lbe95XPf/8D73vRZb/7lt/+SZur++16KpC/6gi+2BRJJ5iOVslnl2Tnne/Sou+0kMfWPt7/34Q+9+U1ve/Sxh+97yf1PPPmYPg5Wj4/FLQV/7ku/qjLFLS+1glCZgrPhOeTcTKeniGoN2W8MnwLTtCLbp/wKVV+IyKj7MMx5o4kJsw8bdu+ZAzfBqRt65vS54jbmEBJNtIiaNOUyOTkxOaE31+1WHTiNWfbsO4BUqVsuVj3p4aJfD5nuiYXbPM2HSEINi9+oevDBB2+55Y43vOGNVNdK1epgPPV2dWlu39jU1aO3Xb58yZbYxcuLKI2qUOvZlk9TV3DGjul4MWjXKdb1q1sDKwvRgbOFOk4rUbAuw5Ya4MQrtfgQe9vztA2mtQcmerClx63+MLgA7ZBsdQMf6YVJgS5nvxogTdQE0YhHRKZWkTiSvS2ryqDshAqrooPgFsTRgBUMH1XmefcpX7li8YFs8bn11ttDpbc3pyan5q7M2mrz7LMn3FDXPxSneQAwHIWfvbChIM+a7923//D65sb58+fci6+Ek0utnBZ82aJgNzeDQjkubVRyWleNLgGigbkBwJyfxGKHXPVHQtu7d0iHLfvw6MmTNMs/MMHGh5RDzoaNDT9q+WtvV9bo1ab9gASIuEjFhQquKLNZUmfJW360VMuACbaC2SUrVdu5pQiV7i1U8Og6ju+Z7BqWr5pa7Xv3e971utd+Bu39nd/97Ze+9GUf/fhHPv1Vr37Hr//an//yrz52082PPf7oPXff+8STj5vcRuFTzzx19933PvzIg9ZZzOoj9dTZE2bC5XfP9IwULlw8/5J77vuhH/53f+tv/AOUPP3M4y+972WukPzQhz6gj2Bu4hUvf+XjTzzyknvvRwwAtolGmKtQOBieTExkpuGu0PQ2XxBjDSZAUyICNloXjXa0DT/2E7+Y4X+W1uDIsJ6dBz2pugG2LXEuorDQ6H2FwbGh22+786YjNyqj973vA25KvPfuewyqY+nuyqzcra2sqlnc6Ko0zpw+uXJxVnfv9ptvP3LwiGPJp86eUd+p0leW5iJDjQ5nuSs1/beN5bWFuKFrwYTy2PCgM0hOqpjEN8A1TpXPta2o/d0KZkY5eGr4ICbTYk1oKBOg0kh3WAnQKgbuam51NVv+OXoFL0JjBwbDjPJpq1NTPAHWgb+SgK3T0yeTGEKyGQJKY++65x7jSaiILOHWV1SxmL3Yu9f1C2sjgyMmJ2gaEVcG1QXiUAGPj4y7PH3//r22BFT7pgnSEroiMslpy1G7+pAiyRNU9T1iShBNeq2sOWbkqb6u6akp/jpmgKPDHPf+WiF0l2EU+uhIHDMOYy/OduzBhiF0O1sPaPXfTLdQ4MoLfzX38to81XVftDH/iedO3XDDjbSRAmsIURSVBHR9vSOedhjoX16ajycdN6/KI25QeAyB55mnnvKwY9fro5nq+oEfMH+yb2b/f3vHr335l33ly+5/+R133HnrzbdqaV/9aa9zqf2B/Qe+/wf/3Xd8+7/6tm//pi/6gi8V5ad/5sc/922f/z3/7rt+6Ad+FDbkeTTwu//dv/z7f+ebfuQnfvCv/9Wvf+iRT+hAvOmNb2Vj0cmTx9nTM3uPP/f0Gz7zLT/6Yz9oxfX48ad5il5sjBNaafiUPwejExHlmOsOHEyFauqFhhCEyOnlRR3K7Z5k+///3td/HbQm5MrYsKGxRWnuWI3eDX/9ZTLlJBrmTM9MwWa4q/mNz+lpExqzs/NGWGboxB0dM7e03b+8+OTTT6mwPun+l7385S+3Kf3Ucyesxkf3IfaUup71aI5Wbjj+7In11bVTJ04iY2JsfGlh0cH1TNTeQWeMVxybOHnpYteFs9T48E1HJ2f2PvvsszYF67tEJtVCsbMnFocIAOPmHZq5uLJIJNy46rBhHoHvNYWLiTna7VpYXpSL1c0VN2qlAocsCS094Yg6MvLcwWIs88lgSjlCHnnGaDlNdrlpFNlioay8bVNuAbR/GlQ8OouwwpvQcrDLAaetCKVFZlnvve++SFxB5kV2y4sxFLe95ou+6ItQYIqvyhQTlXfQk4v+3CtLbnI1wzF/ddsobm1kbIKqGf/3XQ0RDJ52mCJP2RQGNiIlqmidF1tdmTP08qmNNWRys76o6DFV0YDFvrf2LDQHsZQFPOw3mEyZVmaqZEOpSraS+KIv/mKhZb4yfr633OxoyjXmzqzmX369iPX69PvN937Qb/fr3VvS2/WSl9gx+KaxyTc5Yr65NfOKT+46frz/1lu7XvnKez74wa7XvGbft3/79/3XX+v69n/9PT/7K11f8lV2dP7SL/86sfrZX3lX179cMsfKTQv/6b/9oa7//ev/7p0v71pbf+XSOs9P/qIv77LHeGfn7/+9b+n6mr9lFPG3/+E/7fqKr/nb/+Sfd/0ff+sbvuVfdf2tb0AGpuGnPgn3deUeLFUB5aoBbuAJLmEFMPsLlZq4GEsxgnW5TZoe+TQHmZ+xcZqDAhsamxgxqtAlpz+G7v3OQgy5PmPQcPrixXWK4aodqTi+73HTqXH9o5GJ8SnzCJ47HZsYPXbsKEwnT5237Q9dk1PT9lR7FOm5505Scpsx0fbud/+mesMWModJH3vsMdWB1LXJ1CH2E3TvOGzs5i1LJCtXu/rmh4jc4NjI0MSEkwmy5HGCM+ePq8oth1i70GszweUhQj4by6uDI4OmN2ReD1GV1mv3nr1io+Pkv9TKaBEPQ/acbeAy/8omXfhYDkzOO9WitiuT/mHR2rCjTo1hXrWgfuht+gvym7lISKT4DuMzmx3KVOmVj7gtA21iVnJVeBWPDWBgqNcmGLXm+PDQk4889tlveastpmuuLBgaOXjo6G89+cx9d99h252yUv96PXh+NmYX6hC2Lip3cMfdV9tpmwDTSRozorSQHhes11vn2CGtJnVuqU/umSRbik2f1n91tnGvC8EHR12qsLa8dqV7qGdkbBJTN7eu9q9Ebmz1jBnEbK7NTpsgh2dtY17QpJuAYmIp6rVNt3zErcnbVm5tzu4fGLl06cq7fuOdas93/vcPGi+6/t6s1wPve/+99973OZ/9+WY4+4fHDeAvXjz/kY9+2CXeU3vG9OU1uaNT+8nzHbfdsXfP3sceevBjH/nId/yLf/oP/t7Xb/eYW/phuy6HX/1qMwX/9fRTL3v9q4evbrznR77nk+cuXn7Xr9qD+eGPfuhVn/Ia/efbfvOdA5fOXX33r1+8dOHVQ4O//PM/8UVDg7///t8cWprds2dGx39p4crGA+8ZXJq97TNe/9yJZ2561adaTvuZ7/zmr3IP7vbVH/0P3/W/Dw+dvHz+qV/92TuW5+be966X9ff/xtv/y5v7+//lv/hH5EZPH3y0M/mqhtIk96Q/Tg7t5pM0/Vsz+0fxX0nFwCSvK1NMhFAlzEenia5ioMmL6FDu9hhw4qQ5SH7OGy0trriqmS5p8VavekLN/vDTIk5O6idNGSFrmALt6tpiz4I+i6mQu+66R7GurW685z3vO3zwxv6eMZOgtNYGRv0dd5KbsjLReP8rXmYA/NTTjz/wWx9Eg0sC0K9PMDo22D80s7K8eerM6Ze+9KVOoahktCeomp1bMKCwF8M+LcfVH33oQTkVV0sj40rN3vW1rlUKudW90TOyu762rCLyMrT+ZJ9tCtsKygataKVWemPW3Rb+FBtlall4Qdc9FLj0lt1pci93TKcKjuY4RTnsHIiIxVzz9IGfCZMhLwhN3wJQGBwKqYFsHAgoN8d12KifAbBY8q8zqcnae/CAizptvDHCtHTxex/+XRsHaRoFtogXz09nP0Lmo9yj8vYafM/SwiZGCGJDVQlBi6qGDI7O1P/tv/6JzqA/sVtaEoIZkbqBhSfmP3vjUWITGFpzAKQEwbffcqs1TMuMNxw+eN999z311DPvfOc7X/ua11u0eeqpJy5fuWQUIOMXPEe+vnXTTUcX164aj8Ezb4ppdjami50ynxj3PLe9PDBrIfVP3/ymz/2N3/y1t77l89/wGZ8t+zcfu2127srrXvOGd7zrV9ZW1j/3bV/40z/zo1/9VV/zwd9+/6d+ymvuvks3xy1TLzEg0yaieXp6htBY7F1ZXfFoydLy0vSemU/71M+gb7bWmRWX6AceeO9b3/y5FHX//kO4un+/O9mdV48yCG7HpTpxMMhUK1YMDY4duWEPf7NKWkKKpJTFYmtsRZQjYPCrQoHRPad6ld3EyJT21gnCra2VKlDtmZvWtZl2ZxqUOOYhrtOCPgnPxYuX3KPGWPcEf+bkKah0g01MWKLD84MHDtvTpjhs1VLF2HrJ9glG9NJhJFFRF2sJckYCnyGUisWn6T0hVDkpva76qMyKNXvlilVAGCShBpE06TVZfecdd/ORZdPmc3OW/WPwpY6cu3wlJMRWUY8T7I7urGqlIm7XZozd1gf0vSyyRLeOONcSaJ5TTTXGIAFlmxPh1kNvtZY5zRUa6kKPNJIpR+uzLfTX+ydYpyf8DJ9OT0jKs3H4LHc5NFnDQ3GRv/lYh+msyFsONQ3oDhwPf+7Zt+f0c8+69RVHlL0R6PpKTPxo3DS++iU1WUA+zKVSErwg1Lgcl2wlMfnkwbW6rJJm/4vv/EfsNFHjJM3hsJxrMsmn6aPoURjamYCAqv3oQWSvbcB3724alyKJGwGkkIMcuGjRouTUzJT+mIahZ6ObBtp4YKsABf7473/YjN2tt91KOr1MYyQ3vW/a66f7D8wYRxAvfSg6sLpiy/GU2t2+8PPzBMsSdyxC0oRB51qXu773+/6VbBi+ShoTHnn0Ye094xNpHLr9bg8/feakLZBnzpw0B/4jP/p/Iv/d//0dMgWP1WY2nY9o/XF0tsplY72lV1Dh/I//5I/j+a/+2v8lHVonCvO+972/rzeequEeGdtTCNnk28SrBpYmsMk9JBJFIe2iGPS81RPeXOKpPAlAMVDZ2byIf0pcLEf23dh76603j45MSVeri9X33nMfnKTfoNc0stQD//YORpkMsvCuQTZdLBXEOCfImIvCOnGNVKklquSW+tE6jTAF1rf0uCEddh0PPHNz80tLcXckTdFCIFymEM92bRuG2EuINqjcrQctDUcemnXIjbz27T2gfz5La6+YPI9+x7Ebb1pYXpqdvzK3MG+oFvd8ebzVwUkd1/WdzbVV2V+4PMu2cg1btMAKg13CxiGT8Zn9XBnjLgOAw4xX2yN+G4CKXjDsxl85R1AHfkFM+Fz3J1aHGl+XCpWTf7QpORxXQve/4uU47hY/k1I4eO7UcUJjRmp2YU5ReSQF+gEvraqnVFbZ6ZLu8MAYUeBwKyicevjQSss+cnbRL7RS57DBIz8jRxQ27Jj52/Ewh+hKNxbQXK8eqyDx9KY7fiO/2czGIRoSk0KJCzirlc+cm6GJBt/k2+7AiJtTkUdFlZ+yWPUa1tSUD09dKeNLly7K78233Xpg/w2nTp2ZX7584eIZh4GxgRywI7Pjk9Mz04a43kRdcvHFmkXuy/AvLi8M7USdrXZgl+KB53Z7BGbKkixY97Jt89M+9bWPP/nYF37+l737vb+uXGUhNjpUUXZ3284JnkfYbrex0OH8l0O2A1ET9MSuAVsQzMKawIuZpsDcG1UDQs2kSlHWxGWINZWQNQYGADJ+dWdZdoIwjMjxDvYy+sng4bGnmz96VFtaV3gOu1v48E0WgfisPrZqxsq66/pa3MpivU2x6nI+99xp6RpKO2w0e2X+3NkLMoADrnPR9uLeQ48+QskpKuRU1FqsRltyWBGpx03xZkb36u5yh8L0Rr1vvmrvS+6j1efPnsOZRx56mK2lDZ0fHbYxjiSZQBPFvnx5hFA7r56CSq7hsXLsrT8VpYk0zzhq/9XXpNq8lHVgK8ZxUNkpq41VM5wG88uXZjXFK+trs11Lbh+CWdKyFiTiBRtrynAzdfKj3Cm17fYw1Zg/T7YoBUNO67N8ygZT4lKYO4PKp+I2dgH4FLFxV6iukUpUr0kboMyeefo4qq2zL67ODcajJHsdNHWqTm5ENLnhtvtKgirBoPjrU9da0XI7As/GXCWHA26iDbDMTsOQSLo9CaeCNJawBaMyrqjEZRwV4y2bjGC8roQKVXFAkNMmAZCjYkJetQb0y6tLqlnCRGilGw3Xejc93Nnt99KKvfg4YdLFMsatt9z5kvtfuroWSxokXic0Jb7HXZZE2V4yPeTZSxcvXT7nPLrDApAbXGkoug51weDTHhiSpNSRYeSGBu5ap5mf/8SDDz0I5oEPvk8og/7iAxiqZ+ZfqFkcMyoicfjEkqp0wMdnmgQjt2NUkQ5otfhwkHsOz0FZkDJhZLPT5J79miszOX0DlkvXdErhAc+gjR7qZYyOTBJxnU+4vbpKkagBBQBpQ4uKWz2CD6aLhNosqbNfPVhVmfODGlKywQdC9MAsV4gxMqS0jAdlYYNTKrDlxI6rz7oNU0XReCKbZlYrrV1Vb4EsOXzJS6I7bXbaqsHS8ry3h8x+SWJyMva6kIQL5y8RPGixHaNUEEW/VcwbDh8geA6NkQpVFlbbQDZ068ja+iLI2NYW9zPE4sp+tO9eHdntp8x0+Omun3rrZ72p60d/4bNe/xl4EsUAERtHmHKwq8scjjD8MzTCW0ZkrrI5jD+v86lQ9THt0ezEkmiAhGlQBEw2UC3PDJKSz4aYcoCUSZUxanFH2SjvvQf2Wzra3dma2bv/0oXpoYHeODuSr41o/OQmM6STnNjyhuHVpbiIA9eoDWNzqRKSRHVOBDGVVjli9BimAjRARXzrzRuUiEuinWVBnk+tMlBuJiOGboNBJH9umOJuDNPWWmCrujS1b5Aad+9Gew6DIfKVi5ecd6bAk2OmrG4nAd4rPnn6lO7W5OTQS8wnDxjmLYA1ELVplmjanWzO7vKlC5cvnZeIp/fg1zeZcfPbatehQ/E5NhY3BHCwqXukteOmPj3G2AEqFzYwuQ8RAINm1AbBUUTbBw8eTrePiJ4A2YvejsVSmYUQJ+GpbFJAk6Y4YnKIKhLrgT17Qg16BmEz2F9c1FGKcoE2tivv3Us9fNIW+gYbvaIehoulkKY5IAdMDZL4OAP82GNPkH4ERB2zs6O2WlyIncYoiRQHBrDOp2GIBTmxVP0GVJCoHsADuO3WOy5eOq8tza2ssZOcVivAwaHACYlYUY+MjkqXcRfxRz/60de+9rVqDUH33HmXFSaHELd3Vm2MX/Dajzlwq1m6if1DeyYnTbRZCJQp5QjJk08+iR5xzY1JSH5xUr9ddUO2pagnRcIHVod7V5di6LvlJp14jsTG3WGDvqHoT9105Aj79mO30KtQYBghaowC4LbiTvG4GTCpC3xj2OezPMuuT52m6zwjVm67a+ADbRqQJd8cnaai8CmwxhZRDHwXS2ho3rYd/ItjkxP2iSNJPU0TczdfPIDiccBhK7QRKxpbElOp8MAmfE/PkDnTXbIvoRoDd6aY0aOHzbPdgLfwQIvL6MkhYVzRFOtmaBPeWuaMBFFbhjuPAITS2rkUCFO71bXdOrB9dm6vjY1MRGNIqqzl2hQ5v+DWUw8BushCBb//wKELF65YrvTiqecFtP+u7D98eB9RUMxO3m4ubcwvXDl//qyW3EwTXZUKcYzVgdWYpPXpaQikyhdjyIc2KkF75QVCHexo2XKxB3AwuX3oD6Pm5xYAD6oj05gNxkkKqZEAFqLWvTs03GvuCVosde+th0RlvNqc0JmddfRQYPvTDhw4nEPQmASiovBLkbqKSElg9imK3KENVT4lES2TVr2/VxuIGFP3kOgDiSW/loIiv9vnjW0RRu29HjcyclArioaRkaPR015dvXThIkUypYY2NYv6g5LLvglhxpT+7u5+Uu7cMgwUT4q0Dgx9i97v5Stuw5M6mqWCKi2tLHf3mhKbx1hkKlH1HbYoOPsRlLKKAHJ5wTydbRXKnunY1MVojW+88U6U6AUYq+t+A5bWgf0TiW3NOCi6dV1XaWRpX23LG49r+vI0EjgMkh+Go0zusuShDELWKgSkmqDAArpTmduneRI48AAGYNha+Nnl4Nk4AkWHqaRf1FZI2CTDSndybMr4jwMesQ0InWUfHB5dW90ifvK/tbJcSBxiVwvp9wGL6keFkpNYQV7uWA4hzW0Vng0E0yRdmNmxCabFnCCgagQ+rg31qQOueOC2nzYOa3b32rhD8kRkol+SJnQ5R5QZBcIAqCD9Xg5IxkbtTBw2Z6GA4zn3nkEHknr6QruIoP6E7rStc+6mhQQkUdBkmYYRl5Ctr2xofy5fujQ2Yclkgge0Jtpt6+Ww6YUdffyoZ1qVIBo0QYbHHLaXEkdiZFshAD7FGW6oJDF9+EgwqjdGmOoIfOi2AtBts6HG3GboBWAqWH2aqBb18IddcBMNJsnbvrzpclk7TgaH+u6+y5z2srzoQ7kQw1aUqcn9tqzsmY4WT1w6RtOkS0nkXX/ZiQllKpRnBMUd3VGb648g+8KFS+SbAlNLq742Xeg2CxVFFa9MEWw+iRtVmKDjRop0ygEIhVZjrP33VJIMXrly2TGjrB8PqD4YALhhvgptkPChchwqGsMKo1ZaivOuEtjcXMHDGFzsxjV6VgRlwWptw0mlprzQozUmuVV8iDF3CDngmb17+nutC9qBu+HMq9LRnsuj7Dx76snuLR3MTfLYElTFVCMZp2iwWReVWAGF2jYjpZZu206ipaqsIsUhPAhwkA8jb4SCxacMtzyL6xOA2W4OSNTLOtIUTkoGZ9kjji6WrVyQBgb9SuJ8tZWuitVbq+yIoP8wMXTTgaMK/sajN01N77HxiL+zzjH94UYyy/tDwxevnN8/PR5XzAwqe0IWg9KkLbrfiNFkWqCN+/ZTf1QKuvXIl5+YoArKoqryBzz4JEoMH7RiSI6VNeQUKlzKKiXQRhoUJHBtGVknGooS0SGJ9cqYucKWaFUyiWx/Y0C4ODm2Z9vES1fv2vKcJe4Dh455E8DKx+PPPhmJbvdcubKgIEnn0txlwj3Q4/rE2MwgTfhlgZTbivl7H3mAjz4z7Y3NWpkChkpXikmfTlUcMcfmrU3XG4+ICMBU2dkzZ5546LG/8lf+yubiisV2wz/yavEccknsXF2/cmnWy6cze6fJn0rBDjciO7hp3mBgZXmL1E5MHehfW3MeY2OrRwNFRjWSxAD80EbXwcO9hopnz185ctOtff2u5lo6c/Z4b982pV1cunz+QkxJXrgY414CIIqGDm10Vbtn4+zs7EUaqLakZpTnYx/72OVLs2bpiwP790/Pzzs6Hts/tMlnzz6pHYbBJ4R0G5iWjRrQPZp5z0vutTh3/vIlFaX2X4MZNdSmTVabx26+c3xir1Z9ednjgY7R212xbt/AnTffyoHnVhKOP3uGaJOgS+tLxOvAwb0uA9XvMLGmG+UWK1OaIB95+IzrezbWd/oGo+9toGeUrqMuXyYvzp493dsXe6H745KWvOnKJOpavOqEqt6eCZRTmocffvTVr3710ZuOodBBqA9+8AOW4DQKbpQSa3hgUsFGF7oxIXEx5UMSow7uNAKAsU3cN/DlAyzipRxHJZ0y2sBsrWfLFnqS7VH8hjGVKSLRjCj5iI5aYlPXNC6WjIRMMo3umfTklC7WnpmZm265BeZKS8noAfpknEBy3GR40Cb7PXOzF7NDeFWlYM4VeMHAVlon3dbsS3jQsCQl1DMUnV256LSboQEABsICI0/lAFzGJwOmHGU3nyIC41l2hSppchZEdsdMBGmrmzQMcc+dOa/CdqzHJp3zl8+BpxLaGdwqzYVMXFJuhEbo4bAsrF+i9DQpla48qsPFpRhsnlSX/tOEhbU1A5DRoVH8N8C21//hRx+1WLp+dU3h6BhSS6UjipGg49UmfjlNtkFFM4299WzNj95x+93GbzE43Nn5/d//fWTY4RAVce6mktlSG4k6vQQGwWDYjCyLqz8puihs8FpI9VTpKto0s1Z6kBE05wtJtA4ecWHW2AJW4yAJKgTTExqov6rKQwl9EEsSmjuKDYzRN2YwRKfdIi5UUkdVJDc1JQiMm6j4S5eNKpgVlnT37BmnTourehyrGDIyavVrn30oGGJF99Ll827wc139zL69DqZtrlvnjAri/IWzmlmMVYhQOQrhNKH8wklX2TzRqVo0ZXDvvXcge3l51WylXrMMqou8d6s93rq6gmyCwY4+nWPnXN/7Xd/E/v91c8//gxn4hm/42mBg1llsKbPLKHulzqdsnhyMsudu/PlwE5qWZ4+2dGsp97gSNYNNu8rOnYo7JicnY2xny54V5kvnLnqwtrDpaJWh9srYNJVZ0OgGG9fH7Zat+oj0SIisV3JSZLjvvPsu4iUi0bnp2FHrFuZP7U5bX7Q1Qp27TUrMtZoiGB+bcnTi0cce8mm6uwiGhNhDjhhuCkBFiR29pYGE3jYHcqmvYI5NF0eTCJKMenOq5E9jiCqjA8YaKU8ADNpElBEOOklG1eBUS2Yh14hJjjLTSaIvRVnQoIpIjeWFEZEtClLBcGNg9AK3t2s2vrIACRoMeVDOAZ6BHJiENq1K1GYmlau60lzfZqjijhfazYMFMRumBCYmp8cnZyAf3tnw5tjQ+IhD2qoA9YIT9aZIdra3dKcR6Z4DRGqlpaLXPT4Bxqx1zNRYTHGuy2BhaHDSiqQJfHsoTToYvDoHZesnDIg0tD5x5nzXTTHgkke83R1IBf76v//t0YU2SRsCxsTKiYdBoGbktoSPW/a8DZberbYooNOAKeOrIAVFdP3zrNu4AeAOwzNeIUkALa0T7np+0/uCoUdvPRqFYI4hZ8XAGI0r0aXlGFsahNEP4mIHuW1zGOpVhYsXL+i7XLl8/urW+oiH6q6qm02umOsK6DhYYO1u0IJn5EhcjSdKirzobWQGO5aLKkMtG8WdeeT77d/279CsdLvi7Tmd8MAQJnsOsYs0pbB4WR1xGCpFDgYZTDnMKVjM85dLMk59X6WQyvjwgZs3xidwSc3vlovLlwzvDUy6FtajnZEaPS9IurH/4D49W0tsZjmcO8u7kFopVWGL65v06zCLSzGmDh7iWLExoLt37/79N996G+3Cc3t060526npg/2HXuxEyx2j1coccRnWGLc8Pki1aDblYZEuLp4yokBGd7gDMZI4aa2T27JksATAxgwlCXUVIduUCVTCElhpJ9SjiZXrhJncITV7YVgWJ0HzZaE1cSk6xodXpoPxSNMkkbujb5qZQbs0vfw0dTmZnOGZDpGX+GVr0cFMnmIEhya3LyBO90lIuiBeXD4cgbpnCajnFc8uB8KhVh0ZGHQSzBd40+OLCSs+AhZbeg4eOaJOzcHsM+/fOTFgHINVyqjKRBFJRbmvd6Nge0iu/sRCw3eWsIV2lB089+ZCNwNgSlUI+Uy5TMGjtbdU+/tyTsoNyNoagLVrg7/xn//AbvvlfRkcyhK71n+T5YFBTxc/ByBzPf/pP/+G3fuu/5pDJEk3JlAN2PKqcS0BHLDmC8jCGkILgcWnYd37nt/7wj/6MI6kTe2wpnxib8IrnsHMYMNjvAyb4aMAmNxtepvIW4ZpumzW7hbl5E/eKQbmhz6KZ9kbRWgyxHKrsbeW2BT2JVVvGOsbmtlzEdM7osDqPEIqHeGM8GhwLPKEcbeOzDA+j//Lmg3K2Twomsz4ZDp7sMnwAFBifCmKrd/jLVNmNoyDFMIpWsRjPEkj4l1fmDdjHhqxVxGqhC7GVopZENUSMAXDYeyQ5/vRBDUDmzH5kUMwGSciYn7h0LcXMjU9KuGdyqnqqD378E/fc/ZL9M7FEKUkt8OLSitsZTQJ5hlNBaWCVuzbE1LctEAaf0qJ+vAiiEjFARY8lEBiomeLgUIIMh+GqaSr+PhHogKd6hb9lvtI9zSaZMdhmaMjmxjINISFSkYRaSUSksqux1TcWpI6QWX112QRmfhiTUSIidZVrOoalqbHBLipKT4SiGRheIUmUYIstTQsLtvQB5gbDppzQcmj2+XPLqSggpYgYd3cgY2xiEir3uqnmjA41zqY8qLkBy5Gjx2TTdRwwm1k5etPNIBV3TjLb92pf5Ppjjz0+ObWXitoAp8T1ArxITLIkd/PNt7ryTX2hNAE7t1TVtO60Nr86JjKFQtwjvTUGDvkLkSphze6ee9wA8SzDXQZkOqKWwqkyfIBJnpFPbqFKReZt1WnF7LPch/mj417gcnfRsaOOgb3qda/BFK0ZeIYQ4KAk5LJqhAb/Rx79oFCF5JojDjBOq1dyRsGmPPnY/6r1gFzVhYnI4GkeaCsq03ij1dfu1ZjKbzfOukzqM2pgCBoSLwpQjkq3Sb2y0HyqonAPNjpWnpFQ2zTR44LAnCoMxnbctAgALFseE/OmRoJYEPHsEVjV6533lNvSEuSOPVpjnpiyp69vbWMF4NrGcneMzrrHJmLDMIZveQnNio6+s01mOVWGusAfb3AG/4k1G2dKHJWCrgMZ5DDnsGgn/vqWKgzTnOM9fAh7vekTwG7GtLBBuK2jkh5lWlxVkSo4ySEAkfSKhhjCUTwTToSPP/eO93RD2rrlRWbN99DDqGiyE6gcudGAtonx6X37Yvu6IqYtSnB83LVn29PT4zz5iIJpCKCWer+EW6Z8oo2hbPCgX6JUBVr85GYjFW2mc2H2KRYDJ+JlAU/kiw1DiS5soluLIifggfm0x86T8f6QSqM21jfdcaiYHOc8eOCIAbAe6TPPPmVa9cbDN6qSHFEZ7Bux5mcGAY1wDA64lTGu6VpeWn/iiafuuntI/39oakQnQ89yctJ2vh7Z0UC5uNYhHOnKshE1G3knT57W7LsjEQElPFoplxCkAmc/D3l/42v/yk/89M8tzC9+6Rd/HjWjH2//td88derc3/s7f/UnfuoXTYsbyX/DN3z9P//n3wPL53zOG48duwkj/vN//kV5/sqv/BKNrS7Bz//827UMX/qln0ePfud3PvreD3xA8t/2T/7RcydPeQLQRST333unbuH6VnTFna6KHa42nETPNmfOthx6sTFPB3rH43Hqae2GOtjYI5daQcXOJ0UlOVJinBE1qLuzHXM2Y7axoVQIrrV5/pKwV9nyNxpK1MzlmpqWUujUVowV3VSlHqWQMtUY+WJ8Amw8OcoT5mi6s4EtH3ZQlvekFhif8mw54l7BVvQG4fd+70827v8ZDpKHITCTRbaO5cpSyG5U3ts7Nk3PX57TP9aLXtyYt+BkBuXcqUvkj5KQXfIEQwxDevoXFuYw2yw3PDjP06qsOmdqyhHluLRAO6NQxAIg0XPnnvGZngOmrxIVpVufGI9JIKpCfIXSeb0DKSq10sPSIgVHT6iidUNlJwmU8KSEhEFc9YJSoMnSMhdF3FUcslY5LRUFKZRbXMvmug9647oSgGm1AQXVNWeuHpEW1UKAIGlJaH1tqfgmFxJCAwfaDu498uijD88vza9urA8MDh84eNgZY49GDg6MrUXPfM74ZfbynH0BdsublH7yiWcQoE9pKuHee++XVqtq23b2yPucm4ismhqpKhqqUUqLkZIjqvHa5vbqfffdnZX71a7TFjiiH4dMO+GrBdbX6v7Lf/HLf+lX3ml/5ld82Rc+8MCHnnnunNL6a3/1q77zu37wIx998O67brUR9567b/vEJx5JNvWdPHnm7W//9U/5lE/6wi98m5x/5CMf/9jHHnzlK1/2trd9lk7CO97xbmODr/3av+QyGLx2fMxB+q7BuPtrYXn1yvJlreTU2Miy5wVomCWanNHRBq0tLStR8/7Y7XJ/3CyzuhgbCeIutVjH6DfdovjZm2vLPDRvfV7x3dmj/Bgcmdk7A15WiU6Uyna3q8PRqaYnZBpi8qeeM44YNBnBDLXWlrCGkUeGQ387PVpWecKs9k2QlnpzF50lwQVdABVlZ+vaDo8K/cZv/Gsc7h2odjioCv2PTTVKzlE4ETOhqHHpDGkDaW8iWecGIwoY0slIP6sVHTn5jT2SkJsLJhYcRRXp4WAw5PzpM2PebhkZOXzjEdgItNkCmq1R1AHUcxaEwzRT66csTCVYT5wcm/AJ/vANh+ieuxNJJ6oAoMqIFIdpHfxWdPJwfIw7EE/TDA0A23iol04kxIK8lXTsf1iLYfZQtEvShYcP4hUTeaB1utOyeccdd8iFyWfzXuojZNM9c0LgDIylRQdExMMa7rJNKeGMXZZ4JUW0AZMKYnDJhVXQgpdfUsCBMADe+cA3/C8mVPPO/+DeG0nXE0/r9RrC6pnPG0Q4Cj43G/fpWcFdmF+yrO3yHc9WET/DRVyUqEZYhtSWkDzz9LPTe6c1TvIip2aEJFrrGlp6nLR7x0oV8hSyHWVZvl3WqJHXlKah4vp6joF5ffmXfMFHPvLgU48f9zjWnXfcHldM5EhVpesg48c+8rG/+Be//D3vft/LX3bPB9//OwOxD3b30QcfdwDnwY898vmf/1YS9oM//jMSfuLkqS/4ws/+r+98z+vf8ll7p/e4mOTWe++VMQPqC+743t6++fC+Z8+fx+K1lZ3bD3YNdBv7O5Xp/cRlBXDhwjmTdQrDwFUTQTNtiM8GY9tVJripJOQqsnF1a2Vhfm1pcXJ8zF4VOcQXnaHx0YPcUjT2jZbDgv6AhZcYn5D4mek9bjlw+dnG5sbSsmHGFpw9rk7Z7PVmmCKcnp5wqs/pJRWcvmew1fG3VAZNbhnsUvkZpSsb+IunPMkHMxIPGIfhFp3NDcZ0VHqHNlI2PtAydUVRBRX+sl0RUHHBIBLx/ANVV2gmYxmuuiQWs9XEzkmsxMItLRMvl5KkJC0P73h2QvfFxqyJuKeWxEfDtbty9tJzM9N7t09v2jakSjD2HBu2e2nACXVp0QpjM2Nba0iW4YcGY9/IhbOX4Dz+9Alt5i3HbiOpsTnISKzPZauOy19WQEj1ZhUAbQuZSxU6IJaOJ5UzKQiGmqkIKAz1kDtCPL84Nzw6RDdWT61QuSFXl/WP3nzrsdMnnqOllj9N57qkhj67a+buu+4w5l48Ed1LWUYt/aD8IlbLjFR1ikTlQrH6dAsoLp69ZEF4TFOEvOn9ocOoB0BmkIQtFFWsGG/3DmhFXHP1uW97FSJtUqBseHjx8uWpmenxC5NnztD//ssXlh/vOunKIbvQnHCY2TNtO8XB/YcRdvK5E6IM2QWvWvTkmT7M4sLqelz8Qm4uXj6hZLEC2fbwM8U6U9AIYIBFMacg6W7aqQOmaKigwSGs34jmBcddEWVRSXAODnt+5Ed+5vyF8zjrHTd5MyoRJ/eET585f24rZ30WVxeJb/9wLI4h5TNe/9qx8XHtnlL5ks9548LK+pWl5f17xg2i4NFdNc0Ile6r9kB55x763aefeCJL+SL2qaGdGlrbjDpJwxGZsE9yMK/W6Bs0yyKH8gCbECqKWgjV9zzVrEoR10inUIQxagm8w6CazCAcRMFUrVgg0ay8xQUDcv/Bg0JPnT1HMR3FdNSfjppyNBAAwNDHwoxjNku4S4BDBzvVipPB8Zg+KU3DMfDFaz4m/NmoCrgICt1m3DPI5im0MT4H8n6PBgMYNPikrG3gGOXygSr0NG+oDoDaghLeAS8eMHUaGwZlzYFL8k6FJuNw78Kdd96t3XDWl0CTYEdeZRc3jISVjtIADJP9mPgG3qSDiymOP/eMUpiY3EMBjIFB6t/SAY2bJBQhJanCUmsoX0mbf+ZTGQGjRPjT8Gi6r8ZclESduIC2GlX6M2MhuLV2uqqYEINIYMOuxs81WyyVHUlDiIHmMrLajL1lfIx/Lc+ISFcMKg0DTYi4edcYG0uNXVfml+knMrQfTixp2CWBb719g/v3bR8+pA8v095IDIFUTQRLd0xxHZE7ZT05EbvBTCxevnJWqLiVO3a515ZtWc8zrZpLS+g6pLl+NrM3ZrZCTHPSDnMIJB8ISh7YjOTKFDY+lU22iD6jOOH91//2h/723/zfXv+Zn/bBD/zO008fv+POW9xReu+9d77uNa/6vh/4UXT93od//3M/900PP/K4LSxUQqJvfuub3Cv+spfe6wF1PcrXvvrTZhdcUDKytLo2MTr88NPPmT7RPLn9DANI3fxiTMnYoE0FT585NzU0uHPswC//yi8YyU7tmVDDaXdXFLxpepP+UISyxs11cmbFZmnV1oM1hYdgWSUH2BeUdEWnkT8flStNpp8kgCc3T58aCp9qFoJ4efaSAiMT/FUBIkrH51NPPCm6rhrkdhSfPXNB10XQvhkTzjEfq5NtEGKCAwF88JqjbI4ynZ/c9VmOuKoyDb7nb0uOB/oHyx9zGng+Rkflw1OUSC1+Wq06majt2RyKj+21lsCTa4GhtIo9/OMGPG22zAoEJkeKw6dw01RU68Ybj9opcezoLYRYWhgHBs6Kgsli4Z6TCdLnaRjp1N4jjzxCbe66666h4VEqjc94Kwn6z9+g1EmM6sRisrQAYHUmdBQzKTkkIC0CC1XIuuhioY1iAOCPGO75uVkESJe60vCiTWVx9sL53O+d8yYx8xgKo1a3Yoha3ymlMSoJNZuc9DAHPJa7LMreccc97uIhJPAPHY7BAj6YXaIdGGlZXXXgLRD5pZzGAjCoDWUHeZUXe8L1nCW3uOQqu8t2DDqmhkg4GdxDgOiJYcy2cavM1j18QqWLTBR39L2iem2pqLjcGEi00VllysEAYyuQQpsw0QuDTZRQYEbmf+iHf/KbvvHrz5w5/6u/9ptf8eVf8LrXf7qY/+knf9bcBoY+9MjjX/5lX/je//NHXvdZn6mQRAGgXwX/yfOORHUf2T+zZ3zYRuPjZy4c3LvnZbff7ECU+srJOGKu3VXAiuTs7NLBybGRW4899sTjhqTO6Ogr2a7psjeDLMVTV4bbS+gwh+6iumO5esjmtXKaVMHIP5IqY+49Ufzkw6eSwwgACsadDOAz5zHmASB12ayVQ2DYgZuCGJ+f9EmfRIID3hrDsAk8e57COPiq2HK8CYlxbLALGAaGq8PA7wsZHAzmMk04t6AKpcwSDRtUvtoOLGFLh8MezJZZrMxClGjVwbLOpwx5K5xs2zciORMKtm/H5Her4N1pGO8LZQts7Zzglo6trsSOAn1dLY9ZWLOmhqaoslt0fmFu3JreuENO1JXUblEta3xUCCsoJOZTYw4t4eKpMxwYrlqEkE7iqrKenb2iOOgGuac/aKN1ukvkWxHIjo66HGmxxYphcz7/p5gqCbEouYSOHL7BGNh4e2x80qTRXJ4ENrspRdQqsuBkb6/UJaHod3f6Y9Nqb7zOARsHT1Wz9RBi098z4IbA4f6R6SkLxcG8c+fOw5A6322+va7jQJIHaGUkxhpr0Ri45UQFJHfcMZpdd7DRCaRYtIv99rtxH620pKj7RkmlJV2fgSiXS2Ljj2o3ty27XsfhMQQrRzSU7ZOBI0ozK2WfHaEBSTCICoLZ5Q4F/rv/4J/pFOkp/ONv+hewCfiu7/73TlGID3R8ykMVMwbGC0vLb3jzG90xBuCxk2eEKjlZkjzSz5w+rWxgU/SE7cylqB5Ep1wy+fBzargY3Lt5gMSoCLu21n7xV96+b+80RqFHvYQGefZKhKvytzRAa1Rat9NpqjgHLwnpwqnU2RKSScYgHZvwjI8gBotRQux44qPCQwYf/owxm1hoBt8wgsOFRnyUurrDPe1d3eZyArGac2PrytLqisGqqiN28ONd74DkOVCCqsZEUEt/g9FFZ4UaTHNELmzsjgLAHwAGdbkilED8Q69zXG34XxELT1PGlDDL3Yg6TkrlAkJww84YMEba+jIKMQgLLnkffsNzRNWFJoJ28+AJUaCcZEVEPBfRafIrs7E92AXJPuVcTYbfiCGvmpp9eyd1SxSiLFDL4q3SB0NNLH5Ioro84toWduJEaEUBc1BCidIHSzSlxkpKQZgKRg/1c4dVVN+5WA1SEgjTtltV4QlGjlQBNJbqojO324YwSEIRSxS7RBkciEE18kidiGKVGcvHlvXHL43M2Tqqv28cpwKa3jNe+VUlwSC/IsrIM88+KzpURJydUzPRPMiycfjK6uKGSyH7eghMtALdcc1V8QSplTrCYDONFaWie7lq0nk9Znbi8v9eBxMQJqeNLTnGmVCe5e+ziC9HkcfN0diRSXuwayO/rVhQx8EAe1wOenB8xmg+Zt73zcxMjp44e8mGso3F0FKUQU2BGW6MM4OuUeOOyDnpYuY3VGXLOOoS1dVL4RDX1mWPsk3tmYYhen67XboUViSRRVDW12I10+hLvRXPcOfVVnx8YzRTWcImxYZaB3coJ8HCd6VOCIgLLqs4hEpOXJhFxBSfyqwYzY2tgBGvGAzPCJYBj0EIJERELgDMz12RojU6/kZYyTpIlsWCtoxcN4pnvQPmFxpI0GNaESr5w5jIptw40tOa0MI71QWpiOllHR85kouShnSHPyEWkbYQJu2qHPhTY8buFeaqN6lDkx1BCLKZvAScjnGWzoSURwdSL7rL6uI999xDT3i6MgIf7JxxhS0fk0DaYTMv+jLEwDZN52D5mwdGDL4RDEwz4kaPwuWDVBj0P6mlrHIrJgxXOlUK6u7pPXvIjMbcaFMU93irVqoBx38MV4g4rwQVK4d6iXr39kdPXn6m98YCErc1VTSjREIckdOsjFQ7PAHYXyq/eCtpaJfm5s3JodCOISJn5dKq7uGDh+bmLyADYyUnFnjUcoxNjKETTmd1JaEFFtenINXv8Ej/9MwBZDOYWdv4SjLZJE2PhhVFkFv90OBdleifmXzMS2CcoYCtFLVKquwosNRqoSVd7MTZ+uSP2iY0FBh9jqlY47Uj6uDhA0pFTTk1PQmRhJ3SeO7M6efORDTGA9qFQk5c/kL5sUnRjQ7Eiwc2RWKfeHOq9Lw54bmnjit1AqcwcLt0TFdP34K2QWjVy9NSl1bW81pyQmylqN8isCA9jOXNedx3q6QbHJSTsqwCRpsyljEKDJ6glI9YwAxlsUrBqDjkX5+NxCgYRtbQg7aqAlCLfj6nz3mlat+RozdRDJPhl2YvQQtnXSAWe5Nj8SnOYMi+e87qzjCeTGQ57gfgDF4DaGyOKgYOBtM0QTKkQA3sRdUkJoB+DR2rlhmSmIMJdFlhqDv8eZTbp8N38ETJbEfDaCS2vGJL6apnFmUEL3o3I0cOt0gL/X0DUdh6N2yfmClfWUmNAuOmt8542YgP3ikZ9Ql5qHrSuNRWIYtA+OnCxHvuuUv1QZxUINooHVLV8tyCe+Hso3FZVLer9nS/ke1g9PLCMrYgldzjOXjJ2YpMXQkY5nOjRy2A4UrKJ8hSNggpv1DGZioIq3yprkYFHrkY8Fpl6i2ysYWnuMaezhPwqQ6X1OVFxvkc3m91KnhCWNQp9oCwoV1di2vrMsvRNmAIvYVofim6DCihgY5G3nTTYckJ9Slf2R0sjejPy7RiAJz0htzCxi4xWJ43wIx7YREJP+2FHKSC8lnlC5Ipd7Yy8Sk0fjoa4Qa4HFLhiHJVBx+56YhCGvW6hOtkA3FIv2Amks+086tb6yaKPPAf6Os3dY7v9MoeCtxxO5e751XAS3ayptk7PqWXOzkRa3HmjGzaoMVODu1sx4M0MYbpinn8obgQLDbH2zyrZ0hE/BFTUidI/3rP4LgUEY06CaGhPj1zjnc+8dfAiadktR4OypiaIjqVBVEQGWOz+SuQKDn+5AArRaTe+/PCcRquN0jIdMGkbgPjyEB0F2kXEYGkup3j43vWVvUegzmwbfd1m7u2mU6dkxuug1VNAcRHXETezweS2De37kynhUevc4+YYhKK/oQKB5JAGkPADD8fn0KJIh+vbenCGLX29Y3tuHVyfDxmUzaI4SUM3DRzuDmgU+LNwxCpuNEreAUnm+Tr83KrQVwTa+eDVVmfzrKbHzLOVCeqQDlsJDQPLL87A/HeF1SSxkzlHnnJ4+x4JTtEPA/rjaklJSFHdFUO7VWyWotyLa1c6EJDApUcEg8AIvrkkIqCc2meiDD4hCSVJF6Nom8KVFEKgo1dDfjK0lU3yBIhhcWzhIdjfCoaHg5xIYFNukIfeeRhraUJKkH6WbKjEteKDAztXrx0ETHEALBtuQAmpyYHhuL2X5RoPABrbKAFoL+jrG145yYRWGtXkcKRRwAo5M9mqk6xvhSxnODUFBKRbC91tVTjEipIDqYtBlHjlH+nTaA6YEJOUCXRUOA3fM4buECHBKhyM/9EJAQtZ7AwAlgStLXbF91UwO6B6B4YnRqNlf1Hn3r2/JkTGK2Gdjk99aASvQaTrkJeuoz7bnW2529yz0GlftGtbJcvKC14RsZjkbp3qMc+R2zuHx3UGUMAevBOi8shY2yXxcHvJS1u1bO4HCCv7m7oZnNjzsLsAsJEPLD3wMjQghzWvWowyIhtG4vzW/2W0lP5FbAmFwxtdzIbhuKg0Lh02HBiZ3d8eFL5eHYp+qZxGVRrJtmRIF16vgrQvIQlkLV8byrixrmz3qF49iEv+YgLBIw8LM9Gl3tt2cXUPXffdY9+l6RlVpstF3Ghh/TyhUeUKJeiJ/MevUR977Q12NGsacKdwwfTPzAxnW/VDQzS5OXV3tXdnuXu/rWRKYeX1lxP2V3Lz3mzl3LZWt9c2tQID9ise/7cRVqHq9bDzd/gBgXuH9xQNV25XLdGTVBE27NQayWFiNtbTQzImsvfpJ637o0f2H/QnuRzZy9S+0F39Lnlonvw0uw5u4LBPPPcCXdlGJlpd+x3X16cdw3m3n2xSqxfrHNOIUOxlbBRaY5d5VTGy6i7Rka9bB6NKvKSWjX7+Y3V6I8wwRq31w1ZgIhGYu7KZaykM3omREudhbs45jTRxQtnSDhTPk6jWKhcWvJ+Tez3JFFRZGmQPdg/JpZ4DmCTMh0asTS/tgEazBaGBIjiC7icEyEA5cnmtgIwn2++hWfcqBZTFgFp31FWzTgJqjOWoVVmijRG3S0j0EvCphu2z/Bs75MVVJoJKJqXSjsSNtqzi9lreqNRh1VLlduf+mzdNL2kjbQS/9wJj0ScVADa4ziPvLZOV28+enT+yqx5SyMtywwLS3ETH+5bGMBQbaDKHoNUw8Em/bD2BDI80jp86CblIUWfKKaNxlRS2ZdtKRbHw6qubqcT/uszeUtmMwpJLGXA5r4yH/v+tNEqBWPEAGs1Yr2woUH1IYlcVFhEAGUmHDL+hxg8+UNCmyB51KczPUnUXKNDFFUH8QxVd19tLbjp6FEM0Tqpv0mLw/ji1syWJBikRtej3Sznp/mk9uRYFlJBYiDDDYOtgpoxubDx3ozo1lVNzY4J4O316J7EfsnsN+2G+kfH0rbTkS6jntjDiLBYONmJrdFLK6binU2PmtysMxHRTNmTZ3ICb0WsRGHTAmG1uk8sjVv2/w0uluFXdio7HABGitiEn5aKPjO9Dx5IPEOn8+l65AP7D/HZ9h5NIhcdDwkMW8GZ51ZlcLPlVCUiOfbV4ShTApPAZmDmW5qZg/+YzlNn5zgCmIiuh2BLQnFLjqmM2D3CpyoOdAJmM4iH3qc8coSd9yLadJQ+QgKyDRD7f+uz8a/Pxo7g1KxyIACeMuVTRanq4ll5QTAwmUW2AiriAbt9hG3lDWQq8GaodWatNfGDCPzCRAyCFwoAUChpKmepneh7qEKQGk5iUI8P9d1w7Ca8mL14QfndfOMRUc6fOW2/EKkiJbrowbbs1Wgr1P3A4FQACFW6hkOi2FEgOQxVTphIz7lNnNieixhUZcFEdQMVSH5Sr9LlI6FSfkyHrfgLP0hKq6I9ceqkwY/qXygDOYQ+K4/lCb4cjX2dz3WfDRgHpmGClYXsZcWQBzCt3Fy9wp/RcwODgZJmSBM2opye6CRHRV0yFA1E9Fej8Y+bjwpPrLglwmh+yySMUa7zorBhXZT30vLs9k6/kyNrKwtdC66zm0CboOhdxVt4boEwkjRK2qWc9MUOBx1L3S7Vq2M0NVDk+fKXv8JuYS9CzOybxtjaI1OqhecKSFESI020vNA4JOGzI4HL63ESUKhb46g3hDpl4N0xo1Jm1F9K3zhCkJGUN9uwRRRuDkwodjkujypumCUEA3Eyh7y9tQqmRKLUm5uPHi+G5JlOLIqxHqManRg7BAPO5GdUQ8U3s0rlJgZlCo8L6GFr6bChaxoVkYqNEyX42cIQGu60WcDz7LQThtUy4IVWLNwryHZgRGS08nyQmX1inWI1VEBSEDbahGICW67ZocDeuIRUNhgHAgTjIIGuUQRxP/7McYpU9fS586cpiQKIBRaXA4xHdRi8dhek67K2r9q5uEFeN2J2d2Z6yvHtXELQHHrn2ugrZsnJimLzmYdOYuuFZTM+HGhQhBgtdaY0EyrTUTyZyGXea8etNrHHiQNYiQviFYMytoxZdCKND38Y7LaN7myWtISqLEXnlpcyxd/GfZ0ud4a2Y7TKrD7hhE0x5VJO7PLW7xFkOWFkfAIltrJ57xITEGbsaowCXhuw3b9tk7drodAllbj9pifWiKlxaq8ZNaoLEfAQPgZarGBzO+vBP7W3Levri05Bo4MCe0YGmKVJ6eIVm0ybkqBCeBjjnbySEucdr7EgrHct6Pbb76RQJp91rFybqgMrIRmUqIsXQwZydkBpUl0TDoIY16PCf2honzP9JpkVw+EDh0XRQmzsboyNjJEob2c7Vzh7edYuXQSoGpxmZhT03j3THFUoklPfCSWQZEPBwVzGJXKYyb+CeALGAdtF0RC4chTjhbnCFhfxtw1g4xp2ZMQmjTSQM3CWv+6F0JpDLjWOT+y3YJ2GO/jO8FZK2a0tGCGNQ/gLP/mYyZTHMmCKBraxMs9kZCyMwVNBdJc75EGnJufDLQ0FmG8lWkqrSTSgVXIqTq/jqDgVkiCemAgdc/PRmyIZLWFedKzJDoHNJZnqFe/fu1cxOLILs+i2KdcMhJKAWffVWItqSULqVBS5MXLON8ewj6iVPCkwFCtdVOl+i85f51PLzB89c7HXj17ERZNI0JFGXjxU52xDd9fNt94Cp1hsaKVCYdgKDk5ucSXBcCtjORIdzWU63X+QTxv2eb+Ukxzo3SMyWwAVWulb70LsSFm3td0upQvnztLeXEYLyUNhTgnb7ut4YHStY6NzbbNRT0ZTHI0bnJHlLNfGzZ8Pg585mxKnhfSMdJLJqZ0F6DOCYuuAALYgLteiY6zrIxBJ95QLHVEQTzz+1Ctf+Uqrmio7s1lBSczxbu6ZmcI/+H0aiKt5sZ2bIwdHnoaYJDCqC/5Kx+46QTrY+snkx5wiG2fmrii3ecmRjWirbSPOm3RsrqWKCuvylYslbKGDAwNKsPhb2axSU1gbm4tBSVTiRkAxHUgwlKy+Mz4oU1N9AEK30jhZLm7oaBrZZwC4hJh/GT4cGUJfoo2lumlHSOHh8FFu0RuRKU+fjaNgGsjmswBkLaOHipYBwAcXEUgeTDQiho886jqYVeGQNaeRYsd1dqEjs1xetaJOWi0lytBYDJqcHLXn9MqVC9xgsMZEHb44coZZBz3P2R+DujNnTwGoYnBakdubEIrQRc2kxGzV8ropkFiztYZuMiMoMITt6vWpIN2UXyTqJsnSTn9wBxKky4YSZaNbFaDLzcHIG8wFIy5IBHOgjSigTShPg/AsqVZPWxZEhFAxJ3c2CEQx0adcc4MpA1vb+eI+DQBqG8hy47vQakVpnpMmFqJQIsuOVRzcd+Tgvr3xcuypk1sbcZkLWJqOBjSXsaGIw5xZLMfELbXqnRC1bAfs3kB4aHIlJ/VMTvcSo6Lu0P+SR7qxuDSLVbveRopblEKBFRMuMdGirctyn460/pHEDXCoAJyE4OGHH3ZlHB1+6KFHRDFZrcPv4JciMGkLmCwoRycyFAdPWab5QU+caDUIjyXcxx59WAd+7sp8T9ep82cvSN2WFYTt37fXkRIZ50MO3Ndw8cJ5NKxtmEkJxZMduVCIDIc3/jggxCLJaRsYk06u0QtGZNcpeJEFYfAIMzCo8BUbVYyQcJiF4ICkPqWexvMu6222R1EWKnZdZpgwibz9Cme2twGJTkVCUKqSCEVPw7vtjN/msygsmz95QwkxZkdy2b1n4yQbH2SkMsshO+vLi8DQL+5ito5usxY3FPjJx2NTGxNyo/wpw9Dg3GwMd0dH1LJD5NsODitvzjx4fdjmz6eefEIaNqMeOnBQr1iV2etYrTt/h0fhcV3Gpcuzzqp5Kna6N5aLYKBd1FgVqx0WF02oYRSq+hjRahAE+VSjcxuMaauRpPyEmvBXio6i+FRCUEGoptD11vGDFqT92+sL8SyNT61cHtaB0nRMdC9lzVUcgvAOAdiBbLG4qT1KAATMH1AALxpanp227GfuYr46zheQcuPSQSOCsRsOHfaKE5m1vUj2+3qGtRI5/0wgoibOWstq74aNuERDNnmmkJCSdhbyBvn0D60OzpTc99hGNmSDJJGt5w0UvxtvvV2JEgcz2OpgtDFrLgLsV+U51xE1vTO2UGmH7Qq0fqTt/cQnHnJ33H333WvrxYkTx63cnj1z7tDBw3QSvCEu7VPh9/YM6Vfjp1zboqg6rjkn5Hnh2g0LSnB6z14V/c033wJMKgvzV5SIWyiJAf4HH3JbyMTUKLXVjigIZSbv6LSpaWV1QenM7HXjVxwAhlkoI+dgGBwobpTthmw+9gTJb1z7luqRTWnoM8OHXcBgXMGezE+FzKJPKKrfVslS3XYLrF4tNU9JCTckYdcsVn50ipDV/gjO1p6d4fFZhBX94DnwAeU3Hj7qswDwZ31t3V40Mm9rhCj4DIPt14HH/KJIHCpjtlgZkS3JncM3RBMKaTSe22MqhouXzp6/cHpmIjqxWGn5UQJuPCKaVGtZjy0bTIvDDgH4w72FRTNScTMDhVRgmsoorpzM5Ka38OAXsuCXnE6yylitr6tMOUEiDGRUS7nPQ6GCQQDplFtxI+k8ngJJlGcu3Kt6pAjAZ3Gz4R1pqBRhhk0o02gvz04jqMXy9PXZGcodAFkqnfgDYRJmuGRjqcUVl07tnY6NxJhm87Y7NbWNRISQmKQVN6O3Shp5kUq3Xm5r1QpCOxqNW+WIGCZwgrQLXkb2TE/QrtneWfcxGJFlaV5Pr+jmuaJL3e3d6Z6+ZQdKTflYN4pdDZIVaHeYttenvcqotscDc6z0jozqQtvP2O1a+aXFdffsOP0p3bmFuIXDUpN2vVp4AqPs7GAzpOJQhTn5oDlRKPB07YZQKVO0WChUaoSZI+5F0h8e6h/rjymrMiCJUpCd9S9JkaVskIa27blNNVChMIgstthQUypK2suhKRZLbzPynSUIG+Ay4rbAsjYEw79VBAXfKvRW0edxuhbzn8fftnIWhiaocUAb0RI/W6LySP6xhaMBU9mVfFZFVrGE2oeJ7Ea8CwPiQ0MMzHEKE/R+RFBrmhB2fHu9N8Ykl+YuSWZyaHJgLAYk3lFTe1Oh6cF90rhwMeZUNYZQjw4MFiuNQ5UleY0BDESePzXEM/++dpXSuhYE9TRQROSyA9v0tKSpousXfRoK2gtwOZ5aNKwdnJk+SIKRIZbciu4YiIZXw24jCU8dU5mEit7y1MOuHe2igM/iD03Dw3V7OzUfuTNGvzbqzqg+1ZONckZ5B1vCKMto5RiRVd3la8ZFToHxBxpBaTjcm22LI7CZvSH9uqa4RB+WF71Ztqk+8ATZwvrG8Wee8+kdrd6puA+Zf+SO/PbkGMGdFS6UdVDaWQdqpWq2amC8ZttJLCDb9RTfMsGOpx2iM9q9cGWRhI8MjuWjsrs2mW9trJbCmtZBknvhCUfvYJ/Bosnc8alRCjS0ujY4tGprodNZBhkWVHUQZGr/vhmFdvzZZxXZbbfe6jGq3/vQb1NO1NYCmHIxKettXPdOyKM9w/YbRio5Jq+rwD0Zc+nKxfGpkedOPa0gCMnKsk3IYXrd2dTb7YoyxSfvDE8w7E5+xkpnjrlKdgUZkbjHOWaN0hTnyy31rZwx5gDJRF2VXasop/Bstb3tUMIfvlFPZw9ImTL6ktpflWDmhY5EWjXvNR47fHIGLN54C9KiGKzmZyriRjJM2+H4eaIMVMbl1DUVVj6rmY01Mwt/hJb0xr63wRA/BoU5oI5hcAipgYVNOSmA6nApWFrXWoUCB2h3t3LSVqgaSZvJQ7ef8SemYYysvElju9LBgyuxmT40jX5GOtkIUBsaSPF8whDFmYu6mC42eO2eRlUof00xpit+jFBagtTTSlHOqD2dt8dAt0CfQtXOn0hAMjE+AptMmllhJGH0heDtnZjWLnrwQnZEgcc7UNKVEEi8Y6SVdqtNBlkGWNsZv4js/BQKP1vckiGhEkItDsisIGJXIiguYAflNGKAsUUrhC14a0cwdbPX3v2Lc5dVW26KU32d23fgoIyoNJE1Pz9nSkVtCH7Vozh54JsGxoRM1CAKNQoLAYIYOWL75ImrjjfxCRpySw5KIi+ZncoUJAUMHiSA+BwM2yuneMWhByQvOG9GCpjyUiLYKxR5bLTt379H9ODt1s7xT3xcLPiTt6GBqafesIwqr5IQmvSC6cIZccukZysXIGFgOERkCm2LyCxKPj6lK9T5/rDbJiJUlK5omUE2djk6Z4n5lCdbisWcisIHyvTXToTsc2OhXClxBJudZccnyewNatGjZndjSsUtivj4ZGbyFRgslRDAamPIjzM1EZHJJSrC5TRP73Cv84kg8UfxIqyQwOlVi2KINQU9O+4TJ08rnVBg0qOEyGIhLJoUm+pWQaKVpAK1bQi60fFRyXPAjiww8kNS6UmprkYbHv60iOxqeHGBDxixxIUfTs1UCQo3GiShRYUE86t0ZQMzsZeC9w+M2Zp5Nm8wl+4NrtXNxwFtxdRiQQsnfshW5Fkx5/R1MKdj0sKnhHpMTyTx3GXIOAzVAIve9m5pssuWIUG26EILgJvCoAHruDEHBlkm9EdvugmGIknNxBFZc3R+fO/WbrtO2d6KF+UHHb5deeLph06dHvVO7NGjx2684SaPPNkRY8iQh5+GtAH9vTaFaWOjjtCQ5n6HKF1/VS3TPhJkolg3tbb4mSuQqKTNyTsZjB7MZCsp9POXXdUcyvlobTB8y96+zKPOl+wwPhWcUhNFOVod4IkVYoRcu2o8BWZqz1jxRBJlKhXjf5/cIetp0B9BNpFn1SO0WF3ReSZh1/oyQgXF/oksuApV0Aw3BQZQnuwGlSucy/+aHe2XNrQF0/hzwC9HRXaREZgTv7MwlvNqDMOPP3YQX4urxAtJFlxzf0cEQXXV7RM5+eRkDiOzMi5TzlPZy7YwHwN+aYEMJhi3rCxWurSV7KkGLJRJenA0+jjGS3QGQFGLooXFWWVBMLpu6PqZn//5v9bV9R9+9McUQSgw7YW6ElCupNCkxZVLl6WkFIVWluBVf4xPhlpqMwWZnUI9t+hwRfJ5uzfSyQQASXJrQ0R0NSm61QiaXLGWd5d9isLALHU2H5NTFMO4Gg6ebn44e+6k6LYJGv3eetvNRbA3kZEnOWrPIblKFBIIRfSJUeTHUFdyTCZErlo7Iop9UoSQpQnhaEz5+6x6hwO8VKTFLcuYgCoMlR0dAXKPb0HPwhxuMMDAM9lD7LNX3Aytawvs6bRtaGJqfHrGRRDzew/GI9FXLl35nd8599DoQ0cOH73pxmMxBZA1ukrJLZyLu7E71dSRtFwXgrYq2sYhLfmVi9yzhK5Vi3xCiVHt9DInG/QYDuZxCxLnRCRe9fZczXvGrEaDj+Ulo0l/gKXB4SIYJQvP/fffbzuX7DtZsnI51Dvm1eMC51DUKOU0VQp8auEq8LQ47DdZnTtVJM1UubCDtuw5c2OdIIUVEZiu3DvW1quKAt44P+yMyw7Alj5nX9ZHO7QcNZmU3i2SXtQtg1BBuLxqTB4rc0ysyUdCsbvWskLQFtVBXKtkHtKEIJjpPIapYiN7Ia4LsYFMRrpzYUUUcwFohNlgEr1EiGdwIcU+hSua3O6BERnmCY8TQSYRzenqFp0+H6emKGPX3+v60Ic/gngDRef1QoG1mYSvdBJSFS2pFT+KP5VQOek40W2UYYtMKiH0UWAOegUJzeRmuJUBSHEZyMk6DISyilkSQmETygGP0FJsnubCLUW7E4MgGRJqdeQZK/cfOoj6E6dPSSJqkLFRmfTesfNPEGqv2CCFxs5Fahb7jULQGSQJBc9mFHV0m3KVHk85AcSCQJr6bH2k/CmeQgJDaSbmoAFPGKPc4gBu6BM7Li2bo6lmsmbbqbg4RgDisKB7181Z5MSeSVfjdT0HzbijBQbJbiE9ffaUg0H2J91+253qMZinJqZUQ7Im9aXVJfOw9ownIVHBh3h1657FCGl7JybVY+moS2sQ+cKSJiMclTW2nnhQksJKdRT01ZRCJeJ26JreV1kQA/jJgxwZWGVvK0oNKpUso+BMKckgsMb4lISbbYAhm0muR+kw5jiLjdydtOFVkce/SqpCTT9xwHAdfClDpVAJFfx1YM1nIS+YThvZnZ/c2MLeMzKGk6giojay8ymWmnQEYHssGYt5E2zP/Jw4/py0rjPyX8/WxkA52GLzo9GyDJoQCqnAe7t3IKfVFnDx9qlTj1FXSkt1SRRJK+4NDMfkaxWoiw26Vm3At5luM6hXEmyBygkxOocEkT4bmxFQxUlq5R8u+XFNmYSVrpxTe1FoHR+kA1NJKG+QQske4ebjE1oSDwl9BqnYK92UgBhawEw/bZYyvgUGp1t1CBZgNZrQheXogYsllJSqsrVsZi9t/eVT/hxl4tPdEiHAUfP5xD7yrnQKCZ8yPglYuqPYRG8FtN3DQ1FTIoARhDC2LfgO6xBonzJoclUx45gse5GPjzYQKkygI86duKbbZI8v1w+pDXDPK1bkQw3KxrG15bXJqUEXLOEVVVlcnP3Ab73XFU0adjyk3qJo5IJRV9fo544Onecmc2ypCPinfGiIdLFjIyFpk7HY2xhDitYaR5M3tZbmj7+IYnK4jUxZyKn7wJUjhybI3hjLvxNWhMLodsUdF9CabpN3Vw7gifdGRGc0qFF35DABTGzkT7YjslQ6pnrqkdWsTMEIKgMSqgLjjuhtm1zWJ1+ejCjsnA0Q0jIZUqGNsz5bmZblJkCcTncbxzX8kliencMYJagu1iPGnGR/rwkazMEi7Sx9Y6g58Y63TTpMk4QrIUw15CcNprBeVI8mBzYyc2V2wXOIdNWuGVJE9ZwLLVOccd40T4zHFl0+iksiCpztKn88j+L9xm/5dsEMhdESCiNS+lokshph3VRCqfAooRoJNXARqfjMPoN8Uj/YCbQoKJCltm73kUjIwYjFX0SCTqxFBw8bJBS7dmsePXaDgoRKtlMT1s3NYN/scmxXFhd+FOIgk1mNykUUhgO2Sn24P+qmZFxoL5Oy6nbDa5wWyoAH6VlhdmOgKrdjbuLKS+mnGu3Pfe7n/d5DD+KJvIgrtLLGHTStLcMZ6eV8DCQIRvnpk8dhuJznkOkrfy2NiMRAxNhZ5OqWdVOEZiNjI828Y9KrsUIGpY0T0nVNqdIZH47HQTCELUcM2th4Q+BoryoDAbpv0KQCX/2Kx/5Ck6//5fj/Aw4MfadVt3Wv3shLSLni18xyqP7pjMrWlLIrMCmVILLCJmTEgiBqlGkjnVT3kD/wpI1C0kY+3OSJbHGrBcif/Tc+QTJQAfMpLRPPFIDS6jBAjgA7N6LF3pizLImS7Of2aj/jhtiNzcHhuFRFcpUu9UAVWyUkehmfjTJTzMZd/qXeVZGXfrLLoKdDr5/XDqMZQ/T/9UcQCR4wsvlzowFVSGLzZ/hjghQ5hCJYR0jPwo5KHX9X6w2Njqh9wVg7jUXgnajRTROMj4zv7k4bZKnRjWBXtqK/o/sCgzkpSVzyfPfFc9PjrU2IiMHM4b5hSmvGBdtlQsuaY1haH02XKp8u/+c7f0JlERTm7RCIjIouDrQFu2pKRq58MrEukvUsFD4rm0pKx6F8zEn51BsTqkrKq50i7/BHEo3RDWhXoIGx3Q5fzUMIgsqHA9rEH/V7IcGQBiA7EL7CVGilYoapMzlxAbBNgyZsyyr/CEraGgzlqCiKCfcYIipTFWX5clx5hTZGexRp5YEwwz8wmKVTbNjltAqjIjdn3JluuaHaXjV7HzsOXb51/pz3m10MFndZdw3XKgBk1jRjnKi4Y5fbWIsAPjCzIWG6th1fjQYDk/zBj8FCs5lyT0//wIF9+x0Zo3JUV0N3dXNFnr0ROzE2GO/jTURrLJrnXCU54WWnHB1dtVNSg9Dbx4eQKQn2ufMXNFBKl9zvutK9LmHPzmd2EefArK0uogaSqclQadR7HJS/7kZmPibos6vsnE32D6N05COX5S3AZYGkR+zLD0cWsN8sAvt39T70YEOMAlMMpHPUMegaquj8KI+sWGqB9+rM8LS8G7kRUIxcjX1/bsnde+ONx4wU1Fy2mLpLTccFwh6n/C34ZpOLzUYPCMCWoCN6ziHrS0trlnOimbXnaUC/dnh186oHQwThux7XiAmInU2PHKhCg8gcjYueA/TuvfnUC/9E2RIObuRFmWdabABlMDbiRmaNHKKCkJDiMImi85jSK7RDqXIqFXyl6IfSxHgjRxz8FQ0bEjYTDIu77M19xFwjcZd9lUslWjAdvVTcbUUUJHWFas9ZpykB5ZO5UQqks6V7JaDiSUKiYFqpxE9mMrKJ7YEPngQIdzCvk4gIDn8G5cUQbsTnqmVsUewZiF6hStNhWEJrDsqWD8h3di1khpGm0uKRWIzcYgehSWhb40SPqepItnu4d6pypCBU2UaC9p9qnJ49dxaXGLHaOXXI2ISiPXpQyrMDkDnG7rfiHx7JrUiNnsIcWUB9POITvOJfWba9kDsKiYGdLztMULtz+OBh9URkKQpMvqJ6EOjGAy2z2SMtgCt43IsTeevtcQQXI8gN2+W3e/bOcPC8+557AGiNZSlWR/J1tpgOiY2+MV0hwyVtkKNPvYMeQRhX7ONgBJWDnSSHFYR2Rye2PAuAP4d79iGvKiCzrW42Z2ayPbad6Itq5WQEgE97+YcGxxdds7Iw78rNQ0du2H/gkG7IxMSU+99Dn3PfH7SG+/DbAKmTAK1aMA9lWRTVbEZbKktBWZqk5xqHwy/Eri1TBfRiNpjKewXCw1E2h9DIN8FKLrUQdLjxVWAIXowYriX3x0m6he0P/YHnT4/qOiShBO2S7cwvqStaGs8XBWvoLbRlh3i0GT7uWoBRV0TEEE+oXqQdt/RqfsWt8Vmz1zJElI+zgU78mJ5wueK1tR9qr1AMedi6kvAY3BFdamLT0WOPf7wmn8h59U+JX1CVe56RUWRDzgGDYmxoflEHyE7/5rNxVGiIV3WV5U2bpe21hVjVYmxNsvfvi7kvlKFJcxptUd4PSCHRLUrV09zyI8MaMdUP/TTHo4NHOSEX3axYKH92zqXI3ZpX0YPM4/jIog6wxexKZtKnrDLgK7TcZZcnG5A/ZdD4V0SrHanAwThoGbteB9x+OR7TTmuzsf3rhiM3DQ0NR1murJw+d0Z27rznPq/dGBFghW3w5vHNGkZJRC9Xda1kw9gKFB2YVlWYiwu6vp4/0KGPPS9tkytYIUTRy4ribFpMVCkg+aKYifKa1WSfV2WqyVo5ADCdoeEfgvE8VPGNObnoX9grVsv9PNjy+6PtznT/aOgXg2hoKEfziWXcnZ+Ze9OZ0e8rHgoNTqZicFADxSqP3LpUDHWys6v86RuZZDOQG86RRmfsqjEs0sSdyBYIUnO6ukVRctHh69EmI8DU48hQfEsacoffp/fGasjFy7FRNDvG8bq6awyWvS9I4fNAAbSFP8jOlXMkFZLy91lNS32+0G74IKjchbPTv2KFAguTNjPkRiX1UyqOd/7sShSBWGuxCHoMeLZ3KCQ95KbS1LiGfGbPsNIg1gVIaC6cpbora8tIn5gcCx0Kdkdylnq0EpAzIfSpsUVi5ZMPh3zyhDABiGwKaVvyikuUHiRT0StX3BtbcdbH1A4fbLViVYTxVBNZU6UC7uy+cH4WAaqOozffZjmHkah8mUACz3/jauyIMkywcdx7LhpxCGOGrB9h+lJOpVoatGvCbXD6OSiMokKAXOpMoD3/gujwK5v2FqH5KXftryytzJjUgVdQxovoPiEHXP7sCgrkMaho4SmO1Wdx64Vu6JpE/4cchapJ638obgPcRL9Gf5ue6/Cb1RMLGCPvue2k1ammsa6MJLcKSHU8vT+WQnGHj6BoPHIZhjtke6h17hd+IlPYYFZ5lzsWDHKS3HwiBnpMMKjVwd3utgwSQ8s8ZvuRB3+ZeDgfqXPq3rKqTQC68ydI1FrkhA9SJQSPiiCVN4JSkEOMK4+B/wXmuqDms3FcFyMUWF9RtcQBSFbjIGpufqRvuMBN6Bk1GTAqrkvJ3zwYxcBaXLM1Koa7ufNOP5nqwqYusLticCfmcio/kMsSN+MaVPImCkiayofLMVqbgSOvWVqCGG42bpQjwtJkoCozak0ePiEvT19D+caM6bBK0afOhVzY8YG84ydOywv1dvjGowQmqLZC2XT1YxmMQ3YBQ+sskUK66oah3XWzVdpjSXgoSIE5jKBmoMOKiXLlwWgyQLxCl0RCsvwlVZllmUomd9IPm8/iA7sywlHMqc/KVDtrLeDms7DJcsSpxso+Jf9y/1DT5nci+RO7JdFQC0mn+zqcMXh7MVNEVtzG5tCaCmpME6QUeOIhU+0bBx/CqWkxFCoA3SjFqjHczJM5ojeGdJBEM6HKIESxtsEbu605UnJ1amwcwrzgVwydW811ULLiusqFBbsPmVofqS2lu/1DQUpdSx0MD0UVc2LPRMhJzjvQjiZ1PQLQYJgqqXI3AH+QA1hn0HWfgmBjt1pg7KgE5DD9XewW3WlSrgJzLQPidIyRYs8lTgGjsXin88wTpIlWdONjw2VRgJmCgoEnN47XHKZ8akuKiKIMNfCIYrfQdQopiI8pOITFn4nSjua2sgFJmcLJMyYNg29xFNZYAIWVxNNPPSezk5PTTrzaQWUeOPTZlcgTU1JHQ19vt53ZesuUU3bk0aECZ3qppEMFtaXJhtWN3LInuSCXd3CNytjWSJFanYusc4Qw0TkDLCzstmmFtfS2FYTo8i+o69yRpXbhdQYVcDHheXYbi9+KG0z8ExnRpdhC0qbhfxQTDC8ahUiUf4NfWfBRoeJvdoT71cHl4KOwyJuOsR3lHAUcRdHuocBTBhIOi9iEkCSKCAYe1TeZXFtZY5NT/rM5+XQiJ588gKb0iXchT8Qq5z6qLguh5lnoirjwL84vwEK0rBcLkyKS0s4pscxLC0krxovz4TomFPLyZL+Qe6HACJWw5A38GDNS4MyOqlDsZJQxQjw8YvKza25+bikz7FT6DTfdKJapNqP20+di9wUjuobXIiW0lQH7B3VvDJ6VEHZo3/BOo+0aRw5R4JdRM44aLwQUlbLKvwpVKok7qCoDpjEx61iSn1N2ACova9u7cddDW3Wz27OAgD3TB5x0dUhdbeMJedcRG9mg51M/5TVUl8leu2fA16y5jAw4PWM3Uh73MZtrOSFHwQ7Z9AwGYBYJHuotRwUUEtO6yQGBKhtxqtYRGiQTf2AFKXrlgkO8cpedny9ewNgCvkwTJdJtao1wS0yHBU67ya/h6UwkNwM2CP5ohxQDcRuFzz86zotBVMTCw8YKUOmI0YHQssuTv5KSZboX6treoc1Hq1DoC2HZsNmTVnGvs1eXVmA2DhrKx6ggXFmNh8svXZw7f+mim0M8zaGNNTcZpRNrGa2+SywhZErBTT2FZAMYFUjV3qayiP1o7pQisfXqnejkkPHWl9iFTXaq+Hy2GZmoOywwHV/tOrftJbRy2vbIFljDSOsEqF1QUMcj5q4s2DzguC+frIScvB93/O1mj03mximir+2SE3FD7XMJFGU4q0aADfU+6UZxnxukT1HgBCBWRQSAsvp0uyxURWWwMkd9PhVs2Ck37CafekSVmcobJOoF9vjYHv72zZhp0I8wbicKjsJMjO9TWu9/3wO6vt5bvPfee8mGjHjSxnDLWwceoeraJR/rqKQGvTrjcavB7oKNFavLKlhoRydGbV7PdLOuzVFHzlLl0bLWCFeNQsplIf7svQl4v5kpzsxNS7ETVViRr8xjk8HyrIzzrOYZMyt6E5FktKKnV8Gza1WosDVImlj/zzuKBukmJ65xo683lsfIjLLjAJCZ3a3Lpcvd2EKBNcTzL2wccZ9S23RyieaSTLMehnh6xfYq1nTx0mrMM1sXMvUTSWstFCkR9YhRu6dX6RZWK+1EEYlRawPcjmMMKk+VO+I1dWLxVxyMFAUQSEEoJOeSaqP9o2tAeDrzWKzjWY4KihbYqHt9NXrCMhCtjVJ3mWJP//pqvHMxOjxk53HhcnHRmRPPRYZz2Qki1MCAlxwOwqpOfZvjaaVBdu1GzxXF8pEr8IDpiWuKrkbH2KHWaIpjdKnm63fDaAwgNcj2DEvIPRueJnI/Bxpih6/WTurO1lqN7O0zEuWAViqObjHYpCp194CEzF+4u+dTP/VTDx26wUr6Y489Obf4cQeS9x0+KLPStKA5NTmx//ANhgmhd90OQtgctyGVqNUG+hZW5q8ISjM0FqNiaI3lHdNFD6axmWBC6BQGAFC/tBoWIeUOmhMsbAuLUQfZ7khOA1IULEtH1vO+m8/0zagJl5RAEgKSzCzIAmjsdEQ1hzeBvYX62o+OnYglTBwgy1CiAiq0TVQ55V+rrBhVlYyyzjPVEaPg27HCI3zbelgOtpYUjHQZ28aqtuUmAcraC0KxJtNxE7CdCkLRVvkNyJxeBhoEa3KNTuxKgTQY77xBjJWA6fk4MOSuFhprwun3n3zUmJabTa8aGhSGVqy6flEYte2ZHEZXK4oHzYk5chB/5jVi32h1cGIRJDPabf+I9s/QuFlIrzBYSnXFRxWR8smECHXwP7Cnwf9ypH2Nq4Z0xQfncLW4dilCwidKy7YGK7emd2A0OaXTqAmtzVW6vioVn3JuhsBcnP6wmGJ1Ji8xPo0R1LjLUT7sF4VsQjuBowwyhzRNmXlh3f05eyYmdeZ5Y7lqTdfBwRtvNTPiKqfjx08ofqmoa+668558ca9PV/l3f/ftyHbQ5+iNeyLbcdVDbLGyVTV613NzE6MG/DHgsTA/Nh7bEq0BLizOu2Tuurz4hF8VU/6Vo8pCkzuOMNH8RqmnCSmsuPVdn9dz6oWJvcCnIvK+LtEXALYAXujPB1fLv8GGLXyiak2Ky66y5tY8RXAZ+ZB2yD74lvKDhKpsUL7YVYKNzWdqarLA1LOMOROayWdjJVYrmMqUhqSScqF8FD/hzFMQdG/DlprlFUPNSkt3S7iIBi9R3a+vmS6OYd3p01paQmu5xFKCJ6SFShFapR/wSW0lV2n9CWxICgOEndH5t01WoIDSNDDUihuMXFRG6lMOChLC2CeiPHItxqmnKjKHH5iurktyLUpIJyw6mfgI2uyrnrMwLSe8Fy5dpL1CK+fOiMV8nYILPsfoTl0HA48orkakOtxVQTVBEStTLEf5P9+dkdtl7yNz0kcVlQTjhKIm1JCD/+bVnbvvvYfenr94wfgWkfhy2DaM/fuP3nQr/4997BMK0llWqqv3DtvAUOzoVofZcuGEnzuYSCJlnl+4CGB6akwxu60CKqfoR8a9M1BK2NJCvIIkJpjbS/OIL/orSCiHcgkrFZiyp4eQFpJOBzZHQJjrdPm6z4KB4ZqgQFtJR+QXVI6tCNfWntse+VuKJxe+Ck9kI/syfDjKxuRyu9+7vVEqMOJC0WcCN/G1rBSHCOkUUPiNGdn8z567zOZmpE7q2Nyjg9GjySn9FsKgJjpZLpp07CZW70hwszAb1wVmRN24S1fmnQTwnmBMGZ+PN1wILcyiiyLOyNCAc5EwyA7ZLk2o1Kt7KOh/1KAWfrE42LB1fpa/IBM+bKaB5GCq2qos+BQXbczQcFQuKERYGZ9CGZ7w1JBbFJ+ihwJzmamt4JI2LLgyNyuYNDMcsMg5jNX9KIxs0ZO81vpkkcJuTMF02uAresF0BqV/eBdO6XIXAI3SYE6OjSPAYNTSnN6Be9iefeY59Qt4KwpmlalubPPq7f3t3/pdpYhsF4sLiqa1b8BKtVchNZ5eNkrMu1YEqbFQt6BKYnEplr5twRy2/pXbA5ppxoYqDkEN2eUogtnoTXc2R62JpaiDo9vcUYoFH/7Bwv8BU0gqgqQ7P8uzfF40qDOZhgCOAm5nqqWxPBsjYsBnfA1vLCHUB5XoRNrhtkgjBjHtNHz6cgdeAUpJu+6mQZ+KQGERMM2LdBFTET2H4GyVDRlCgTnwYcJCp2luNk6/PPPccaNZi7LacQvwyr3AcNVVTPCoNlwWBFX1HCsTkLcIeH6zWZ5/fLvNkoiRmDCls0rlHWoJTIplGuQeo0OeUMJWmiXvPh0g4i8jlRduRizDdKGQiNQSmdiFmXuhR8fHat4YX+J+x7yiucb0kBqIii8mXhgcwhIok95sZZRr/DVoW8WcqUYO2hVV0RE+GdT52emWWZ/lI+fllqijwRTSy0IKeHr8IHp09GePnxzMtVwbv/SiNaGqGxu/rGnpcr/kJS+Znp7SMsPjeQFBlzxjNRQPzBGbZErMbcbxd5XU1R4v4LiYXteDfNp7JVPxCE08TtwyKcIRMTnfYqPPKiF2mgCWC+5aifWbXi2h4R+fbWP2upyV5ba3aYVr+BtPDrQ1kIWq+czQa8jb/q2ucicS7tZgr93AJuUhZ03L2fi00PbF4I+njNFetg9BtX4b4tE23MDsqa0UucsRSpUTIgCrVeCPyErIPIghpPkOPm3xNR/j8tp4NNwIrorVyTtGR8whCrMODBS9Xibob43LY4okDUKhAuD8nvFU9QQrqJIQRLxR0iLvT/cTlKQkNHbhI7TlKGKAlRnoH+agumVKe/nsdsWsNWAmIxbL5SXwY50SqKDic7TAhNjFH7RXU2b/PSx6mCaTKrfaJTA8q0qAgrtQFOuFthO75mg8i3EAGhhBIjaf5WjsGjs1STTpoo1suTcIx12JqLrNA0L7Dx5y12lsmlHv2PkIDzVXmEeOHHb2zs4qzbKjepcuXyBjNoStLS1iGUYRi3y1ecOI16O1DkHHjF2M8LtW1lZt3MABlYVOSNEmCcSwGawotSwOBI9TavMzcpdZDBkv+Be1oU3IFw38Az0bYgqi+fwToComF4aiH04dnE7MFQrSSk7lSvYIUQ0OAn4luj9MSUvDB9ohVPRUopbA+CBmYAThoYIguNyiO3tbesutKM+evWDsQ29Pn7kQJZu7oESMFkUfuH9gaX3ZgqeHWpKeQIhIMkqAM9GQ/oaqICJ7RhxSEdSElvtPZsPfRDQi89kY/tJiyyVHkU2cSl1Rmid0iuRcvWxXZG7bDJzB6/ylKWo+Ap3cj8W/Vk2VTWONgT0I2gIHGxvK4kwZbYY+Es4uDcqorg0ZfBqqw5FUgixHBRXpDZjP8mHDk5Gk1GphmqCgN7Md2co6ooCLKbTXqQeP4NoFeeg2G7/26UBb2VK6dqJSb9UQBrm8yaU8TsDvm1mZ2Rt3gp+/cCYa7ekpxb+wODc2MKT+NhVpZwj/oYnob1tAmhgdg//K6pxZPnfHeGAIzoX55fHhOLFcRHY6GkktB8qL2qqASr1ftBFtmFCZVT4t0zjqu2FfO7zzt+hpfDpxdnpytya5G9+2o6IUzY3NYaIHSOFnl4OPWV82AMaxtrCzKMlJwSTsNSvO67yYGR2OnU9CKpZDkwqOmZ9bMeFkbZLeUlc+BWY1L9ICH9sEHK1ylUwEjbZvoeCuiV8ItV9WaqJqaL0XEj1HBoaSqKKofBr/FyPzj/YrqsC1HElkSm5YVRlxWINk0xqmKixBwaY89lhx2Y2xkFU4+XC0tMRpwhzSQ1W90qIPTED/++/5N/X9v+w/Jgd0ZHJI0Wp4K1ZJZPG9E0/b/5pf+dS3tqwd8HwNbldw7dDWr05o49OJp/Esxx8SVACdQoxm8GVqoZ64MKq/cgDub18WZ7I34A0PqiHN2yHgTHrJXMpdNrAQpv/zbNpkoa4OvWhg9YfNGNPY2Stx8SXMZJSBz5fenx1F1/iSCGMvZM/u2tWoULRLBo4GjxyimwNzAxt/bnFRiAYKAyHMjKBysDOd1sQE/z+ZKZziagwglBYHo71h+9Tba3E2f9o0mFSKKSgRy+YQHQjWJgwra8kOsoSCAcjBOyBqEuuvf/3flVKDqzLsaAamFCgH0xqVXZOf8GxM7TFsPkUscx19APgwvTFWD4MOhn8xVA9ZC6iu0h468s5zamqPWahb77oPR6SiP7yy5GRJ3BFvLcHwRq9JgcEpUxDKo1hDzjXlWIsUMoqzxl160dKqREUpR5Cds7uihzvE8XkO4pGQbXi7cNIJssHAEZ/tLZaBJfkWjkRYkDX9g6VZGOS01aO7PsXEVp7sMvBofQpb2P63zUAu//hqkdEW1u44dPG8AWrBDHmWvI+cxUyP6Q3MiS08Xrieny86+UeJ4EM0cTtr+RQW2TB4AWD5tbTelYplfGM4G34+vbuxZh55jFZxS5+HuloXeOzpp3WaLNRzKxfwFcXsauQnsmTegU0gnAZy5qs1luaRuCMEVCyTlNF5jXea07cvtKIQBg0p1T55MkVnACZhZetnZS4jsIlYQSDF6vTk4xhdlKBpFKN294MPEsKY1nbXY7ayUZ8kLcE8/sWTwgOtibYWPdk1ahKqVIrILEPUohOmKNCI3tNrxwl4a0v4GQF5Hi4SE6z0MizmwQirorSjoiLz5wi7Qxz5/CEGcMCnkauiQE54yFLooa0jWzFFDEzqBExQMjzyr3qmvUakNk4dOXKjTdfG5JcXVi0Axu3wlN9ZBRdxRafKHGPMdmZ0GLAsxc4TXuuxFKQnRkoiSu7Elm517SoKu4zoke8w7Uy26VdTB0zKVAvaV8w8+QngHJQEl+szkby4VTzBl+BOUzl2LK8GtjaeOrYZvOkwAgfybdiCbGwOOWUzlUq52ZY+y43XOnH4EJLlLbi10J9ktaXWmMjB+SidmN6Tjm1DrWoRQvCxgqh7ndebAcbJ6hAuL7SHWra5502aURW4znJl0VBF66qNNV1MY33acTCZD2gBkEYSktUBAS0q/9Q2MSsOsBsHrPXJli5T0shfU8kuTzaAokoL0UTPuFGVcUxPjAGQdy9diRtNSA7erXTx1+IWtmxKQgXgTP/Q2zI84eHmuM5Uitd51mfS0NKpilt2KLCJxBTfkEvai06ada3ee1F86dmZXqe7M0mcIhYyLL0SRXrF0/ZiDj5EIebM8prLmOHY7Z6e2WdW2d4pC0KaBRX25VmvuY+IBYn7emHTZ/K5uRF7MHGwKgX0w+my5VBd78ynqdTLLTmxirzK/wvd1/nYAMcHMPLDkU1xaG5WOoWk034hHwqhpCuosSuWLmDhb9lZcQhypxxIbAljpYFmRffp2iQTmnyWtoUju0kiRkWSQWVbApU0hbGT380JHC02DrQ0h6jhJ/2VHGM6k1jqSCsUGIpd/FWpUomr+eLFmxAbqNxAu2//IXWHGcGFKzR0nq5aitUlfu7UaRWEIKlHDqKQ+kYG+12ZIG6MZ3PVhBsAEzfE/FmY4hKCISsOQM7Bn2eF+uSu0AIDI6dBRlRk0XLaBVCSQ7QYLCqC9Q4jVO8lasP+7DaI5DAalJEFaGPBJkQEh1tkVNJFSaXbENA4xP3DDUgAgT/pLGxREhitwARp3zRQGKtjoIZEQ8UpvK34Qdk1/wagcTTAfMpUktxyjjs+GdO8JSXEoGYmNbmu/L/jzrs58Mv8uyU+nV/yZHJ4fSPmz+KVVyoUo53QQ4ebrCJmnyaaYudASYy6E04d/mI0W9Jyq4SYBC4ar9kArn20C54POotN6YyM1/RrAD/vypgIYsBr58p9nQ1PcQPvChIwR+sKoUq/HQSmVu+CAFrksHl7I4QnD8o0NDekB8IkWDYlx4A06x5IUojTr9UnXF+NHT8pqzo0JM/QNrhkdZ1NJOgkBxhsD052RUsV05vbcauOUOqqAT917kP6xlpaS3cZJa4uYlTMQQ9RJ+Swx81hUXG7F6NFhiogKQwuZN3k909vWkxuiygagoys4FJnow0ok57eVW51ofPtLXkNI78eeGJTXeLXKDDkGzvLOUTLsaiisY8lb2XTEreID6UlBtHkVhJyHQKZctgkXUEFc527hef5P5IuMHbFKlSR6uzsFW2dS5hjgBPDBm8Z7XTMlTwfU/urEyO/+mwHxmcZqhg1dXsLm0+lK2i4N1T00sUroti2abFHh9la7sXLl51ZKjwO5GOg8nb/B1GL++rNbWapuyOuOAt5Sltcj8IJuQJwA56EMI7Rh5ZVKUZQfxxyKuR8GmrTEewupnQ6GngVR8ErtXBk8ZRPfkX0P8QUNyLvOc6rtCO5eu4mYxZJ0Vdjyl8qYFL9/PLWW2KXXznK33lXDgbBpSFsn+btK+/FdrJZqVg8wzpGTyIBYvQEoctkfWpbxrxQlZv1lB3jrmBT9xpYxpIso5mlseubwQ2vOpFy8/9Sh7NoiNSzCgjOp+HYzmdv+YvVEMYdS+5/FiZYkMVd+CsJbrLBrtACQBF6NKyyqbtBnEqiZCRVN+eKxU/TxK0mF/0cygYK2RAaI3H4MxPVFGcLHC2/JgVPpFKYG1QccBcxDc0c/P8QA6C4V5ChwB6SXd9Yts+JImkVBSgwNlErIB0eKVWDjOhwp8mshTscKZfl3/LJ4FKAYhYPadO3KOadeLDjlltu9QqE7VPySSCeeeZZF1gDkGFMzFNSXtGjdXF5Iv7gmb2Q7sKXhA1zq1aE12MdMrcleG1dpDDUpLIQuUiTMNEIC+0ksnHDwQ3shaZgZDwdLbC4Pq3DtFnS4fV8Jw60PDoKCGkmTK8BJpYKtxG/KGdHfqIEwqytLqMQGztN0JwXqUPF2dg+LJ0X/oAxsq2zZtrDqzFmzjdMsSTWKiE0RnFSmsDpEy0sxDyTpR2tqzb2/IVL5a90RAwuqwt6+sYnxkTEbbfKxHlow2Pdz9D8kAjzUUGPY9KbhqbRnlMktuJmOIKmPyPVrWxCGzjbVV6knobICNKTQHbpEnXlGM4bNKqNFVRUIaxiiR4mp9zLqXfakpJQ0MhjHmLp2dTmhYm2148KirAx+iJRS7YrMkGVBE8IfRYTOP5wU8BlwwaYG6qQKreEx3NvyWtpDQ7oPHjxCsA1XQVWueq0K8lOnyYKzzLyQHZxyqdQUdR2fG686Tb1BR3Wcnr5TmcMQ3UEKK/xhePXqjZqSVxqAmlkyG0pDlRH2RtkaL1Xl1dcpFx1WxZGcJ8Q8lFFbHotJIuKHXnMcSBi6rMoL3pa7ujlXTMNj2J2ur1ZChrArRb4D+yitCSm0HbalVyJVo5YI7DmziooJCVZxB7JrkeQbWAjSykEPqUutEx+ttzXKohMEisq6ZWcZfVZ0tlkv6+54951jZvur3VPQ5zWPnvmkpo0thRHVyjY20oll4uonidAFSXkJbCri4s+oVUEUqlSDpqu1uG2VrnjPDxqiCKjyGuRnj8NwUX2n9gu2gpbEVYpjo3HXVkUtTFkMiQzFKpdlQSBrZGwPKELGbIsuyALc5wczT9TvUKV2NWumACGRP6UZ7IrT1aZNogLhgOn6FIHhp9i+eTwWUlkKtfcPl9oEm1LH9uEQVADNkccu+KBMkU4P7e8b99+GyF0al6IpdMnYqfh6beCGkcDmaPrlv7IpE6yJtf9z4tLMfNh4CR7eMpflHC7KrkrFvFIoCwTCwPf4HHuIJPtZQ/gulT9arwPWNueUzDE0GsIBQiieuLFJv7gK7cQKDBR9O8a2hr28akGlk+n4a/daODLAT2YWnZqgjoyHiX0QlMFwDZRyDQK7EbeTDHrS/rZbjoue+a3rcwJEBa0O90xmVTJpWiFhGVyrYqjBZbA/GMXYYpXRJGZNk4H3FWatPRiq0dsnjiez9rdjrmrRBipGIzHGmt31+Zu7MDjJYiMg8nQbl1xnFdw1mBtjeIZbqdeu2PyDHBBiltC7K4yPlUuFVQKJlYl+qe0U3JyGDU4WFvrakplYDCnprLbLN0ykVaoY8tE6TS8ar/JJCxJkvHMexzeAGWoH93APIsS0WsaPRzZkYmZGLfZbDgVe60hEVTkEcXE+Sex2vS04kYL7DWMbR3brCIFX76y7T6g/QdvVKukiMSifWhQnHbWEYxRllFOhLp4JjavhXG1bKKMZj0O+4aEyqppDG+LGAAM3nz05mNHb/Xqz5XL848/fnptc4U6MW57lLGNq+tRNTouv5kLWjHV5wCZRLSAV53btXBogi2LeWd4RPAgLY0lxuoTxugDD0PUwt7t9iJx0BMHO1P/IYo6adckEGoj1+wgvOXetjWm7Y6IBDRhcnk4PNJEEeo/+q/dSndYFbE+LW/7lKNOw2c4+ls9JgBMoiOpqmq0L68tgiTQqQYAKUYQ3GXqIBShlvdEkdvQDcu6QqvCJCoRIecaVVBCfSgV8kFfoOUz1jsOs4tjqKtBrC6xQSzHcxfO8teRkQTKSxvpe1fvtXxVjsqOSiL3UAZwwMe3f/kWMqmvrlz4RT8piq+1JJsaEbGd9jPHSIMQBg4G+QgsZoJixBQyjX6hbPTAIKeywC2IaYLCJ8uLDzepLFmS8al67qdmnkyhRdMY/CKzMCiD4FfUg1GdRUKRmzCVYoX6NI7kLlPhCdI9lOvqjT9caGB6ewadRZZDlSDGRpRAvuMJMsfb+odHjA35D+STVObz5A6ShLqWZT4upgm25mJ7hSIwlke99hgS73W1uuCUZ+yJDL5jHwrihWfKk+ewpGRxQSOmiWMbOYiJlSCHDHH0cb1DDFdIyDbkUaPkQ9i4EJBxpX3w3dfo6Nhdd96i1VUup0+dvXDhMbILLSQFjC9RLdhNkL2XkX67OHR14k1cgq2n7CES9Vk+VK12QHeUiVglvVno0gxedBqdo/BNUQjgqmasOaEp4+S4JlhfYJ5EED1prjKPbhWfpsgLLHxKAtqb4AusbKF6odwpNQbvWNPasGJeAfc2YkdJnHQLE49cxaw4+DCxNx9yWZNCXNod33W8O/tt5JlixDXgURZBuUjZNY52T8mDJ/ZosPLttW1aurK8+tQTzxKpmjEudZVo5Nqzpanh4IvaylrljvtPaYK+5G1krc0QDjMXMJdPBKTA8FHEyCilraRR0iDhQDZ/MKQlwGyiiJ2ztlSOEyfNLB0W5K5FoSBi5JP9nUASYlBYI+kmj5F8KnCnT7klJEJGbYlWwGYnsRB1AgCruQkqxPgEHCWcmoUqBlomUmxIaVH0R/+I2AlUn4UtFFjVKM+Du3HXvhRdHGMZ1QXWuOMh2+7dmNlCQYjXTlxvLwqxZuhAUQOXqLEO4YaRbDQc9bOW6/ieB2/V+g89+DjpwXHslor+hXfJOLyyChd9NVUvCdhq3dITXnZtICNXtnIYFntgWgoWidpfoc1Vl7e6uEFQJ2t6tbUpQEFomuxf767vtDY8tDyzfwix5xNaPqWf7e5fp6dsMuUTj7qmaXWeQusiaDRvIVR4dSc4bpTCxKUrabANWJBKkKJHwMnQPV+q2KpQujdXNFZ2+cQKuZY1EMYYAZI4bRJBLrrNVo7EWON10SlFnb0yp1d85cqcaSdKu7Ky5l0mEcFEvZ4mEjZ9ups9wHZDh4Jg5p+pgTOYklU/+uHmHhgY4V9un9iTpRRPwJdncamIKUjZNG+ikaCiHKSRIBnTYgJPBkMqFTk1rhUrImbHRH0YXZ9EHXbSkHJUX/HNFfBp4Cl32YWZZxv6GiSfShRvlbLZeDRHcUcjGimEfNKYvPIR5ZWvZmpb7AbndQ5JV4ovtCvRTnpCgTfWVoMpOdqkMbjgPkZ909Cf0ORVDxS4HY4+DwwPGJkqjFqGjdVuvIuZVP3r2JjhJMChQ4c93jcxPmUMPze7+OTjJzBafkid1onqwuOllvWNVd1CdaXOjuwpknyR3BsQ8fas8YMtkxRcXIvS5vmxJqhP4c89FNiH6Sq21pMinXwHWWojq/wriCfjKH452OHfKrguhwwBh0mBwu76AsPRRGkcKi/uKpWyC3457q8MUxgaPBvRQ8kGJHcEhICFsl7d3YyE5DQw6yW1zfDgiCZ6bSW6uLQMf1xtRFhNV6gK9YfNEJttymWd6BLHaxl2ny2vxS4644aeiDI4PLq8vqyM+oejdWoEHc7Yx5ZGsn6D4jRBxp+FkXFo2rkJLkPPJiSd6SIJYXyIWQGwyxP9grwWTTxqNEt7eZbGUpakNywXWLEloNXVz2FHVy1NZA06nx1zH0LaCnvNUfCNHQjbNAeS/OQwApI10sVgY+hKVKB6rNHbB5apRYVSYKJQLjSXJJD4TB1DXkSomtQbBzxM88nR+HBIKxSYLpEk1x/bHjYYj/pFfyNbx9UFCuyimbV1TWW0VaPelYkFfaayECjizYI+99/efptG90Y7bjQCTz75tIpJ3aki0Dsyz2LSnt4aHsuwe+2nxicsvVFmpaIVxYL1lbiSdnVtUZ6hpdQcjLRSiFtMDEbEUc8QDvjNa6azBQm4MiwH2agFqbxadrxPG8xlCk+xNT47XjDIOC2r1mkzxjVL2NX1NbbojalgZcsf/Qhil+Gjh5wArYInfwRA3D3jk+HfaocDBgTh390xMHGz7xg0NPPypdnHzz1FY589eUpLaxpPbYgtlbooJFvcKI3WHbfVbsdbc2BK1IJHbYMwVDGReNZW9flnZcPZzv21hCAvzWlnM7INTDmikxRVA0viaWy1tISkQoEVqTCn7EVFWdRCAoYB09feOgqMAcNoFQ3uAzhrkoaMdGTVGWHPM2L5Lm5xc1QwnMVMsspRhqfNZU0UDqGl2IMh4NFZoOuFobC1aX9eotd9gCwT/h1aHMm1TSgwDTD4tpxKjft1uewpcVPUxrqqXMfNZrjllZoB30GKWzFwVj+GxGjN+ExNx2GDGw7eaM/jyROnV/NNA2lkG74lSPZx3ODH60EWzI1Y9u2fHu4fjuG6rULrbqKK7rK0kMsniqE97Q5PCPR2zEi32E/ecogY80FxvUPIR8NoGERhu+YhHa0i5ANP2K3bJEVqmcQbdaxvAJ2Gj+T5QMUEJWnSJ3oEZXy2na0HhCtKq3foAwtyTC42UumOjbQ9A3HZ5dJi7LmVXzUjCVQGMZ/roeeTT2tXL170IOms1lWXJHol61sjk6N4RaURUxEjavcAfSbBGjO6wF+NUKSa/sphRruHHNN88Sd6QzzyuLGdEavJy5/GIUfIgEFCTINW3kvXKKzk6K0Glr133zSJorckyqcgcWFwVSpH8N7uojT8hMp1kZfcVf+St2iTIQn4dqWul+YvslwaGBSFaetj2798O2xE1leUXY4vKqFNatE2yMnAqDj0jFrVdgITGn98KIsMQiU6MLZYAd/mf0eaz3OCbL7DnSOCwlNBbISFArt4UmNgSw7JQBEW4Kr+iwcNCUkOzBwBs9HH1jk3JPTY+27CV+PpCXn6SYGNbJ95+mRMM+Z4APHJYmuDI26Gkwx2jI7F675ub1W0ElV8cBpvk0UVR8KbH3O3Z04+7XjivaUhoptZjZ0fLROMUEaKJcd1rTKRnyrgtt1qnXxWtsvf7n6fjYGy3CS+MKS8tWQuOOV/morOWQi91CxiRQ+NbJultdalZILQGZVMJmE5MKBj23lINjx6yAaAE+N7tKiXL83rtjA01pSBqlCDoTisQyAlSyrp7O4xsg20eb9h4SFOsJnHSdpiy1HpYM6KObQQkzoMhYlE0yjl2I6c3YRC0ib/z+wX8qQn2MaRNVS0sZtbntSKnlfNPJWD0jp1Igo60YNGssEWdzDZxRNlbBgYYJjmkxGLKQcYDR0vn8SDjf3xw8SAKwSGM1FFwRZOdhk+Fdr2aBU+Mlp80yxtttwVHWRFUcFwowRtleWkKx5zVx/xYTg0IFDJwh+lvy0SpNIkVF4+oWoF1yw0dOpwahk1fJr+/k0Xx6nyLGPJFLWKZ+6yJbTEL75us5Xb/YcOAncjEZ/u7dzkngtLbbGPFshbU3KI9Gy2Y6zrEzw8mtxA1dcnk+zsm1zll8RV9RNCkNiiqlO4+KNctOhyEZuig8OBP4CykoOwCn5jdSmidhRSfRrrFwy5Rzy74L0pWRgKrCKy65ieJBR7HKjkyDucUt8DtmI1tgtcuMvkHEaroRsyAon2vMtlvTrAly/PXrp0meP0mXNaVmNadV/pODGA9qr3UUugbUP23a6+1H/wZJblI3Aa2/qMcUoakbI+acm0PQgJ3Fp6TfjwUV8TNUnA7RMuQZUdjj+9kR1IYJaEVoi61iX7E5MhA0ynoFeND15xRK6ysSIzAZMPEXMI5a+wCrNmzSdgpqiVkOQM/SNVtUBMmARA8Kht+Dd55OYd4pSFGO6O0PIUXYqoKsPdnUfoK64oDQ36RwgIFc3+M9ESF9mVU5+AAegpME10nn8cE8S0W+AGvigMaSjZiMv7+uOoIeNZ+u5FF+r1G9DiiSRlAKSuze7WqsZwY83U16aNyb270fkZGhjcjuUQEzJmtKz0xBVZIUg9u6MDYzrlipCKahzs0DPkhm1wpJZ5MV1ltOY6qpbZjtnIFnODxcFlRRPHGCIbUVrkLXqCvnWcVlcqYjCmbSJKtNtRogGVK6oC+c/OL/PiVhg1vlVFI1QXRGgZUfgwCuDqVhSMJAVVQsXK4V5PvWWfJdEGcFX8O1FDReTsjurZxnLOysqFC9Gual3ND5e6BgGUp1F4W/LavTaJ9fvXMsrH2mpLDsVISlgc4S7V07AXOJzpiB6cIDxoxQyeZlwZ0a1K8lo0CEqa2ZXHQlI2TwhdX67cDZ0wjU/cyL0eL7zvdLf2YKfeBZ+ygeydmdmrXtY108YSYpBliI0bceyqNGYi8DxVxc5JeViviOlvjeHjUKs3W7UecqKylWiYOM0fRLYmI6OY21yLfLV4oKi40K3Ob3n1tjeoRG5Ca8u/a2c9a+X0Tc6QDfg3d6KaI2jGsnFVuI1lsYo3uLm1VMVr1GupVG9HD9ImivnVlZmpPd19g4Z01g43lxY1eW50Ghn2NM8WklVHMUi0A2TAyd6NEmQJJSGILFdINhNlBzTUNpaF/cmHui0ocugoW3uNKEerOhcQucKfrOqwNRoExit88aJ0PD+Ov9vb+mOgCGhAMtxSBkjYI1VpxIkV8/4xc6jkRhy4j0w6CpoTqj3Rm1J9YlJoguxW1RKfIZsKrMXZzFPb7eLbbFFjw2PIvTSjBaZp9ZV1s4TKRHCSq6bg4zOZEvZa7jFGeeltNOpprm60Nv2DKSTiikgt0dUCigoh8gtmbm6hMqJ6gk1qOKak7WGmsTU5rEvcLMBCUpTAIGLwLlkdze7/G6ZyEfnJoq9cl2eRw1+uMzxhQnhiZCSPkZE+DI7dcvYCUE9lTVHLVLkbIGgAGFGKn5DjkrxzFCsqOQDAtHOVok8ECMIfPls5ZxEUtOlpcavjEEjLJ3/qJYpOn3JLE9bGvzItlUqu/Buq+FuyV9SZbEgsgjRsujlWn8WhKB6l3NjcsJ3XpI+7+Mz+Ijiw5b4U+ieWfMEAG7tJmuM6H588G8jOz4oV0fm+AI/QUGCpNnFCrFKwYmiaO7/EQoaKL3TGCDhbTO1xry20JtBjwcm2Esdz47ifOcPYg5EmTqrvXF1ejcNAUqGdzrXKoJmW0PatLKccGIYyZ64Csrt191InN/nHkDELnj9DFEqTrSaIW55lB3CaVOFQDxlkikGjo3FaI6LnPeCQAgiYGHvrwkUrDbgaDY5NC3xENfaHhUhFpyRRHTwwqddEPy9fPmVDqKbVFHGMZi/P0vxU/miLcAISFZYGR3Q0MJJAA77B7OXSSP5/mpHQi+LmX8QUPQ3ryBx4nwDYTdxs+OOLpyi6xCDp6uR07MmRQZ+V2WK1jlfhB48b5Rak6IP5qZ++Cr+IliwzMJrTSjeATfa0t/QWnUU2GEEV9zo7moUXNTnNJHpnoJLoybtFeEq0sszBKGfizXAnISESAK72DEQX1d3ya/YY2WcV9b5zRtZMcEARq8HFgtDAXsezIbtJt3yyM9T4haOVtWrPms8EacjmKFPw7FBg/WQ8RSgckaUU0OFBTW4Iup3uljxyWstSrdmzKJCYgOntM6JXNgZ20VHpNi/lgYd4MAFvdRt0gSRmnMpD5uUxK6Po9hp6qs2LCDCSbtHlx67bDkUVxIDUcWj5x2vbZSLPrTXAzLDPMgEfA3fD1dZ8ZhOgYkKBTyBUMXQy+/q2ghbSgNx2WGdzwxbTeB7ZG3bAooOn2E6fPlsH1j25BBWN5alEYatiTsxqg7hQhqfXR+1F4XAOVpAk/OdgqsMj6H+qiYRe1FTXujURGNWrUQfhz56bKLmhL3IQZLK1L6GoQ/0YriztZjdLQo0xUMarbspstSy9ERErrujRZiWkvq9qDC6fQBvWlfKDLPWGkxu7vMjAAQ/g4F7wjYfGIPxfxHRUOs8LrQ0/7drzWlCMWwqzLpIUQ+wlQlWlnzmILrYxDLUQsLCUBz9Wl2ipskWXR7XNpA8NxA07FMENBlQG/XaHmYAmTNIKfM1flohVgoaGSK9tWgMeXWeLqxEpIkf8BABZpg2eCqzmQGjpsOAK023GQ1ymogY/OsBo7e4eqPdsNLSjIxOOE43Zl6zq7e91b3M0bKZNN9b1opWH+igW3QfjUAGTC1XQt3qM3bloVEGVNHeLuvzx2ZDEw9oKwiKkmT6KQQJpiGYtaQ5u43LRb4xErvjoN8gCbBEsA/2DuzmexOv4DqJjlsLkkyyjmR9gyukQMvvc2acs5NTpHDUu4KAhuHSt2yKTFYs/yRSd4eYZDMh3hql6EcYuVS+BrvFME/T/mCOz0Gp20FlUccggG21KsDEItqFGV5mDAvMfnxi1AGFVQQdS3MLGUXGBYSl3mQYAW6iCUP7cxcxKhbDx5NMg4YhyaXdbKoniKgzRYryYwfQX88bzaNsbJI27kbkos7bICbUNSbU05E5SR1M3rzr4pvSdLb+yHHsW6HZsP+od0o3TPVOJ7x2bRj/8POChuronqT4tgb+OqgK+zjPJa9FfpHYClA/k5WAzUY1p63GqTBPsFBvhcwhZvbIZazqxVKw5HhmesIlvdGR8emb/9PTM6PiIps7eZ5d94ipuh1yS0ajTtTZXDRRiLiIne9tn4iNhLaq0GGXGcISvKtmev2R041P+MtzOTFUxPOikGjuG/T7KKCIOkFF9RfMfZYavmlmZISsLi8vqUo687T+6c7Tb3f0Xzp9VQoavesKMvrEpYgVD9QNbynRhDkb9373dTU8bMRAGYJRAGqBQcWml/v8/xaW3HnoJEaCKkFT0eWc2LkrooQdqBeMdj+2Z8Yzt9dfm22sRXVjO0Y2wWgsErgpaemXGvHI1m6D6MgldVQu5c2h+c5S+Pja75+td/neJx1mbpAXMH3Htu0cUWi6QRCVypQAZFgZeW7uIdHrMcDFGeHVxJQ8BDl+pLJKfvfTGusFyI4jUnsnfIymK1SrIUA5eLzsMB4IKSlZxDD4EFKWpC2GOZgkfO+OuYyAI4yp4ciylyH9/1etmVFTjzTwqEeZ84Y6ak82vF1eXGC0/PLo/160w25kPfOfaKZScqnWjuaLIVNGZxF2zFMLg2ZIpBLEpMmVNP7TkeepTQ4OCglJukAnpTxpRg/pCq6d40UKHb0uPo5lcE/FymhkLjjQRp47AmSJB43b5oYbHNao0dwNtPsul/lodpqFKdHvasFTq0zrllARl1S+eSvHS2ZU6qrbRElX89GP7aF7MlxVmtOGlqimCRge/GZR/4cTTWfSUPdpoA8jON1S2jxeXNwz1bnV3HyNdr8tcMxLemItIK9vHmLy94qIzlHkY2XcOgDVqqr3c++U8yF2KTDqsXAmlwlHxmM4EjuTgnECHB83vEVDEm9lir8pPf4gwPgdyfh6D7KjXcJUOjmoqzrjYb9lYrmdoZD5I5yOhzTnNZmcrVgBEz6nJyyJ+DdMkMSdvtk8r6jYfs9aUrUUNX6w5joyVSulZC2cOyciwNgG9xdlf+LXrXOlRlKoMweIoB3QbptBkPlmKydQzSrFa39ti/pSND8af2HZNOilk4cRBbe+W+g+2ev3xijzNBkV7Xc0+n2fDg51OpcyRWmQ3/SYyJi3wdODC1AHIY1qgPW0jADOaTWSKbEdqrXCOgQ6WSKxxQHy90DykjX6OPzD2jKtc73U2//rlc5rkfIbKGCwEhFHSdBtDr7j6GEakJ49IiqrUY0TGIaP1oK+MScKC8DtgHWEKpoV1wJCf9tgwh985vA6cnvi28jZrWtVRsMyeZ/r2/QeN0dP+fMj3neVT5We6nlPucpFFaWGxm92zrYnRa51qVT26/IAYu+ISE5eNNaUY5DJNPIJ0EiLl9GrwJGk0ARIEhyb8/50KVTpOuaZkkIeYInjSmPDHhVdcRESdEE8UgDHBD8K+YWozkC32WwKi4AjzDWroTEOUC1m93N7efrq5BmfALRNimajyZaTqfkEoEtfkXerf/sXVmxcavO/myE2bapM3fAGuabPc6MQ0+3U6wGhrZgcxEfhqx+MKPdZNMbjbWE7f6rAMmEkDL13pKI9d1FJOE985D/+A8AGvQCIF2h9RUbtyDRk4vwGJhgj+MsLKMwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=320x240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some preds and targets\n",
    "index = 0\n",
    "\n",
    "visualized_image = shared_coco_val_dataset[index][0].copy()\n",
    "\n",
    "draw = ImageDraw.Draw(visualized_image)\n",
    "\n",
    "for box, label in zip(preds[index]['boxes'], preds[index]['labels']):\n",
    "    draw.rectangle(xy=((box[0], box[1]), (box[2], box[3])), outline='red')\n",
    "    draw.text(xy=(box[0], box[1]), text=category_names[label.item()])\n",
    "\n",
    "for box, label in zip(targets[index]['boxes'], targets[index]['labels']):\n",
    "    draw.rectangle(xy=((box[0], box[1]), (box[2], box[3])), outline='green')\n",
    "    draw.text(xy=(box[0], box[1]), text=category_names[label.item()])\n",
    "\n",
    "visualized_image.save('clipvitbase32_cocoshared_example.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = MeanAveragePrecision(\n",
    "    box_format='xyxy',\n",
    "    iou_type='bbox',\n",
    "    iou_thresholds=None, # Defaults to trying from 0.5 -> 0.95 in steps of 0.05 \n",
    "    rec_thresholds=None,\n",
    "    max_detection_thresholds=None, # Uses [1, 10, 100]\n",
    "    class_metrics=False,\n",
    "    extended_summary=False, # This way, we can see the ious and scores calculated\n",
    "    average='macro',\n",
    "    backend='pycocotools'\n",
    ")\n",
    "\n",
    "metric.update(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_metric = metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objectness Threshold: 0.2; Score Threshold: 0.1; Min Dim: 0\n",
      "mAP: 0.1742\n",
      "Num Objects: 13878\n"
     ]
    }
   ],
   "source": [
    "print(f\"Objectness Threshold: {objectness_threshold}; Score Threshold: {score_threshold}; Min Dim: {min_dim}\")\n",
    "print(f\"mAP: {round(computed_metric['map'].item(), 4):.4f}\\nNum Objects: {len(predictions_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectness Threshold: 0.2; Score Threshold: 0.1; Min Dim: 0\n",
    "mAP: 0.1742\n",
    "Num Objects: 13878"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
